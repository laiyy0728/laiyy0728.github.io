<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Laiyy 的个人小站</title>
  
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://www.laiyy.top/"/>
  <updated>2019-12-04T08:17:08.000Z</updated>
  <id>https://www.laiyy.top/</id>
  
  <author>
    <name>Laiyy</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>hadoop（11） Map Reduce &lt;BR /&gt; MapReduce 框架原理</title>
    <link href="https://www.laiyy.top/hadoop/map-reduce/hadoop-11.html"/>
    <id>https://www.laiyy.top/hadoop/map-reduce/hadoop-11.html</id>
    <published>2019-12-04T08:17:08.000Z</published>
    <updated>2019-12-04T08:17:08.000Z</updated>
    
    <content type="html"><![CDATA[<p>在了解了 Hadoop 的序列化操作，实现了基本的 Bean 序列化的一个 demo，接下来分析一下 MapReduce 的框架原理。</p><a id="more"></a><h1 id="InputFormat"><a href="#InputFormat" class="headerlink" title="InputFormat"></a>InputFormat</h1><h2 id="切片与MapTask-并行度决定机制"><a href="#切片与MapTask-并行度决定机制" class="headerlink" title="切片与MapTask 并行度决定机制"></a>切片与MapTask 并行度决定机制</h2><p>MapTask 的并行度决定 Map 阶段的任务处理并发度，进而影响整个 Job 的处理速度。</p><p>问题：</p><blockquote><p>一个 1G 的数据，启动 8 个MapTask，可以提高集群的并发处理能力。但是如果是一个 1K 的数据，也启动 8 个MapTask，会提高性能吗？<br>MapTask 是否越多越好？<br>什么因素会影响到 MapTask 的并行度？</p></blockquote><h3 id="MapTask并行度决定机制"><a href="#MapTask并行度决定机制" class="headerlink" title="MapTask并行度决定机制"></a>MapTask并行度决定机制</h3><p>前置概念：</p><blockquote><p>数据块：Block 在 HDFS 物理上把数据分成一块一块的。<br>数据切片：在逻辑上对输入进行分片，并不会在磁盘上将其分片存储。</p></blockquote><p>现在，假设有一个 300M 的数据，分别存放在 DataNode 1、2、3 上，DataNode1 上存储 0~128M 数据，DataNode2 上存储 128~256M 数据，DataNode3 上存储 256~300M 数据。<br>如果数据切片大小为 100M，则读取第一个切片没有问题，当读取第2、3个切片时，需要将DataNode1 上的剩余的数据拷贝到 MapTask2 上，将 DataNode2 上剩余的数据拷贝到 MapTask3 上，这样会存在大量的数据 IO，严重影响性能。</p><p><img src="/images/hadoop/map-reduce/100-split.png" alt="切片大小为 100M"></p><p>如果数据切片大小为 128M（即与 Block 大小一致），此时，每个 MapTask 都读取 128M 数据，则可以分别运行在三台 DataNode 上，没有数据拷贝，此时性能最高。</p><blockquote><p>MapTask 并行度决定机制</p></blockquote><ol><li>一个 Job 的 Map 阶段并行度由客户端在提交 Job 时的切片数决定</li><li>每个切片分配一个 MapTask 并行实例处理</li><li>默认情况下，切片大小等于 BlockSize</li><li>切片时不考虑数据集整体，而是逐个针对每个文件单独切片</li></ol><h3 id="Job-提交流程、切片源码"><a href="#Job-提交流程、切片源码" class="headerlink" title="Job 提交流程、切片源码"></a>Job 提交流程、切片源码</h3><p>在 Job 调用 <code>job.waitForCompletion</code> 时，进行任务提交。此方法会调用 <code>submit()</code> 方法进行真正的提交。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">waitForCompletion</span><span class="params">(<span class="keyword">boolean</span> verbose</span></span></span><br><span class="line"><span class="function"><span class="params">                                )</span> <span class="keyword">throws</span> IOException, InterruptedException,</span></span><br><span class="line"><span class="function">                                        ClassNotFoundException </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (state == JobState.DEFINE) &#123;</span><br><span class="line">        <span class="comment">// 调用真正的提交</span></span><br><span class="line">        submit();</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> (verbose) &#123;</span><br><span class="line">        <span class="comment">// 打印日志</span></span><br><span class="line">        monitorAndPrintJob();</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="comment">// 忽略</span></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> isSuccessful();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">submit</span><span class="params">()</span> </span></span><br><span class="line"><span class="function">        <span class="keyword">throws</span> IOException, InterruptedException, ClassNotFoundException </span>&#123;</span><br><span class="line">    <span class="comment">// 判断任务状态</span></span><br><span class="line">    ensureState(JobState.DEFINE);</span><br><span class="line">    <span class="comment">// 将老旧的 API 转换为新的 API，为兼容性考虑</span></span><br><span class="line">    setUseNewAPI();</span><br><span class="line">    <span class="comment">// 连接</span></span><br><span class="line">    connect();</span><br><span class="line">    <span class="keyword">final</span> JobSubmitter submitter = </span><br><span class="line">        getJobSubmitter(cluster.getFileSystem(), cluster.getClient());</span><br><span class="line">    status = ugi.doAs(<span class="keyword">new</span> PrivilegedExceptionAction&lt;JobStatus&gt;() &#123;</span><br><span class="line">        <span class="function"><span class="keyword">public</span> JobStatus <span class="title">run</span><span class="params">()</span> <span class="keyword">throws</span> IOException, InterruptedException, </span></span><br><span class="line"><span class="function">        ClassNotFoundException </span>&#123;</span><br><span class="line">            <span class="comment">// 提交任务的详细信息</span></span><br><span class="line">            <span class="keyword">return</span> submitter.submitJobInternal(Job.<span class="keyword">this</span>, cluster);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;);</span><br><span class="line">    state = JobState.RUNNING;</span><br><span class="line">    LOG.info(<span class="string">"The url to track the job: "</span> + getTrackingURL());</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><blockquote><p>connect 详细操作流程</p></blockquote><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">synchronized</span> <span class="keyword">void</span> <span class="title">connect</span><span class="params">()</span></span></span><br><span class="line"><span class="function">          <span class="keyword">throws</span> IOException, InterruptedException, ClassNotFoundException </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (cluster == <span class="keyword">null</span>) &#123;</span><br><span class="line">      cluster = </span><br><span class="line">        ugi.doAs(<span class="keyword">new</span> PrivilegedExceptionAction&lt;Cluster&gt;() &#123;</span><br><span class="line">                   <span class="function"><span class="keyword">public</span> Cluster <span class="title">run</span><span class="params">()</span></span></span><br><span class="line"><span class="function">                          <span class="keyword">throws</span> IOException, InterruptedException, </span></span><br><span class="line"><span class="function">                                 ClassNotFoundException </span>&#123;</span><br><span class="line">                     <span class="comment">// 创建一个新的 Cluster</span></span><br><span class="line">                     <span class="keyword">return</span> <span class="keyword">new</span> Cluster(getConfiguration());</span><br><span class="line">                   &#125;</span><br><span class="line">                 &#125;);</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="title">Cluster</span><span class="params">(Configuration conf)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">    <span class="keyword">this</span>(<span class="keyword">null</span>, conf);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="title">Cluster</span><span class="params">(InetSocketAddress jobTrackAddr, Configuration conf)</span> </span></span><br><span class="line"><span class="function">    <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">    <span class="keyword">this</span>.conf = conf;</span><br><span class="line">    <span class="keyword">this</span>.ugi = UserGroupInformation.getCurrentUser();</span><br><span class="line">    <span class="comment">// Cluster 初始化</span></span><br><span class="line">    initialize(jobTrackAddr, conf);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">initialize</span><span class="params">(InetSocketAddress jobTrackAddr, Configuration conf)</span></span></span><br><span class="line"><span class="function">      <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">synchronized</span> (frameworkLoader) &#123;</span><br><span class="line">        <span class="keyword">for</span> (ClientProtocolProvider provider : frameworkLoader) &#123;</span><br><span class="line">        ClientProtocol clientProtocol = <span class="keyword">null</span>; </span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="keyword">if</span> (jobTrackAddr == <span class="keyword">null</span>) &#123;</span><br><span class="line">                <span class="comment">// 创建一个 LocalJobRunner（在本地运行时）</span></span><br><span class="line">                clientProtocol = provider.create(conf);</span><br><span class="line">            &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                <span class="comment">// 创建一个 YARNRunner（在集群运行时）</span></span><br><span class="line">                clientProtocol = provider.create(jobTrackAddr, conf);</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="comment">// 省略</span></span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 省略</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><blockquote><p>connect 连接成功，提交任务详细信息</p></blockquote><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">JobStatus <span class="title">submitJobInternal</span><span class="params">(Job job, Cluster cluster)</span> </span></span><br><span class="line"><span class="function"><span class="keyword">throws</span> ClassNotFoundException, InterruptedException, IOException </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 校验输出路径</span></span><br><span class="line">    checkSpecs(job);</span><br><span class="line"></span><br><span class="line">    Configuration conf = job.getConfiguration();</span><br><span class="line">    <span class="comment">// 缓存处理</span></span><br><span class="line">    addMRFrameworkToDistributedCache(conf);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 任务临时目录， tmp/hadoop-Administrator\mapred\staging，每次运行任务都会在这个目录下创建一个文件夹，将所需数据都保存在内</span></span><br><span class="line">    <span class="comment">// 当任务执行结束后，会删除文件夹内的所有数据</span></span><br><span class="line">    Path jobStagingArea = JobSubmissionFiles.getStagingDir(cluster, conf);</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 获取网络 ip</span></span><br><span class="line">    InetAddress ip = InetAddress.getLocalHost();</span><br><span class="line">    <span class="comment">// 省略</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">// 生成一个唯一的 jobId</span></span><br><span class="line">    JobID jobId = submitClient.getNewJobID();</span><br><span class="line">    job.setJobID(jobId);</span><br><span class="line">    Path submitJobDir = <span class="keyword">new</span> Path(jobStagingArea, jobId.toString());</span><br><span class="line">    JobStatus status = <span class="keyword">null</span>;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        <span class="comment">// 省略</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">// 提交文件的信息到之前创建的文件夹下（本机下不会提交）</span></span><br><span class="line">        copyAndConfigureFiles(job, submitJobDir);</span><br><span class="line"></span><br><span class="line">        Path submitJobFile = JobSubmissionFiles.getJobConfPath(submitJobDir);</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 写入切片信息到文件夹</span></span><br><span class="line">        <span class="keyword">int</span> maps = writeSplits(job, submitJobDir);</span><br><span class="line">        conf.setInt(MRJobConfig.NUM_MAPS, maps);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 省略</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">// 写入任务信息到文件夹</span></span><br><span class="line">        writeConf(conf, submitJobFile);</span><br><span class="line">        </span><br><span class="line">        printTokens(jobId, job.getCredentials());</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 提交完成后，删除文件夹内信息</span></span><br><span class="line">        status = submitClient.submitJob(</span><br><span class="line">            jobId, submitJobDir.toString(), job.getCredentials());</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 省略</span></span><br><span class="line">    &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">        <span class="comment">// 省略</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><img src="/images/hadoop/map-reduce/job-staging.png" alt="Hadoop 任务临时路径"><br><img src="/images/hadoop/map-reduce/split-file.png" alt="hadoop 临时切片文件"><br><img src="/images/hadoop/map-reduce/job-submit.png" alt="hadoop Job 提交流程"></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;在了解了 Hadoop 的序列化操作，实现了基本的 Bean 序列化的一个 demo，接下来分析一下 MapReduce 的框架原理。&lt;/p&gt;
    
    </summary>
    
      <category term="hadoop" scheme="https://www.laiyy.top/categories/hadoop/"/>
    
      <category term="map-reduce" scheme="https://www.laiyy.top/categories/hadoop/map-reduce/"/>
    
    
      <category term="hadoop" scheme="https://www.laiyy.top/tags/hadoop/"/>
    
      <category term="map-reduce" scheme="https://www.laiyy.top/tags/map-reduce/"/>
    
  </entry>
  
  <entry>
    <title>hadoop（10） Map Reduce &lt;BR /&gt;  序列化</title>
    <link href="https://www.laiyy.top/hadoop/map-reduce/hadoop-10.html"/>
    <id>https://www.laiyy.top/hadoop/map-reduce/hadoop-10.html</id>
    <published>2019-12-04T06:17:08.000Z</published>
    <updated>2019-12-04T06:17:08.000Z</updated>
    
    <content type="html"><![CDATA[<p>在 MapReduce 的 <a href="/hadoop/map-reduce/hadoop-9.html#Hadoop-数据序列化类型">数据序列化类型</a> 中，介绍了几种常见的 Hadoop 序列化类，实现了一个基础的 <code>WordCount</code> Demo，使用到了 Long、String、Integer 对应的序列化类，那么接下来就需要了解一下 Hadoop 具体的怎么序列化的。</p><a id="more"></a><h1 id="Hadoop-序列化"><a href="#Hadoop-序列化" class="headerlink" title="Hadoop 序列化"></a>Hadoop 序列化</h1><h2 id="序列化概述"><a href="#序列化概述" class="headerlink" title="序列化概述"></a>序列化概述</h2><blockquote><p>什么是序列化、反序列化</p></blockquote><p>序列化：就是把内存中的对象，转换为<code>字节序列</code> 或其他数据传输协议，以便存储到磁盘或网络传输。<br>反序列化：就是将<code>收到的字节序列</code>或<code>其他数据传输协议</code>或<code>磁盘的持久化数据</code>，转换成内存中的对象。</p><blockquote><p>为什么要序列化？</p></blockquote><p>一般来说，<code>对象</code> 只能生存在内存中，断电即消失。而且，<code>对象</code> 只能由本地进程使用，不能被发送到网络上的另外一台计算机中。<br>然而，<code>序列化</code> 可以存储 <code>对象</code>，且可以将对象 <code>发送到远程计算机</code>。</p><blockquote><p>为什么不用 Java 自身的序列化？</p></blockquote><p>Java 的序列化是一个重量级的框架(Serializable)，一个对象被序列化后，别额外附带很多信息，如：校验信息、Header、继承体系等，不便于在网络中高效传输。基于此，Hadoop 开发了一套属于自己的序列化机制：Writable。</p><blockquote><p>Hadoop 序列化的特点</p></blockquote><ol><li>紧凑：高效使用存储空间</li><li>快速：读写数据的额外开销小</li><li>可扩展：随着通信协议的升级而升级</li><li>互操作：支持多语言交互</li></ol><h2 id="自定义实现序列化"><a href="#自定义实现序列化" class="headerlink" title="自定义实现序列化"></a>自定义实现序列化</h2><p>实现步骤：</p><ol><li>实现 Writable 接口</li><li>反序列化时，需要反射调用空参构造函数</li><li>重写序列化方法</li><li>重写反序列化 方法</li><li>反序列化的顺序和序列化的顺序保持一致</li><li>重写 toString</li><li>实现 Comparable 接口（MapReduce 的 Shuffle 过程要求对 key 必须能排序；当需要排序的时候才做）</li></ol><hr><h1 id="序列化-Demo"><a href="#序列化-Demo" class="headerlink" title="序列化 Demo"></a>序列化 Demo</h1><p>需求：根据 <a href="/file/hadoop/map-reduce/phone.txt">测试文件</a>，统计每个手机号的<code>上行流量</code>、<code>下行流量</code>、<code>总流量</code>。<br>文件中，倒数第三列为上行流量，倒数第二列为下行流量，最后一列为网络请求状态码。</p><h2 id="创建统计流量的-Bean-对象"><a href="#创建统计流量的-Bean-对象" class="headerlink" title="创建统计流量的 Bean 对象"></a>创建统计流量的 Bean 对象</h2><p>创建一个统计流量的 Bean 对象，并实现序列化操作</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">FlowBean</span> <span class="keyword">implements</span> <span class="title">Writable</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 上行流量</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">long</span> upFlow;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 下行流量</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">long</span> downFlow;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 总流量</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">long</span> sumFlow;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 空参构造，反射用</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">FlowBean</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">set</span><span class="params">(<span class="keyword">long</span> upFlow, <span class="keyword">long</span> downFlow)</span></span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.upFlow = upFlow;</span><br><span class="line">        <span class="keyword">this</span>.downFlow = downFlow;</span><br><span class="line">        <span class="keyword">this</span>.sumFlow = upFlow + downFlow;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">toString</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> upFlow + <span class="string">"\t"</span> + downFlow + <span class="string">"\t"</span> + sumFlow;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 省略 get、set</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 序列化</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> dataOutput 输入输出</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@throws</span> IOException 可能异常</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">write</span><span class="params">(DataOutput dataOutput)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">        dataOutput.writeLong(upFlow);</span><br><span class="line">        dataOutput.writeLong(downFlow);</span><br><span class="line">        dataOutput.writeLong(sumFlow);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 反序列化</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> dataInput 输入数据</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@throws</span> IOException 可能异常</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">readFields</span><span class="params">(DataInput dataInput)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">        <span class="comment">// 必须和序列化方法顺序一致</span></span><br><span class="line">        upFlow = dataInput.readLong();</span><br><span class="line">        downFlow = dataInput.readLong();</span><br><span class="line">        sumFlow = dataInput.readLong();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="MapReduce-程序"><a href="#MapReduce-程序" class="headerlink" title="MapReduce 程序"></a>MapReduce 程序</h2><h3 id="Mapper"><a href="#Mapper" class="headerlink" title="Mapper"></a>Mapper</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">FlowCountMapper</span> <span class="keyword">extends</span> <span class="title">Mapper</span>&lt;<span class="title">LongWritable</span>, <span class="title">Text</span>, <span class="title">Text</span>, <span class="title">FlowBean</span>&gt; </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> FlowBean flowBean = <span class="keyword">new</span> FlowBean();</span><br><span class="line">    <span class="keyword">private</span> Text outKey = <span class="keyword">new</span> Text();</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">map</span><span class="params">(LongWritable key, Text value, Context context)</span> <span class="keyword">throws</span> IOException, InterruptedException </span>&#123;</span><br><span class="line">        <span class="comment">// 1   17319758889 192.168.100.1   www.baidu.com 2481    24685   200</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">// 1. 获取一行</span></span><br><span class="line">        String line = value.toString();</span><br><span class="line">        <span class="comment">// 2. 切割</span></span><br><span class="line">        String[] fields = line.split(<span class="string">"\t"</span>);</span><br><span class="line">        <span class="comment">// 3. 封装对象</span></span><br><span class="line">        outKey.set(fields[<span class="number">1</span>]);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">int</span> length = fields.length;</span><br><span class="line">        <span class="keyword">long</span> upFlow = Long.parseLong(fields[length - <span class="number">3</span>]);</span><br><span class="line">        <span class="keyword">long</span> downFlow = Long.parseLong(fields[length - <span class="number">2</span>]);</span><br><span class="line"></span><br><span class="line">        flowBean.setUpFlow(upFlow);</span><br><span class="line">        flowBean.setDownFlow(downFlow);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 4. 写出</span></span><br><span class="line">        context.write(outKey, flowBean);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="Reducer"><a href="#Reducer" class="headerlink" title="Reducer"></a>Reducer</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">FlowCountReducer</span> <span class="keyword">extends</span> <span class="title">Reducer</span>&lt;<span class="title">Text</span>, <span class="title">FlowBean</span>, <span class="title">Text</span>, <span class="title">FlowBean</span>&gt; </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> FlowBean flowBean = <span class="keyword">new</span> FlowBean();</span><br><span class="line">    </span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">reduce</span><span class="params">(Text key, Iterable&lt;FlowBean&gt; values, Context context)</span> <span class="keyword">throws</span> IOException, InterruptedException </span>&#123;</span><br><span class="line">        <span class="comment">// 两个相同的手机号的访问记录</span></span><br><span class="line">        <span class="comment">// 11   17319788888 192.168.100.11   www.java1234.com 231    28   200</span></span><br><span class="line">        <span class="comment">// 12   17319788888 192.168.100.12    211    7852   200</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">long</span> sumUpFlow = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">long</span> sumDownFlow = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> (FlowBean value : values) &#123;</span><br><span class="line">            sumUpFlow += value.getUpFlow();</span><br><span class="line">            sumDownFlow += value.getDownFlow();</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        flowBean.set(sumUpFlow, sumDownFlow);</span><br><span class="line">        context.write(key, flowBean);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="Deiver"><a href="#Deiver" class="headerlink" title="Deiver"></a>Deiver</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> IOException, ClassNotFoundException, InterruptedException </span>&#123;</span><br><span class="line">    <span class="comment">// 获取 job 对象</span></span><br><span class="line">    Configuration configuration = <span class="keyword">new</span> Configuration();</span><br><span class="line">    Job job = Job.getInstance(configuration);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 设置 jar 存放路径</span></span><br><span class="line">    job.setJarByClass(FlowCountDriver.class);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 关联 Mapper、Reducer 业务类</span></span><br><span class="line">    job.setMapperClass(FlowCountMapper.class);</span><br><span class="line">    job.setReducerClass(FlowCountReducer.class);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 指定 Mapper 输出的 KV 类型</span></span><br><span class="line">    job.setMapOutputKeyClass(Text.class);</span><br><span class="line">    job.setMapOutputValueClass(FlowBean.class);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 指定最终输出的数据 KV 类型</span></span><br><span class="line">    job.setOutputKeyClass(Text.class);</span><br><span class="line">    job.setOutputValueClass(FlowBean.class);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 指定 job 的输入文件所在目录</span></span><br><span class="line">    FileInputFormat.setInputPaths(job, <span class="keyword">new</span> Path(args[<span class="number">0</span>]));</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 指定 job 的输出结果所在目录</span></span><br><span class="line">    FileOutputFormat.setOutputPath(job, <span class="keyword">new</span> Path(args[<span class="number">1</span>]));</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 提交 job</span></span><br><span class="line"><span class="comment">//        job.submit();</span></span><br><span class="line">    <span class="keyword">boolean</span> succeed = job.waitForCompletion(<span class="keyword">true</span>);</span><br><span class="line"></span><br><span class="line">    System.exit(succeed ? <span class="number">0</span> : <span class="number">1</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="运行测试"><a href="#运行测试" class="headerlink" title="运行测试"></a>运行测试</h2><p>设置输入输出路径：<br><img src="/images/hadoop/map-reduce/flow-count-args.png" alt="输入输出路径"></p><p>查看输出结果：<br><img src="/images/hadoop/map-reduce/flow-count-result.png" alt="flow count result"></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;在 MapReduce 的 &lt;a href=&quot;/hadoop/map-reduce/hadoop-9.html#Hadoop-数据序列化类型&quot;&gt;数据序列化类型&lt;/a&gt; 中，介绍了几种常见的 Hadoop 序列化类，实现了一个基础的 &lt;code&gt;WordCount&lt;/code&gt; Demo，使用到了 Long、String、Integer 对应的序列化类，那么接下来就需要了解一下 Hadoop 具体的怎么序列化的。&lt;/p&gt;
    
    </summary>
    
      <category term="hadoop" scheme="https://www.laiyy.top/categories/hadoop/"/>
    
      <category term="map-reduce" scheme="https://www.laiyy.top/categories/hadoop/map-reduce/"/>
    
    
      <category term="hadoop" scheme="https://www.laiyy.top/tags/hadoop/"/>
    
      <category term="map-reduce" scheme="https://www.laiyy.top/tags/map-reduce/"/>
    
  </entry>
  
  <entry>
    <title>hadoop（9） Map Reduce &lt;BR /&gt;  基础概念，WordCount Demo 实现</title>
    <link href="https://www.laiyy.top/hadoop/map-reduce/hadoop-9.html"/>
    <id>https://www.laiyy.top/hadoop/map-reduce/hadoop-9.html</id>
    <published>2019-12-02T07:37:26.000Z</published>
    <updated>2019-12-02T07:37:26.000Z</updated>
    
    <content type="html"><![CDATA[<p>HDFS、MapReduce、Yarn 是 Hadoop 的三大模块，其中，HDFS 负责存储，MapReduce 负责计算，Yarn 负责资源调度</p><a id="more"></a><h1 id="MapReduce"><a href="#MapReduce" class="headerlink" title="MapReduce"></a>MapReduce</h1><p>MapReduce 是一个 <code>分布式运算程序的编程框架</code>，是用户开发 <code>基于Hadoop的数据分析应用</code>的核心框架。</p><p>MapReduce 的核心功能，是将 用户编写的业务逻辑代码，和自带的默认组件，整合成一个完整的分布式运算程序，并发的运行在一个 Hadoop 集群上。</p><h2 id="优缺点"><a href="#优缺点" class="headerlink" title="优缺点"></a>优缺点</h2><h3 id="优点"><a href="#优点" class="headerlink" title="优点"></a>优点</h3><blockquote><p>易于编程</p></blockquote><p>简单地实现一些接口，就可以完成一个分布式程序。这个分布式程序可以分布到大量的廉价 pc 机器上运行。也就是说，写一个分布式程序和写一个串行程序一模一样。 就是因为这个特点，使得MapReduce编程变得非常流行。</p><blockquote><p>良好的扩展性</p></blockquote><p>当计算资源不能得到满足时，可以通过简单的扩展机器来扩展计算能力。</p><blockquote><p>高容错性</p></blockquote><p>MapReduce 设计初衷，就是使程序能够部署在廉价的 pc 机器上，这就要求它具有很高的容错性。<br>如：一台机器挂掉了，它可以把上面的计算任务转移到另外一个节点上，不至于这个任务运行失败，而且这个过程不需要人工参与，完全由 Hadoop 内部完成。</p><blockquote><p>适合 PB 级以上海量数据离线处理</p></blockquote><p>可以实现上千台服务器集群并发工作，提供数据处理能力。</p><h3 id="缺点"><a href="#缺点" class="headerlink" title="缺点"></a>缺点</h3><blockquote><p>不擅长实时计算</p></blockquote><p>无法像 MySQL 一样，在毫秒级或秒级内返回结果</p><blockquote><p>不擅长流式计算</p></blockquote><p>流式计算的输入数据是动态的，而 MapReduce 的输入数据集的静态的，不能动态变化。这是由 MapReduce 自身的设计特点决定的。</p><blockquote><p>不擅长 DAG(有向图) 计算</p></blockquote><p>有向图：多个应用程序存在依赖关系，后一个程序的输入是前一个程序的输出。<br>MapReduce 可以做 DAG 计算，但是不推荐。原因的每个 MapReduce 的输出结果都会写入磁盘，会造成大量的磁盘 IO，导致性能低下。</p><h2 id="核心思想"><a href="#核心思想" class="headerlink" title="核心思想"></a>核心思想</h2><p>MapReduce 运算程序一般分为两个阶段：Map 阶段(分),Reduce 阶段(合)。<br>Map 阶段的兵法 MapTask，完全并发运行，互不相干。<br>Reduce 阶段的并发 ReduceTask，完全并发运行，互补相干。但是它们的数据依赖于上一阶段的所有 MapTask 并发实例的输出。<br>MapReduce 编程模型只能包含一个 Map 阶段和一个 Reduce 阶段，如果业务逻辑复杂，只能多个 MapReduce 程序串行运行。</p><p>例如：<br><img src="/images/hadoop/map-reduce/map-reduce.png" alt="MapReduce思想"></p><h2 id="MapReduce-进程"><a href="#MapReduce-进程" class="headerlink" title="MapReduce 进程"></a>MapReduce 进程</h2><p>一个完整的 MapReduce 程序在分布式运行时有三类实例进程：</p><blockquote><p>MrAppMaster：负责整个程序的过程调度以及正太协调<br>MapTask：负责 Map 阶段的整个数据处理流程<br>ReduceTask：负责 Reduce 阶段的整个数据处理流程</p></blockquote><h2 id="Hadoop-数据序列化类型"><a href="#Hadoop-数据序列化类型" class="headerlink" title="Hadoop 数据序列化类型"></a>Hadoop 数据序列化类型</h2><table><thead><tr><th style="text-align:center">Java 类型</th><th style="text-align:center">Hadoop Writable 类型</th></tr></thead><tbody><tr><td style="text-align:center">boolean</td><td style="text-align:center">BooleanWritable</td></tr><tr><td style="text-align:center">byte</td><td style="text-align:center">ByteWritable</td></tr><tr><td style="text-align:center">int</td><td style="text-align:center">IntWritable</td></tr><tr><td style="text-align:center">float</td><td style="text-align:center">FloatWritable</td></tr><tr><td style="text-align:center">long</td><td style="text-align:center">LongWritable</td></tr><tr><td style="text-align:center">double</td><td style="text-align:center">DoubleWritable</td></tr><tr><td style="text-align:center">String</td><td style="text-align:center">Text</td></tr><tr><td style="text-align:center">Map</td><td style="text-align:center">MapWritable</td></tr><tr><td style="text-align:center">array</td><td style="text-align:center">ArrayWritable</td></tr></tbody></table><h2 id="MapReduce-编程规范"><a href="#MapReduce-编程规范" class="headerlink" title="MapReduce 编程规范"></a>MapReduce 编程规范</h2><p>MapReduce 编程分为三个部分： Mapper、Reducer、Driver</p><h3 id="Mapper-阶段"><a href="#Mapper-阶段" class="headerlink" title="Mapper 阶段"></a>Mapper 阶段</h3><ol><li>用户自定义的 Mapper 要继承自己的父类</li><li>Mapper 的数据数据是 KV 对形式，KV 类型自定义</li><li>Mapper 的业务逻辑写在 map() 方法中</li><li>Mapper 的输出数据是 KV 对形式，KV 类型自定义</li><li>map() 方法对每个 KV 只调用一次</li></ol><h2 id="Reducer-阶段"><a href="#Reducer-阶段" class="headerlink" title="Reducer 阶段"></a>Reducer 阶段</h2><ol><li>用户自定义的 Reducer 要继承自己的父类</li><li>Reducer 的输入类型对应 Mapper 的输出数据类型，也是 KV</li><li>Reducer 的业务逻辑写在对应的 reduce() 方法中</li><li>reduce() 方法对每个 KV 只调用一次</li></ol><h2 id="Driver-阶段"><a href="#Driver-阶段" class="headerlink" title="Driver 阶段"></a>Driver 阶段</h2><p>相当于 YARN 集群的客户端，用于提交整个程序到 YARN 集群，提交的是封装了 MapReduce 程序相关运行参数的 Job 对象</p><hr><h1 id="WordCount-Demo"><a href="#WordCount-Demo" class="headerlink" title="WordCount(Demo)"></a>WordCount(Demo)</h1><p>需求：给定一个文本文件 <a href="/file/hadoop/map-reduce/README.txt">README.txt</a>，统计文本中每个单词出现的总次数</p><p>流程分析：</p><blockquote><p>Mapper 阶段</p></blockquote><ol><li>将 MapTask 传给我们的文本内容转换为 String</li><li>根据空格将单词分为单词</li><li>将单词输出为 &lt;单词, 1&gt; (如果有相同的单词，输出的也是 &lt;单词, 1&gt;， 因为 map 阶段只做拆分，不做合并)</li></ol><blockquote><p>Reducer 阶段</p></blockquote><ol><li>汇总各个 key 的个数</li><li>输出该 key 的总次数</li></ol><blockquote><p>Driver</p></blockquote><ol><li>获取配置信息，获取 job 对象实例</li><li>指定本程序的 jar 包所在的本地路径</li><li>关联 Mapper、Reducer 业务类</li><li>指定 Mapper 输出的 KV 类型</li><li>指定最终输出的数据 KV 类型</li><li>指定 job 的原始文件所在目录</li><li>指定 job 的输出结果所在目录</li><li>提交 job</li></ol><h2 id="Mapper-实现"><a href="#Mapper-实现" class="headerlink" title="Mapper 实现"></a>Mapper 实现</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@author</span> laiyy</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@date</span> 2019/12/3 16:36</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * LongWritable：输入数据的 key（此处为偏移量） 类型</span></span><br><span class="line"><span class="comment"> * Text：输入数据的 value（每一行数据） 类型</span></span><br><span class="line"><span class="comment"> * Text：输出数据的 key 类型</span></span><br><span class="line"><span class="comment"> * IntWritable：输出数据的 value 类型</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">WordCountMapper</span> <span class="keyword">extends</span> <span class="title">Mapper</span>&lt;<span class="title">LongWritable</span>, <span class="title">Text</span>, <span class="title">Text</span>, <span class="title">IntWritable</span>&gt; </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> Text outKey = <span class="keyword">new</span> Text();</span><br><span class="line">    <span class="keyword">private</span> IntWritable writable = <span class="keyword">new</span> IntWritable(<span class="number">1</span>);</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">map</span><span class="params">(LongWritable key, Text value, Context context)</span> <span class="keyword">throws</span> IOException, InterruptedException </span>&#123;</span><br><span class="line">        <span class="comment">// 1. 将当前读入的行数据转换为 String 类型</span></span><br><span class="line">        String line = value.toString();</span><br><span class="line">        <span class="comment">// 2. 切割单词</span></span><br><span class="line">        String[] words = line.split(<span class="string">" "</span>);</span><br><span class="line">        <span class="comment">// 3. 循环写出</span></span><br><span class="line">        <span class="keyword">for</span> (String word : words) &#123;</span><br><span class="line">            outKey.set(word);;</span><br><span class="line">            writable.set(<span class="number">1</span>);</span><br><span class="line">            context.write(outKey, writable);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="Reducer-实现"><a href="#Reducer-实现" class="headerlink" title="Reducer 实现"></a>Reducer 实现</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@author</span> laiyy</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@date</span> 2019/12/3 16:49</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * Text：Map 阶段输出的 key 类型</span></span><br><span class="line"><span class="comment"> * IntWritable：Map 阶段输出的 value 的类型</span></span><br><span class="line"><span class="comment"> * Text：最终结果的 key 的类型</span></span><br><span class="line"><span class="comment"> * IntWritable：最终结果的 value 类型</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">WordCountReducer</span> <span class="keyword">extends</span> <span class="title">Reducer</span>&lt;<span class="title">Text</span>, <span class="title">IntWritable</span>, <span class="title">Text</span>, <span class="title">IntWritable</span>&gt; </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> IntWritable outValue = <span class="keyword">new</span> IntWritable();</span><br><span class="line">    </span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">reduce</span><span class="params">(Text key, Iterable&lt;IntWritable&gt; values, Context context)</span> <span class="keyword">throws</span> IOException, InterruptedException </span>&#123;</span><br><span class="line">        <span class="comment">/*</span></span><br><span class="line"><span class="comment">            在 Map 阶段输出的数据格式为： &#123;key1,1&#125;, &#123;key2,1&#125; ,如： &#123;china,1&#125;, &#123;japan,1&#125;, &#123;china, 1&#125;</span></span><br><span class="line"><span class="comment">            在 Reducer 阶段作为输入时， 相同的将合并，即</span></span><br><span class="line"><span class="comment">            key：china，</span></span><br><span class="line"><span class="comment">            values：[1,1]</span></span><br><span class="line"><span class="comment">         */</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">int</span> sum = <span class="number">0</span>;</span><br><span class="line">        <span class="comment">// 1. 累加求和</span></span><br><span class="line">        <span class="keyword">for</span> (IntWritable value : values) &#123;</span><br><span class="line">            sum += value.get();</span><br><span class="line">        &#125;</span><br><span class="line">        outValue.set(sum);</span><br><span class="line">        context.write(key, outValue);</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="Driver-实现"><a href="#Driver-实现" class="headerlink" title="Driver 实现"></a>Driver 实现</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">WordCountDriver</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> IOException, ClassNotFoundException, InterruptedException </span>&#123;</span><br><span class="line">        <span class="comment">// 获取 job 对象</span></span><br><span class="line">        Configuration configuration = <span class="keyword">new</span> Configuration();</span><br><span class="line">        Job job = Job.getInstance(configuration);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 设置 jar 存放路径</span></span><br><span class="line">        job.setJarByClass(WordCountDriver.class);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 关联 Mapper、Reducer 业务类</span></span><br><span class="line">        job.setMapperClass(WordCountMapper.class);</span><br><span class="line">        job.setReducerClass(WordCountReducer.class);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 指定 Mapper 输出的 KV 类型</span></span><br><span class="line">        job.setMapOutputKeyClass(Text.class);</span><br><span class="line">        job.setMapOutputValueClass(IntWritable.class);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 指定最终输出的数据 KV 类型</span></span><br><span class="line">        job.setOutputKeyClass(Text.class);</span><br><span class="line">        job.setOutputValueClass(IntWritable.class);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 指定 job 的输入文件所在目录</span></span><br><span class="line">        FileInputFormat.setInputPaths(job, <span class="keyword">new</span> Path(<span class="string">"d:/dev/README.txt"</span>));</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 指定 job 的输出结果所在目录</span></span><br><span class="line">        FileOutputFormat.setOutputPath(job, <span class="keyword">new</span> Path(<span class="string">"d:/dev/mr-demo1"</span>));</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 提交 job，为 true 时打印执行信息</span></span><br><span class="line"><span class="comment">//        job.submit();</span></span><br><span class="line">        <span class="keyword">boolean</span> succeed = job.waitForCompletion(<span class="keyword">true</span>);</span><br><span class="line"></span><br><span class="line">        System.exit(succeed ? <span class="number">0</span> : <span class="number">1</span>);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="执行测试"><a href="#执行测试" class="headerlink" title="执行测试"></a>执行测试</h2><p>运行时可以看到打印信息如下：<br><img src="/images/hadoop/map-reduce/word-count-demo.png" alt="word-count-succeed"><br><img src="/images/hadoop/map-reduce/word-count-demo-succeed.png" alt="word-count-succeed"></p><p>打开执行后的 <code>part-r-00000</code> 文件如下：<br><img src="/images/hadoop/map-reduce/word-count-result.png" alt="word-count-result"></p><h2 id="在集群中运行"><a href="#在集群中运行" class="headerlink" title="在集群中运行"></a>在集群中运行</h2><p>将 Driver 的输入、输出路径改为参数获取方式：<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 指定 job 的输入文件所在目录</span></span><br><span class="line">FileInputFormat.setInputPaths(job, <span class="keyword">new</span> Path(args[<span class="number">0</span>]));</span><br><span class="line"></span><br><span class="line"><span class="comment">// 指定 job 的输出结果所在目录</span></span><br><span class="line">FileOutputFormat.setOutputPath(job, <span class="keyword">new</span> Path(args[<span class="number">1</span>]));</span><br></pre></td></tr></table></figure></p><p>在 pom.xml 文件中增加如下配置：<br><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">build</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">plugins</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">plugin</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>maven-compiler-plugin<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.3.2<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">source</span>&gt;</span>1.8<span class="tag">&lt;/<span class="name">source</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">target</span>&gt;</span>1.8<span class="tag">&lt;/<span class="name">target</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">plugin</span>&gt;</span></span><br><span class="line"></span><br><span class="line">        <span class="tag">&lt;<span class="name">plugin</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>maven-assembly-plugin<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">descriptorRefs</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">descriptorRef</span>&gt;</span>jar-with-dependencies<span class="tag">&lt;/<span class="name">descriptorRef</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;/<span class="name">descriptorRefs</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">archive</span>&gt;</span></span><br><span class="line">                    <span class="comment">&lt;!-- 打包主类 --&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">mainClass</span>&gt;</span>com.laiyy.study.mapreduce.wordcount.WordCountDriver<span class="tag">&lt;/<span class="name">mainClass</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;/<span class="name">archive</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">executions</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">execution</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">id</span>&gt;</span>make-assembly<span class="tag">&lt;/<span class="name">id</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">phase</span>&gt;</span>package<span class="tag">&lt;/<span class="name">phase</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">goals</span>&gt;</span></span><br><span class="line">                        <span class="tag">&lt;<span class="name">goal</span>&gt;</span>single<span class="tag">&lt;/<span class="name">goal</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;/<span class="name">goals</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;/<span class="name">execution</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;/<span class="name">executions</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">plugin</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">plugins</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">build</span>&gt;</span></span><br></pre></td></tr></table></figure></p><p>然后使用 <code>mvn package</code> 打包后，会生成两个文件：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hadoop-1.0-SNAPSHOT.jar</span><br><span class="line">hadoop-1.0-SNAPSHOT-jar-with-dependencies.jar</span><br></pre></td></tr></table></figure><p>第一个 jar 是没有 hadoop 依赖的，第二个 jar 是有 hadoop 依赖的。</p><p>由于在 hadoop 集群上运行，所以可以使用第一个 jar。如果服务器上没有 hadoop 依赖，则使用第二个 jar 即可。</p><p>将第一个 jar 上传至 hadoop，由于使用的是 hadoop 集群，所以输入、输出路径均为 HDFS 路径。</p><p>运行测试：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop02 hadoop-2.7.2]# hadoop jar hadoop-1.0-SNAPSHOT.jar com.laiyy.study.mapreduce.wordcount.WordCountDriver /laiyy /laiyy/output</span><br><span class="line">19/12/04 14:11:07 INFO client.RMProxy: Connecting to ResourceManager at hadoop03/192.168.233.132:8032</span><br><span class="line">19/12/04 14:11:09 WARN mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.</span><br><span class="line">19/12/04 14:11:10 INFO input.FileInputFormat: Total input paths to process : 3</span><br><span class="line">19/12/04 14:11:10 INFO mapreduce.JobSubmitter: number of splits:3</span><br><span class="line">19/12/04 14:11:10 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1575438331337_0001</span><br><span class="line">19/12/04 14:11:11 INFO impl.YarnClientImpl: Submitted application application_1575438331337_0001</span><br><span class="line">19/12/04 14:11:11 INFO mapreduce.Job: The url to track the job: http://hadoop03:8088/proxy/application_1575438331337_0001/</span><br><span class="line">19/12/04 14:11:11 INFO mapreduce.Job: Running job: job_1575438331337_0001</span><br><span class="line">19/12/04 14:11:24 INFO mapreduce.Job: Job job_1575438331337_0001 running in uber mode : false</span><br><span class="line">19/12/04 14:11:24 INFO mapreduce.Job:  map 0% reduce 0%</span><br><span class="line">...</span><br></pre></td></tr></table></figure></p><p>执行结束后，查看 HDFS 中 /laiyy/output 文件夹内容，并下载 <code>part-r-0000</code> 文件，查看文件输出.</p><p><img src="/images/hadoop/map-reduce/wordcount-in-cluster.png" alt="WordCount在集群运行结果"><br><img src="/images/hadoop/map-reduce/word-count-cluster-result.png" alt="WordCount在集群运行结果"></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;HDFS、MapReduce、Yarn 是 Hadoop 的三大模块，其中，HDFS 负责存储，MapReduce 负责计算，Yarn 负责资源调度&lt;/p&gt;
    
    </summary>
    
      <category term="hadoop" scheme="https://www.laiyy.top/categories/hadoop/"/>
    
      <category term="map-reduce" scheme="https://www.laiyy.top/categories/hadoop/map-reduce/"/>
    
    
      <category term="hadoop" scheme="https://www.laiyy.top/tags/hadoop/"/>
    
      <category term="map-reduce" scheme="https://www.laiyy.top/tags/map-reduce/"/>
    
  </entry>
  
  <entry>
    <title>Hadoop（8） &lt;br/&gt; DataNode、小文件存档</title>
    <link href="https://www.laiyy.top/hadoop/hdfs/hadoop-8.html"/>
    <id>https://www.laiyy.top/hadoop/hdfs/hadoop-8.html</id>
    <published>2019-12-02T01:56:18.000Z</published>
    <updated>2019-12-02T01:56:18.000Z</updated>
    
    <content type="html"><![CDATA[<p>在了解了 NameNode、SecondaryNameNode 的工作机制、FsImage 与 Edits 数据备份、NameNode 安全机制与多目录后，对 NameNode 有了一些基础了解。在此基础之上，接下来了解一下 DataNode 的工作机制。</p><a id="more"></a><h1 id="DataNode-工作机制"><a href="#DataNode-工作机制" class="headerlink" title="DataNode 工作机制"></a>DataNode 工作机制</h1><p>DataNode 中存储的每个数据块，以文件形式存储在磁盘上。包括 2 个文件：数据本身、元数据(包括数据块的长度、校验和、时间戳)</p><ol><li>DataNode 启动后，向 NameNode 注册</li><li>NameNode 注册成功后，会同步在 NameNode 元数据中</li><li>DataNode 每个一个<code>固定的周期</code>向 NameNode 再注册（默认1小时）</li><li>DataNode 与 NameNode 以 <code>3 秒一次</code> 的心跳机制判断是否断开。心跳返回结果带有 NameNode 给 DataNode 的命令</li><li>NameNode 超过 <code>10 分钟</code>没有收到心跳，则认为该节点不可用</li></ol><p><img src="/images/hadoop/client/datanode-work.png" alt="DataNode 工作机制"></p><hr><h1 id="DataNode-数据完整性"><a href="#DataNode-数据完整性" class="headerlink" title="DataNode 数据完整性"></a>DataNode 数据完整性</h1><ol><li>当 DataNode 读取 Block 时，它会计算 CheckSum(校验和)</li><li>如果计算后的 CheckSum 与 Block 创建时的值不一样，说明 Block 已经损坏</li><li>Client 读取其他 DataNode 上的 Block</li><li>DataNode 在其文件创建后，周期性的验证 CheckSum</li></ol><p><img src="/images/hadoop/client/check-sum.png" alt="DataNode 数据完整性"></p><hr><h1 id="掉线时限"><a href="#掉线时限" class="headerlink" title="掉线时限"></a>掉线时限</h1><p>DataNode 进程死亡或者网路故障，造成 DataNode 与 NameNode 无法通信，NameNode 不会立即把该节点判定为 <code>死亡</code>，要经过一段时间后才会判定为死亡，这段时间称为 <code>超时时长</code>。HDFS 默认的超时时长为 10min + 30s</p><p>超时时长计算公示： <code>2 * dfs.namenode.heartbeat.recheck-interval + 10 * dfs.heartbeat.interval</code></p><p>具体可参考 <a href="https://hadoop.apache.org/docs/stable/hadoop-project-dist/hadoop-hdfs/hdfs-default.xml" target="_blank" rel="noopener">官方文档</a>，默认值为： <code>dfs.namenode.heartbeat.recheck-interval</code> 5 分钟(300000)、<code>dfs.heartbeat.interval</code> 3秒（3s）</p><p>如果需要修改掉线时限，可以修改 <code>hdfs-site.xml</code> 文件。</p><hr><h1 id="服役新数据节点"><a href="#服役新数据节点" class="headerlink" title="服役新数据节点"></a>服役新数据节点</h1><p>现在已经有 3 台服务器构成了一个 hadoop 集群，如果现在需要在此基础上，再增加一个新的数据节点，就称为 <code>新数据节点服役</code>。</p><blockquote><p>环境准备</p></blockquote><ol><li>以 hadoop04 为主，克隆一台 hadoop05</li><li>修改 hadoop05 的 ip、主机名称</li><li>删除原来 HDFS 中的 <code>data/</code> 和 <code>log/</code></li><li>应用 <code>/etc/profile</code> 配置文件</li></ol><blockquote><p>服役新节点</p></blockquote><ol><li>启动原始集群 02、03、04 </li><li>删除 05 的 <code>data/</code> 和 <code>log/</code></li><li>启动 05 的 DataNode(<code>sbin/hadoop-daemon.sh start datanode</code>)</li><li>启动 05 的 NodeManager(<code>sbin/yarn-daemon.sh start nodemanager</code>)</li><li>在 05 上上传文件进行测试</li><li>查看 WebUI 的 datanodes</li></ol><p><img src="/images/hadoop/client/datanodes.png" alt="datanodes"><br><img src="/images/hadoop/client/05-upload-file.png" alt="新 DataNode 上传文件"><br><img src="/images/hadoop/client/05-file-block.png" alt="新 DataNode 上传文件"></p><hr><h1 id="退役旧数据节点"><a href="#退役旧数据节点" class="headerlink" title="退役旧数据节点"></a>退役旧数据节点</h1><h2 id="主机白名单"><a href="#主机白名单" class="headerlink" title="主机白名单"></a>主机白名单</h2><p>添加到白名单里的主机节点，都允许访问 NameNode，否则不允许访问。</p><p>配置步骤：</p><blockquote><p>在 NameNode 的 <code>%HADOOP_HOME%/etc/hadoop</code> 目录下创建 <code>dfs.hosts</code> 文件，添加白名单（此次不添加 05）<br><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># dfs.hosts</span></span><br><span class="line">hadoop02</span><br><span class="line">hadoop03</span><br><span class="line">hadoop04</span><br></pre></td></tr></table></figure></p></blockquote><blockquote><p>在 NameNode 的 <code>hdfs-site.xml</code> 文件中增加 dfs.hosts 配置</p></blockquote><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&lt;!-- 配置白名单 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.hosts<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>/opt/module/hadoop-2.7.2/etc/hadoop/dfs.hosts<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure><blockquote><p>分发到 03、04，并刷新 NameNode</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop02 hadoop]# xsync hdfs-site.xml</span><br><span class="line">[root@hadoop02 hadoop]# hdfs dfsadmin -refreshNodes</span><br><span class="line">Refresh nodes successful</span><br></pre></td></tr></table></figure><blockquote><p>更新 ResourceManager</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop03 ~]# yarn rmadmin -refreshNodes</span><br><span class="line">19/12/02 14:26:29 INFO client.RMProxy: Connecting to ResourceManager at hadoop03/192.168.233.132:8033</span><br></pre></td></tr></table></figure><blockquote><p>查看 WebUI</p></blockquote><p>在执行上述操作的时候，02、03、04、05 都未关闭，也就是说，在执行上述操作之前，在 WebUI 的 DataNodes 中是可以看到 02、03、04、05 四台机器的。<br>在执行完上述操作后，再次查看 WebUI<br><img src="/images/hadoop/client/white-list.png" alt="白名单"></p><blockquote><p>如果数据不均衡，可以使用命令来实现集群的再平衡</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop02 hadoop-2.7.2]# sbin/start-balancer.sh </span><br><span class="line">starting balancer, logging to /opt/module/hadoop-2.7.2/logs/hadoop-root-balancer-hadoop02.out</span><br><span class="line">Time Stamp               Iteration#  Bytes Already Moved  Bytes Left To Move  Bytes Being Moved</span><br></pre></td></tr></table></figure><p>此时再查看 <code>README.TXT</code> 文件的块信息，由 05 变更到 02 上了。</p><p><img src="/images/hadoop/client/data-balance.png" alt="数据平衡"></p><h2 id="黑名单退役"><a href="#黑名单退役" class="headerlink" title="黑名单退役"></a>黑名单退役</h2><p>在黑名单上的主机会被强制退出。</p><p>在测试实现这种情况之前，需要将现场恢复，即将 hdfs-site.xml 中添加的白名单配置先注释掉，并刷新 NameNode 和 ResourceManager，启动 05 上的 DataNode</p><p>在 NameNode 的 <code>%HADOOP_HOME%/etc/hadoop</code> 目录下，创建 <code>dfs.hosts.exclude</code> 文件，并添加 05</p><p>修改 NameNode 上的 <code>hdfs-site.xml</code> 文件，增加 <code>dfs.hosts.exclude</code> 配置</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&lt;!-- 黑名单 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.hosts.exclude<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>/opt/module/hadoop-2.7.2/etc/hadoop/dfs.hosts.exclude<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure><p>刷新 NameNode、ResourceManager<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop02 hadoop]# hdfs dfsadmin -refreshNodes</span><br><span class="line">Refresh nodes successful</span><br><span class="line"></span><br><span class="line">[root@hadoop03 ~]# yarn rmadmin -refreshNodes</span><br><span class="line">19/12/02 14:26:29 INFO client.RMProxy: Connecting to ResourceManager at hadoop03/192.168.233.132:8033</span><br></pre></td></tr></table></figure></p><p>查看 WebUI，提示正在退役中(Decommission In Progress)，此时正在退役的节点会将数据块复制到其他节点上，保证数据的完整性。<br><img src="/images/hadoop/client/decommission.png" alt="退役节点"></p><p>稍等一会后再刷新页面，提示 05 节点已退役完成：Decommissioned。</p><p>如果数据不平衡，可以和白名单一样，使用 balance 命令平衡数据。</p><blockquote><p>需要注意的点：</p></blockquote><ol><li>等待退役节点状态为 <code>Decommissioned</code>，此时所有的块都已经复制完成，停止该节点及节点资源管理器。注意：如果副本数是 3，服役的节点小于等于 3，是不能退役的！需要修改副本数后才能退役！</li><li>不允许白名单和黑名单中存在同一个主机</li></ol><hr><h1 id="DataNode-多目录"><a href="#DataNode-多目录" class="headerlink" title="DataNode 多目录"></a>DataNode 多目录</h1><p>修改配置与 NameNode 多目录差不多，也是修改 <code>hdfs-site.xml</code>，增加如下配置<br><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.datanode.data.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>file:///$&#123;hadoop.tmp.dir&#125;/dfs/data1,file:///$&#123;hadoop.tmp.dir&#125;/dfs/data2<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure></p><p>分发到不同主机上后，重启 hadoop 集群即可。</p><blockquote><p>注意：</p></blockquote><p>DataNode 与 NameNode 不同，DataNode 每个目录中存放的数据<code>不一样</code>。数据不是副本！</p><hr><h1 id="小文件存档"><a href="#小文件存档" class="headerlink" title="小文件存档"></a>小文件存档</h1><h2 id="小文件存档的弊端"><a href="#小文件存档的弊端" class="headerlink" title="小文件存档的弊端"></a>小文件存档的弊端</h2><p>鉴于每个文件在 DataNode 中分块存储，每个块的元数据村存在 NameNode 中，因此 HDFS 存储小文件会非常低效。因为大量的小文件会耗尽 NameNode 中的大部分内存。<br>但是，需要注意的是，存储小文件所需要的磁盘容量和数据块的大小无关。</p><p>如：一个 1MB 的文件，设置为 128M 的块存储，实际使用的磁盘空间是 1MB，而不是 128MB。</p><h2 id="解决办法之一"><a href="#解决办法之一" class="headerlink" title="解决办法之一"></a>解决办法之一</h2><p>HDFS 存档文件或 HAR 文件，是一个更搞笑的文件存档工具，它将文件存在 HDFS 块，在减少 NameNode 内存使用的同时，允许对文件进行透明访问。<br>具体来说，HDFS 存档文件对内还是一个一个的独立文件，对外（NameNode）而言却是一个整体，减少了 NameNode 的内存。</p><blockquote><p>测试</p></blockquote><p>在 HDFS 中，存放几个测试文件：<br><img src="/images/hadoop/client/before-har.png" alt="before har"></p><p>文件压缩：<br><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 参数解释</span></span><br><span class="line"><span class="comment"># archive：开始文件压缩</span></span><br><span class="line"><span class="comment"># -archiveName：指定压缩的名称</span></span><br><span class="line"><span class="comment"># -p： 从那个目录，压缩到那个目录</span></span><br><span class="line">[root@hadoop03 hadoop-2.7.2]<span class="comment"># hadoop  archive -archiveName outout.har -p / /output</span></span><br></pre></td></tr></table></figure></p><p>执行完成后，查看 WebUI<br><img src="/images/hadoop/client/har-suscceed.png" alt="文件压缩后"></p><p>可以看到，文件成功输出了，但是我们看不到文件的内容是否和压缩前一致，解决办法：使用 <code>hadoop fs -ls -R har:///output/output.har</code> 命令查看</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop02 hadoop-2.7.2]# hadoop fs -ls -R har:///output/outout.har</span><br><span class="line">-rw-r--r--   3 root supergroup      15429 2019-12-02 16:23 har:///output/outout.har/LICENSE.txt</span><br><span class="line">-rw-r--r--   3 root supergroup        101 2019-12-02 16:22 har:///output/outout.har/NOTICE.txt</span><br><span class="line">-rw-r--r--   3 root supergroup       1366 2019-12-02 16:22 har:///output/outout.har/README.txt</span><br></pre></td></tr></table></figure><p>文档解压：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop02 hadoop-2.7.2]# hadoop fs -cp har:///output/outout.har /har</span><br></pre></td></tr></table></figure></p><hr><h1 id="回收站"><a href="#回收站" class="headerlink" title="回收站"></a>回收站</h1><p>开启回收站功能，可以将删除的文件，在不超时的情况下，恢复原数据，起到防止误删、备份等作用。</p><h2 id="回收站参数设置及工作机制"><a href="#回收站参数设置及工作机制" class="headerlink" title="回收站参数设置及工作机制"></a>回收站参数设置及工作机制</h2><blockquote><p>开启回收站功能参数</p></blockquote><ol><li><code>fs.trash.interval</code>：默认值为 0，表示 <code>禁用回收站</code>，其他值表示该文件的存活时间，单位 <code>分钟</code></li><li><code>fs.trash.checkpoint.interval</code>：默认值为 0，表示 <code>检查回收站的时间间隔</code>，如果为 0，则该值与 <code>fs.trash.interval</code> 的时间间隔相同。单位 <code>分钟</code></li><li>要求：<code>fs.trash.checkpoint.interval</code> &lt;= <code>fs.trash.interval</code></li></ol><p>修改 <code>core-site.xml</code> 文件<br><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>fs.trash.interval<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>1<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure></p><blockquote><p>删除一条数据测试</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop03 hadoop-2.7.2]# hadoop fs -rm /README.txt</span><br><span class="line">19/12/02 17:31:15 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 1 minutes, Emptier interval = 0 minutes.</span><br><span class="line">Moved: &apos;hdfs://hadoop02:9000/README.txt&apos; to trash at: hdfs://hadoop02:9000/user/root/.Trash/Current</span><br></pre></td></tr></table></figure><blockquote><p>在 WebUI 中查看回收站</p></blockquote><p><img src="/images/hadoop/client/trash-warn.png" alt="trash warn"></p><p>错误原因：进入垃圾回收站的默认用户名为 <code>dr.who</code>， 需要修改回收站用户名</p><p>修改 core-site.xml，并分发的 03、04 上，重启集群<br><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>hadoop.http.staticuser.user<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>root<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure></p><p>再次查看 WebUI：<br><img src="/images/hadoop/client/trash-succeed.png" alt="trash succeed"></p><hr><h1 id="快照管理"><a href="#快照管理" class="headerlink" title="快照管理"></a>快照管理</h1><p>快照，相当于对目录做了一次备份。此操作并 <em>不会立即赋值所有文件</em> ，而是 <em>指向同一个文件</em>。当写入发生时，才会产生新文件。</p><h2 id="常见命令"><a href="#常见命令" class="headerlink" title="常见命令"></a>常见命令</h2><blockquote><p>开启指定目录的快照功能： <code>hdfs dfsadmin -allowSnapshot &lt;path&gt;</code></p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop02 hadoop-2.7.2]# hdfs dfsadmin -allowSnapshot /laiyy</span><br><span class="line">Allowing snaphot on /laiyy succeeded</span><br></pre></td></tr></table></figure><blockquote><p>禁用指定目录的快照功能(默认)：<code>hdfs dfsadmin -disallowSnapshot &lt;path&gt;</code><br>对指定目录创建快照：<code>hdfs dfs -createSnapshot &lt;path&gt;</code></p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop02 hadoop-2.7.2]# hdfs dfs -createSnapshot /laiyy</span><br><span class="line">Created snapshot /laiyy/.snapshot/s20191203-135428.244</span><br></pre></td></tr></table></figure><p>此时在 WebUI 中是看不到快照文件的，因为这个快照文件是<code>隐藏文件</code>，输入 <code>/laiyy/.snapshot</code> 即可查看<br><img src="/images/hadoop/client/no-snapshot.png" alt="看不到快照"><br><img src="/images/hadoop/client/snapshot.png" alt="看到快照"><br><img src="/images/hadoop/client/snapshot1.png" alt="看到快照"></p><blockquote><p>创建目录快照并指定名称：<code>hdfs dfs -createSnapshot &lt;path&gt; &lt;name&gt;</code><br>快照重命名：<code>hdfs dfs -renameSnapshot &lt;path&gt; &lt;oldName&gt; &lt;newName&gt;</code></p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop02 hadoop-2.7.2]# hdfs dfs -renameSnapshot /laiyy s20191203-135428.244 laiyy_snapshot</span><br></pre></td></tr></table></figure><p>查看 WebUI，可以看到快照名称已经修改了。<br><img src="/images/hadoop/client/rename-snapshot.png" alt="修改快照名称"></p><blockquote><p>列出当前用户可以快照的目录：<code>hdfs lsSnapshottableDir</code><br>比较两个快照目录的不同：<code>hdfs snapshotDiff &lt;path&gt; &lt;from&gt; &lt;to&gt;</code></p></blockquote><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># path 哪个路径的快照</span></span><br><span class="line"><span class="comment"># from、to：比较 form 和 to 两个快照的区别</span></span><br><span class="line"><span class="comment"># 此时的 from 用 "." 指代 /laiyy 文件夹，此时比较是没有任何区别的</span></span><br><span class="line">[root@hadoop02 hadoop-2.7.2]<span class="comment"># hdfs snapshotDiff /laiyy . .snapshot/laiyy_snapshot</span></span><br><span class="line">Difference between current directory and snapshot laiyy_snapshot under directory /laiyy:</span><br></pre></td></tr></table></figure><p>在已经创建快照之后，再往 /laiyy 下上传一个文件，比较结果</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop02 hadoop-2.7.2]# hdfs snapshotDiff /laiyy . .snapshot/laiyy_snapshot</span><br><span class="line">Difference between current directory and snapshot laiyy_snapshot under directory /laiyy:</span><br><span class="line">M.</span><br><span class="line">-./LICENSE.txt</span><br></pre></td></tr></table></figure><p>再创建一个新的快照，比较两个快照之间的区别</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop02 hadoop-2.7.2]# hdfs snapshotDiff /laiyy .snapshot/laiyy_snapshot .snapshot/laiyy_snapshot1</span><br><span class="line">Difference between snapshot laiyy_snapshot and snapshot laiyy_snapshot1 under directory /laiyy:</span><br><span class="line">M.</span><br><span class="line">+./LICENSE.txt</span><br></pre></td></tr></table></figure><blockquote><p>删除快照：<code>hdfs dfs -deleteSnapshot &lt;path&gt; &lt;name&gt;</code></p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hdfs dfs -deleteSnapshot /laiyy laiyy_snapshot</span><br></pre></td></tr></table></figure><p>查看 WebUI</p><p><img src="/images/hadoop/client/delete-snapshot.png" alt="删除快照"></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;在了解了 NameNode、SecondaryNameNode 的工作机制、FsImage 与 Edits 数据备份、NameNode 安全机制与多目录后，对 NameNode 有了一些基础了解。在此基础之上，接下来了解一下 DataNode 的工作机制。&lt;/p&gt;
    
    </summary>
    
      <category term="hadoop" scheme="https://www.laiyy.top/categories/hadoop/"/>
    
      <category term="hdfs" scheme="https://www.laiyy.top/categories/hadoop/hdfs/"/>
    
    
      <category term="hadoop" scheme="https://www.laiyy.top/tags/hadoop/"/>
    
      <category term="hdfs" scheme="https://www.laiyy.top/tags/hdfs/"/>
    
      <category term="DataNode" scheme="https://www.laiyy.top/tags/DataNode/"/>
    
      <category term="trash" scheme="https://www.laiyy.top/tags/trash/"/>
    
      <category term="snapshot" scheme="https://www.laiyy.top/tags/snapshot/"/>
    
  </entry>
  
  <entry>
    <title>Hadoop（7） &lt;br/&gt; NameNode 和 SecondaryNameNode、集群安全模式</title>
    <link href="https://www.laiyy.top/hadoop/hdfs/hadoop-7.html"/>
    <id>https://www.laiyy.top/hadoop/hdfs/hadoop-7.html</id>
    <published>2019-11-28T01:24:43.000Z</published>
    <updated>2019-11-28T01:24:48.000Z</updated>
    
    <content type="html"><![CDATA[<p>此前通过代码了解了 HDFS API 和 I/O 操作，并了解了 HDFS 读写数据的过程，对 HDFS 整体运行过程有了初步了解。接下来就需要了解一下 NN（NameNode）、2NN（SecondaryNameNode） 的区别</p><a id="more"></a><h1 id="NN-和-2NN-的工作机制"><a href="#NN-和-2NN-的工作机制" class="headerlink" title="NN 和 2NN 的工作机制"></a>NN 和 2NN 的工作机制</h1><p>如果 NameNode 中的元数据存储在 NameNode 节点的磁盘中，由于要经常进行随机访问，还要响应客户端请求，效率会很低。因此，元数据必须要放在内存中。但是，如果只存储在内存中，一旦断点、服务重启，元数据就会丢失。因此，基于这种情况，产生了在磁盘中备份元数据的 <code>FsImage</code>。</p><p>在此基础上，当在内存中更新元数据，如果同时更新 FsImage，会导致效率降低；如果不更新，会产生一致性问题，一旦 NameNode 断电，数据就会丢失。<br>基于这种情况，Hadoop 引入了 <code>Edits</code> 文件(只进行追加操作，效率高)。每当元数据有更新或者添加时，就会修改内存中的元数据并追加到 Edits 中。<br>这样，一旦 NameNode 断电，可以通过 FsImage 和 Edits 合并成一个元数据。</p><p>但是这样还有一个问题没有解决，那就是如果长时间添加数据到 Edits 中，会导致该文件数据过大，效率很低，而且，一旦断电，恢复元数据需要的时间很长。<br>因此，需要定时进行 FsImage 和 Edits 的合并。 如果这个操作由 NameNode 完成，效率又会降低。因此引入了一个新的节点 <code>SecondaryNameNode</code>，专门用于 FsImage 和 Edits 的合并。</p><p>流程：</p><ol><li>NameNode 启动时，加载 Edits 和 FsImage 到内存（每个 block 占元数据 150byte）</li><li>客户端进行增删改操作时，NameNode 要先记录操作日志，更新Edits，再去进行其他后续请求</li><li>SecondaryNameNode 请求 NameNode，检查是否触发检查点（触发条件：检查时间到，或 Edits 中的数据满：达到 100W 条）</li><li>2NN 请求执行检查点（CheckPoint）</li><li>NameNode 滚动正在写的 Edits（即从 edits_001 文件，滚动到 edits_002 文件，后续的操作日志将写入 edit_002 中）</li><li>将 edits_001 和 FsImage 拷贝到 2NN</li><li>2NN 将 FsImage 和 edits_001 加载到内存并合并</li><li>2NN 生成新的 FsImage（如：fsimage.checkpoint）</li><li>将新生成的 FsImage 拷贝到 NameNonde，并重命名为 fsimage，加载到内存</li></ol><p><img src="/images/hadoop/client/nn-2nn.png" alt="NameNode 工作机制"></p><hr><h1 id="镜像文件和编辑日志-FsImage、Edits"><a href="#镜像文件和编辑日志-FsImage、Edits" class="headerlink" title="镜像文件和编辑日志 (FsImage、Edits)"></a>镜像文件和编辑日志 (FsImage、Edits)</h1><p>在 NameNode 所在的服务器中，查看 fsimage 和 edits 文件(<code>/opt/module/hadoop-2.7.2/data/tmp/dfs/name/current</code>)<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">-rw-r--r--. 1 root root    1383 11月 26 11:13 edits_0000000000000000001-0000000000000000019</span><br><span class="line">-rw-r--r--. 1 root root    1816 11月 26 12:13 edits_0000000000000000020-0000000000000000043</span><br><span class="line">-rw-r--r--. 1 root root      42 11月 26 13:13 edits_0000000000000000044-0000000000000000045</span><br><span class="line">-rw-r--r--. 1 root root 1048576 11月 26 13:13 edits_0000000000000000046-0000000000000000046</span><br><span class="line">-rw-r--r--. 1 root root      42 11月 26 14:53 edits_0000000000000000047-0000000000000000048</span><br><span class="line">-rw-r--r--. 1 root root 1048576 11月 26 14:53 edits_0000000000000000049-0000000000000000049</span><br><span class="line">-rw-r--r--. 1 root root     260 11月 26 17:39 edits_0000000000000000050-0000000000000000054</span><br><span class="line">-rw-r--r--. 1 root root 1048576 11月 26 17:39 edits_0000000000000000055-0000000000000000055</span><br><span class="line">-rw-r--r--. 1 root root    1081 11月 27 10:11 edits_0000000000000000056-0000000000000000072</span><br><span class="line">-rw-r--r--. 1 root root      42 11月 27 11:11 edits_0000000000000000073-0000000000000000074</span><br><span class="line">-rw-r--r--. 1 root root 1048576 11月 27 11:48 edits_0000000000000000075-0000000000000000080</span><br><span class="line">-rw-r--r--. 1 root root    1339 11月 28 15:32 edits_0000000000000000081-0000000000000000098</span><br><span class="line">-rw-r--r--. 1 root root      42 11月 28 16:32 edits_0000000000000000099-0000000000000000100</span><br><span class="line">-rw-r--r--. 1 root root 1048576 11月 28 16:32 edits_0000000000000000101-0000000000000000101</span><br><span class="line">-rw-r--r--. 1 root root      42 11月 29 11:21 edits_0000000000000000102-0000000000000000103</span><br><span class="line">-rw-r--r--. 1 root root 1048576 11月 29 11:21 edits_0000000000000000104-0000000000000000104</span><br><span class="line">-rw-r--r--. 1 root root 1048576 11月 29 14:19 edits_inprogress_0000000000000000105</span><br><span class="line">-rw-r--r--. 1 root root     765 11月 29 11:21 fsimage_0000000000000000103</span><br><span class="line">-rw-r--r--. 1 root root      62 11月 29 11:21 fsimage_0000000000000000103.md5</span><br><span class="line">-rw-r--r--. 1 root root     765 11月 29 14:19 fsimage_0000000000000000104</span><br><span class="line">-rw-r--r--. 1 root root      62 11月 29 14:19 fsimage_0000000000000000104.md5</span><br><span class="line">-rw-r--r--. 1 root root       4 11月 29 14:19 seen_txid</span><br><span class="line">-rw-r--r--. 1 root root     207 11月 29 14:19 VERSION</span><br></pre></td></tr></table></figure></p><h2 id="查看-FsImage-文件"><a href="#查看-FsImage-文件" class="headerlink" title="查看 FsImage 文件"></a>查看 FsImage 文件</h2><p>此时，查看 <code>fsimage_0000000000000000103</code> 文件，可以看到一些简略信息，详细信息都被二进制编码了。</p><p><img src="/images/hadoop/client/cat-fsimage.png" alt="cat fsimage"></p><p>我们可以通过 <code>hdfs</code> 的命令，将文件转储为可以看懂的 XML 文件：<br><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 参数解释：</span></span><br><span class="line"><span class="comment"># oiv：转储 fsimage 文件</span></span><br><span class="line"><span class="comment"># -p：以何种格式转储</span></span><br><span class="line"><span class="comment"># -i：转储哪个文件</span></span><br><span class="line"><span class="comment"># -o：转储到什么位置</span></span><br><span class="line">hdfs oiv -p XML -i fsimage_0000000000000000103 -o ~/fsimage.xml</span><br></pre></td></tr></table></figure></p><p>执行命令，查看对应文件夹下的 <code>fsimage.xml</code> 文件(<code>cat ~/fsimage.xml</code>)<br><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version="1.0"?&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">fsimage</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">NameSection</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">genstampV1</span>&gt;</span>1000<span class="tag">&lt;/<span class="name">genstampV1</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">genstampV2</span>&gt;</span>1011<span class="tag">&lt;/<span class="name">genstampV2</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">genstampV1Limit</span>&gt;</span>0<span class="tag">&lt;/<span class="name">genstampV1Limit</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">lastAllocatedBlockId</span>&gt;</span>1073741834<span class="tag">&lt;/<span class="name">lastAllocatedBlockId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">txid</span>&gt;</span>103<span class="tag">&lt;/<span class="name">txid</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">NameSection</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">INodeSection</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">lastInodeId</span>&gt;</span>16402<span class="tag">&lt;/<span class="name">lastInodeId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">inode</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">id</span>&gt;</span>16385<span class="tag">&lt;/<span class="name">id</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">type</span>&gt;</span>DIRECTORY<span class="tag">&lt;/<span class="name">type</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">name</span>&gt;</span><span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">mtime</span>&gt;</span>1574923975056<span class="tag">&lt;/<span class="name">mtime</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">permission</span>&gt;</span>root:supergroup:rwxr-xr-x<span class="tag">&lt;/<span class="name">permission</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">nsquota</span>&gt;</span>9223372036854775807<span class="tag">&lt;/<span class="name">nsquota</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">dsquota</span>&gt;</span>-1<span class="tag">&lt;/<span class="name">dsquota</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">inode</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">inode</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">id</span>&gt;</span>16398<span class="tag">&lt;/<span class="name">id</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">type</span>&gt;</span>FILE<span class="tag">&lt;/<span class="name">type</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">name</span>&gt;</span>log.out<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">replication</span>&gt;</span>2<span class="tag">&lt;/<span class="name">replication</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">mtime</span>&gt;</span>1574818660432<span class="tag">&lt;/<span class="name">mtime</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">atime</span>&gt;</span>1574923642491<span class="tag">&lt;/<span class="name">atime</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">perferredBlockSize</span>&gt;</span>134217728<span class="tag">&lt;/<span class="name">perferredBlockSize</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">permission</span>&gt;</span>root:supergroup:rw-r--r--<span class="tag">&lt;/<span class="name">permission</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">blocks</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">block</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">id</span>&gt;</span>1073741829<span class="tag">&lt;/<span class="name">id</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">genstamp</span>&gt;</span>1006<span class="tag">&lt;/<span class="name">genstamp</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">numBytes</span>&gt;</span>1349614<span class="tag">&lt;/<span class="name">numBytes</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;/<span class="name">block</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;/<span class="name">blocks</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">inode</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">INodeSection</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">INodeReferenceSection</span>&gt;</span><span class="tag">&lt;/<span class="name">INodeReferenceSection</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">SnapshotSection</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">snapshotCounter</span>&gt;</span>0<span class="tag">&lt;/<span class="name">snapshotCounter</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">SnapshotSection</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">INodeDirectorySection</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">directory</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">parent</span>&gt;</span>16385<span class="tag">&lt;/<span class="name">parent</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">directory</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">INodeDirectorySection</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">FileUnderConstructionSection</span>&gt;</span><span class="tag">&lt;/<span class="name">FileUnderConstructionSection</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">SnapshotDiffSection</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">diff</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">inodeid</span>&gt;</span>16385<span class="tag">&lt;/<span class="name">inodeid</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">diff</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">SnapshotDiffSection</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">SecretManagerSection</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">currentId</span>&gt;</span>0<span class="tag">&lt;/<span class="name">currentId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">tokenSequenceNumber</span>&gt;</span>0<span class="tag">&lt;/<span class="name">tokenSequenceNumber</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">SecretManagerSection</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">CacheManagerSection</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">nextDirectiveId</span>&gt;</span>1<span class="tag">&lt;/<span class="name">nextDirectiveId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">CacheManagerSection</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">fsimage</span>&gt;</span></span><br></pre></td></tr></table></figure></p><h2 id="查看-Edits-文件"><a href="#查看-Edits-文件" class="headerlink" title="查看 Edits 文件"></a>查看 Edits 文件</h2><p>使用命令将 edits 文件转储为 xml：<code>hdfs oev -p XML -i edits_0000000000000000102-0000000000000000103 -o ~/edits.xml</code><br><strong><em>oev：转储 edits 文件</em></strong></p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version="1.0" encoding="UTF-8"?&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">EDITS</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">EDITS_VERSION</span>&gt;</span>-63<span class="tag">&lt;/<span class="name">EDITS_VERSION</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">RECORD</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">OPCODE</span>&gt;</span>OP_START_LOG_SEGMENT<span class="tag">&lt;/<span class="name">OPCODE</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">DATA</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">TXID</span>&gt;</span>102<span class="tag">&lt;/<span class="name">TXID</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">DATA</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">RECORD</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">RECORD</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">OPCODE</span>&gt;</span>OP_END_LOG_SEGMENT<span class="tag">&lt;/<span class="name">OPCODE</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">DATA</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">TXID</span>&gt;</span>103<span class="tag">&lt;/<span class="name">TXID</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">DATA</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">RECORD</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">EDITS</span>&gt;</span></span><br></pre></td></tr></table></figure><h2 id="注意"><a href="#注意" class="headerlink" title="注意"></a>注意</h2><p>NameNode 通过 <code>%HADOOP_HOME%/data/tmp/name/current/seen_txid</code> 文件，来确定下次开机启动的时候，合并哪些 Edits。</p><hr><h1 id="CheckPoint-设置"><a href="#CheckPoint-设置" class="headerlink" title="CheckPoint 设置"></a>CheckPoint 设置</h1><p>2NN CheckPoint 检查点时间设置，通常情况下，每隔一小时执行一次。</p><p>此配置可以参考 <a href="https://hadoop.apache.org/docs/stable/hadoop-project-dist/hadoop-hdfs/hdfs-default.xml" target="_blank" rel="noopener">Hadoop 官方文档</a> 中的 <code>dfs.namenode.checkpoint.period</code> 设置项，单位为 秒。</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.checkpoint.period<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>3600<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure><p>CheckPoint 每分钟检查一次操作次数，当操作次数达到 <code>100万</code> 时，SecondaryNameNode 执行一次。<br><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&lt;!-- 设置 CheckPoint 操作此时达到多少时执行 2NN --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.checkpoint.txns<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>1000000<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- 设置多长时间检查一次操作数 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.checkpoint.check.period<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>60<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure></p><hr><h1 id="NameNode-故障处理"><a href="#NameNode-故障处理" class="headerlink" title="NameNode 故障处理"></a>NameNode 故障处理</h1><p>NameNode 故障后，可以采用如下两种方式进行数据恢复。</p><h2 id="将-2NN-中的数据拷贝到-NN-存储数据的目录"><a href="#将-2NN-中的数据拷贝到-NN-存储数据的目录" class="headerlink" title="将 2NN 中的数据拷贝到 NN 存储数据的目录"></a>将 2NN 中的数据拷贝到 NN 存储数据的目录</h2><p><strong><em>注意：此操作依赖于 2NN 的数据完整性</em></strong></p><p>步骤：</p><blockquote><p>kill -9 NameNode<br>删除 NameNode 存储的数据(<code>%HADOOP_HOME%/data/tmp/name/*</code>)<br>拷贝 2NN 中的数据到 NN 存储数据目录( 2NN 下的 <code>%HADOOP_HOME%/data/tmp/namesecondary/*</code>)<br>重启 NameNode</p></blockquote><p>拷贝方法：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scp -r root@hadoop04:/opt/module/hadoop-2.7.2/data/tmp/dfs/namesecondary/* /opt/module/hadoop-2.7.2/data/tmp/dfs/name/</span><br></pre></td></tr></table></figure></p><p>单独其中 NameNode： <code>sbin/hadoop-daemon.sh start namenode</code></p><h2 id="导入检查点"><a href="#导入检查点" class="headerlink" title="导入检查点"></a>导入检查点</h2><p>使用 -importCheckpoint 选项，启动 NameNode 守护进程，进而将 2NN 中的数据拷贝到 NameNode 中。</p><p>步骤：</p><ol><li><p>修改 NameNode 的 hdfs-site.xml 文件：</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.checkpoint.period<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>120<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.name.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>your hadoop namenode dir<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure></li><li><p>kill -9 NameNode</p></li><li>删除 NameNode 中存储的数据(<code>%HADOOP_HOME%/data/tmp/name/*</code>)</li><li>如果 2NN 和 NameNode 不在同一个主机节点上，需要将 2NN 存储数据的目录，拷贝到 NN 存储数据的平级目录，并删除 <code>in_use.lock</code> 文件。</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">scp -r root@hadoop04:/opt/module/hadoop-2.7.2/data/tmp/dfs/namesecondary/* /opt/module/hadoop-2.7.2/data/tmp/dfs/</span><br><span class="line">cd /opt/module/hadoop-2.7.2/data/tmp/dfs/namesecondary</span><br><span class="line">rm -rf in_use.lock</span><br></pre></td></tr></table></figure><ol start="5"><li><p>导入检查点数据</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/hdfs namenode -importCheckpoint</span><br></pre></td></tr></table></figure></li><li><p>启动 NameNode<br><code>sbin/hadoop-daemon.sh start namenode</code></p></li></ol><hr><h1 id="集群安全模式"><a href="#集群安全模式" class="headerlink" title="集群安全模式"></a>集群安全模式</h1><h2 id="安全模式的条件"><a href="#安全模式的条件" class="headerlink" title="安全模式的条件"></a>安全模式的条件</h2><blockquote><p>NameNode 启动</p></blockquote><p>NameNode 启动时，首先将镜像文件（FsImage）加载到内存中，并执行编辑日志（Edits）中的各项操作。<br>一旦在内存中成功简历文件系统元数据的映像，则创建一个新的 FsImage 文件和一个空白的编辑日志，此时，NameNode 开始监听 DataNode 的请求。<br>这个过程中，NameNode 一直处于安全模式，即：NameNode 的文件系统对客户端来说是<code>只读</code>的。</p><blockquote><p>DataNode 启动</p></blockquote><p>系统中的数据块的位置并不是由 NameNode 维护的，而是以<code>块列表</code>的形式存储在 DataNode 中 。<br>在系统的<code>正常操作期间</code>，NameNode 会在内存中保留所有块位置的映射信息。<br>在<code>安全模式</code>下，DataNode 会向 NameNode 发送最新的块列表信息，NameNode 了解到足够多的<code>块位置</code>信息后，即可搞笑运行文件系统。</p><blockquote><p>安全模式退出判断</p></blockquote><p>如果满足 <code>最小副本条件</code>，NameNode 将会在 <code>30s</code> 后退出安全模式。<br>所谓 <code>最小副本条件</code>：是指在整个文件系统中 99.9% 的块满足最小副本级别（默认值：dfs.replication.min=1）。<br>在启动一个刚刚格式化的 HDFS 集群时，因为系统中还没有任何块，所以 NameNode 不会进入安全模式。</p><h2 id="安全模式的命令、语法等"><a href="#安全模式的命令、语法等" class="headerlink" title="安全模式的命令、语法等"></a>安全模式的命令、语法等</h2><p>当集群处于<code>安全模式</code>，不能执行任何写操作。集群启动完成后，自动退出安全模式。</p><h3 id="常用命令："><a href="#常用命令：" class="headerlink" title="常用命令："></a>常用命令：</h3><blockquote><p>bin/hdfs dfsadmin -safemode get：查看安全模式状态</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop02 hadoop-2.7.2]# bin/hdfs dfsadmin -safemode get</span><br><span class="line">Safe mode is OFF</span><br></pre></td></tr></table></figure><blockquote><p>bin/hdfs dfsadmin -safemode enter：进入安全模式</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop02 hadoop-2.7.2]# bin/hdfs dfsadmin -safemode enter</span><br><span class="line">Safe mode is ON</span><br></pre></td></tr></table></figure><p><img src="/images/hadoop/client/safe-mode-enter.png" alt="SafeMode Enter"></p><p>此时的 HDFS 文件系统状态为：<br><img src="/images/hadoop/client/safe-mode-file-system.png" alt="SafeMode FileSystem"></p><p>上传一个文件测试一下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop02 hadoop-2.7.2]# bin/hdfs dfs -put README.txt /</span><br><span class="line">put: Cannot create file/README.txt._COPYING_. Name node is in safe mode.</span><br></pre></td></tr></table></figure></p><p>可以发现，上传时已经报错：不能上传文件，因为 NameNode 处于 SafeMode。所以在 HDFS 中没有新上传的文件。</p><blockquote><p>bin/hdfs dfsadmin -safemode leave：离开安全模式</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop02 hadoop-2.7.2]# bin/hdfs dfsadmin -safemode leave</span><br><span class="line">Safe mode is OFF</span><br></pre></td></tr></table></figure><p>此时再次执行上传文件，查看文件系统状态<br><img src="/images/hadoop/client/safe-mode-leave-file-system.png" alt="SafeMode FileSystem"></p><blockquote><p>bin/hdfs dfsadmin -safemode wait：等待安全模式</p></blockquote><h3 id="等待安全模式"><a href="#等待安全模式" class="headerlink" title="等待安全模式"></a>等待安全模式</h3><p>测试等待安全模式的步骤：</p><blockquote><p>先使集群进入到安全模式</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop02 hadoop-2.7.2]# bin/hdfs dfsadmin -safemode enter</span><br><span class="line">Safe</span><br></pre></td></tr></table></figure><blockquote><p>在 <code>%HADOOP_HOME%</code> 路径下创建一个脚本 <code>safemode.sh</code></p></blockquote><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#!/bin/bash</span></span><br><span class="line"></span><br><span class="line">hdfs dfsadmin -safemode <span class="built_in">wait</span></span><br><span class="line"></span><br><span class="line">hdfs dfs -put /opt/module/hadoop-2.7.2/NOTICE.txt /</span><br></pre></td></tr></table></figure><p>修改权限：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">chmod 777 safemode.sh</span><br></pre></td></tr></table></figure></p><p>执行脚本，可以看到当前进程阻塞住了，并没有上传 NOTICE.txt 文件。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./safemode.sh</span><br></pre></td></tr></table></figure></p><p>在 xshell 中再打开一个窗口，执行命令：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop02 hadoop-2.7.2]# bin/hdfs dfsadmin -safemode leave</span><br><span class="line">Safe mode is OFF</span><br></pre></td></tr></table></figure></p><p>再查看之前阻塞的进程，发现已经正常通行，且 NOTICE.txt 文件上传到了 HDFS 中<br><img src="/images/hadoop/client/safe-mode-wait.png" alt="SafeMode FileSystem"></p><hr><h1 id="NameNode-多目录配置"><a href="#NameNode-多目录配置" class="headerlink" title="NameNode 多目录配置"></a>NameNode 多目录配置</h1><p><strong>NameNode 的本地目录可以配置为多个，且每个目录存在的内容相同，增加了可靠性</strong><br><strong>注意：此方法只是保证了数据的可靠性，并不是保证 NameNode 可靠性，它们对应的依然是一个 NameNode 实例</strong></p><blockquote><p>第 0 步：关闭集群</p></blockquote><blockquote><p>第一步：修改 ddfs-site.xml 文件，增加如下内容，并分发到三台机器上</p></blockquote><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.name.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>file:///$&#123;hadoop.tmp.dir&#125;/dfs/name1,file:///$&#123;hadoop.tmp.dir&#125;/dfs/name2<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">xsync etc/hadoop/hdfs-site.xml</span><br></pre></td></tr></table></figure><blockquote><p>第二步：删除 data 和 logs 中的所有数据</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop02 hadoop-2.7.2]# rm -rf data/ logs/</span><br><span class="line">[root@hadoop03 hadoop-2.7.2]# rm -rf data/ logs/</span><br><span class="line">[root@hadoop04 hadoop-2.7.2]# rm -rf data/ logs/</span><br></pre></td></tr></table></figure><blockquote><p>格式化集群并启动</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop02 hadoop-2.7.2]# hdfs namenode -format</span><br><span class="line">[root@hadoop03 hadoop-2.7.2]# hdfs namenode -format</span><br><span class="line">[root@hadoop04 hadoop-2.7.2]# hdfs namenode -format</span><br></pre></td></tr></table></figure><p>查看 <code>%HADOOP_HOME%/data/dfs</code> 文件夹：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop04 ~]# ll /opt/module/hadoop-2.7.2/data/tmp/dfs/</span><br><span class="line">总用量 0</span><br><span class="line">drwxr-xr-x. 3 root root 21 11月 29 16:52 name1</span><br><span class="line">drwxr-xr-x. 3 root root 21 11月 29 16:52 name2</span><br></pre></td></tr></table></figure></p><p>可见两个文件夹都创建成功了。</p><p>启动集群：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop02 hadoop-2.7.2]# sbin/start-dfs.sh</span><br><span class="line">[root@hadoop03 hadoop-2.7.2]# sbin/start-yarn.sh</span><br></pre></td></tr></table></figure></p><blockquote><p>上传文件并测试，可以看到在 name1、name2 中都有对应的文件，且信息完全相同</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop02 hadoop-2.7.2]# hadoop fs -put NOTICE.txt /</span><br></pre></td></tr></table></figure><p><img src="/images/hadoop/client/more-dir.png" alt="namenode more dir"></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;此前通过代码了解了 HDFS API 和 I/O 操作，并了解了 HDFS 读写数据的过程，对 HDFS 整体运行过程有了初步了解。接下来就需要了解一下 NN（NameNode）、2NN（SecondaryNameNode） 的区别&lt;/p&gt;
    
    </summary>
    
      <category term="hadoop" scheme="https://www.laiyy.top/categories/hadoop/"/>
    
      <category term="hdfs" scheme="https://www.laiyy.top/categories/hadoop/hdfs/"/>
    
    
      <category term="hadoop" scheme="https://www.laiyy.top/tags/hadoop/"/>
    
      <category term="hdfs" scheme="https://www.laiyy.top/tags/hdfs/"/>
    
      <category term="NameNode" scheme="https://www.laiyy.top/tags/NameNode/"/>
    
  </entry>
  
  <entry>
    <title>Hadoop（6） &lt;br/&gt; HDFS API 操作</title>
    <link href="https://www.laiyy.top/hadoop/hdfs/hadoop-6.html"/>
    <id>https://www.laiyy.top/hadoop/hdfs/hadoop-6.html</id>
    <published>2019-11-27T01:24:43.000Z</published>
    <updated>2019-11-27T01:24:48.000Z</updated>
    
    <content type="html"><![CDATA[<p>此前，完成了一个基础的完全分布式集群，并且使用 Java 程序代码实现测试连通了 Hadoop 集群，且在 HDFS 中创建了一个文件夹。由此开始学习 Hadoop 的一些 Java API 操作。</p><a id="more"></a><p>API 操作通用方法</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Before</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">initFileSystem</span><span class="params">()</span> <span class="keyword">throws</span> URISyntaxException, IOException, InterruptedException </span>&#123;</span><br><span class="line">    Configuration configuration = <span class="keyword">new</span> Configuration();</span><br><span class="line">    <span class="comment">// 两个副本</span></span><br><span class="line">    configuration.set(<span class="string">"dfs.replication"</span>, <span class="string">"2"</span>);</span><br><span class="line"></span><br><span class="line">    fileSystem = FileSystem.get(<span class="keyword">new</span> URI(<span class="string">"hdfs://hadoop02:9000"</span>), configuration, <span class="string">"root"</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">@After</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">closeFileSystem</span><span class="params">()</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (<span class="keyword">null</span> != fileSystem) &#123;</span><br><span class="line">        fileSystem.close();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h1 id="HDFS-API-操作"><a href="#HDFS-API-操作" class="headerlink" title="HDFS API 操作"></a>HDFS API 操作</h1><h2 id="文件上传"><a href="#文件上传" class="headerlink" title="文件上传"></a>文件上传</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Test</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">testCopyFromLocalFile</span><span class="params">()</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">    <span class="comment">// 上传文件，参数1：待上传文件位置，参数2：HDFS 路径</span></span><br><span class="line">    fileSystem.copyFromLocalFile(<span class="keyword">new</span> Path(<span class="string">"d:\\log\\error.log"</span>), <span class="keyword">new</span> Path(<span class="string">"/error.log"</span>));</span><br><span class="line">    System.out.println(<span class="string">"上传完成"</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><img src="/images/hadoop/client/copy-from-local.png" alt="文件上传"></p><p>将 <code>$HADOOP_HOME$/etc/hadoop/hdfs-site.xml</code> 文件，拷贝到 Java 程序的 <code>/resources</code> 文件夹下，并修改为：<br><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- 副本数量改为 1 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.replication<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>1<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure></p><p>注释掉程序中设置副本数的代码，再次上传文件，查看上传后文件副本数</p><p>结论：<br>1、如果程序中未设置副本数，且不存在 hdfs-site.xml 文件，则以 Hadoop 中设置的 hdfs-site.xml 中的副本数优先<br>2、如果程序中未设置副本数，存在 hdfs-site.xml 文件，以程序中的 hdfs-site.xml 中的副本数优先<br>3、如果程序中设置了副本数，且存在 hdfs-site.xml，以程序中设置的副本数优先<br>4、如果程序中设置了副本数，且不存在 hdfs-site.xml，以程序中设置的副本数优先</p><p>即：<code>Java 程序</code> &gt; <code>resources 中的 hdfs-site.xml</code> &gt; <code>hadoop 中的 hdfs-site.xml</code> &gt; <code>hadoop 默认的副本数</code></p><h2 id="文件下载"><a href="#文件下载" class="headerlink" title="文件下载"></a>文件下载</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Test</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">testCopyToLocalFile</span><span class="params">()</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">    <span class="comment">// 从 HDFS 拷贝的本机</span></span><br><span class="line">    fileSystem.copyToLocalFile(<span class="keyword">new</span> Path(<span class="string">"/error.log"</span>), <span class="keyword">new</span> Path(<span class="string">"d:\\log\\copy-to-local.log"</span>));</span><br><span class="line">    <span class="comment">// 参数1：是否删除源数据，参数2：HDFS，参数3：本地路径，参数4：是否开启本地模式校验</span></span><br><span class="line">    <span class="comment">// 参数4： 为true 时，下载成功后不会生成 .crc 文件，为 false 时会生成 .crc 文件</span></span><br><span class="line">    <span class="comment">// .crc 文件：校验数据可靠性的文件</span></span><br><span class="line">    fileSystem.copyToLocalFile(<span class="keyword">false</span>, <span class="keyword">new</span> Path(<span class="string">"/error.log"</span>), <span class="keyword">new</span> Path(<span class="string">"d:\\log\\copy-to-local-1.log"</span>), <span class="keyword">true</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="文件删除"><a href="#文件删除" class="headerlink" title="文件删除"></a>文件删除</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Test</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">testDelete</span><span class="params">()</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">    <span class="comment">// 参数1：HDFS</span></span><br><span class="line">    <span class="comment">// 参数2：是否递归删除，当参数1是文件夹时，需要设置为 true，否则报错</span></span><br><span class="line">    fileSystem.delete(<span class="keyword">new</span> Path(<span class="string">"/error1.log"</span>), <span class="keyword">false</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="文件改名"><a href="#文件改名" class="headerlink" title="文件改名"></a>文件改名</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Test</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">testRename</span><span class="params">()</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">    <span class="comment">// 参数1：要修改的 HDFS</span></span><br><span class="line">    <span class="comment">// 参数2：修改为 HDFS</span></span><br><span class="line">    fileSystem.rename(<span class="keyword">new</span> Path(<span class="string">"/error.log"</span>), <span class="keyword">new</span> Path(<span class="string">"/log.out"</span>));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="查看文件详情"><a href="#查看文件详情" class="headerlink" title="查看文件详情"></a>查看文件详情</h2><p>可以查看文件名称、权限、长度、块信息等</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">testListFiles</span><span class="params">()</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">    <span class="comment">// 参数1：HDFS</span></span><br><span class="line">    <span class="comment">// 参数2：是否遍历</span></span><br><span class="line">    <span class="comment">// 返回值：获取到的文件信息迭代器</span></span><br><span class="line">    RemoteIterator&lt;LocatedFileStatus&gt; files = fileSystem.listFiles(<span class="keyword">new</span> Path(<span class="string">"/"</span>), <span class="keyword">false</span>);</span><br><span class="line">    <span class="keyword">while</span> (files.hasNext()) &#123;</span><br><span class="line">        <span class="comment">// 文件信息</span></span><br><span class="line">        LocatedFileStatus next = files.next();</span><br><span class="line">        System.out.println(next);</span><br><span class="line">        <span class="keyword">for</span> (BlockLocation blockLocation : next.getBlockLocations()) &#123;</span><br><span class="line">            <span class="comment">// 块信息</span></span><br><span class="line">            System.out.println(blockLocation);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>返回值：<br><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">// 文件信息</span><br><span class="line">&#123;</span><br><span class="line">    "path": "hdfs://hadoop02:9000/error1.log",   // 文件路径</span><br><span class="line">    "isDirectory": false,                       // 是否是文件夹</span><br><span class="line">    "length":1349614,               // 文件长度</span><br><span class="line">    "replication": 2,           // 副本数</span><br><span class="line">    "blocksize": 134217728,     // 块大小</span><br><span class="line">    "modification_time": 1574819199782, // 修改时间</span><br><span class="line">    "access_time": 1574819199617,  </span><br><span class="line">    "owner": "root",                // 所有者</span><br><span class="line">    "group": "supergroup",          // 所有组</span><br><span class="line">    "permission": "rw-r--r--",      // 权限</span><br><span class="line">    "isSymlink": false</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">// 块信息</span><br><span class="line">// 分别代表：起始位置，结束位置，块所在的hadoop服务器</span><br><span class="line">0,1349614,hadoop03,hadoop02</span><br></pre></td></tr></table></figure></p><h2 id="判断是否是文件夹"><a href="#判断是否是文件夹" class="headerlink" title="判断是否是文件夹"></a>判断是否是文件夹</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Test</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">testIsDir</span><span class="params">()</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">    RemoteIterator&lt;LocatedFileStatus&gt; files = fileSystem.listFiles(<span class="keyword">new</span> Path(<span class="string">"/"</span>), <span class="keyword">true</span>);</span><br><span class="line">    <span class="keyword">while</span> (files.hasNext()) &#123;</span><br><span class="line">        System.out.println(files.next().getPath().getName() + <span class="string">" 是否是文件夹？"</span> + !files.next().isFile());</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><hr><h1 id="HDFS-I-O-流操作"><a href="#HDFS-I-O-流操作" class="headerlink" title="HDFS I/O 流操作"></a>HDFS I/O 流操作</h1><h2 id="文件上传-1"><a href="#文件上传-1" class="headerlink" title="文件上传"></a>文件上传</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Test</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">testPutFileToHdfs</span><span class="params">()</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 2、获取输入流</span></span><br><span class="line"></span><br><span class="line">    FileInputStream inputStream = <span class="keyword">new</span> FileInputStream(<span class="keyword">new</span> File(<span class="string">"d:/log/error.log"</span>));</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 3、获取输出流</span></span><br><span class="line">    FSDataOutputStream fsDataOutputStream = fileSystem.create(<span class="keyword">new</span> Path(<span class="string">"/test-io.log"</span>));</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 4、流的对拷</span></span><br><span class="line">    IOUtils.copyBytes(inputStream, fsDataOutputStream, configuration);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 5、关闭资源</span></span><br><span class="line">    IOUtils.closeStream(inputStream);</span><br><span class="line">    IOUtils.closeStream(fsDataOutputStream);</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="文件下载-1"><a href="#文件下载-1" class="headerlink" title="文件下载"></a>文件下载</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Test</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">testGetFileFromHdfs</span><span class="params">()</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">    <span class="comment">// 获取输入流</span></span><br><span class="line">    FSDataInputStream inputStream = fileSystem.open(<span class="keyword">new</span> Path(<span class="string">"/log.out"</span>));</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 获取输出流</span></span><br><span class="line">    FileOutputStream outputStream = <span class="keyword">new</span> FileOutputStream(<span class="keyword">new</span> File(<span class="string">"d:/log/log1.out"</span>));</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 流的对拷</span></span><br><span class="line">    IOUtils.copyBytes(inputStream, outputStream, configuration);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 关闭资源</span></span><br><span class="line">    IOUtils.closeStream(outputStream);</span><br><span class="line">    IOUtils.closeStream(inputStream);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="HDFS-文件定位读取"><a href="#HDFS-文件定位读取" class="headerlink" title="HDFS 文件定位读取"></a>HDFS 文件定位读取</h2><p>先往 HDFS 中上传一个大于 128M 的文件，在管理器中查看一下文件的<code>分块大于1</code>。</p><p><img src="/images/hadoop/client/more-block.png" alt="大于1块的文件"></p><p>可见当前文件分为了两块存储。如果此时进行下载，会将两块数据合并起来下载。但如果只想要下载其中的一部分，现在的下载方法无法实现。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 只读取第一块的数据</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">testReadFileSeek1</span><span class="params">()</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">    <span class="comment">// 获取输入流</span></span><br><span class="line">    FSDataInputStream inputStream = fileSystem.open(<span class="keyword">new</span> Path(<span class="string">"/hadoop-2.7.2.tar.gz"</span>));</span><br><span class="line"></span><br><span class="line">    FileOutputStream outputStream = <span class="keyword">new</span> FileOutputStream(<span class="string">"d:/log/hadoop.part1"</span>);</span><br><span class="line"></span><br><span class="line">    <span class="comment">//  只拷贝 128 M</span></span><br><span class="line">    <span class="keyword">byte</span>[] buffer = <span class="keyword">new</span> <span class="keyword">byte</span>[<span class="number">1024</span>];</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="number">1024</span> * <span class="number">128</span>; i++) &#123;</span><br><span class="line">        inputStream.read(buffer);</span><br><span class="line">        outputStream.write(buffer);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    IOUtils.closeStream(outputStream);</span><br><span class="line">    IOUtils.closeStream(inputStream);</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 再读取第二块</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">testReadFileSeek2</span><span class="params">()</span> <span class="keyword">throws</span> IOException</span>&#123;</span><br><span class="line">    <span class="comment">// 获取输入流</span></span><br><span class="line">    FSDataInputStream inputStream = fileSystem.open(<span class="keyword">new</span> Path(<span class="string">"/hadoop-2.7.2.tar.gz"</span>));</span><br><span class="line">    <span class="comment">// 指定读取开始点</span></span><br><span class="line">    inputStream.seek(<span class="number">1024</span> * <span class="number">1024</span> * <span class="number">128</span>);</span><br><span class="line">    <span class="comment">// 获取输出流</span></span><br><span class="line">    FileOutputStream outputStream = <span class="keyword">new</span> FileOutputStream(<span class="string">"d:/log/hadoop.part2"</span>);</span><br><span class="line">    <span class="comment">// 对拷</span></span><br><span class="line">    IOUtils.copyBytes(inputStream, outputStream, configuration);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 关闭资源</span></span><br><span class="line">    IOUtils.closeStream(outputStream);</span><br><span class="line">    IOUtils.closeStream(inputStream);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 拼接两块数据</span></span><br><span class="line"><span class="comment">// 由于当前是 windows 环境，使用 cmd 窗口拼接。</span></span><br><span class="line"><span class="comment">// cmd 进入两块所在目录</span></span><br><span class="line"><span class="comment">// 命令：type hadoop.part2 &gt;&gt; hadoop.part1</span></span><br><span class="line"><span class="comment">// 再把 part1 的后缀改为 tar.gz 即可查看</span></span><br></pre></td></tr></table></figure><hr><h1 id="HDFS-读写数据流程"><a href="#HDFS-读写数据流程" class="headerlink" title="HDFS 读写数据流程"></a>HDFS 读写数据流程</h1><h2 id="HDFS-写数据流程"><a href="#HDFS-写数据流程" class="headerlink" title="HDFS 写数据流程"></a>HDFS 写数据流程</h2><ol><li>使用 FileSystem.get 创建一个<code>分布式文件系统</code>客户端，向 NameNode 请求上传文件</li><li>NameNode 检查 HDFS 中是否有待上传的文件（根据路径、文件名判断），如果存在该文件，则报错<code>文件已存在</code></li><li>如果 NameNode 检查后，HDFS 没有待上传的文件，则开始响应上传文件</li><li>请求上传第一个 block（根据配置不同，block 大小也不同），此时会向 DataNode 请求，由 DataNode 决定可以上传到哪几个节点上</li><li>DataNode 返回可以上传的节点（判断条件：节点距离，负载）</li><li>FileSystem 创建输出流（FsDataOutputStream），与 DataNode 建立通道（串行）</li><li>DataNode 应答，所有可上传节点应答成功后，开始传输数据</li><li>所有数据传输完成后，通知 NameNode</li></ol><p><img src="/images/hadoop/client/write-data.png" alt="hdfs 写数据流程"></p><h3 id="节点距离计算"><a href="#节点距离计算" class="headerlink" title="节点距离计算"></a>节点距离计算</h3><p><code>节点距离：两个节点到最近的共同祖先的距离总和</code></p><p>HDFS 写数据过程中，NameNode 会选择距离上传数据最近距离的 DataNode 接收数据，此时需要计算节点距离。</p><p><img src="/images/hadoop/client/distance.png" alt="节点距离"></p><blockquote><p>(d1-r1-n0, d1-r1-n0)，由于这两个节点在同一个服务器上，此时距离为 0。即：同一节点上的进程距离为 0。<br>(d1-r1-n1, d1-r1-n2)，由于这两个节点都在同一个机架上，所以 n1、n2 的共同祖先都为 r1，此时距离为 1+1=2<br>(d1-r2-n0, d1-r3-n2)，这两个节点在同一个集群的不同机架上，即这两个节点的共同祖先为 d1，节点到集群还需要经过机架，所以这两个节点到共同祖先的距离都为 2，则节点距离为 2+2=4<br>(d1-r2-n1, d2-r4-n1)，这两个节点也不在同一个集群，则共同祖先为最外围的“网段”，此时每个节点到“网段”的距离都为 3，所以节点距离为 3+3=6</p></blockquote><h3 id="机架感知（副本存储节点选择）"><a href="#机架感知（副本存储节点选择）" class="headerlink" title="机架感知（副本存储节点选择）"></a>机架感知（副本存储节点选择）</h3><p>默认情况下，当副本数为 3 时，HDFS 的副本策略是在 <code>本地机架</code> 上的一个节点放置一个副本，在 <code>本地机架的另外一个节点</code> 上放置一个副本，最后再 <code>另外一个机架</code> 的不同节点上防止最后一个副本。</p><p>老版本的 hadoop 正好相反，是在 <code>本地机架</code> 上放置一个副本，在 <code>另外一个机架</code> 上放置 2 个副本。</p><p><img src="/images/hadoop/client/fuben.png" alt="默认情况下副本选择情况"></p><h2 id="HDFS-读数据流程"><a href="#HDFS-读数据流程" class="headerlink" title="HDFS 读数据流程"></a>HDFS 读数据流程</h2><ol><li>客户端请求下载文件（向 NameNode 发送请求）</li><li>NameNode 返回目标文件元数据</li><li>客户端创建输入流</li><li>客户端请求读取数据（根据距离决定从那个 DataNode 获取数据）</li><li>DataNode 传输数据</li></ol><p><img src="/images/hadoop/client/read-data.png" alt="读数据流程"></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;此前，完成了一个基础的完全分布式集群，并且使用 Java 程序代码实现测试连通了 Hadoop 集群，且在 HDFS 中创建了一个文件夹。由此开始学习 Hadoop 的一些 Java API 操作。&lt;/p&gt;
    
    </summary>
    
      <category term="hadoop" scheme="https://www.laiyy.top/categories/hadoop/"/>
    
      <category term="hdfs" scheme="https://www.laiyy.top/categories/hadoop/hdfs/"/>
    
    
      <category term="hadoop" scheme="https://www.laiyy.top/tags/hadoop/"/>
    
      <category term="hdfs" scheme="https://www.laiyy.top/tags/hdfs/"/>
    
  </entry>
  
  <entry>
    <title>Hadoop（5） &lt;br/&gt; HDFS</title>
    <link href="https://www.laiyy.top/hadoop/hdfs/hadoop-5.html"/>
    <id>https://www.laiyy.top/hadoop/hdfs/hadoop-5.html</id>
    <published>2019-09-22T09:01:31.000Z</published>
    <updated>2019-11-26T09:01:31.000Z</updated>
    
    <content type="html"><![CDATA[<p>在此前，已经成功启动、测试了 hadoop 集群的功能，了解了部分 hadoop 知识，下面就需要开始针对 hadoop 进行继续深入学习 HDFS、MapReduce 的知识。</p><a id="more"></a><h1 id="HDFS-概述"><a href="#HDFS-概述" class="headerlink" title="HDFS 概述"></a>HDFS 概述</h1><blockquote><p>HDFS 是一种分布式文件管理系统，用于文件存储，通过目录树来定位文件；其次，由于是分布式的，由多台服务器联合起来实现功能。<br>HDFS 使用场景：适合一次写入、多次独处的场景，且<code>不支持文件的修改</code>，适合用于做数据分析，不适合做网盘应用。</p></blockquote><h2 id="HDFS-的优缺点"><a href="#HDFS-的优缺点" class="headerlink" title="HDFS 的优缺点"></a>HDFS 的优缺点</h2><h3 id="优点"><a href="#优点" class="headerlink" title="优点"></a>优点</h3><blockquote><p>高容错性</p></blockquote><p>数据自动保存多个副本。通过增加副本的形式，提供了容错性。默认 3 个副本，当有其中一个副本挂掉了，会在其他服务器上再增加一个副本，保证最多有三个副本存在。且三个副本不能在同一个机器上</p><blockquote><p>适合处理大数据</p></blockquote><p>数据规模：能够处理 GB、TB、PB 级别数据<br>文件规模：能够处理百万以上的文件数量</p><blockquote><p>可以构建在廉价机器上，通过多副本机制，提高可靠性</p></blockquote><h3 id="缺点"><a href="#缺点" class="headerlink" title="缺点"></a>缺点</h3><blockquote><p>不适合低延迟数据访问：如毫秒级数据存储</p></blockquote><blockquote><p>无法高效的对大量小文件进行存储</p><blockquote><p>存储大量小文件的话，会占用 NameNode 大量内存来存储文件目录和块信息，这样是不可取的。NameNode 的内存总是有限的<br>小文件存储的寻址时间会超过读取时间，违反了 HDFS 的设计目标</p></blockquote></blockquote><blockquote><p>不支持并发写入、文件随机修改</p><blockquote><p>一个文件只能有一个写，不允许多个线程同时写<br>仅支持数据的追加(append)，不支持文件随机修改</p></blockquote></blockquote><h2 id="HDFS-组成架构"><a href="#HDFS-组成架构" class="headerlink" title="HDFS 组成架构"></a>HDFS 组成架构</h2><p><img src="/images/hadoop/hdfs/hdfs.png" alt="HDFS"></p><blockquote><p>NameNode(nn)：就是 Master，是一个管理者</p></blockquote><p>管理HDFS 的命名空间；配置副本策略；管理数据块映射信息；处理客户端读写请求</p><blockquote><p>DataNode：就是 Slave。NameNode 下达命令，DataNode 执行实际操作。</p></blockquote><p>存储实际的数据块；执行数据块的读/写操作</p><blockquote><p>Client：客户端</p></blockquote><ol><li>文件切分。文件上传到 HDFS 的时候，Client 将文件切分成一个一个的 Block（默认 128M）然后进行上传</li><li>与 NameNode 交互，获取文件位置信息</li><li>与 DataNode 交互，读取、写入数据</li><li>提供一些命令管理 HDFS，如 NameNode 格式化</li><li>通过一些命令访问 HDFS，如对 HDFS 的增删改查</li></ol><blockquote><p>Secondary NameNode：非 NameNode 热备，当 NameNode 挂掉后，并不会马上替换 NameNode 提供服务</p></blockquote><ol><li>辅助 NameNode，分担其工作，如：定期合并 Fsimage(镜像文件)、Edits(编辑日志)，并推送到 NameNode</li><li>紧急情况下辅助恢复 NameNode，但是可能会丢失数据</li></ol><h2 id="HDFS-文件块大小"><a href="#HDFS-文件块大小" class="headerlink" title="HDFS 文件块大小"></a>HDFS 文件块大小</h2><p>HDFS 中的文件上是分块存储（Block），大小可通过参数配置 (dfs.blocksize)，默认在 2.X 中为 128M，1.X 为 64M</p><p>HDFS 块大小设置主要取决于磁盘传输速度。</p><hr><h1 id="自带-Shell-操作"><a href="#自带-Shell-操作" class="headerlink" title="自带 Shell 操作"></a>自带 Shell 操作</h1><h2 id="基本语法"><a href="#基本语法" class="headerlink" title="基本语法"></a>基本语法</h2><p>bin/hadoop fs 具体命令<br>bin/hdfs dfs 具体命令</p><h3 id="常用命令"><a href="#常用命令" class="headerlink" title="常用命令"></a>常用命令</h3><ol><li><p>启动集群</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sbin/start-dfs.sh</span><br><span class="line">sbin/start-yarn.sh</span><br></pre></td></tr></table></figure></li><li><p>获取帮助文档</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -<span class="built_in">help</span> [<span class="built_in">command</span>]</span><br></pre></td></tr></table></figure></li><li><p>查看 HDFS 目录信息</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -ls</span><br><span class="line">hadoop fs -l -R [dir path] <span class="comment"># 递归查询</span></span><br></pre></td></tr></table></figure></li><li><p>在 HDFS 上创建目录</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -mkdir -p [your dir path]<span class="comment"># 创建多级目录</span></span><br></pre></td></tr></table></figure></li><li><p>将本地文件剪切到 HDFS</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -moveFromLocal [<span class="built_in">local</span> file] [hdfs]</span><br></pre></td></tr></table></figure></li><li><p>追加一个文件到已经存在的文件末尾</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -appendToFile [<span class="built_in">local</span> file] [hdfs]</span><br></pre></td></tr></table></figure></li></ol><p>可能的报错信息 1：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">appendToFile: Failed to APPEND_FILE /user/laiyy/haha.txt for DFSClient_NONMAPREDUCE_-1628325628_1 on 192.168.233.131 because lease recovery is in progress. Try again later.</span><br></pre></td></tr></table></figure></p><p>可能的报错信息 2：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ava.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[192.168.233.131:50010,DS-f6860e33-55fb-44b1-9b95-4a61b0264267,DISK], DatanodeInfoWithStorage[192.168.233.133:50010,DS-8191d13c-f9c0-4d3c-8e3d-fa29d8a76ee5,DISK]], original=[DatanodeInfoWithStorage[192.168.233.131:50010,DS-f6860e33-55fb-44b1-9b95-4a61b0264267,DISK], DatanodeInfoWithStorage[192.168.233.133:50010,DS-8191d13c-f9c0-4d3c-8e3d-fa29d8a76ee5,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via &apos;dfs.client.block.write.replace-datanode-on-failure.policy&apos; in its configuration.</span><br></pre></td></tr></table></figure></p><p>错误原因：<br>1、使用 jps 查看三台机器上的 DataNode 是否都存在，如果缺少了某个 DataNode，则会出现这种错误。<br>2、如果三台 DataNode 都存在，则查看三台机器上的 <code>%HADOOP_HOME%/data/dfs/data/current/VERSION</code> 和 <code>%HADOOP_HOME%/data/dfs/name/current/VERSION</code> 文件，对比三台机器上的文件，查看 namenode 的 <code>namespaceID</code>、<code>clusterID</code> 是否一致，查看 datanode 的 <code>storageID</code>、<code>clusterID</code> 是否一致。如果不一致，则会出现这种错误。</p><p>解决办法：</p><blockquote><p>第一步：停止集群 <code>sbin/stop-dfs.sh</code>、<code>sbin/stop-yarn.sh</code><br>第二步：删除 <code>%HADOOP_HOME%/data</code> 下的数据<br>第三步：格式化 NameNode <code>bin/hdfs namenode -format</code><br>第四步：重启集群 <code>sbin/start-dfs.sh</code>、<code>sbin/start-yarn.sh</code></p></blockquote><ol start="7"><li>将本地文件复制到 HDFS</li></ol><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -copyFromLocal [<span class="built_in">local</span> file] [hdfs]</span><br><span class="line">hadoop fs -put [<span class="built_in">local</span> file] [hdfs]</span><br></pre></td></tr></table></figure><ol start="8"><li>从 HDFS 拷贝到本地 </li></ol><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -copyToLocal [hdfs] [<span class="built_in">local</span> path]</span><br><span class="line">hadoop fs -get [hdfs] [<span class="built_in">local</span> path]</span><br></pre></td></tr></table></figure><ol start="9"><li>从 HDFS 的一个路径，拷贝到另外一个路径</li></ol><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -cp [hdfs] [hdfs]</span><br></pre></td></tr></table></figure><ol start="10"><li>从 HDFS 的一个路径，剪切到另外一个路径</li></ol><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -mv [hdfs] [hdfs]</span><br></pre></td></tr></table></figure><ol start="11"><li>合并下载多个文件</li></ol><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -getmerge [hadfs] [<span class="built_in">local</span> path]</span><br><span class="line"><span class="comment"># like：[hadoop fs -getmerge /user/laiyy/* merge.txt]</span></span><br></pre></td></tr></table></figure><ol start="12"><li>查看文件</li></ol><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -tail [hdfs txt file]</span><br></pre></td></tr></table></figure><ol start="13"><li>删除文件</li></ol><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -rm [hdfs]</span><br></pre></td></tr></table></figure><ol start="14"><li>删除空目录</li></ol><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -rmdir [hdfs empty dir]</span><br></pre></td></tr></table></figure><ol start="15"><li>统计文件夹大小信息</li></ol><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -du -s -h [hdfs]</span><br></pre></td></tr></table></figure><ol start="16"><li>设置 HDFS 文件副本数量</li></ol><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -setrep [num] [hdfs]</span><br></pre></td></tr></table></figure><hr><h1 id="HDFS-客户端环境测试"><a href="#HDFS-客户端环境测试" class="headerlink" title="HDFS 客户端环境测试"></a>HDFS 客户端环境测试</h1><h2 id="pom"><a href="#pom" class="headerlink" title="pom"></a>pom</h2><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependencies</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>junit<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>junit<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">version</span>&gt;</span>4.12<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.logging.log4j<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>log4j-core<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.12.1<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.hadoop<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>hadoop-client<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.7.2<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.hadoop<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>hadoop-common<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.7.2<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.hadoop<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>hadoop-hdfs<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.7.2<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependencies</span>&gt;</span></span><br></pre></td></tr></table></figure><h2 id="测试使用客户端创建目录"><a href="#测试使用客户端创建目录" class="headerlink" title="测试使用客户端创建目录"></a>测试使用客户端创建目录</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">Configuration configuration = <span class="keyword">new</span> Configuration();</span><br><span class="line"><span class="comment">// 指定 NameNode（从 core-site.xml 中获取）</span></span><br><span class="line">configuration.set(<span class="string">"fs.defaultFS"</span>,<span class="string">"hdfs://hadoop02:9000"</span>);</span><br><span class="line"><span class="comment">// 获取 hdfs 客户端</span></span><br><span class="line">FileSystem fileSystem = FileSystem.get(configuration);</span><br><span class="line"><span class="comment">// 在 hdfs 上创建路径</span></span><br><span class="line">fileSystem.mkdirs(<span class="keyword">new</span> Path(<span class="string">"/laiyy"</span>));</span><br><span class="line"><span class="comment">// 关闭资源</span></span><br><span class="line">fileSystem.close();</span><br></pre></td></tr></table></figure><p>运行结果：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">org.apache.hadoop.security.AccessControlException: Permission denied: user=Administrator, access=WRITE, inode=&quot;/laiyy&quot;:root:supergroup:drwxr-xr-x</span><br><span class="line">at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:319)</span><br><span class="line">at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:292)</span><br><span class="line">at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:213)</span><br><span class="line">at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:190)</span><br><span class="line">at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1720)</span><br></pre></td></tr></table></figure></p><p>错误原因： 使用 win10 调用 hadoop，用户为 <code>Administrator</code>，而 HDFS 的用户为 <code>root</code>，用户权限不足</p><p>解决方法： 在运行 main 方法时，动态的给定一hadoop用户值。</p><p><img src="/images/hadoop/client/hadoop-user-name.png" alt="Hadoop username"></p><p>再次运行：</p><p><img src="/images/hadoop/client/client-create-dir.png" alt="client create dir"></p><h2 id="另一种方式"><a href="#另一种方式" class="headerlink" title="另一种方式"></a>另一种方式</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">Configuration configuration = <span class="keyword">new</span> Configuration();</span><br><span class="line"><span class="comment">// 获取 hdfs 客户端；参数1：NameNode地址，参数2：配置信息，参数3：hadoop 用户</span></span><br><span class="line">FileSystem fileSystem = FileSystem.get(<span class="keyword">new</span> URI(<span class="string">"hdfs://hadoop02:9000"</span>), configuration, <span class="string">"root"</span>);</span><br><span class="line"><span class="comment">// 在 hdfs 上创建路径</span></span><br><span class="line">fileSystem.mkdirs(<span class="keyword">new</span> Path(<span class="string">"/laiyy"</span>));</span><br><span class="line"><span class="comment">// 关闭资源</span></span><br><span class="line">fileSystem.close();</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;在此前，已经成功启动、测试了 hadoop 集群的功能，了解了部分 hadoop 知识，下面就需要开始针对 hadoop 进行继续深入学习 HDFS、MapReduce 的知识。&lt;/p&gt;
    
    </summary>
    
      <category term="hadoop" scheme="https://www.laiyy.top/categories/hadoop/"/>
    
      <category term="hdfs" scheme="https://www.laiyy.top/categories/hadoop/hdfs/"/>
    
    
      <category term="hadoop" scheme="https://www.laiyy.top/tags/hadoop/"/>
    
      <category term="hdfs" scheme="https://www.laiyy.top/tags/hdfs/"/>
    
  </entry>
  
  <entry>
    <title>Hadoop（4） &lt;br/&gt; 完全分布式</title>
    <link href="https://www.laiyy.top/hadoop/hadoop-4.html"/>
    <id>https://www.laiyy.top/hadoop/hadoop-4.html</id>
    <published>2019-09-21T09:01:31.000Z</published>
    <updated>2019-09-21T09:01:31.000Z</updated>
    
    <content type="html"><![CDATA[<p>在之前的例子中，完成了一个单机版的 Hadoop + HDFS + YARN 的搭建过程，并成功执行测试成功。<br>本例中将尝试搭建一个完全分布式的 Hadoop 集群，并验证测试。</p><a id="more"></a><h1 id="Hadoop-集群准备"><a href="#Hadoop-集群准备" class="headerlink" title="Hadoop 集群准备"></a>Hadoop 集群准备</h1><p>Hadoop 集群需要准备至少三台 Linux 主机（<code>hadoop02</code>、<code>hadoop03</code>、<code>hadoop04</code>），本例使用 VM 模拟三台 CentOS 7 主机。三台主机环境需要一致，都需要关闭防火墙、设置静态 ip、设置主机名称、JDK、Hadoop 等安装</p><h2 id="虚拟机准备"><a href="#虚拟机准备" class="headerlink" title="虚拟机准备"></a>虚拟机准备</h2><p>以 hadoop01 为源，克隆三台虚拟机 <code>hadoop02</code>、<code>hadoop03</code>、<code>hadoop04</code></p><h2 id="编写一个集群分发脚本"><a href="#编写一个集群分发脚本" class="headerlink" title="编写一个集群分发脚本"></a>编写一个集群分发脚本</h2><p>需要 linux 中事先安装有 <code>rsync</code> 脚本。如果执行命令 <code>rsync</code> 提示没有此命令，在 CentOS 下，执行 <code>yum install -y rsync</code> 安装即可。</p><p>需求：循环复制文件到所有节点的相同目录下</p><p>在 hadoop01 的 root 用户家目录中，创建一个 bin 目录用于存放脚本，并创建 <code>xsync</code> 脚本文件</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#!/bin/bash</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 获取输入参数的个数，如果没有参数，直接退出</span></span><br><span class="line">params=<span class="variable">$#</span></span><br><span class="line"><span class="keyword">if</span>((params==0)); <span class="keyword">then</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">'please input param'</span></span><br><span class="line"><span class="built_in">exit</span>;</span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 获取文件名称</span></span><br><span class="line">param_1=<span class="variable">$1</span></span><br><span class="line">file_name=`basename <span class="variable">$param_1</span>`</span><br><span class="line"><span class="built_in">echo</span> <span class="string">'file_name is $file_name'</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 获取上级目录的绝对路径</span></span><br><span class="line">dir=`<span class="built_in">cd</span> -P $(dirname <span class="variable">$param_1</span>); <span class="built_in">pwd</span>`</span><br><span class="line"><span class="built_in">echo</span> <span class="string">'dir is $dir'</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 获取当前用户名称</span></span><br><span class="line">user=`whoami`</span><br><span class="line"></span><br><span class="line"><span class="comment"># 循环 hadoop02-04，同步文件</span></span><br><span class="line"><span class="keyword">for</span>((host=2;host&lt;=4;host++)); <span class="keyword">do</span></span><br><span class="line">    <span class="built_in">echo</span> <span class="string">'rsync file to hadoop0$host'</span></span><br><span class="line">    rsync -rvl <span class="variable">$dir</span>/<span class="variable">$file_name</span> <span class="variable">$user</span>@hadoop0<span class="variable">$host</span>:<span class="variable">$dir</span></span><br><span class="line"><span class="keyword">done</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">echo</span> <span class="string">'rsync file done'</span></span><br></pre></td></tr></table></figure><p>需要注意：</p><ol><li>执行当前脚本的 user 必须有权限操作当前主机待分发的文件或文件夹；也必须在对应的需要分发的主机上拥有此用户，且有操作对应文件夹的权限。</li><li>待分发的文件、文件夹必须使用绝对路径，以保证同步到对应主机的位置也是正确的</li></ol><blockquote><p>测试分发脚本</p></blockquote><p>执行 <code>xsync /root/bin</code>，在 hadoop02-04 上查看 /root 目录下是否同步了 xsync 脚本</p><p><img src="/images/hadoop/full-dis/xsync.png" alt="xsync"></p><p><strong><em>注意：如果 xsync 命令识别不了，可以把 xsync 文件放置在 /usr/local/bin 目录下</em></strong></p><h1 id="集群部署"><a href="#集群部署" class="headerlink" title="集群部署"></a>集群部署</h1><h2 id="集群部署规划"><a href="#集群部署规划" class="headerlink" title="集群部署规划"></a>集群部署规划</h2><table><thead><tr><th style="text-align:center"></th><th style="text-align:center">hadoop02</th><th style="text-align:center">hadoop03</th><th style="text-align:center">hadoop04</th></tr></thead><tbody><tr><td style="text-align:center">HDFS</td><td style="text-align:center">NamdeNode、DataNode</td><td style="text-align:center">DataNode</td><td style="text-align:center">SecondaryNameNode</td></tr><tr><td style="text-align:center">YARN</td><td style="text-align:center">NodeManager</td><td style="text-align:center">ResourceManager、NodeManager</td><td style="text-align:center">NodeManager</td></tr></tbody></table><p>需要保证：</p><blockquote><p>NameNode 和 SecondaryNameNode 不在一台机器上<br>ResourceManager 上没有 NameNode 和 SecondaryNameNode，防止内存消耗过大</p></blockquote><h2 id="核心配置文件"><a href="#核心配置文件" class="headerlink" title="核心配置文件"></a>核心配置文件</h2><blockquote><p>core-site.xml</p></blockquote><p>在 <code>hadoop02</code>  上，修改 core-site.xml 文件</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- 修改 hdfs 地址 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>fs.defaultFS<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>hdfs://hadoop02:9000<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- 修改 hadoop 运行时的数据存储位置，可以不存在，启动时会自动创建 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>hadoop.tmp.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>/opt/module/hadoop-2.7.2/data/tmp<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure><blockquote><p>HDFS</p></blockquote><p>修改 hadoop-env.sh 中的 JAVA_HOME <code>export JAVA_HOME=/opt/module/jdk1.8.0_144</code></p><p>修改 hdfs-site.xml 文件<br><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- 副本数量改为3 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.replication<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>3<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- 指定 hadoop 辅助名称节点主机配置（SecondaryNameNode，2nn） --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.secondary.http-address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop04:50090<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure></p><blockquote><p>YARN</p></blockquote><p>修改 yarn-env.sh、mapred-env.sh 中的 JAVA_HOME <code>export JAVA_HOME=/opt/module/jdk1.8.0_144</code></p><p>修改 yarn-site.xml</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- 修改 reduce 获取数据的方式（洗牌） --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.aux-services<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>mapreduce_shuffle<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- 修改 resourcemanager 的 地址  --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.hostname<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop03<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- 开启日志聚集</span></span><br><span class="line"><span class="comment">    &lt;property&gt;</span></span><br><span class="line"><span class="comment">        &lt;name&gt;yarn.log-aggregation-enable&lt;/name&gt;</span></span><br><span class="line"><span class="comment">        &lt;value&gt;true&lt;/value&gt;</span></span><br><span class="line"><span class="comment">    &lt;/property&gt;</span></span><br><span class="line"><span class="comment">     --&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- 日志保留时间 7 天，单位：秒 </span></span><br><span class="line"><span class="comment">    &lt;property&gt;</span></span><br><span class="line"><span class="comment">        &lt;name&gt;yarn.log-aggregation.retain-seconds&lt;/name&gt;</span></span><br><span class="line"><span class="comment">        &lt;value&gt;604800&lt;/value&gt;</span></span><br><span class="line"><span class="comment">    &lt;/property&gt;</span></span><br><span class="line"><span class="comment">    --&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure><p>修改 mapred-site.xml<br><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- 指定 MR 运行在 YARN 上  --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.framework.name<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>yarn<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">&lt;!-- 修改历史服务器地址</span></span><br><span class="line"><span class="comment">    &lt;property&gt;</span></span><br><span class="line"><span class="comment">        &lt;name&gt;mapreduce.jobhistory.address&lt;/name&gt;</span></span><br><span class="line"><span class="comment">        &lt;value&gt;hadoop01:10020&lt;/value&gt;</span></span><br><span class="line"><span class="comment">    &lt;/property&gt;</span></span><br><span class="line"><span class="comment">    --&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- 修改历史服务器 WebUI 地址</span></span><br><span class="line"><span class="comment">    &lt;property&gt;</span></span><br><span class="line"><span class="comment">        &lt;name&gt;mapreduce.jobhistory.webapp.address&lt;/name&gt;</span></span><br><span class="line"><span class="comment">        &lt;value&gt;hadoop01:19888&lt;/value&gt;</span></span><br><span class="line"><span class="comment">    &lt;/property&gt;</span></span><br><span class="line"><span class="comment">    --&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure></p><blockquote><p>将修改后的配置文件同步到 03、04 上</p></blockquote><p><code>xsync /opt/module/hadoop-2.7.2/etc/hadoop/</code> 即可</p><h1 id="集群启动"><a href="#集群启动" class="headerlink" title="集群启动"></a>集群启动</h1><h2 id="集群单点启动"><a href="#集群单点启动" class="headerlink" title="集群单点启动"></a>集群单点启动</h2><blockquote><p>第一次启动需要格式化 NameNode</p></blockquote><p><code>bin/hdfs namenode -format</code></p><blockquote><p>启动</p></blockquote><p>在 <code>hadoop02</code> 上执行 <code>sbin/hadoop-daemon.sh start namenode</code> 及 <code>sbin/hadoop-daemon.sh start datanode</code></p><p>在 <code>hadoop03</code> 上执行 <code>sbin/hadoop-daemon.sh start datanode</code></p><p>在 <code>hadoop04</code> 上执行 <code>sbin/hadoop-daemon.sh start datanode</code></p><h2 id="集群群起"><a href="#集群群起" class="headerlink" title="集群群起"></a>集群群起</h2><h3 id="ssh-免密登陆"><a href="#ssh-免密登陆" class="headerlink" title="ssh 免密登陆"></a>ssh 免密登陆</h3><p>在 <code>hadoop02</code> 上使用 <code>ssh-keygen</code> 生成秘钥，将生成后的 <code>id_rsa.pub</code> 文件中的内容，拷贝到 <code>hadoop03</code>、<code>hadoop04</code> 中</p><p>在 <code>hadoop02</code> 中使用 <code>ssh-copy-id hadoop02</code>、<code>ssh-copy-id hadoop03</code>、<code>ssh-copy-id hadoop04</code> 命令拷贝公钥。</p><p>如果不将公钥拷贝到本机，使用 <code>ssh hadoop02</code> 登陆本机时也需要输入密码。</p><p>此时即完成 hadoop02 对 03、04 的免密登陆，以同样的方式，在 03、04 上实现免密登陆</p><h3 id="群起集群-HDFS"><a href="#群起集群-HDFS" class="headerlink" title="群起集群 HDFS"></a>群起集群 HDFS</h3><blockquote><p>配置 slaves</p></blockquote><p>在 hadoop02 中配置修改 <code>etc/hadoop/slaves</code> 文件，注意：文件内容不允许有空格，不允许有空行</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">vim etc/hadoop/slaves </span><br><span class="line"></span><br><span class="line">hadoop02</span><br><span class="line">hadoop03</span><br><span class="line">hadoop04</span><br></pre></td></tr></table></figure><blockquote><p>分发到 03、04 上： <code>xsync etc/hadoop/slaves</code></p></blockquote><blockquote><p>停止现有的服务，群起服务</p></blockquote><p>在 hadoop02 中，使用命令 <code>sbin/start-dfs.sh</code> 群起服务<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop02 hadoop-2.7.2]# sbin/start-dfs.sh</span><br><span class="line">Starting namenodes on [hadoop02]</span><br><span class="line">hadoop02: starting namenode, logging to /opt/module/hadoop-2.7.2/logs/hadoop-root-namenode-hadoop02.out</span><br><span class="line">hadoop02: starting datanode, logging to /opt/module/hadoop-2.7.2/logs/hadoop-root-datanode-hadoop02.out</span><br><span class="line">hadoop04: starting datanode, logging to /opt/module/hadoop-2.7.2/logs/hadoop-root-datanode-hadoop04.out</span><br><span class="line">hadoop03: starting datanode, logging to /opt/module/hadoop-2.7.2/logs/hadoop-root-datanode-hadoop03.out</span><br><span class="line">Starting secondary namenodes [hadoop04]</span><br><span class="line">hadoop04: starting secondarynamenode, logging to /opt/module/hadoop-2.7.2/logs/hadoop-root-secondarynamenode-hadoop04.out</span><br></pre></td></tr></table></figure></p><p>使用 jps 在三台服务器上查看启动情况</p><h3 id="群起集群-YARN"><a href="#群起集群-YARN" class="headerlink" title="群起集群 YARN"></a>群起集群 YARN</h3><p><strong><em>注意：</em></strong> <code>由于在 yarn-site.xml 中存在配置 yarn.resourcemanager.hostname 的值为 hadoop03，所以在群起 yarn 时，必须在 hadoop03 上启动，否则会报错</code></p><p>使用命令 <code>sbin/start-yarn.sh</code> 群起 YARN<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop03 hadoop-2.7.2]# sbin/start-yarn.sh </span><br><span class="line">starting yarn daemons</span><br><span class="line">starting resourcemanager, logging to /opt/module/hadoop-2.7.2/logs/yarn-root-resourcemanager-hadoop03.out</span><br><span class="line">hadoop02: starting nodemanager, logging to /opt/module/hadoop-2.7.2/logs/yarn-root-nodemanager-hadoop02.out</span><br><span class="line">hadoop04: starting nodemanager, logging to /opt/module/hadoop-2.7.2/logs/yarn-root-nodemanager-hadoop04.out</span><br><span class="line">hadoop03: starting nodemanager, logging to /opt/module/hadoop-2.7.2/logs/yarn-root-nodemanager-hadoop03.out</span><br></pre></td></tr></table></figure></p><h3 id="查看启动结果"><a href="#查看启动结果" class="headerlink" title="查看启动结果"></a>查看启动结果</h3><blockquote><p>hadoop02</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop02 hadoop-2.7.2]# jps</span><br><span class="line">2353 DataNode</span><br><span class="line">2837 NodeManager</span><br><span class="line">2985 Jps</span><br><span class="line">2221 NameNode</span><br></pre></td></tr></table></figure><blockquote><p>hadoop03</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop03 hadoop-2.7.2]# jps</span><br><span class="line">2544 ResourceManager</span><br><span class="line">1932 DataNode</span><br><span class="line">2829 NodeManager</span><br><span class="line">2991 Jps</span><br></pre></td></tr></table></figure><blockquote><p>hadoop04</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop04 hadoop-2.7.2]# jps</span><br><span class="line">1745 DataNode</span><br><span class="line">2329 Jps</span><br><span class="line">1804 SecondaryNameNode</span><br><span class="line">2175 NodeManager</span><br></pre></td></tr></table></figure><hr><h1 id="集群时间同步"><a href="#集群时间同步" class="headerlink" title="集群时间同步"></a>集群时间同步</h1><p>使用 crontab 定时同步时间</p><h2 id="crontab-定时任务"><a href="#crontab-定时任务" class="headerlink" title="crontab 定时任务"></a>crontab 定时任务</h2><blockquote><p>基本语法： <code>crontab [command]</code></p></blockquote><table><thead><tr><th style="text-align:center">command</th><th style="text-align:center">功能</th></tr></thead><tbody><tr><td style="text-align:center">-e</td><td style="text-align:center">编辑 crontab 定时任务</td></tr><tr><td style="text-align:center">-l</td><td style="text-align:center">查询 crontab 任务</td></tr><tr><td style="text-align:center">-r</td><td style="text-align:center">删除当前用户所有的 crontab 任务</td></tr></tbody></table><blockquote><p>crontab 语法参数</p></blockquote><table><thead><tr><th style="text-align:center"></th><th style="text-align:center">含义</th><th style="text-align:center">范围</th></tr></thead><tbody><tr><td style="text-align:center">第一个 *</td><td style="text-align:center">一小时当中的第几分钟</td><td style="text-align:center">0~59</td></tr><tr><td style="text-align:center">第二个 *</td><td style="text-align:center">一天当中的第几个小时</td><td style="text-align:center">0~23</td></tr><tr><td style="text-align:center">第三个 *</td><td style="text-align:center">一个月当中的第几天</td><td style="text-align:center">1~31</td></tr><tr><td style="text-align:center">第四个 *</td><td style="text-align:center">一年当中的第几个月</td><td style="text-align:center">1~12</td></tr><tr><td style="text-align:center">第五个 *</td><td style="text-align:center">一周当中的星期几</td><td style="text-align:center">0~7(0 和 7 都代表星期日)</td></tr></tbody></table><blockquote><p>crontab 特殊符号</p></blockquote><table><thead><tr><th style="text-align:center">特殊符号</th><th style="text-align:center">含义</th></tr></thead><tbody><tr><td style="text-align:center">*</td><td style="text-align:center">代表任何时间</td></tr><tr><td style="text-align:center">,</td><td style="text-align:center">代表不连续的时间。如：“0 8,12,16 <em> </em> *”，代表每天 8点0分，12点0分，16点0分 执行</td></tr><tr><td style="text-align:center">-</td><td style="text-align:center">代表连续时间范围。如：“0 5 <em> </em> 1-6”，代表 周一到周六的凌晨5点0分 执行</td></tr><tr><td style="text-align:center">*/n</td><td style="text-align:center">代表每隔多久执行一次。如：“<em>10 </em> <em> </em> *”，代表每隔 10 分钟执行一次</td></tr></tbody></table><h2 id="时间同步"><a href="#时间同步" class="headerlink" title="时间同步"></a>时间同步</h2><h3 id="时间服务器-hadoop02"><a href="#时间服务器-hadoop02" class="headerlink" title="时间服务器(hadoop02)"></a>时间服务器(hadoop02)</h3><blockquote><p>查看 ntp 是否安装</p></blockquote><p>在 hadoop02 中，执行 <code>rpm -qa | grep ntp</code>，如果没有任何输出，则代表 ntp 没有安装。没有安装的情况下，执行 <code>yum install -y ntp</code> 进行安装。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop02 ~]# rpm -qa | grep ntp</span><br><span class="line">ntpdate-4.2.6p5-29.el7.centos.x86_64</span><br><span class="line">ntp-4.2.6p5-29.el7.centos.x86_64</span><br></pre></td></tr></table></figure></p><blockquote><p>修改 ntp 配置文件</p></blockquote><p>修改 <code>/etc/ntp.conf</code> 文件</p><ul><li>授权网段 <code>192.168.x.0-192.168.x.255</code> 上的机器都可以从 hadoop02 上查询和同步时间</li></ul><p>打开第 17 行的注释，修改网段即可。</p><p>将 <code>#restrict 192.168.1.0 mask 255.255.255.0 nomodify notrap</code> 修改为 <code>restrict 192.168.233.0 mask 255.255.255.0 nomodify notrap</code></p><ul><li>修改集群在局域网中不使用其他互联网时间</li></ul><p>将 <code>第21~24行</code> 注释即可。</p><ul><li>当该节点(hadoop02) 丢失网络连接，依然可用采用本地时间作为时间服务器为集群中的其他节点提供时间同步</li></ul><p>在上一步的位置增加如下配置<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">server 127.127.1.0</span><br><span class="line">fudge 127.127.1.0 stratum 10</span><br></pre></td></tr></table></figure></p><p><strong><em>注意</em></strong>：<br><br><code>127.0.0.1</code> 是本地地址 <br><br><code>127.127.1.0</code> 是回环地址</p><blockquote><p>修改 /etc/sysconfig/ntpd 文件</p></blockquote><p>在文件中增加 <code>SYNC_HWCLOCK=yes</code>，代表 保证硬件时间与系统时间一起同步</p><blockquote><p>启动/重启ntpd</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop02 ~]# systemctl status ntpd.service</span><br><span class="line">● ntpd.service - Network Time Service</span><br><span class="line">   Loaded: loaded (/usr/lib/systemd/system/ntpd.service; disabled; vendor preset: disabled)</span><br><span class="line">   Active: inactive (dead)  # 可以看到此时未启动</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">[root@hadoop02 ~]# systemctl start ntpd.service</span><br><span class="line">[root@hadoop02 ~]# systemctl status ntpd.service</span><br><span class="line">● ntpd.service - Network Time Service</span><br><span class="line">   Loaded: loaded (/usr/lib/systemd/system/ntpd.service; disabled; vendor preset: disabled)</span><br><span class="line">   Active: active (running) since 一 2019-09-23 17:04:23 CST; 3s ago # 可以看到此时是运行状态</span><br><span class="line">  Process: 1437 ExecStart=/usr/sbin/ntpd -u ntp:ntp $OPTIONS (code=exited, status=0/SUCCESS)</span><br><span class="line"> Main PID: 1438 (ntpd)</span><br><span class="line">   CGroup: /system.slice/ntpd.service</span><br><span class="line">           └─1438 /usr/sbin/ntpd -u ntp:ntp -g</span><br><span class="line">...</span><br></pre></td></tr></table></figure><p>设置开机启动：<code>systemctl enable ntpd.service</code></p><h3 id="其他机器-03、04"><a href="#其他机器-03、04" class="headerlink" title="其他机器(03、04)"></a>其他机器(03、04)</h3><p>在 03、04 上，使用 crontab 同步 02 的时间。</p><p>先随便修改一个时间 <code>date -s &#39;2018-11-11 11:11:11&#39;</code>，然后编写 crontab 脚本，每分钟从 hadoop02 上同步时间。等待一分钟后再次查看时间。</p><hr><h1 id="hadoop-源码编译"><a href="#hadoop-源码编译" class="headerlink" title="hadoop 源码编译"></a>hadoop 源码编译</h1><p>在 apache 的 hadoop 官方网站上，hadoop 源码是 32 位的，当需要 64 位的 hadoop 时，就需要重新编译源码</p><p>需要准备：</p><blockquote><p>能联网的 CentOS、hadoop 源码包、jdk 64 位，apache-ant、maven、protobuf 序列化框架</p></blockquote><p>本例使用版本：</p><blockquote><p>hadoop：1.7.2<br>apache-ant：1.9.9<br>maven：3.0.5<br>protobuf：2.5.0<br>jdk：1.8.0_144 64 bit</p></blockquote><p>另外需要安装插件：<code>yum install -y glibc-headers gcc-c++ make cmake openssl ncurses-devel</code> </p><p><strong><em>注意：所有操作必须在 root 用户下完成</em></strong></p><h2 id="安装-protobuf"><a href="#安装-protobuf" class="headerlink" title="安装 protobuf"></a>安装 protobuf</h2><p>解压 protobuf-2.5.0 到 /opt/module/，进入 /opt/module/protobuf-2.5.0/ 文件夹，依次执行下列命令：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">./configure</span><br><span class="line">make</span><br><span class="line">make check</span><br><span class="line">make install</span><br><span class="line">ldconfig</span><br></pre></td></tr></table></figure></p><p>修改环境变量，设置 protobuf 的环境到 PATH 中。<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">export LD_LIBRARY_PATH=/opt/module/protobuf-2.5.0</span><br><span class="line">export PATH=$PATH:$LD_LIBRARY_PATH</span><br></pre></td></tr></table></figure></p><p>验证 protobuf 安装是否成功 <code>protoc --version</code></p><h2 id="编译源码"><a href="#编译源码" class="headerlink" title="编译源码"></a>编译源码</h2><p>执行 <code>tar -zxf hadoop-2.7.2-src.tar.gz</code> 解压，然后执行 <code>mvn package -Pdist,native -DskipTests -Dtar</code>，成功后，编译好的 64 位安装包就在 hadoop-2.7.2-src/hadoop-dist/target 下。编译期间报错的话继续在此执行此命令就行。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;在之前的例子中，完成了一个单机版的 Hadoop + HDFS + YARN 的搭建过程，并成功执行测试成功。&lt;br&gt;本例中将尝试搭建一个完全分布式的 Hadoop 集群，并验证测试。&lt;/p&gt;
    
    </summary>
    
      <category term="hadoop" scheme="https://www.laiyy.top/categories/hadoop/"/>
    
    
      <category term="hadoop" scheme="https://www.laiyy.top/tags/hadoop/"/>
    
  </entry>
  
  <entry>
    <title>Hadoop（3） &lt;br/&gt; yarn、history server、logs server</title>
    <link href="https://www.laiyy.top/hadoop/hadoop-3.html"/>
    <id>https://www.laiyy.top/hadoop/hadoop-3.html</id>
    <published>2019-09-20T09:01:31.000Z</published>
    <updated>2019-09-20T09:01:31.000Z</updated>
    
    <content type="html"><![CDATA[<p>在上例中，测试了 HDFS 以及在 HDFS 下执行 MapReduce 示例。本例中，测试启动 YARN，并在 YARN 中执行 MapReduce 程序、并查看历史执行信息和执行日志信息</p><a id="more"></a><h1 id="配置-YARN"><a href="#配置-YARN" class="headerlink" title="配置 YARN"></a>配置 YARN</h1><h2 id="配置-yarn-env-sh"><a href="#配置-yarn-env-sh" class="headerlink" title="配置 yarn-env.sh"></a>配置 yarn-env.sh</h2><p>修改 yarn-env.sh 中的 JAVA_HOME</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vim etc/hadoop/yarn-env.sh</span><br></pre></td></tr></table></figure><p>将第 23 行的注释去掉，修改 JAVA_HOME 为 <code>export JAVA_HOME=/opt/module/jdk1.8.0_144</code></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">22 # some Java parameters</span><br><span class="line">23 # export JAVA_HOME=/home/y/libexec/jdk1.6.0/</span><br><span class="line">24 if [ &quot;$JAVA_HOME&quot; != &quot;&quot; ]; then</span><br><span class="line">25   #echo &quot;run java in $JAVA_HOME&quot;</span><br><span class="line">26   JAVA_HOME=$JAVA_HOME</span><br><span class="line">27 fi</span><br></pre></td></tr></table></figure><h2 id="配置-yarn-site-xml"><a href="#配置-yarn-site-xml" class="headerlink" title="配置 yarn-site.xml"></a>配置 yarn-site.xml</h2><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">vim etc/hadoop/yarn-site.xml</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- 修改 reduce 获取数据的方式（洗牌） --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.aux-services<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>mapreduce_shuffle<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- 修改 resourcemanager 的 地址  --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.hostname<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop01<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure><h2 id="配置-mapred-env-sh"><a href="#配置-mapred-env-sh" class="headerlink" title="配置 mapred-env.sh"></a>配置 mapred-env.sh</h2><p>修改 mapred-env.sh 的 JAVA_HOME：第 16 行去掉注释，修改 JAVA_HOME 为 <code>export JAVA_HOME=/opt/module/jdk1.8.0_144</code></p><h2 id="创建并修改-mapred-site-xml-文件"><a href="#创建并修改-mapred-site-xml-文件" class="headerlink" title="创建并修改 mapred-site.xml 文件"></a>创建并修改 mapred-site.xml 文件</h2><p>拷贝 <code>etc/hadoop/mapred-site.xml.template</code> 文件为 <code>mapred-site.xml</code> 文件，指定 MR 运行在 YARN 上<br><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">cp mapred-site.xml.template mapred-site.xml</span><br><span class="line">vim mapred-site.xml</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- 指定 MR 运行在 YARN 上  --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.framework.name<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>yarn<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure></p><h1 id="启动-YARN"><a href="#启动-YARN" class="headerlink" title="启动 YARN"></a>启动 YARN</h1><p>在保证 NameNode 和 DataNode 启动的情况下，启动 ResourceManager 和 NodeManager。</p><p>进入 <code>/opt/module/hadoop-2.7.2</code>，利用 <code>yarn-daemon.sh</code> 启动。 注意启动顺序：ResourceManager 先启动</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">sbin/yarn-daemon.sh start resourcemanager</span><br><span class="line"></span><br><span class="line">sbin/yarn-daemon.sh start nodemanager</span><br></pre></td></tr></table></figure><p>查看是否启动成功</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop01 hadoop-2.7.2]# jps</span><br><span class="line">1345 NameNode</span><br><span class="line">1505 DataNode</span><br><span class="line">2068 ResourceManager</span><br><span class="line">2327 NodeManager</span><br></pre></td></tr></table></figure><h2 id="查看-Web-UI"><a href="#查看-Web-UI" class="headerlink" title="查看 Web UI"></a>查看 Web UI</h2><p>访问 hadoop01:50070，hdfs 正常使用，继续访问 hadoop01:8088，查看 MapReduce 程序运行进程</p><p>50070：HDFS<br>8088：MapReduce</p><p><img src="/images/hadoop/yarn-history-and-log/map-reduce-8088.png" alt="map reduce 进程"></p><h2 id="测试-8088-的-MapReduce"><a href="#测试-8088-的-MapReduce" class="headerlink" title="测试 8088 的 MapReduce"></a>测试 8088 的 MapReduce</h2><p>删除 hdfs 中的 /user/laiyy/output： <code>bin/hdfs dfs -rm -r /user/laiyy/output</code></p><p>执行 MapReduce word count</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.2.jar wordcount /user/laiyy/input /user/laiyy/output</span><br></pre></td></tr></table></figure><p>控制台打印日志如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">...</span><br><span class="line"></span><br><span class="line">19/09/20 17:35:36 INFO mapreduce.Job: The url to track the job: http://hadoop01:8088/proxy/application_1568971486858_0001/</span><br><span class="line">19/09/20 17:35:36 INFO mapreduce.Job: Running job: job_1568971486858_0001</span><br><span class="line">19/09/20 17:35:46 INFO mapreduce.Job: Job job_1568971486858_0001 running in uber mode : false</span><br><span class="line">19/09/20 17:35:46 INFO mapreduce.Job:  map 0% reduce 0%</span><br><span class="line">19/09/20 17:35:52 INFO mapreduce.Job:  map 100% reduce 0%</span><br><span class="line">19/09/20 17:35:58 INFO mapreduce.Job:  map 100% reduce 100%</span><br><span class="line">19/09/20 17:35:59 INFO mapreduce.Job: Job job_1568971486858_0001 completed successfully</span><br></pre></td></tr></table></figure></p><blockquote><p>在什么地方执行的任务：The url to track the job: <a href="http://hadoop01:8088/proxy/application_1568971486858_0001/" target="_blank" rel="noopener">http://hadoop01:8088/proxy/application_1568971486858_0001/</a><br>map、reduce 执行流程：map x% reduce x%<br>执行结果：Job job_1568971486858_0001 completed successfully</p></blockquote><p>在 8088 上查看执行信息<br><img src="/images/hadoop/yarn-history-and-log/yarn-map-reduce.png" alt="yarn map reduce"></p><h2 id="配置-Yarn-历史运行服务器"><a href="#配置-Yarn-历史运行服务器" class="headerlink" title="配置 Yarn 历史运行服务器"></a>配置 Yarn 历史运行服务器</h2><p>在 8088 上，某任务执行结束后，可以在进度条后看到有一个 <code>history</code> 选项卡，此选项卡可以查看历史运行记录。但是在没有配置历史运行服务器的时候，此选项卡打开后是 404，要想看到历史执行记录，需要配置 <code>历史运行服务器</code></p><p>配置方式：</p><blockquote><ol><li>修改 mapred-site.xml 文件</li><li>启动历史服务器</li><li>查看 JobHistory</li></ol></blockquote><ul><li>修改 mapred-site.xml 文件</li></ul><p>打开 mapred-site.xml 文件，增加如下配置<br><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- 指定 MR 运行在 YARN 上  --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.framework.name<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>yarn<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">&lt;!-- 修改历史服务器地址 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.jobhistory.address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop01:10020<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- 修改历史服务器 WebUI 地址 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.jobhistory.webapp.address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop01:19888<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure></p><ul><li>启动历史服务器</li></ul><p>执行命令 <code>sbin/mr-jobhistory-daemon.sh start historyserver</code></p><p>查看启动是否成功</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop01 hadoop-2.7.2]# jps</span><br><span class="line">1505 ResourceManager</span><br><span class="line">2373 JobHistoryServer</span><br><span class="line">1753 NodeManager</span><br><span class="line">1370 DataNode</span><br><span class="line">1292 NameNode</span><br></pre></td></tr></table></figure><p>访问 8088 中的 <code>history</code> 选项卡，查看历史执行记录</p><p>如果出现下面的情况，是因为在本机没有在 hosts 配置 <code>hadoop01</code> 的地址，修改本机 hosts 文件，增加上 hadoop01 的映射即可<br><img src="/images/hadoop/yarn-history-and-log/error-history.png" alt="error history"></p><p>配置好 hosts 后，刷新页面，即可看到该任务的执行流程<br><img src="/images/hadoop/yarn-history-and-log/history-success.png" alt="history success"></p><h2 id="日志服务器"><a href="#日志服务器" class="headerlink" title="日志服务器"></a>日志服务器</h2><p>Logs 选项卡可以查看整个执行过程的相关日志，此时点击 Logs 选项卡，会提示如下信息<br><img src="/images/hadoop/yarn-history-and-log/no-logs.png" alt="没有日志服务器"></p><p>按照提示信息，我们需要配置 <code>日志服务器</code></p><blockquote><p>日志聚集的概念：应用运行完成后，将程序运行日志的信息上传到 HDFS 系统上<br>日志聚集的好处：可以方便的查看到程序运行详情，方便开发调试</p></blockquote><p><strong><em>注意</em></strong>：<br>开启日志聚集功能，需要重启 <code>NodeManager</code>、<code>ResourceManager</code>、<code>HistoryManager</code></p><p>开启日志聚集的步骤：</p><blockquote><ol><li>停止服务</li><li>修改配置 <code>yarn-site.xml</code></li><li>重新启动</li><li>执行测试</li></ol></blockquote><ul><li>停止服务</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop01 hadoop-2.7.2]# sbin/mr-jobhistory-daemon.sh stop historyserver</span><br><span class="line">stopping historyserver</span><br><span class="line">[root@hadoop01 hadoop-2.7.2]# sbin/yarn-daemon.sh stop nodemanager</span><br><span class="line">stopping nodemanager</span><br><span class="line">nodemanager did not stop gracefully after 5 seconds: killing with kill -9</span><br><span class="line">[root@hadoop01 hadoop-2.7.2]# sbin/yarn-daemon.sh stop resourcemanager</span><br><span class="line">stopping resourcemanager</span><br><span class="line">[root@hadoop01 hadoop-2.7.2]# jps</span><br><span class="line">3332 Jps</span><br><span class="line">1370 DataNode</span><br><span class="line">1292 NameNode</span><br></pre></td></tr></table></figure><ul><li>配置 yarn-site.xml</li></ul><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- 修改 reduce 获取数据的方式（洗牌） --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.aux-services<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>mapreduce_shuffle<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- 修改 resourcemanager 的 地址  --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.hostname<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop01<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">&lt;!-- 开启日志聚集 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.log-aggregation-enable<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- 日志保留时间 7 天，单位：秒 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.log-aggregation.retain-seconds<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>604800<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure><ul><li>重新启动</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop01 hadoop-2.7.2]# sbin/yarn-daemon.sh start resourcemanager</span><br><span class="line">starting resourcemanager, logging to /opt/module/hadoop-2.7.2/logs/yarn-root-resourcemanager-hadoop01.out</span><br><span class="line">[root@hadoop01 hadoop-2.7.2]# sbin/yarn-daemon.sh start nodemanager</span><br><span class="line">starting nodemanager, logging to /opt/module/hadoop-2.7.2/logs/yarn-root-nodemanager-hadoop01.out</span><br><span class="line">[root@hadoop01 hadoop-2.7.2]# sbin/mr-jobhistory-daemon.sh start historyserver</span><br><span class="line">starting historyserver, logging to /opt/module/hadoop-2.7.2/logs/mapred-root-historyserver-hadoop01.out</span><br><span class="line">[root@hadoop01 hadoop-2.7.2]# jps</span><br><span class="line">3825 Jps</span><br><span class="line">3622 NodeManager</span><br><span class="line">3784 JobHistoryServer</span><br><span class="line">1370 DataNode</span><br><span class="line">1292 NameNode</span><br><span class="line">3373 ResourceManager</span><br></pre></td></tr></table></figure><ul><li>执行测试</li></ul><p>删除 hdfs 上的 output 文件夹，重新执行 word count 示例</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">bin/hdfs dfs -rm -r /user/laiyy/output</span><br><span class="line"></span><br><span class="line">hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.2.jar wordcount /user/laiyy/input /user/laiyy/output</span><br></pre></td></tr></table></figure><p>在 8088 上选择最后一个执行的任务，进入 <code>history</code> 选项卡，再进入 <code>Logs</code> 选项卡查看结果<br><img src="/images/hadoop/yarn-history-and-log/log.png" alt="logs"></p><hr><h1 id="配置文件的说明"><a href="#配置文件的说明" class="headerlink" title="配置文件的说明"></a>配置文件的说明</h1><p>Hadoop 配置文件分为量类：默认配置文件、自定义配置文件。自定义配置文件的优先级更高</p><h2 id="默认配置文件"><a href="#默认配置文件" class="headerlink" title="默认配置文件"></a>默认配置文件</h2><table><thead><tr><th style="text-align:center">默认配置文件</th><th style="text-align:center">存放位置</th></tr></thead><tbody><tr><td style="text-align:center">core-default.xml</td><td style="text-align:center">hadoop-common-xxx.jar/core-default.xml</td></tr><tr><td style="text-align:center">hdfs-default.xml</td><td style="text-align:center">hadoop-hdfs-xxx.jar/hdfs-default.xml</td></tr><tr><td style="text-align:center">yarn-default.xml</td><td style="text-align:center">hadoop-yarn-common-xxx.jar/yarn-default.xml</td></tr><tr><td style="text-align:center">mapred-defaultt.xml</td><td style="text-align:center">hadoop-mapreduce-client-core-xxx.jar/mapred-default.xml</td></tr></tbody></table><h2 id="自定义配置文件"><a href="#自定义配置文件" class="headerlink" title="自定义配置文件"></a>自定义配置文件</h2><p><code>core-site.xml</code>、<code>hdfs-site.xml</code>、<code>yarn-site.xml</code>、<code>mapred-site.xml</code> 存放在 <code>$HADOOP_HOME/etc/hadoop</code> 文件夹下，可根据需求修改配置</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;在上例中，测试了 HDFS 以及在 HDFS 下执行 MapReduce 示例。本例中，测试启动 YARN，并在 YARN 中执行 MapReduce 程序、并查看历史执行信息和执行日志信息&lt;/p&gt;
    
    </summary>
    
      <category term="hadoop" scheme="https://www.laiyy.top/categories/hadoop/"/>
    
    
      <category term="hadoop" scheme="https://www.laiyy.top/tags/hadoop/"/>
    
  </entry>
  
  <entry>
    <title>Hadoop（2） &lt;br/&gt; 伪分布式</title>
    <link href="https://www.laiyy.top/hadoop/hadoop-2.html"/>
    <id>https://www.laiyy.top/hadoop/hadoop-2.html</id>
    <published>2019-09-20T03:43:06.000Z</published>
    <updated>2019-09-20T03:43:06.000Z</updated>
    
    <content type="html"><![CDATA[<p>配置伪分布式集群，需要注意修改对应的 hdfs 配置文件、JAVA_HOME、副本备份个数等信息。另外在启动集群之前，需要格式化 NameNode（只有第一次启动需要格式化）</p><a id="more"></a><h1 id="修改配置文件"><a href="#修改配置文件" class="headerlink" title="修改配置文件"></a>修改配置文件</h1><h2 id="修改-core-site-xml-文件"><a href="#修改-core-site-xml-文件" class="headerlink" title="修改 core-site.xml 文件"></a>修改 core-site.xml 文件</h2><p>修改 core-site.xml 中关于 hdfs、数据存储等配置</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cd /opt/module/hadoop-2.7.2/etc/hadoop</span><br><span class="line">vim core-site.xml</span><br></pre></td></tr></table></figure><p>将 <code>configutation</code> 标签内容修改为：<br><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- 修改 hdfs 地址 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>fs.defaultFS<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>hdfs://hadoop01:9000<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- 修改 hadoop 运行时的数据存储位置，可以不存在，启动时会自动创建 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>hadoop.tmp.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>/opt/module/hadoop-2.7.2/etc/hadoop/data/tmp<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure></p><h2 id="修改-hadoop-env-sh"><a href="#修改-hadoop-env-sh" class="headerlink" title="修改 hadoop-env.sh"></a>修改 hadoop-env.sh</h2><p>修改 hadoop 的默认 JDK 路径，如果不修改配置，则可能在分布式集群环境下导致 JAVA_HOME 失效</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vim hadoop-env.sh</span><br></pre></td></tr></table></figure><p>将 JAVA_HOME 从原来的 <code>export JAVA_HOME=${JAVA_HOME}</code>，修改为 <code>/opt/module/jdk1.8.0_144/</code></p><h2 id="修改-hdfs-site-xml"><a href="#修改-hdfs-site-xml" class="headerlink" title="修改 hdfs-site.xml"></a>修改 hdfs-site.xml</h2><p>指定 hdfs 副本的数量为 1 个，默认为 3 个<br><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.replication<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>1<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure></p><hr><h1 id="启动集群"><a href="#启动集群" class="headerlink" title="启动集群"></a>启动集群</h1><h2 id="格式化-NameNode"><a href="#格式化-NameNode" class="headerlink" title="格式化 NameNode"></a>格式化 NameNode</h2><p>第一次启动集群时，需要格式化 NameNode，后面如果再启动时不需要格式化 NameNode</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">cd /opt/module/hadoop-2.7.2</span><br><span class="line"></span><br><span class="line">bin/hdfs namenode -format</span><br></pre></td></tr></table></figure><p>控制台输出：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">...</span><br><span class="line"></span><br><span class="line">19/09/20 15:23:31 INFO namenode.FSNamesystem: Retry cache on namenode is enabled</span><br><span class="line">19/09/20 15:23:31 INFO namenode.FSNamesystem: Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis</span><br><span class="line">19/09/20 15:23:31 INFO util.GSet: Computing capacity for map NameNodeRetryCache</span><br><span class="line">19/09/20 15:23:31 INFO util.GSet: VM type       = 64-bit</span><br><span class="line">19/09/20 15:23:31 INFO util.GSet: 0.029999999329447746% max memory 966.7 MB = 297.0 KB</span><br><span class="line">19/09/20 15:23:31 INFO util.GSet: capacity      = 2^15 = 32768 entries</span><br><span class="line">19/09/20 15:23:31 INFO namenode.FSImage: Allocated new BlockPoolId: BP-1194915434-192.168.233.130-1568964211854</span><br><span class="line">19/09/20 15:23:31 INFO common.Storage: Storage directory /opt/module/hadoop-2.7.2/etc/hadoop/data/tmp/dfs/name has been successfully formatted.</span><br><span class="line">19/09/20 15:23:31 INFO namenode.NNStorageRetentionManager: Going to retain 1 images with txid &gt;= 0</span><br><span class="line">19/09/20 15:23:31 INFO util.ExitUtil: Exiting with status 0</span><br><span class="line">19/09/20 15:23:31 INFO namenode.NameNode: SHUTDOWN_MSG: </span><br><span class="line">/************************************************************</span><br><span class="line">SHUTDOWN_MSG: Shutting down NameNode at hadoop01/192.168.233.130</span><br><span class="line">************************************************************/</span><br></pre></td></tr></table></figure></p><p>当看到控制台输出 <code>SHUTDOWN_MSG: Shutting down NameNode at hadoop01/192.168.233.130</code> 时，即为格式化完成。</p><h2 id="启动-NameNode、DataNode"><a href="#启动-NameNode、DataNode" class="headerlink" title="启动 NameNode、DataNode"></a>启动 NameNode、DataNode</h2><p>启动 NameNode</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop01 hadoop-2.7.2]# sbin/hadoop-daemon.sh start namenode</span><br><span class="line">starting namenode, logging to /opt/module/hadoop-2.7.2/logs/hadoop-root-namenode-hadoop01.out</span><br></pre></td></tr></table></figure><p>启动 DataNode<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sbin/hadoop-daemon.sh start datanode</span><br></pre></td></tr></table></figure></p><h2 id="验证是否启动成功"><a href="#验证是否启动成功" class="headerlink" title="验证是否启动成功"></a>验证是否启动成功</h2><blockquote><p>JPS 验证</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop01 hadoop-2.7.2]# jps</span><br><span class="line">1345 NameNode</span><br><span class="line">1505 DataNode</span><br><span class="line">1583 Jps</span><br></pre></td></tr></table></figure><blockquote><p>Web UI 验证</p></blockquote><p>浏览器访问 hadoop01 的 ip:50070，查看 WebUI 是否可以访问</p><p>集群的基础信息：<br><img src="/images/hadoop/hdfs-info/hdfs-1.png" alt="hdfs"></p><p>集群的详细信息：<br><img src="/images/hadoop/hdfs-info/hdfs-2.png" alt="hdfs"></p><p>DataNode 信息：<br><img src="/images/hadoop/hdfs-info/hdfs-3.png" alt="hdfs"></p><p>HDFS 文件管理系统：<br><img src="/images/hadoop/hdfs-info/hdfs-4.png" alt="hdfs"></p><hr><h1 id="HDFS-管理"><a href="#HDFS-管理" class="headerlink" title="HDFS 管理"></a>HDFS 管理</h1><h2 id="创建一个文件夹"><a href="#创建一个文件夹" class="headerlink" title="创建一个文件夹"></a>创建一个文件夹</h2><p>在 hdfs 根目录下再创建其他文件夹以保存文件</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/hdfs dfs -mkdir -p /user/laiyy/input</span><br></pre></td></tr></table></figure><p>然后在 WebUI 中查看<br><img src="/images/hadoop/hdfs-info/hdfs-5.png" alt="hdfs"></p><h2 id="将-wcinput-文件夹里的东西上传到-hdfs-中"><a href="#将-wcinput-文件夹里的东西上传到-hdfs-中" class="headerlink" title="将 wcinput 文件夹里的东西上传到 hdfs 中"></a>将 wcinput 文件夹里的东西上传到 hdfs 中</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">cd /opt/module/demo</span><br><span class="line"></span><br><span class="line">../hadoop-2.7.2/bin/hdfs dfs -put wcinput/wc.input /user/laiyy/input</span><br></pre></td></tr></table></figure><p><code>-put</code> :上传文件</p><p>整体命令：将 wcinput 下的 wc.input 文件，上传到 hdfs 中的 /user/laiyy/input 下</p><p>验证上传结果：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop01 demo]# ../hadoop-2.7.2/bin/hdfs dfs -ls -R /user/laiyy/input</span><br><span class="line">-rw-r--r--   1 root supergroup         57 2019-09-20 16:20 /user/laiyy/input/wc.input</span><br></pre></td></tr></table></figure></p><p><img src="/images/hadoop/hdfs-info/hdfs-6.png" alt="hdfs"></p><h2 id="使用-hdfs-的文件路径运行-word-count-示例"><a href="#使用-hdfs-的文件路径运行-word-count-示例" class="headerlink" title="使用 hdfs 的文件路径运行 word count 示例"></a>使用 hdfs 的文件路径运行 word count 示例</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.2.jar wordcount /user/laiyy/input /user/laiyy/output</span><br></pre></td></tr></table></figure><p>此时的 <code>input</code>、<code>output</code> 的路径都是 hdfs 的路径，不是linux的路径。</p><p>查看执行结果<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop01 hadoop-2.7.2]# bin/hdfs dfs -ls -R /user/laiyy</span><br><span class="line">drwxr-xr-x   - root supergroup          0 2019-09-20 16:20 /user/laiyy/input</span><br><span class="line">-rw-r--r--   1 root supergroup         57 2019-09-20 16:20 /user/laiyy/input/wc.input</span><br><span class="line">drwxr-xr-x   - root supergroup          0 2019-09-20 16:28 /user/laiyy/output</span><br><span class="line">-rw-r--r--   1 root supergroup          0 2019-09-20 16:28 /user/laiyy/output/_SUCCESS</span><br><span class="line">-rw-r--r--   1 root supergroup         55 2019-09-20 16:28 /user/laiyy/output/part-r-00000</span><br></pre></td></tr></table></figure></p><p><img src="/images/hadoop/hdfs-info/hdfs-7.png" alt="hdfs"></p><p><strong><em>直接查看 hdfs 中 output 中的执行结果</em></strong>：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop01 hadoop-2.7.2]# bin/hdfs dfs -cat /user/laiyy/output/part-r-00000</span><br><span class="line">hadoop3</span><br><span class="line">hdfs1</span><br><span class="line">laiyy1</span><br><span class="line">laiyy07281</span><br><span class="line">mapreduce1</span><br><span class="line">yarn1</span><br></pre></td></tr></table></figure></p><hr><h1 id="关于-NameNode-格式化"><a href="#关于-NameNode-格式化" class="headerlink" title="关于 NameNode 格式化"></a>关于 NameNode 格式化</h1><p>一定不能经常格式化 NameNode。当需要格式化 NameNode 时，需要先用 jps 命令，查看一下 NameNode 和 DataNode 是否都已经关闭，如果没有关闭，需要关闭 NameNode 和 DataNode。</p><p>在关闭 NameNode 和 DataNode 的情况下，删除 <code>HADOOP_HOME</code> 下的 <code>data</code> 和 <code>log</code> 文件夹，然后执行 NameNode 格式化命令。</p><p>其中 <code>data</code> 文件夹可能不在 <code>HADOOP_HOME</code> 下，此时该文件夹在 <code>HADOOP_HOME/etc/hadoop</code> 下。</p><blockquote><p>为何在 DataNode 存在时不能格式化 NameNode？</p></blockquote><p>在 <code>data</code> 文件夹或 <code>data/tmp/dfs</code> 文件夹下，有两个文件夹，分别为 <code>data</code>、<code>name</code>，分别对应 DataNode 和 NameNode。</p><p>在 <code>data/current/</code> 和 <code>name/current/</code> 下，都有一个 <code>VERSION</code> 文件，在 <code>VERSION</code> 文件中，可以看到对应的信息：</p><ul><li><p>NameNode</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">namespaceID=1748201392</span><br><span class="line">clusterID=CID-7c41ca27-aaa9-4b85-9966-36af0e361a58</span><br><span class="line">cTime=0</span><br><span class="line">storageType=NAME_NODE</span><br><span class="line">blockpoolID=BP-1270008624-192.168.233.130-1568966288591</span><br><span class="line">layoutVersion=-63</span><br></pre></td></tr></table></figure></li><li><p>DataNode</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">storageID=DS-9be19535-bada-4b25-9076-f7260386a990</span><br><span class="line">clusterID=CID-7c41ca27-aaa9-4b85-9966-36af0e361a58</span><br><span class="line">cTime=0</span><br><span class="line">datanodeUuid=a4e2c662-26b0-4f7f-8bd4-f6012b54c3e7</span><br><span class="line">storageType=DATA_NODE</span><br><span class="line">layoutVersion=-56</span><br></pre></td></tr></table></figure></li></ul><p>对比两个文件，可以看到 DataNode 和 NameNode 中的 <code>clusterID</code> 完全一致。</p><p>此时，如果由于 DataNode 没有停止，或 <code>data</code> 文件夹没有清空，就格式化 NameNode 的话，会导致 NameNode 的 <code>clusterID</code> 重新生成， 此时，NameNode 和 DataNode 的 <code>clusterID</code> 不一致，导致崩溃。</p><blockquote><p>DataNode 和 NameNode 在 clusterID 不一致，导致只能同时只能有一个工作的问题 </p></blockquote><p><img src="/images/hadoop/hdfs-info/format-namenode-error.png" alt="format namenode error"></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;配置伪分布式集群，需要注意修改对应的 hdfs 配置文件、JAVA_HOME、副本备份个数等信息。另外在启动集群之前，需要格式化 NameNode（只有第一次启动需要格式化）&lt;/p&gt;
    
    </summary>
    
      <category term="hadoop" scheme="https://www.laiyy.top/categories/hadoop/"/>
    
    
      <category term="hadoop" scheme="https://www.laiyy.top/tags/hadoop/"/>
    
  </entry>
  
  <entry>
    <title>Hadoop 学习（1）  &lt;br /&gt; 基础概念、基础环境搭建安装、官方示例</title>
    <link href="https://www.laiyy.top/hadoop/hadoop-1.html"/>
    <id>https://www.laiyy.top/hadoop/hadoop-1.html</id>
    <published>2019-09-17T15:19:13.000Z</published>
    <updated>2019-09-17T15:19:13.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Hadoop"><a href="#Hadoop" class="headerlink" title="Hadoop"></a>Hadoop</h1><p>Hadoop 是 Apache 基金会所开发的分布式系统基础架构，主要解决海量数据的存储、分析计算问题。Hadoop 通常是指一个更广泛的概念：Hadoop 生态圈（包括 HBase、Spark 等）</p><a id="more"></a><h2 id="Hadoop-的三大发型版本"><a href="#Hadoop-的三大发型版本" class="headerlink" title="Hadoop 的三大发型版本"></a>Hadoop 的三大发型版本</h2><blockquote><p>Apache</p></blockquote><p>最原始版本，对于入门学习最好</p><blockquote><p>Cloudera</p></blockquote><p>收费，在大型互联网公司用的比较多</p><blockquote><p>Hortonworks</p></blockquote><p>文档比较好</p><h2 id="Hadoop-的优势"><a href="#Hadoop-的优势" class="headerlink" title="Hadoop 的优势"></a>Hadoop 的优势</h2><blockquote><p>高可靠性</p></blockquote><p>Hadoop 底层维护多个数据副本（默认3个），所以即使 Hadoop 某个计算元素或存储出现故障，也不会导致数据的丢失</p><blockquote><p>高扩展性</p></blockquote><p>在集群中分配任务数据，可方便的扩展数以千计的节点</p><blockquote><p>高效性</p></blockquote><p>在 MapReduce 思想下，Hadoop 是并行工作的，以加快任务处理速度</p><blockquote><p>高容错性</p></blockquote><p>自动将失败的任务重新分配执行</p><h2 id="1-x-与-2-x-的区别"><a href="#1-x-与-2-x-的区别" class="headerlink" title="1.x 与 2.x 的区别"></a>1.x 与 2.x 的区别</h2><p>Hadoop 包含的模块，以及 1.X、2.X 的区别：<br><img src="/images/hadoop/install/hadoop.png" alt="Hadoop"></p><hr><h1 id="Hadoop-三大组件"><a href="#Hadoop-三大组件" class="headerlink" title="Hadoop 三大组件"></a>Hadoop 三大组件</h1><h2 id="HDFS"><a href="#HDFS" class="headerlink" title="HDFS"></a>HDFS</h2><p>HDFS 架构：</p><ul><li>NameNode(nn)：<br>相当于一本书的目录；存储文件的元数据，如：文件名、目录结构、文件属性（生成时间、副本数、文件权限），以及每个文件的快列表和快所在的 DataNode</li><li>DateNode(dn)：<br>相当于目录对应的具体内容；在本地文件系统存储文件块数据，以及块数据的校验和</li><li>Secondary NameNode(2nn)：用来监控 HDFS 状态的辅助后台程序，每个一段时间获取 HDFS 元数据快照。</li></ul><h2 id="Yarn"><a href="#Yarn" class="headerlink" title="Yarn"></a>Yarn</h2><p>ResourceManager（相当于老板） &gt; NodeManager（相当于技术总监）/ApplicationMaster（相当于项目经理）</p><p>其中 NodeManager 负责某一个节点，ApplicationMaster 负责节点中的某个任务</p><ul><li><p>ResourceManager</p><blockquote><p>处理客户端请求：管理整个服务器集群资源（磁盘、cpu等）<br>监控 NodeManager<br>启动、监控 ApplicationMaster（在集群上运行的任务）<br>资源的分配、调度</p></blockquote></li><li><p>NodeManager</p><blockquote><p>管理单个节点上的资源<br>处理来自 ResourceManager 的命令<br>处理 ApplicationMaster 的命令</p></blockquote></li><li><p>ApplicationMaster</p><blockquote><p>负责数据切分<br>为应用程序申请资源并分配给内部任务<br>任务的监控和容错</p></blockquote></li><li><p>Container：为 ApplicationMaster 服务</p><blockquote><p>YARN 中资源的抽象，封装了节点上多维度资源，如：内存、CPU、磁盘、网络等，服务 ApplicationMaster</p></blockquote></li></ul><p><img src="/images/hadoop/install/yarn.png" alt="yarn"></p><h2 id="MapReduce"><a href="#MapReduce" class="headerlink" title="MapReduce"></a>MapReduce</h2><p>MapReduce 将计算过程分为两个阶段：Map 阶段、Reduce 阶段</p><ul><li>Map 阶段：并行处理输入数据</li><li>Reduce 阶段：对 Map 结果进行汇总</li></ul><p><img src="/images/hadoop/install/map-reduce.png" alt="MapReduce"></p><h2 id="大数据生态体系"><a href="#大数据生态体系" class="headerlink" title="大数据生态体系"></a>大数据生态体系</h2><p><img src="/images/hadoop/install/life-cycle.png" alt="大数据生态体系"></p><hr><h1 id="Hadoop-环境搭建"><a href="#Hadoop-环境搭建" class="headerlink" title="Hadoop 环境搭建"></a>Hadoop 环境搭建</h1><p>环境准备</p><blockquote><p>CentOS 7<br>JDK 1.8<br>Hadoop 2.9.2</p></blockquote><h2 id="CentOS-设置"><a href="#CentOS-设置" class="headerlink" title="CentOS 设置"></a>CentOS 设置</h2><h3 id="修改网卡"><a href="#修改网卡" class="headerlink" title="修改网卡"></a>修改网卡</h3><p>使用 ROOT 用户，设置 NAT 模式网络连接、设置静态 IP （防止 dhcp 导致 ip 变化）<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vim /etc/sysconfig/network-scripts/ifcfg-ens33</span><br></pre></td></tr></table></figure></p><p>禁用掉 ipv6，将获取 ip 的方式从 <code>dhcp</code> 改为 <code>static</code>，设置静态 ip 地址 <code>IPADDR</code>、网关 <code>GATEWAY</code>、dns <code>DNS1</code></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">TYPE=Ethernet</span><br><span class="line">PROXY_METHOD=none</span><br><span class="line">BROWSER_ONLY=no</span><br><span class="line">BOOTPROTO=static</span><br><span class="line">DEFROUTE=yes</span><br><span class="line">IPV4_FAILURE_FATAL=no</span><br><span class="line">IPV6INIT=no</span><br><span class="line">IPV6_AUTOCONF=no</span><br><span class="line">IPV6_DEFROUTE=no</span><br><span class="line">IPV6_FAILURE_FATAL=no</span><br><span class="line">IPV6_ADDR_GEN_MODE=stable-privacy</span><br><span class="line">NAME=ens33</span><br><span class="line">UUID=672a42a7-bbbb-453e-8ebe-ca0ae27eef49</span><br><span class="line">DEVICE=ens33</span><br><span class="line">ONBOOT=yes</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">IPADDR=192.168.52.100</span><br><span class="line">GATEWAY=192.168.52.2</span><br><span class="line">DNS1=192.168.52.2</span><br></pre></td></tr></table></figure><p><strong><em> 注意：网关需要与虚拟机中的 NAT 网卡设置一致！</em></strong></p><p><img src="/images/hadoop/install/network-1.png" alt="网卡设置"><br><img src="/images/hadoop/install/network-2.png" alt="网卡设置"><br><img src="/images/hadoop/install/network-3.png" alt="网卡设置"></p><p><strong><em>另外，也需要将 VM8 网卡设置一个静态ip，且这个静态 ip 不能与虚拟机的静态 ip一致，必须在一个网段</em></strong><br><img src="/images/hadoop/install/network-4.png" alt="网卡设置"></p><h3 id="修改-hostname、hosts"><a href="#修改-hostname、hosts" class="headerlink" title="修改 hostname、hosts"></a>修改 hostname、hosts</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">vim /etc/sysconfig/network</span><br><span class="line"></span><br><span class="line">NETWORKING=yes</span><br><span class="line">HOSTNAME=hadoop01</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">vim /etc/hosts</span><br><span class="line"></span><br><span class="line">192.168.52.100 hadoop01</span><br><span class="line">192.168.52.101 hadoop02</span><br><span class="line">192.168.52.102 hadoop03</span><br><span class="line">192.168.52.103 hadoop04</span><br></pre></td></tr></table></figure><p>其中，<code>hosts</code> 文件中的 <code>hadoop02</code>、<code>hadoop03</code>、<code>hadoop04</code> 暂时还没有，先配置上，为后面集群做准备。</p><h2 id="安装-JDK、Hadoop"><a href="#安装-JDK、Hadoop" class="headerlink" title="安装 JDK、Hadoop"></a>安装 JDK、Hadoop</h2><p>寻找一个文件夹或创建一个空文件夹，作为 jdk、hadoop 的安装目录。本例以 /opt 文件夹为例。</p><p>在 /opt 文件夹下创建 <code>module</code> 文件夹，存放 jdk、hadoop 安装文件，创建 <code>software</code> 文件夹，存在 jdk、hadoop 安装包</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cd /opt</span><br><span class="line">mkdir module software</span><br></pre></td></tr></table></figure><p>利用 xftp 将下载好的 jdk1.8、hadoop 2.9.2 存入 software 文件夹下，解压安装到 module 文件夹下</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">cd software</span><br><span class="line"></span><br><span class="line">tar -zxf jdk-8u144-linux-x64.tar.gz -C ../module/</span><br><span class="line">tar -zxf hadoop-2.9.2.tar.gz -C ../module/</span><br></pre></td></tr></table></figure><p>设置 jdk、hadoop 环境变量</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vim /etc/profile</span><br></pre></td></tr></table></figure><p>在文件最后添加：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">export JAVA_HOME=/opt/module/jdk1.8.0_144</span><br><span class="line">export HADOOP_HOME=/opt/module/hadoop-2.9.2</span><br><span class="line">export PATH=$PATH:$JAVA_HOME/bin:$HADOOP_HOME/bin:$HADOOP_HOME/sbin</span><br></pre></td></tr></table></figure></p><p>应用环境变量：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">source /etc/profile</span><br></pre></td></tr></table></figure></p><p>使用 <code>java</code>、<code>javac</code>、<code>hadoop</code> 命令，测试环境变量设置是否成功</p><hr><h1 id="官方案例-grep"><a href="#官方案例-grep" class="headerlink" title="官方案例[grep]"></a>官方案例[grep]</h1><h2 id="创建一个用于输入的文件夹"><a href="#创建一个用于输入的文件夹" class="headerlink" title="创建一个用于输入的文件夹"></a>创建一个用于输入的文件夹</h2><p>任意找一个地方，创建一个 input 文件夹，本例使用与 hadoop 统计目录。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mkdir -p demo/input</span><br></pre></td></tr></table></figure></p><!-- more --><p>拷贝 hadoop/etc/hadoop/*.xml，到 input 文件夹，用于 grep 案例的输入源</p><h2 id="执行官方-demo"><a href="#执行官方-demo" class="headerlink" title="执行官方 demo"></a>执行官方 demo</h2><p>在 demo 文件夹下，执行 hadoop 官方 demo<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop jar ../hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.2.jar grep input/ output &apos;dfs[a-z.]+&apos;</span><br></pre></td></tr></table></figure></p><p>解释：</p><blockquote><p>hadoop：以 hadoop 命令执行<br>jar：执行的是 jar 包<br>xx.jar：具体 jar 包，本例是 2.7.2 版本的官方 hadoop MapReduce 示例<br>grep：由于有多个示例，选择执行哪个示例，此处是执行 <code>grep</code> 案例<br>input：指明输入示例的文件夹<br>output：指明输出结果的文件夹，且这个文件夹必须不存在，否则会报<code>文件夹已存在</code>的错误<br>dfs[a-z.]+：正则过滤</p></blockquote><h2 id="查看控制台输出"><a href="#查看控制台输出" class="headerlink" title="查看控制台输出"></a>查看控制台输出</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line">19/09/20 14:29:11 INFO Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id</span><br><span class="line">19/09/20 14:29:11 INFO jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=</span><br><span class="line">19/09/20 14:29:11 INFO input.FileInputFormat: Total input paths to process : 8</span><br><span class="line">19/09/20 14:29:11 INFO mapreduce.JobSubmitter: number of splits:8</span><br><span class="line">19/09/20 14:29:11 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_local1540340101_0001</span><br><span class="line"></span><br><span class="line">...</span><br><span class="line"></span><br><span class="line">19/09/20 14:29:13 INFO mapred.LocalJobRunner: reduce &gt; reduce</span><br><span class="line">19/09/20 14:29:13 INFO mapred.Task: Task &apos;attempt_local801724989_0002_r_000000_0&apos; done.</span><br><span class="line">19/09/20 14:29:13 INFO mapred.LocalJobRunner: Finishing task: attempt_local801724989_0002_r_000000_0</span><br><span class="line">19/09/20 14:29:13 INFO mapred.LocalJobRunner: reduce task executor complete.</span><br><span class="line">19/09/20 14:29:14 INFO mapreduce.Job: Job job_local801724989_0002 running in uber mode : false</span><br><span class="line">19/09/20 14:29:14 INFO mapreduce.Job:  map 100% reduce 100%</span><br><span class="line">19/09/20 14:29:14 INFO mapreduce.Job: Job job_local801724989_0002 completed successfully</span><br><span class="line">19/09/20 14:29:14 INFO mapreduce.Job: Counters: 30</span><br><span class="line">File System Counters</span><br><span class="line">FILE: Number of bytes read=1158544</span><br><span class="line">FILE: Number of bytes written=2216290</span><br><span class="line">FILE: Number of read operations=0</span><br><span class="line">FILE: Number of large read operations=0</span><br><span class="line">FILE: Number of write operations=0</span><br><span class="line">Map-Reduce Framework</span><br><span class="line">Map input records=1</span><br><span class="line">Map output records=1</span><br><span class="line">Map output bytes=17</span><br><span class="line">Map output materialized bytes=25</span><br><span class="line">Input split bytes=120</span><br><span class="line">Combine input records=0</span><br><span class="line">Combine output records=0</span><br><span class="line">Reduce input groups=1</span><br><span class="line">Reduce shuffle bytes=25</span><br><span class="line">Reduce input records=1</span><br><span class="line">Reduce output records=1</span><br><span class="line">Spilled Records=2</span><br><span class="line">Shuffled Maps =1</span><br><span class="line">Failed Shuffles=0</span><br><span class="line">Merged Map outputs=1</span><br><span class="line">GC time elapsed (ms)=18</span><br><span class="line">Total committed heap usage (bytes)=273203200</span><br><span class="line">Shuffle Errors</span><br><span class="line">BAD_ID=0</span><br><span class="line">CONNECTION=0</span><br><span class="line">IO_ERROR=0</span><br><span class="line">WRONG_LENGTH=0</span><br><span class="line">WRONG_MAP=0</span><br><span class="line">WRONG_REDUCE=0</span><br><span class="line">File Input Format Counters </span><br><span class="line">Bytes Read=123</span><br><span class="line">File Output Format Counters </span><br><span class="line">Bytes Written=23</span><br></pre></td></tr></table></figure><h2 id="检查执行结果"><a href="#检查执行结果" class="headerlink" title="检查执行结果"></a>检查执行结果</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop01 demo]# ll output/</span><br><span class="line">总用量 4</span><br><span class="line">-rw-r--r--. 1 root root 11 9月  20 14:29 part-r-00000</span><br><span class="line">-rw-r--r--. 1 root root  0 9月  20 14:29 _SUCCESS</span><br></pre></td></tr></table></figure><p>看到生成了两个文件：<code>part-r-00000</code>、<code>_SUCCESS</code>。</p><p>其中，<code>_SUCCESS</code> 文件大小为 0，没有任何内容，只是标记当前执行成功了。</p><p>查看 <code>part-r-00000</code> 文件的内容<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop01 demo]# cat output/part-r-00000 </span><br><span class="line">1dfsadmin</span><br></pre></td></tr></table></figure></p><p>可以看到统计到的符合正则过滤的条件的单词，只有一个，为 <code>dfsadmin</code>。此时如果再次执行刚才的 hadoop 任务，控制台将报错如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">19/09/20 14:42:58 INFO jvm.JvmMetrics: Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized</span><br><span class="line">org.apache.hadoop.mapred.FileAlreadyExistsException: Output directory file:/opt/module/demo/output already exists</span><br><span class="line">at org.apache.hadoop.mapreduce.lib.output.FileOutputFormat.checkOutputSpecs(FileOutputFormat.java:146)</span><br><span class="line">at org.apache.hadoop.mapreduce.JobSubmitter.checkSpecs(JobSubmitter.java:266)</span><br><span class="line">at org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:139)</span><br></pre></td></tr></table></figure></p><hr><h1 id="官方案例-word-count"><a href="#官方案例-word-count" class="headerlink" title="官方案例[word count]"></a>官方案例[word count]</h1><h2 id="创建输入源"><a href="#创建输入源" class="headerlink" title="创建输入源"></a>创建输入源</h2><p>创建一个 <code>wcinput</code> 用于 word count 案例的输入源，并创建一个 <code>wc.input</code> 文件，输入一些字符串<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop01 demo]# mkdir wcinput</span><br><span class="line">[root@hadoop01 demo]# cd wcinput/</span><br><span class="line">[root@hadoop01 wcinput]# vim wc.input</span><br><span class="line">hadoop yarn</span><br><span class="line">hadoop mapreduce</span><br><span class="line">hadoop hdfs</span><br><span class="line">laiyy</span><br><span class="line">laiyy0728</span><br></pre></td></tr></table></figure></p><h2 id="执行-word-count-示例"><a href="#执行-word-count-示例" class="headerlink" title="执行 word count 示例"></a>执行 word count 示例</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop jar ../hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.2.jar wordcount wcinput/ wcoutput</span><br></pre></td></tr></table></figure><p>与上例的区别仅仅是将 <code>grep</code> 换为 <code>wordcount</code>，调整了输入、输出目录，去掉了正则过滤。</p><p>查看输出结果：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop01 demo]# cat wcoutput/part-r-00000 </span><br><span class="line">hadoop3</span><br><span class="line">hdfs1</span><br><span class="line">laiyy1</span><br><span class="line">laiyy07281</span><br><span class="line">mapreduce1</span><br><span class="line">yarn1</span><br></pre></td></tr></table></figure></p><p>可以看到每个单词出现的频率</p>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;Hadoop&quot;&gt;&lt;a href=&quot;#Hadoop&quot; class=&quot;headerlink&quot; title=&quot;Hadoop&quot;&gt;&lt;/a&gt;Hadoop&lt;/h1&gt;&lt;p&gt;Hadoop 是 Apache 基金会所开发的分布式系统基础架构，主要解决海量数据的存储、分析计算问题。Hadoop 通常是指一个更广泛的概念：Hadoop 生态圈（包括 HBase、Spark 等）&lt;/p&gt;
    
    </summary>
    
      <category term="hadoop" scheme="https://www.laiyy.top/categories/hadoop/"/>
    
    
      <category term="hadoop" scheme="https://www.laiyy.top/tags/hadoop/"/>
    
  </entry>
  
  <entry>
    <title>RocketMQ（3） Rocket 集群</title>
    <link href="https://www.laiyy.top/rocketmq/rocketmq-3.html"/>
    <id>https://www.laiyy.top/rocketmq/rocketmq-3.html</id>
    <published>2019-04-21T11:29:16.000Z</published>
    <updated>2019-04-21T11:29:16.000Z</updated>
    
    <content type="html"><![CDATA[<p>RocketMQ 集群模式分为四种：<code>单 master</code>、<code>多 master</code>、<code>多 master 多 slave 异步复制</code>、<code>多 master 多 slave 同步双写</code></p><a id="more"></a><h1 id="四种集群模式"><a href="#四种集群模式" class="headerlink" title="四种集群模式"></a>四种集群模式</h1><h2 id="单-master"><a href="#单-master" class="headerlink" title="单 master"></a>单 master</h2><p>风险较大，一旦 broker 宕机或者重启，将导致整个服务部可用。不建议线上环境使用</p><h2 id="多-master"><a href="#多-master" class="headerlink" title="多 master"></a>多 master</h2><p>一个集群全部都是 master，没有 slave</p><ul><li><p>优点<br>配置简单，单个 master 宕机，或者重启未付，对应用没有影响，在磁盘配置为 RAID10 时，即是机器宕机不可恢复的情况，消息也不会丢失（异步刷盘会丢失少量消息，同步刷盘不会丢失消息），性能最高</p></li><li><p>缺点<br>单个 broker 宕机期间，这台机器上未被消费的消息在机器恢复之前不可订阅，消息的实时性会受到影响。</p></li></ul><h2 id="多-master-多-slave-异步复制"><a href="#多-master-多-slave-异步复制" class="headerlink" title="多 master 多 slave 异步复制"></a>多 master 多 slave 异步复制</h2><p>每个 master 配置一个 slave，有多对 master slave，HA 采用的是异步复制方式，主备有短暂的消息延迟（毫秒级），master 收到消息后立即向应用返回成功标志，同时向 slave 写入消息。</p><ul><li><p>优点<br>即是磁盘损坏，消息丢失的非常少，且消息的实时性不会受到影响。因为 master 宕机后，消费者仍然可以从 slave 消费，此过程对应用透明，不需要人工干预，性能同多个 master 模式一样</p></li><li><p>缺点<br>master 宕机，磁盘损坏下，会丢失少量消息</p></li></ul><h2 id="多-master-多-slave-同步双写"><a href="#多-master-多-slave-同步双写" class="headerlink" title="多 master 多 slave 同步双写"></a>多 master 多 slave 同步双写</h2><p>每个 master 配置一个 slave，有多对 master slave，HA 采用同步双写模式，主备都成功才会返回成功</p><ul><li><p>优点<br>数据与服务都无单点，master 宕机情况下，消息无延迟，服务可用性与数据可用性最高</p></li><li><p>缺点<br>性能比异步复制低 10% 左右，发送单个 master 的 RT 会略高，主机宕机后，slave 不能自动切换为主机（后续版本会支持）</p></li></ul><hr><h1 id="一主一从"><a href="#一主一从" class="headerlink" title="一主一从"></a>一主一从</h1><h2 id="修改-master-配置"><a href="#修改-master-配置" class="headerlink" title="修改 master 配置"></a>修改 master 配置</h2><p>进入 <code>conf/2m-2s-async</code>，修改文件：<code>broker-a-s.properties</code>:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">rm -rf broker-a-s.properties </span><br><span class="line">cp broker-a.properties  broker-a-s.properties</span><br></pre></td></tr></table></figure></p><p>然后打开 <code>broker-a-s.properties</code>，修改：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">brokerId=1</span><br><span class="line">brokerRole=SLAVE</span><br></pre></td></tr></table></figure></p><p>修改两个配置文件的 nameserver 为两个服务器对应的 nameserver 地址，多个地址用英文分号分割</p><h2 id="修改-slave-配置"><a href="#修改-slave-配置" class="headerlink" title="修改 slave 配置"></a>修改 slave 配置</h2><p>将 master 的 <code>broker-a.properties</code>、<code>broker-a-s.properties</code> 同步过来，在 master 上执行<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">scp broker-a.properties 192.168.52.201:/usr/local/include/mq/rocketmq/conf/2m-2s-async/</span><br><span class="line">scp broker-a-s.properties 192.168.52.201:/usr/local/include/mq/rocketmq/conf/2m-2s-async/</span><br></pre></td></tr></table></figure></p><h2 id="启动集群"><a href="#启动集群" class="headerlink" title="启动集群"></a>启动集群</h2><p>依次启动 master、slave 的 nameserver<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nohup ./bin/mqnamesrv &amp;</span><br></pre></td></tr></table></figure></p><p>在 master 上使用 <code>broker-a.properties</code> 启动 broker<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nohup sh ./bin/mqbroker -c /usr/local/include/mq/rocketmq/conf/2m-2s-async/broker-a.properties &gt; /dev/null 2&gt;&amp;1 &amp;</span><br></pre></td></tr></table></figure></p><p>在 slave 上使用 <code>broker-a-s.properties</code> 启动 broker<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nohup sh ./bin/mqbroker -c /usr/local/include/mq/rocketmq/conf/2m-2s-async/broker-a-s.properties &gt; /dev/null 2&gt;&amp;1 &amp;</span><br></pre></td></tr></table></figure></p><h2 id="验证集群"><a href="#验证集群" class="headerlink" title="验证集群"></a>验证集群</h2><p>在 rocketmq-console 中，修改 nameserver 配置：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rocketmq.config.namesrvAddr=192.168.52.200:9876;192.168.52.201:9876</span><br></pre></td></tr></table></figure></p><p>启动 console，并查看集群属性<br><img src="/images/rocketmq/1-master-1-slave.png" alt="一主一从"></p><h2 id="缺陷"><a href="#缺陷" class="headerlink" title="缺陷"></a>缺陷</h2><p>当主节点挂掉后，消息将无法写入</p><hr><h1 id="双主双从"><a href="#双主双从" class="headerlink" title="双主双从"></a>双主双从</h1><p>双主双从，异步刷盘，同步复制（生产环境建议采用此方式）</p><h2 id="集群搭建"><a href="#集群搭建" class="headerlink" title="集群搭建"></a>集群搭建</h2><p>准备4份 RocketMQ 环境，修改配置文件 <code>conf/2m-2s-sync/broker-a.properties</code>，将 <code>brokerRole</code> 改为：<code>SYNC_MASTER</code>,<code>flushDiskType</code> 改为 <code>ASYNC_FLUSH</code>，nameserver 为四台服务器的 nameserver 地址其他与之前 async 的配置一样</p><p>修改 <code>conf/2m-2s-sync/broker-a-s.0properties</code> 的 <code>brokerId</code> 为大于 0 的值，<code>brokerRole</code> 为 <code>SLAVE</code>，nameserver 为四台服务器的 nameserver 地址。</p><p>修改 <code>conf/2m-2s-sync/broker-b.0properties</code>、<code>conf/2m-2s-sync/broker-b-2.0properties</code>，与 a 的区别在与 <code>brokerName</code> 都为 broker-b</p><h2 id="启动集群-1"><a href="#启动集群-1" class="headerlink" title="启动集群"></a>启动集群</h2><p>每台机器都启动 nameserveer<br><code>nohup ./bin/mqnamesrv &amp;</code></p><p>在第一台机器上启动 broker-a<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nohup sh ./bin/mqbroker -c /usr/local/include/mq/rocketmq/conf/2m-2s-sync/broker-a.properties &gt; /dev/null 2&gt;&amp;1 &amp;</span><br></pre></td></tr></table></figure></p><p>在第二台机器上启动 broker-b<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nohup sh ./bin/mqbroker -c /usr/local/include/mq/rocketmq/conf/2m-2s-sync/broker-b.properties &gt; /dev/null 2&gt;&amp;1 &amp;</span><br></pre></td></tr></table></figure></p><p>在第三台机器上启动 broker-a-s<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nohup sh ./bin/mqbroker -c /usr/local/include/mq/rocketmq/conf/2m-2s-sync/broker-a-s.properties &gt; /dev/null 2&gt;&amp;1 &amp;</span><br></pre></td></tr></table></figure></p><p>在第四台机器上启动 broker-b-s<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nohup sh ./bin/mqbroker -c /usr/local/include/mq/rocketmq/conf/2m-2s-sync/broker-b-s.properties &gt; /dev/null 2&gt;&amp;1 &amp;</span><br></pre></td></tr></table></figure></p><h2 id="验证集群-1"><a href="#验证集群-1" class="headerlink" title="验证集群"></a>验证集群</h2><p>修改 rocket-console 的配置：<code>rocketmq.config.namesrvAddr=192.168.52.200:9876;192.168.52.201:9876;192.168.52.202:9876;192.168.52.203:9876</code>，启动 console，打开 <code>集群选项卡</code>：<br><img src="/images/rocketmq/2-master-2-slave-sync.png" alt="双主双从-同步双写-异步刷盘"></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;RocketMQ 集群模式分为四种：&lt;code&gt;单 master&lt;/code&gt;、&lt;code&gt;多 master&lt;/code&gt;、&lt;code&gt;多 master 多 slave 异步复制&lt;/code&gt;、&lt;code&gt;多 master 多 slave 同步双写&lt;/code&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="rocketmq" scheme="https://www.laiyy.top/categories/rocketmq/"/>
    
    
  </entry>
  
  <entry>
    <title>RocketMQ（2）  顺序消息、事务消息</title>
    <link href="https://www.laiyy.top/rocketmq/rocketmq-2.html"/>
    <id>https://www.laiyy.top/rocketmq/rocketmq-2.html</id>
    <published>2019-04-21T09:29:47.000Z</published>
    <updated>2019-04-21T09:29:47.000Z</updated>
    
    <content type="html"><![CDATA[<p>RocketMQ 顺序消息：消息有序是指可以按照消息发送顺序来消费。RocketMQ 可以严格的保证消息有序，但是这个顺序逼格不是全局顺序，只是分区(queue)顺序。要保证群居顺序，只能有一个分区。</p><a id="more"></a><h1 id="顺序消息"><a href="#顺序消息" class="headerlink" title="顺序消息"></a>顺序消息</h1><p>在 MQ 模型中，顺序要由三个阶段保证：</p><ul><li>消息被发送时，保持顺序</li><li>消息被存储时的顺序和发送的顺序一致</li><li>消息被消费时的顺序和存储的顺序一致</li></ul><p>发送时保持顺序，意味着对于有顺序要求的消息，用户应该在同一个线程中采用同步的方式发送。存储保持和发送的顺序一致，则要求在同一线程中被发送出来的消息 A/B，存储时 A 要在 B 之前。而消费保持和存储一致，则要求消息 A/B 到达 Consumer 之后必须按照先后顺序被处理。</p><p><img src="/images/rocketmq/order.png" alt="order"></p><h2 id="生产者"><a href="#生产者" class="headerlink" title="生产者"></a>生产者</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.laiyy.study.rocketmqprovider.order;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.rocketmq.client.exception.MQBrokerException;</span><br><span class="line"><span class="keyword">import</span> org.apache.rocketmq.client.exception.MQClientException;</span><br><span class="line"><span class="keyword">import</span> org.apache.rocketmq.client.producer.DefaultMQProducer;</span><br><span class="line"><span class="keyword">import</span> org.apache.rocketmq.client.producer.MessageQueueSelector;</span><br><span class="line"><span class="keyword">import</span> org.apache.rocketmq.client.producer.SendResult;</span><br><span class="line"><span class="keyword">import</span> org.apache.rocketmq.common.message.Message;</span><br><span class="line"><span class="keyword">import</span> org.apache.rocketmq.common.message.MessageQueue;</span><br><span class="line"><span class="keyword">import</span> org.apache.rocketmq.remoting.common.RemotingHelper;</span><br><span class="line"><span class="keyword">import</span> org.apache.rocketmq.remoting.exception.RemotingException;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.UnsupportedEncodingException;</span><br><span class="line"><span class="keyword">import</span> java.util.List;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@author</span> laiyy</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@date</span> 2019/4/21 16:18</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@description</span></span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">OrderProducer</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> MQClientException, UnsupportedEncodingException, RemotingException, InterruptedException, MQBrokerException </span>&#123;</span><br><span class="line">        <span class="comment">// 1、创建 DefaultMQProducer</span></span><br><span class="line">        DefaultMQProducer producer = <span class="keyword">new</span> DefaultMQProducer(<span class="string">"demo-producer"</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 2、设置 name server</span></span><br><span class="line">        producer.setNamesrvAddr(<span class="string">"192.168.52.200:9876"</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 3、开启 producer</span></span><br><span class="line">        producer.start();</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 连续发送 5 条信息</span></span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> index = <span class="number">1</span>; index &lt;= <span class="number">5</span>; index++) &#123;</span><br><span class="line">            <span class="comment">// 创建消息</span></span><br><span class="line">            Message message = <span class="keyword">new</span> Message(<span class="string">"TOPIC_DEMO"</span>, <span class="string">"TAG_A"</span>, <span class="string">"KEYS_!"</span>, (<span class="string">"HELLO！"</span> + index).getBytes(RemotingHelper.DEFAULT_CHARSET));</span><br><span class="line"></span><br><span class="line">            <span class="comment">// 指定 MessageQueue，顺序发送消息</span></span><br><span class="line">            <span class="comment">// 第一个参数：消息体</span></span><br><span class="line">            <span class="comment">// 第二个参数：选中指定的消息队列对象（会将所有的消息队列传进来，需要自己选择）</span></span><br><span class="line">            <span class="comment">// 第三个参数：选择对应的队列下标</span></span><br><span class="line">            SendResult result = producer.send(message, <span class="keyword">new</span> MessageQueueSelector() &#123;</span><br><span class="line">                <span class="comment">// 第一个参数：所有的消息队列对象</span></span><br><span class="line">                <span class="comment">// 第二个参数：消息体</span></span><br><span class="line">                <span class="comment">// 第三个参数：传入的消息队列下标</span></span><br><span class="line">                <span class="meta">@Override</span></span><br><span class="line">                <span class="function"><span class="keyword">public</span> MessageQueue <span class="title">select</span><span class="params">(List&lt;MessageQueue&gt; list, Message message, Object o)</span> </span>&#123;</span><br><span class="line">                    <span class="comment">// 获取队列下标</span></span><br><span class="line">                    <span class="keyword">int</span> index = (<span class="keyword">int</span>) o;</span><br><span class="line">                    <span class="keyword">return</span> list.get(index);</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;, <span class="number">0</span>);</span><br><span class="line">            System.out.println(<span class="string">"发送第："</span> + index + <span class="string">" 条信息成功："</span> + result);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// 关闭 producer</span></span><br><span class="line">        producer.shutdown();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>控制台输出结果：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">发送第：1 条信息成功：SendResult [sendStatus=SEND_OK, msgId=C0A800677E4C18B4AAC26ACE66560000, offsetMsgId=C0A834C800002A9F00000000000000B8, messageQueue=MessageQueue [topic=TOPIC_DEMO, brokerName=broker-a, queueId=0], queueOffset=1]</span><br><span class="line">发送第：2 条信息成功：SendResult [sendStatus=SEND_OK, msgId=C0A800677E4C18B4AAC26ACE66630001, offsetMsgId=C0A834C800002A9F0000000000000171, messageQueue=MessageQueue [topic=TOPIC_DEMO, brokerName=broker-a, queueId=0], queueOffset=2]</span><br><span class="line">发送第：3 条信息成功：SendResult [sendStatus=SEND_OK, msgId=C0A800677E4C18B4AAC26ACE66660002, offsetMsgId=C0A834C800002A9F000000000000022A, messageQueue=MessageQueue [topic=TOPIC_DEMO, brokerName=broker-a, queueId=0], queueOffset=3]</span><br><span class="line">发送第：4 条信息成功：SendResult [sendStatus=SEND_OK, msgId=C0A800677E4C18B4AAC26ACE66690003, offsetMsgId=C0A834C800002A9F00000000000002E3, messageQueue=MessageQueue [topic=TOPIC_DEMO, brokerName=broker-a, queueId=0], queueOffset=4]</span><br><span class="line">发送第：5 条信息成功：SendResult [sendStatus=SEND_OK, msgId=C0A800677E4C18B4AAC26ACE666C0004, offsetMsgId=C0A834C800002A9F000000000000039C, messageQueue=MessageQueue [topic=TOPIC_DEMO, brokerName=broker-a, queueId=0], queueOffset=5]</span><br><span class="line">17:45:11.545 [NettyClientSelector_1] INFO RocketmqRemoting - closeChannel: close the connection to remote address[192.168.52.200:10909] result: true</span><br><span class="line">17:45:11.548 [NettyClientSelector_1] INFO RocketmqRemoting - closeChannel: close the connection to remote address[192.168.52.200:9876] result: true</span><br><span class="line">17:45:11.549 [NettyClientSelector_1] INFO RocketmqRemoting - closeChannel: close the connection to remote address[192.168.52.200:10911] result: true</span><br><span class="line"></span><br><span class="line">Process finished with exit code 0</span><br></pre></td></tr></table></figure></p><p>可以看到，所有消息的  <code>queueId</code> 都为 0，顺序消息生产成功。</p><h2 id="消费者"><a href="#消费者" class="headerlink" title="消费者"></a>消费者</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">OrderConsumer</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> MQClientException </span>&#123;</span><br><span class="line">        <span class="comment">// 1、创建 DefaultMQPushConsumer</span></span><br><span class="line">        DefaultMQPushConsumer consumer = <span class="keyword">new</span> DefaultMQPushConsumer(<span class="string">"demo-consumer"</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 2、设置 name server</span></span><br><span class="line">        consumer.setNamesrvAddr(<span class="string">"192.168.52.200:9876"</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 设置消息拉取最大数</span></span><br><span class="line">        consumer.setConsumeMessageBatchMaxSize(<span class="number">2</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 3、设置 subscribe</span></span><br><span class="line">        consumer.subscribe(<span class="string">"TOPIC_DEMO"</span>, <span class="comment">// 要消费的主题</span></span><br><span class="line">                <span class="string">"*"</span> <span class="comment">// 过滤规则</span></span><br><span class="line">        );</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 4、创建消息监听</span></span><br><span class="line">        consumer.registerMessageListener(<span class="keyword">new</span> MessageListenerOrderly() &#123;</span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="function"><span class="keyword">public</span> ConsumeOrderlyStatus <span class="title">consumeMessage</span><span class="params">(List&lt;MessageExt&gt; list, ConsumeOrderlyContext consumeOrderlyContext)</span> </span>&#123;</span><br><span class="line">                <span class="comment">// 5、获取消息信息</span></span><br><span class="line">                <span class="keyword">for</span> (MessageExt msg : list) &#123;</span><br><span class="line">                    <span class="comment">// 获取主题</span></span><br><span class="line">                    String topic = msg.getTopic();</span><br><span class="line">                    <span class="comment">// 获取标签</span></span><br><span class="line">                    String tags = msg.getTags();</span><br><span class="line">                    <span class="comment">// 获取信息</span></span><br><span class="line">                    <span class="keyword">try</span> &#123;</span><br><span class="line">                        String result = <span class="keyword">new</span> String(msg.getBody(), RemotingHelper.DEFAULT_CHARSET);</span><br><span class="line">                        System.out.println(<span class="string">"Consumer 消费信息：topic："</span> + topic+ <span class="string">"，tags："</span> + tags + <span class="string">"，消息体："</span> + result);</span><br><span class="line">                    &#125; <span class="keyword">catch</span> (UnsupportedEncodingException e) &#123;</span><br><span class="line">                        e.printStackTrace();</span><br><span class="line">                        <span class="keyword">return</span> ConsumeOrderlyStatus.SUSPEND_CURRENT_QUEUE_A_MOMENT;</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">                <span class="comment">// 6、返回消息读取状态</span></span><br><span class="line">                <span class="keyword">return</span> ConsumeOrderlyStatus.SUCCESS;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;);</span><br><span class="line">        <span class="comment">// 启动消费者</span></span><br><span class="line">        consumer.start();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>顺序消费者与之前的 demo 最大的不同，在于 <code>message listener</code> 从 <code>MessageListenerConcurrently</code> 变为 <code>MessageListenerOrderly</code>，消费标识从 <code>ConsumeConcurrentlyStatus</code> 变为 <code>ConsumeOrderlyStatus</code>。</p><p>查看控制台输出：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">Consumer 消费信息：topic：TOPIC_DEMO，tags：TAG_A，消息体：HELLO！1</span><br><span class="line">Consumer 消费信息：topic：TOPIC_DEMO，tags：TAG_A，消息体：HELLO！2</span><br><span class="line">Consumer 消费信息：topic：TOPIC_DEMO，tags：TAG_A，消息体：HELLO！3</span><br><span class="line">Consumer 消费信息：topic：TOPIC_DEMO，tags：TAG_A，消息体：HELLO！4</span><br><span class="line">Consumer 消费信息：topic：TOPIC_DEMO，tags：TAG_A，消息体：HELLO！5</span><br></pre></td></tr></table></figure></p><hr><h1 id="事务消息"><a href="#事务消息" class="headerlink" title="事务消息"></a>事务消息</h1><p>在 RocketMQ 4.3 版本后，开放了事务消息。</p><h2 id="RocketMQ-事务消息流程"><a href="#RocketMQ-事务消息流程" class="headerlink" title="RocketMQ 事务消息流程"></a>RocketMQ 事务消息流程</h2><p>RocketMQ 的事务消息，只要是通过消息的异步处理，可以保证本地事务和消息发送同事成功执行或失败，从而保证数据的最终一致性。</p><p><img src="/images/rocketmq/transaction-message.png" alt="Transaction message"></p><p>MQ 事务消息解决分布式事务问题，但是第三方 MQ 支持事务消息的中间件不多，如 RockctMQ，它们支持事务的方式也是类似于采用二阶段提交，但是市面上一些主流的 MQ 都是不支持事务消息的，如：Kafka、RabbitMQ</p><p>以 RocketMQ 为例，事务消息实现思路大致为：</p><ul><li>第一阶段的 Prepared 消息，会拿到消息的地址</li><li>第二阶段执行本地事务</li><li>第三阶段通过第一阶段拿到的地址去访问消息，并修改状态</li></ul><p>也就是说，在业务方法内想要消息队列提交两次消息，一次发送消息和一次确认消息。如果确认消息发送失败，RocketMQ 会定期扫描消息集群中的事务消息。这时候发现了 prepared 消息，它会向消息发送者确认，所以生产方需要实现一个 check 接口。RocketMQ 会根据发送端设置的策略来决定是回滚还是继续发送确认消息。这样就保证了消息发送与本地事务同时成功或同时失败。<br><img src="/images/rocketmq/transaction-message-1.png" alt="Transaction message"></p><p>事务消息的成功投递需要三个 Topic，分别是</p><ul><li>Half Topic：用于记录所有的 prepare 消息</li><li>Op Half Topic：记录以及提交了状态的 prepare 消息</li><li>Real Topic：事务消息真正的 topic，在 commit 后才会将消息写入该 topic，从而进行消息投递。</li></ul><h2 id="事务消息实现"><a href="#事务消息实现" class="headerlink" title="事务消息实现"></a>事务消息实现</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">TransactionProducer</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> MQClientException, UnsupportedEncodingException, RemotingException, InterruptedException, MQBrokerException </span>&#123;</span><br><span class="line">        <span class="comment">// 1、创建 TransactionMQProducer</span></span><br><span class="line">        TransactionMQProducer producer = <span class="keyword">new</span> TransactionMQProducer(<span class="string">"transaction-producer"</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 2、设置 name server</span></span><br><span class="line">        producer.setNamesrvAddr(<span class="string">"192.168.52.200:9876"</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 3、指定消息监听对象，用于执行本地事务和消息回查</span></span><br><span class="line">        TransactionListenerImpl transactionListener = <span class="keyword">new</span> TransactionListenerImpl();</span><br><span class="line">        producer.setTransactionListener(transactionListener);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 4、线程池</span></span><br><span class="line">        ThreadPoolExecutor executor = <span class="keyword">new</span> ThreadPoolExecutor(<span class="number">2</span>, <span class="number">5</span>, <span class="number">100</span>, TimeUnit.SECONDS, <span class="keyword">new</span> ArrayBlockingQueue&lt;Runnable&gt;(<span class="number">2000</span>), <span class="keyword">new</span> ThreadFactory() &#123;</span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="function"><span class="keyword">public</span> Thread <span class="title">newThread</span><span class="params">(Runnable r)</span> </span>&#123;</span><br><span class="line">                Thread thread = <span class="keyword">new</span> Thread(r);</span><br><span class="line">                thread.setName(<span class="string">"client-transaction-msg-thread"</span>);</span><br><span class="line">                <span class="keyword">return</span> thread;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;);</span><br><span class="line"></span><br><span class="line">        producer.setExecutorService(executor);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 5、开启 producer</span></span><br><span class="line">        producer.start();</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 6、创建消息</span></span><br><span class="line">        Message message = <span class="keyword">new</span> Message(<span class="string">"TRANSACTION_TOPIC"</span>, <span class="string">"TAG_A"</span>, <span class="string">"KEYS_!"</span>, <span class="string">"HELLO！TRANSACTION!"</span>.getBytes(RemotingHelper.DEFAULT_CHARSET));</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 7、发送消息</span></span><br><span class="line">        TransactionSendResult result = producer.sendMessageInTransaction(message, <span class="string">"hello-transaction"</span>);</span><br><span class="line"></span><br><span class="line">        System.out.println(result);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 关闭 producer</span></span><br><span class="line">        producer.shutdown();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>事务消息监听器：<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">TransactionListenerImpl</span> <span class="keyword">implements</span> <span class="title">TransactionListener</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 存储对应书屋的状态信息， key：事务id，value：事务执行的状态</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">private</span> ConcurrentMap&lt;String, Integer&gt; maps = <span class="keyword">new</span> ConcurrentHashMap&lt;&gt;();</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 执行本地事务</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> message</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> o</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@return</span></span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> LocalTransactionState <span class="title">executeLocalTransaction</span><span class="params">(Message message, Object o)</span> </span>&#123;</span><br><span class="line">        <span class="comment">// 事务id</span></span><br><span class="line">        String transactionId = message.getTransactionId();</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 0：执行中，状态未知</span></span><br><span class="line">        <span class="comment">// 1：本地事务执行成功</span></span><br><span class="line">        <span class="comment">// 2：本地事务执行失败</span></span><br><span class="line"></span><br><span class="line">        maps.put(transactionId, <span class="number">0</span>);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            System.out.println(<span class="string">"正在执行本地事务。。。。"</span>);</span><br><span class="line">            <span class="comment">// 模拟本地事务</span></span><br><span class="line">            TimeUnit.SECONDS.sleep(<span class="number">65</span>);</span><br><span class="line">            System.out.println(<span class="string">"本地事务执行成功。。。。"</span>);</span><br><span class="line">            maps.put(transactionId, <span class="number">1</span>);</span><br><span class="line">        &#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">            maps.put(transactionId, <span class="number">2</span>);</span><br><span class="line">            <span class="keyword">return</span> LocalTransactionState.ROLLBACK_MESSAGE;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> LocalTransactionState.COMMIT_MESSAGE;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 消息回查</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> messageExt</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@return</span></span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> LocalTransactionState <span class="title">checkLocalTransaction</span><span class="params">(MessageExt messageExt)</span> </span>&#123;</span><br><span class="line">        String transactionId = messageExt.getTransactionId();</span><br><span class="line"></span><br><span class="line">        System.out.println(<span class="string">"正在执行消息回查，事务id："</span> + transactionId);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 获取事务id的执行状态</span></span><br><span class="line">        <span class="keyword">if</span> (maps.containsKey(transactionId)) &#123;</span><br><span class="line">            <span class="keyword">int</span> status = maps.get(transactionId);</span><br><span class="line">            System.out.println(<span class="string">"消息回查状态："</span> + status);</span><br><span class="line">            <span class="keyword">switch</span> (status) &#123;</span><br><span class="line">                <span class="keyword">case</span> <span class="number">0</span>:</span><br><span class="line">                    <span class="keyword">return</span> LocalTransactionState.UNKNOW;</span><br><span class="line">                <span class="keyword">case</span> <span class="number">1</span>:</span><br><span class="line">                    <span class="keyword">return</span> LocalTransactionState.COMMIT_MESSAGE;</span><br><span class="line">                <span class="keyword">default</span>:</span><br><span class="line">                    <span class="keyword">return</span> LocalTransactionState.ROLLBACK_MESSAGE;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> LocalTransactionState.UNKNOW;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>运行生产者，查看控制台输出：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">正在执行本地事务。。。。</span><br><span class="line">正在执行消息回查，事务id：C0A800678F0818B4AAC26AEDDEB10000</span><br><span class="line">消息回查状态：0</span><br><span class="line">本地事务执行成功。。。。</span><br></pre></td></tr></table></figure></p><p>需要注意：消息回查会隔一段时间执行一次，如果执行本地事务的时间太短，则控制台不会输出事务回查日志。</p><hr><h1 id="广播消息"><a href="#广播消息" class="headerlink" title="广播消息"></a>广播消息</h1><h2 id="生产者-1"><a href="#生产者-1" class="headerlink" title="生产者"></a>生产者</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Producer</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> MQClientException, UnsupportedEncodingException, RemotingException, InterruptedException, MQBrokerException </span>&#123;</span><br><span class="line">        <span class="comment">// 1、创建 DefaultMQProducer</span></span><br><span class="line">        DefaultMQProducer producer = <span class="keyword">new</span> DefaultMQProducer(<span class="string">"boardcast-producer"</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 2、设置 name server</span></span><br><span class="line">        producer.setNamesrvAddr(<span class="string">"192.168.52.200:9876"</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 3、开启 producer</span></span><br><span class="line">        producer.start();</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> index = <span class="number">1</span>; index &lt;= <span class="number">10</span>; index++) &#123;</span><br><span class="line">            Message message = <span class="keyword">new</span> Message(<span class="string">"BOARD_CAST_TOPIC"</span>, <span class="string">"TAG_A"</span>, <span class="string">"KEYS_"</span> + index, (<span class="string">"HELLO！"</span> + index).getBytes(RemotingHelper.DEFAULT_CHARSET));</span><br><span class="line">            SendResult result = producer.send(message);</span><br><span class="line">            System.out.println(result);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 关闭 producer</span></span><br><span class="line">        producer.shutdown();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="消费者-1"><a href="#消费者-1" class="headerlink" title="消费者"></a>消费者</h2><p>消费者需要将消费模式修改为 广播消费：  consumer.setMessageModel(MessageModel.BROADCASTING);</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Consumer</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> MQClientException </span>&#123;</span><br><span class="line">        <span class="comment">// 1、创建 DefaultMQPushConsumer</span></span><br><span class="line">        DefaultMQPushConsumer consumer = <span class="keyword">new</span> DefaultMQPushConsumer(<span class="string">"boardcast-consumer"</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 2、设置 name server</span></span><br><span class="line">        consumer.setNamesrvAddr(<span class="string">"192.168.52.200:9876"</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 设置消息拉取最大数</span></span><br><span class="line">        consumer.setConsumeMessageBatchMaxSize(<span class="number">2</span>);</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        <span class="comment">// 修改消费模式，默认是集群消费模式，修改为广播消费模式</span></span><br><span class="line">        consumer.setMessageModel(MessageModel.BROADCASTING);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 3、设置 subscribe</span></span><br><span class="line">        consumer.subscribe(<span class="string">"BOARD_CAST_TOPIC"</span>, <span class="comment">// 要消费的主题</span></span><br><span class="line">                <span class="string">"*"</span> <span class="comment">// 过滤规则</span></span><br><span class="line">        );</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 4、创建消息监听</span></span><br><span class="line">        consumer.registerMessageListener(<span class="keyword">new</span> MessageListenerConcurrently() &#123;</span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="function"><span class="keyword">public</span> ConsumeConcurrentlyStatus <span class="title">consumeMessage</span><span class="params">(List&lt;MessageExt&gt; list, ConsumeConcurrentlyContext consumeConcurrentlyContext)</span> </span>&#123;</span><br><span class="line">                <span class="comment">// 5、获取消息信息</span></span><br><span class="line">                <span class="keyword">for</span> (MessageExt msg : list) &#123;</span><br><span class="line">                    <span class="comment">// 获取主题</span></span><br><span class="line">                    String topic = msg.getTopic();</span><br><span class="line">                    <span class="comment">// 获取标签</span></span><br><span class="line">                    String tags = msg.getTags();</span><br><span class="line">                    <span class="comment">// 获取信息</span></span><br><span class="line">                    <span class="keyword">try</span> &#123;</span><br><span class="line">                        String result = <span class="keyword">new</span> String(msg.getBody(), RemotingHelper.DEFAULT_CHARSET);</span><br><span class="line">                        System.out.println(<span class="string">"A  Consumer 消费信息：topic："</span> + topic+ <span class="string">"，tags："</span> + tags + <span class="string">"，消息体："</span> + result);</span><br><span class="line">                    &#125; <span class="keyword">catch</span> (UnsupportedEncodingException e) &#123;</span><br><span class="line">                        e.printStackTrace();</span><br><span class="line">                        <span class="keyword">return</span> ConsumeConcurrentlyStatus.RECONSUME_LATER;</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">                <span class="comment">// 6、返回消息读取状态</span></span><br><span class="line">                <span class="keyword">return</span> ConsumeConcurrentlyStatus.CONSUME_SUCCESS;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;);</span><br><span class="line">        consumer.start();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="验证"><a href="#验证" class="headerlink" title="验证"></a>验证</h2><h3 id="生产者控制台输出"><a href="#生产者控制台输出" class="headerlink" title="生产者控制台输出"></a>生产者控制台输出</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">SendResult [sendStatus=SEND_OK, msgId=C0A80067971418B4AAC26B2965570000, offsetMsgId=C0A834C800002A9F00000000000026D0, messageQueue=MessageQueue [topic=BOARD_CAST_TOPIC, brokerName=broker-a, queueId=1], queueOffset=0]</span><br><span class="line">SendResult [sendStatus=SEND_OK, msgId=C0A80067971418B4AAC26B2965660001, offsetMsgId=C0A834C800002A9F000000000000278F, messageQueue=MessageQueue [topic=BOARD_CAST_TOPIC, brokerName=broker-a, queueId=2], queueOffset=10]</span><br><span class="line">SendResult [sendStatus=SEND_OK, msgId=C0A80067971418B4AAC26B29656C0002, offsetMsgId=C0A834C800002A9F000000000000284E, messageQueue=MessageQueue [topic=BOARD_CAST_TOPIC, brokerName=broker-a, queueId=3], queueOffset=0]</span><br><span class="line">SendResult [sendStatus=SEND_OK, msgId=C0A80067971418B4AAC26B2965700003, offsetMsgId=C0A834C800002A9F000000000000290D, messageQueue=MessageQueue [topic=BOARD_CAST_TOPIC, brokerName=broker-a, queueId=0], queueOffset=0]</span><br><span class="line">SendResult [sendStatus=SEND_OK, msgId=C0A80067971418B4AAC26B29657B0004, offsetMsgId=C0A834C800002A9F00000000000029CC, messageQueue=MessageQueue [topic=BOARD_CAST_TOPIC, brokerName=broker-a, queueId=1], queueOffset=1]</span><br><span class="line">SendResult [sendStatus=SEND_OK, msgId=C0A80067971418B4AAC26B2965880005, offsetMsgId=C0A834C800002A9F0000000000002A8B, messageQueue=MessageQueue [topic=BOARD_CAST_TOPIC, brokerName=broker-a, queueId=2], queueOffset=11]</span><br><span class="line">SendResult [sendStatus=SEND_OK, msgId=C0A80067971418B4AAC26B29658E0006, offsetMsgId=C0A834C800002A9F0000000000002B4A, messageQueue=MessageQueue [topic=BOARD_CAST_TOPIC, brokerName=broker-a, queueId=3], queueOffset=1]</span><br><span class="line">SendResult [sendStatus=SEND_OK, msgId=C0A80067971418B4AAC26B2965960007, offsetMsgId=C0A834C800002A9F0000000000002C09, messageQueue=MessageQueue [topic=BOARD_CAST_TOPIC, brokerName=broker-a, queueId=0], queueOffset=1]</span><br><span class="line">SendResult [sendStatus=SEND_OK, msgId=C0A80067971418B4AAC26B29659D0008, offsetMsgId=C0A834C800002A9F0000000000002CC8, messageQueue=MessageQueue [topic=BOARD_CAST_TOPIC, brokerName=broker-a, queueId=1], queueOffset=2]</span><br><span class="line">SendResult [sendStatus=SEND_OK, msgId=C0A80067971418B4AAC26B2965AB0009, offsetMsgId=C0A834C800002A9F0000000000002D87, messageQueue=MessageQueue [topic=BOARD_CAST_TOPIC, brokerName=broker-a, queueId=2], queueOffset=12]</span><br><span class="line">19:24:35.135 [NettyClientSelector_1] INFO RocketmqRemoting - closeChannel: close the connection to remote address[192.168.52.200:10911] result: true</span><br><span class="line">19:24:35.140 [NettyClientSelector_1] INFO RocketmqRemoting - closeChannel: close the connection to remote address[192.168.52.200:9876] result: true</span><br><span class="line">19:24:35.140 [NettyClientSelector_1] INFO RocketmqRemoting - closeChannel: close the connection to remote address[192.168.52.200:10909] result: true</span><br></pre></td></tr></table></figure><h3 id="消费者控制台输出"><a href="#消费者控制台输出" class="headerlink" title="消费者控制台输出"></a>消费者控制台输出</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">A  Consumer 消费信息：topic：BOARD_CAST_TOPIC，tags：TAG_A，消息体：HELLO！1</span><br><span class="line">A  Consumer 消费信息：topic：BOARD_CAST_TOPIC，tags：TAG_A，消息体：HELLO！2</span><br><span class="line">A  Consumer 消费信息：topic：BOARD_CAST_TOPIC，tags：TAG_A，消息体：HELLO！5</span><br><span class="line">A  Consumer 消费信息：topic：BOARD_CAST_TOPIC，tags：TAG_A，消息体：HELLO！4</span><br><span class="line">A  Consumer 消费信息：topic：BOARD_CAST_TOPIC，tags：TAG_A，消息体：HELLO！3</span><br><span class="line">A  Consumer 消费信息：topic：BOARD_CAST_TOPIC，tags：TAG_A，消息体：HELLO！7</span><br><span class="line">A  Consumer 消费信息：topic：BOARD_CAST_TOPIC，tags：TAG_A，消息体：HELLO！6</span><br><span class="line">A  Consumer 消费信息：topic：BOARD_CAST_TOPIC，tags：TAG_A，消息体：HELLO！8</span><br><span class="line">A  Consumer 消费信息：topic：BOARD_CAST_TOPIC，tags：TAG_A，消息体：HELLO！9</span><br><span class="line">A  Consumer 消费信息：topic：BOARD_CAST_TOPIC，tags：TAG_A，消息体：HELLO！10</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">B  Consumer 消费信息：topic：BOARD_CAST_TOPIC，tags：TAG_A，消息体：HELLO！1</span><br><span class="line">B  Consumer 消费信息：topic：BOARD_CAST_TOPIC，tags：TAG_A，消息体：HELLO！2</span><br><span class="line">B  Consumer 消费信息：topic：BOARD_CAST_TOPIC，tags：TAG_A，消息体：HELLO！3</span><br><span class="line">B  Consumer 消费信息：topic：BOARD_CAST_TOPIC，tags：TAG_A，消息体：HELLO！5</span><br><span class="line">B  Consumer 消费信息：topic：BOARD_CAST_TOPIC，tags：TAG_A，消息体：HELLO！4</span><br><span class="line">B  Consumer 消费信息：topic：BOARD_CAST_TOPIC，tags：TAG_A，消息体：HELLO！6</span><br><span class="line">B  Consumer 消费信息：topic：BOARD_CAST_TOPIC，tags：TAG_A，消息体：HELLO！7</span><br><span class="line">B  Consumer 消费信息：topic：BOARD_CAST_TOPIC，tags：TAG_A，消息体：HELLO！8</span><br><span class="line">B  Consumer 消费信息：topic：BOARD_CAST_TOPIC，tags：TAG_A，消息体：HELLO！9</span><br><span class="line">B  Consumer 消费信息：topic：BOARD_CAST_TOPIC，tags：TAG_A，消息体：HELLO！10</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;RocketMQ 顺序消息：消息有序是指可以按照消息发送顺序来消费。RocketMQ 可以严格的保证消息有序，但是这个顺序逼格不是全局顺序，只是分区(queue)顺序。要保证群居顺序，只能有一个分区。&lt;/p&gt;
    
    </summary>
    
      <category term="rocketmq" scheme="https://www.laiyy.top/categories/rocketmq/"/>
    
    
      <category term="MQ" scheme="https://www.laiyy.top/tags/MQ/"/>
    
      <category term="RocketMQ" scheme="https://www.laiyy.top/tags/RocketMQ/"/>
    
  </entry>
  
  <entry>
    <title>RocketMQ（1） 环境搭建、基础运行</title>
    <link href="https://www.laiyy.top/rocketmq/rocketmq-1.html"/>
    <id>https://www.laiyy.top/rocketmq/rocketmq-1.html</id>
    <published>2019-04-21T08:44:07.000Z</published>
    <updated>2019-04-21T08:44:07.000Z</updated>
    
    <content type="html"><![CDATA[<p>MQ 全称为 <code>Message Queue</code>，是一种应用程序程序对应用程序的通信方式，应用程序通过读写出入队列的消息来通信，而无需专用连接来连接它们。消息传递指的是程序之间通过在消息中发送数据来进行通信，而不是通过直接调用来通信，直接调用通常用于诸如远程过程调用的技术。</p><a id="more"></a><hr><h1 id="主流-MQ-对比"><a href="#主流-MQ-对比" class="headerlink" title="主流 MQ 对比"></a>主流 MQ 对比</h1><p>主流 MQ 有 Kafka、RocketMQ、RabbitMQ 等</p><h2 id="Kafka"><a href="#Kafka" class="headerlink" title="Kafka"></a>Kafka</h2><p>Kafka 是 Apache 的一个子项目，使用 Scala 实现的一个高性能分布式 publish/subscribe 消息队列系统，主要特点：</p><ul><li>快速持久化：通过磁盘顺序读写与零拷贝机制，可以在 O(1) 的系统开销下进行消息持久化</li><li>高吞吐：在一台普通的服务器上可以达到 10W/S 的吞吐量</li><li>高堆积：支持 Topic 下消费者长时间离线，消息堆积量大</li><li>完全的分布式系统，Broker、Producer、Consumer 都原生支持分布式，依赖 ZK 实现负载均衡</li><li>支持 Hadoop 数据并行加载；对于像 Hadoop 一样的日志数据和离线分析系统，但又要求实时处理的限制，是一个可行的解决方案</li></ul><h2 id="RocketMQ"><a href="#RocketMQ" class="headerlink" title="RocketMQ"></a>RocketMQ</h2><p>前身是 Metaq，3.0 版本更名为 RocketMQ，alibaba 出品，现交 Apache 孵化。RocketMQ 是一款分布式、队列模型的消息中间件，特点：</p><ul><li>能够保证严格的消息顺序</li><li>提供丰富的消息拉取模式</li><li>高效的订阅者水平扩展能力</li><li>实时的消息订阅机制</li><li>支持事务消息</li><li>亿级消息堆积能力</li></ul><h2 id="RabbitMQ"><a href="#RabbitMQ" class="headerlink" title="RabbitMQ"></a>RabbitMQ</h2><p>使用 Erlang 编写的一个开源的消息队列，本身支持：AMQP、XMPP、SMTP、STOMP 等协议，是一个重量级消息队列，更适合企业级开发。同时也实现的 broker 架构，生产者不会讲消息直接发送给队列，消息在发送给客户端时，现在中心队列排队。<br>对路由、负载均衡、数据持久化有很好的支持。</p><hr><h1 id="RocketMQ-单机环境搭建"><a href="#RocketMQ-单机环境搭建" class="headerlink" title="RocketMQ 单机环境搭建"></a>RocketMQ 单机环境搭建</h1><h2 id="版本"><a href="#版本" class="headerlink" title="版本"></a>版本</h2><ul><li>JDK 版本：1.8+</li><li>RocketMQ：4.4.0</li><li>Maven：3.x</li><li>os：CentOS 6.5 x64</li></ul><h2 id="单机版环境搭建"><a href="#单机版环境搭建" class="headerlink" title="单机版环境搭建"></a>单机版环境搭建</h2><ol><li><p>解压 RocketMQ 4.4.0 到指定文件夹，并修改解压后的文件夹名称</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">unzip rocketmq-all-4.4.0-bin-release.zip -d /usr/local/include/mq/</span><br><span class="line">cd /usr/local/include/mq/</span><br><span class="line">mv rocketmq-all-4.4.0-bin-release/ rocketmq</span><br></pre></td></tr></table></figure></li><li><p>创建日志、数据文件夹</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">mkdir logs store &amp;&amp; cd store</span><br><span class="line">mkdir commitlog consumequeue index</span><br></pre></td></tr></table></figure></li><li><p>修改 <code>conf/2m-2s-async/broker-a.properties</code></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br></pre></td><td class="code"><pre><span class="line"># 所属集群名称</span><br><span class="line">brokerClusterName=rocketmq-cluster</span><br><span class="line"># brijer 名称，不同的配置文件，名称不一样</span><br><span class="line">brokerName=broker-a</span><br><span class="line"># 0 表示 master，大于0表示 salve</span><br><span class="line">brokerId=0</span><br><span class="line"># nameServer 地址，分号分割</span><br><span class="line">namesrvAddr=192.168.52.200:9876</span><br><span class="line"># 在发送消息时，自动创建服务器不存在的 Topic，默认创建的队列数</span><br><span class="line">defaultTopicQueueNums=4</span><br><span class="line"># 是否允许 Broker 自动创建 Topic，生产环境需关闭</span><br><span class="line">autoCreateTopicEnable=true</span><br><span class="line"># 是否允许 Broker 自动创建订阅组，生产环境需关闭</span><br><span class="line">autoCreateSubscriptionGroup=true</span><br><span class="line"># Broker 对外服务的监听端口</span><br><span class="line">listenPort=10911</span><br><span class="line"># 删除文件的时间点，默认是凌晨4点</span><br><span class="line">deleteWhen=04</span><br><span class="line"># 文件保留时间，默认 48 小时</span><br><span class="line">fileReservedTime=48</span><br><span class="line"># commitLog 每个文件的大小，默认 1G</span><br><span class="line">mapedFileSizeCommitLog=1073741824</span><br><span class="line"># consumeQueue 每个文件默认存 30W 条，根据需求调整</span><br><span class="line">mapedFileSizeConsumeQueue=300000</span><br><span class="line"># 检测屋里文件磁盘空间</span><br><span class="line">diskMaxUsedSpaceRatio=88</span><br><span class="line"># 存储路径</span><br><span class="line">storePathRootDir=/usr/local/include/mq/rocketmq/store</span><br><span class="line"># commitLog 存储路径</span><br><span class="line">storePathCommitLog=/usr/local/include/mq/rocketmq/store/commitlog</span><br><span class="line"># 消息队列存储路径</span><br><span class="line">storePathConsumeQueue=/usr/local/include/mq/rocketmq/store/consumequeue</span><br><span class="line"># 消息索引存储路径</span><br><span class="line">storePathIndex=/usr/local/include/mq/rocketmq/store/index</span><br><span class="line"># checkpoint 文件存储路径</span><br><span class="line">storeCheckPoint=/usr/local/include/mq/rocketmq/store/checkpoint</span><br><span class="line"># abort 文件存储路径</span><br><span class="line">abortFile=/usr/local/include/mq/rocketmq/store/abort</span><br><span class="line"># 限制消息大小</span><br><span class="line">maxMessageSize=65535</span><br><span class="line"># broker 角色</span><br><span class="line"># 1、ASYNC_MASTER：异步复制的 Master</span><br><span class="line"># 2、SYNC_MASTER：同步双鞋 Master</span><br><span class="line"># 3、SLAVE：从</span><br><span class="line">brokerRole=ASYNC_MASTER</span><br><span class="line"># 刷盘方式</span><br><span class="line"># 1、ASYNC_FLUSH：异步刷盘</span><br><span class="line"># 2、SYNC_FLUSH：同步刷盘</span><br><span class="line">flushDiskType=ASYNC_FLUSH</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#checkTransactionMessageEnable=false</span><br><span class="line"></span><br><span class="line"># 发送消息的线程数量</span><br><span class="line"># sendMessageThreadPoolNums=128</span><br><span class="line"># 拉取消息线程池数量</span><br><span class="line"># pullMessageThreadPoolNums=128</span><br></pre></td></tr></table></figure></li><li><p>修改 <code>conf</code> 下所有的 xml 文件，将 xml 中的 <code>${user.home}</code> 修改为 rocketmq 目录</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sed -i &apos;s#$&#123;user.home&#125;#/usr/local/include/mq/rocketmq#g&apos; *.xml</span><br></pre></td></tr></table></figure></li><li><p>修改 <code>bin/runbroker.sh</code>、<code>bin/runserver.sh</code> 中的 JVM 参数<br><img src="/images/rocketmq/runbroker.sh.png" alt="runbroker.sh"><br><img src="/images/rocketmq/runserver.sh.png" alt="runserver.sh"></p></li><li><p>启动 broker</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nohup sh ./bin/mqnamesrv &amp;</span><br></pre></td></tr></table></figure></li><li><p>使用 <code>conf/2m-2s-async/broker-a.properties</code> 配置文件，启动 broker</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nohup sh ./bin/mqbroker -c /usr/local/include/mq/rocketmq/conf/2m-2s-async/broker-a.properties &gt; /dev/null 2&gt;&amp;1 &amp;</span><br></pre></td></tr></table></figure></li><li><p>使用 jps 查看启动结果<br><img src="/images/rocketmq/jps.png" alt="jps"></p></li></ol><h2 id="RocketMQ-控制台搭建"><a href="#RocketMQ-控制台搭建" class="headerlink" title="RocketMQ 控制台搭建"></a>RocketMQ 控制台搭建</h2><p>下载地址：<a href="https://github.com/apache/rocketmq-externals.git" target="_blank" rel="noopener">https://github.com/apache/rocketmq-externals.git</a> master 分支，拉取到本地，使用 IDE 打开，修改：<code>rocketmq-externals-master\rocketmq-console\src\main\resources\application.properties</code> 配置文件，指定 RocketMQ nameserver 地址(默认端口为 9876)：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rocketmq.config.namesrvAddr=192.168.52.200:9876</span><br></pre></td></tr></table></figure></p><p>访问 <a href="http://localhost:8080" target="_blank" rel="noopener">http://localhost:8080</a><br><img src="/images/rocketmq/console.png" alt="rocketmq-console"></p><hr><h1 id="消息的生产、消费"><a href="#消息的生产、消费" class="headerlink" title="消息的生产、消费"></a>消息的生产、消费</h1><h2 id="一个简单的消息生产者"><a href="#一个简单的消息生产者" class="headerlink" title="一个简单的消息生产者"></a>一个简单的消息生产者</h2><p>使用 SpringBoot 搭建一个简单的消息生产者：<br><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependencies</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.springframework.boot<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spring-boot-starter-actuator<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.springframework.boot<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spring-boot-starter-test<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">scope</span>&gt;</span>test<span class="tag">&lt;/<span class="name">scope</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.rocketmq<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>rocketmq-client<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">version</span>&gt;</span>$&#123;rocketmq.version&#125;<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependencies</span>&gt;</span></span><br></pre></td></tr></table></figure></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Producer</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> MQClientException, UnsupportedEncodingException, RemotingException, InterruptedException, MQBrokerException </span>&#123;</span><br><span class="line">        <span class="comment">// 1、创建 DefaultMQProducer</span></span><br><span class="line">        DefaultMQProducer producer = <span class="keyword">new</span> DefaultMQProducer(<span class="string">"demo-producer"</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 2、设置 name server</span></span><br><span class="line">        producer.setNamesrvAddr(<span class="string">"192.168.52.200:9876"</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 3、开启 producer</span></span><br><span class="line">        producer.start();</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 4、创建消息</span></span><br><span class="line">        Message message = <span class="keyword">new</span> Message(<span class="string">"TOPIC_DEMO"</span>, <span class="string">"TAG_A"</span>, <span class="string">"KEYS_!"</span>, <span class="string">"HELLO！"</span>.getBytes(RemotingHelper.DEFAULT_CHARSET));</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 5、发送消息</span></span><br><span class="line">        SendResult result = producer.send(message);</span><br><span class="line">        System.out.println(result);</span><br><span class="line">        <span class="comment">// 6、关闭 producer</span></span><br><span class="line">        producer.shutdown();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>运行验证控制台打印信息：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">SendResult [sendStatus=SEND_OK, msgId=C0A80067617C18B4AAC26A932C790000, offsetMsgId=C0A834C800002A9F0000000000000000, messageQueue=MessageQueue [topic=TOPIC_DEMO, brokerName=broker-a, queueId=0], queueOffset=0]</span><br><span class="line">16:40:30.148 [NettyClientSelector_1] INFO RocketmqRemoting - closeChannel: close the connection to remote address[192.168.52.200:10909] result: true</span><br><span class="line">16:40:30.152 [NettyClientSelector_1] INFO RocketmqRemoting - closeChannel: close the connection to remote address[192.168.52.200:9876] result: true</span><br><span class="line">16:40:30.152 [NettyClientSelector_1] INFO RocketmqRemoting - closeChannel: close the connection to remote address[192.168.52.200:10911] result: true</span><br></pre></td></tr></table></figure></p><p>查看 rocketmq-console 中 <code>消息</code> 选项卡，并选择主题为 <code>TOPIC_DEMO</code>：<br><img src="/images/rocketmq/message-topic-demo.png" alt="TOPIC_DEMO"></p><p>点击 <code>MESSAGE DETAIL</code> 查看消息具体内容：<br><img src="/images/rocketmq/message-detail.png" alt="message detail"></p><h2 id="一个简单的消息消费者"><a href="#一个简单的消息消费者" class="headerlink" title="一个简单的消息消费者"></a>一个简单的消息消费者</h2><p>依赖与生产者一致</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Consumer</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> MQClientException </span>&#123;</span><br><span class="line">        <span class="comment">// 1、创建 DefaultMQPushConsumer</span></span><br><span class="line">        DefaultMQPushConsumer consumer = <span class="keyword">new</span> DefaultMQPushConsumer(<span class="string">"demo-consumer"</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 2、设置 name server</span></span><br><span class="line">        consumer.setNamesrvAddr(<span class="string">"192.168.52.200:9876"</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 设置消息拉取最大数</span></span><br><span class="line">        consumer.setConsumeMessageBatchMaxSize(<span class="number">2</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 3、设置 subscribe</span></span><br><span class="line">        consumer.subscribe(<span class="string">"TOPIC_DEMO"</span>, <span class="comment">// 要消费的主题</span></span><br><span class="line">                <span class="string">"*"</span> <span class="comment">// 过滤规则</span></span><br><span class="line">        );</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 4、创建消息监听</span></span><br><span class="line">        consumer.registerMessageListener(<span class="keyword">new</span> MessageListenerConcurrently() &#123;</span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="function"><span class="keyword">public</span> ConsumeConcurrentlyStatus <span class="title">consumeMessage</span><span class="params">(List&lt;MessageExt&gt; list, ConsumeConcurrentlyContext consumeConcurrentlyContext)</span> </span>&#123;</span><br><span class="line">                <span class="comment">// 5、获取消息信息</span></span><br><span class="line">                <span class="keyword">for</span> (MessageExt msg : list) &#123;</span><br><span class="line">                    <span class="comment">// 获取主题</span></span><br><span class="line">                    String topic = msg.getTopic();</span><br><span class="line">                    <span class="comment">// 获取标签</span></span><br><span class="line">                    String tags = msg.getTags();</span><br><span class="line">                    <span class="comment">// 获取信息</span></span><br><span class="line">                    <span class="keyword">try</span> &#123;</span><br><span class="line">                        String result = <span class="keyword">new</span> String(msg.getBody(), RemotingHelper.DEFAULT_CHARSET);</span><br><span class="line">                        System.out.println(<span class="string">"Consumer 消费信息：topic："</span> + topic+ <span class="string">"，tags："</span> + tags + <span class="string">"，消息体："</span> + result);</span><br><span class="line">                    &#125; <span class="keyword">catch</span> (UnsupportedEncodingException e) &#123;</span><br><span class="line">                        e.printStackTrace();</span><br><span class="line">                        <span class="keyword">return</span> ConsumeConcurrentlyStatus.RECONSUME_LATER;</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">                <span class="comment">// 6、返回消息读取状态</span></span><br><span class="line">                <span class="keyword">return</span> ConsumeConcurrentlyStatus.CONSUME_SUCCESS;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 7、启动消费者（启动后会阻塞）</span></span><br><span class="line">        consumer.start();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>运行消费者，查看控制台打印信息：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Consumer 消费信息：topic：TOPIC_DEMO，tags：TAG_A，消息体：HELLO！</span><br></pre></td></tr></table></figure></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;MQ 全称为 &lt;code&gt;Message Queue&lt;/code&gt;，是一种应用程序程序对应用程序的通信方式，应用程序通过读写出入队列的消息来通信，而无需专用连接来连接它们。消息传递指的是程序之间通过在消息中发送数据来进行通信，而不是通过直接调用来通信，直接调用通常用于诸如远程过程调用的技术。&lt;/p&gt;
    
    </summary>
    
      <category term="rocketmq" scheme="https://www.laiyy.top/categories/rocketmq/"/>
    
    
      <category term="MQ" scheme="https://www.laiyy.top/tags/MQ/"/>
    
      <category term="RocketMQ" scheme="https://www.laiyy.top/tags/RocketMQ/"/>
    
  </entry>
  
  <entry>
    <title>Spring Cloud 微服务（34） --- APM(三) &lt;BR&gt; Pinpoint</title>
    <link href="https://www.laiyy.top/spring-cloud/spring-cloud-34.html"/>
    <id>https://www.laiyy.top/spring-cloud/spring-cloud-34.html</id>
    <published>2019-04-17T08:38:55.000Z</published>
    <updated>2019-04-17T08:38:55.000Z</updated>
    
    <content type="html"><![CDATA[<p><code>Pinpoint</code> 是韩国人编写的 APM 系统，是一个分析大规模分布式系统的平台，并提供处理大量跟踪数据的解决方案。</p><a id="more"></a><h1 id="Pinpoint"><a href="#Pinpoint" class="headerlink" title="Pinpoint"></a>Pinpoint</h1><h2 id="特点"><a href="#特点" class="headerlink" title="特点"></a>特点</h2><ul><li>分布式事务追踪，跟踪跨分布式应用的消息</li><li>自动检测应用拓展</li><li>水平扩展，以便支持大规模服务器集群</li><li>提供代码级了践行，便于定位失败点和瓶颈</li><li>提供字节码增强技术，添加新功能无需修改代码</li></ul><h2 id="优势"><a href="#优势" class="headerlink" title="优势"></a>优势</h2><ul><li>非侵入式：使用字节码增强技术，添加新功能无需修改代码</li><li>资源消耗小：对性能影响最小（资源使用量增加约3%）</li></ul><h2 id="架构模块"><a href="#架构模块" class="headerlink" title="架构模块"></a>架构模块</h2><ul><li>HBase：主要用于存储数据</li><li>Pinpoint Collector：部署在 Web 容器上</li><li>Pinpoint Web：部署在 Web 容器上</li><li>Pinpoint Agent：附加到用于分析的 Java 应用程序</li></ul><p>流程：首先通过 agent 收集调用应用的数据，将数据发送到 collector，collector 通过处理和分析数据，最后存储到 HBase 中，可以通过 Pinpoint Web UI 查看已经分析好的调用分析数据</p><h2 id="数据结构"><a href="#数据结构" class="headerlink" title="数据结构"></a>数据结构</h2><ul><li>Span：RPC 跟踪的基本单位，表示 RPC 到达时处理的工作，包含跟踪数据。Span 将子项标记未 SpanEvent，作为数据结构，每个 Span 包含一个 TraceId</li><li>Trace：一系列跨度，由相关的 RPC(Span) 组成。同一跟踪中的跨距共享相同的 TransactionId。Trace 通过 SpanIds 和 ParentSpanIds 排序为分层树结构</li><li>TraceId：由 TransactionId、SpanId、ParentSpanId 组成的秘钥集合。<code>TransactionId</code> 代表消息id，SpanId 和 ParentSpanId 表示 RPC 父子关系<blockquote><p>TransactionId：来自单个事务的分布式系统发送、接收的消息id，必须在整个服务器组是全局唯一的<br>SpanId：接收 RPC 消息时处理的作业 ID，是在 RPC 到达节点时生成的<br>ParentSpanId：生成 RPC 的父 span 的 spanId，如果节点是事务的起始点，不会有父跨度。</p></blockquote></li></ul><p><img src="/images/spring-cloud/apm/pinpoint.png" alt="pinpont 架构图"></p><h2 id="兼容性"><a href="#兼容性" class="headerlink" title="兼容性"></a>兼容性</h2><h3 id="JDK-兼容性"><a href="#JDK-兼容性" class="headerlink" title="JDK 兼容性"></a>JDK 兼容性</h3><table><thead><tr><th style="text-align:center">Pinpoint 版本</th><th style="text-align:center">Agent 需要的 JDK 版本</th><th style="text-align:center">Collector 需要的 JDK 版本</th><th style="text-align:center">Web 需要的 JDK 版本</th></tr></thead><tbody><tr><td style="text-align:center">1.0.x</td><td style="text-align:center">6-8</td><td style="text-align:center">6+</td><td style="text-align:center">6+</td></tr><tr><td style="text-align:center">1.1.x</td><td style="text-align:center">6-8</td><td style="text-align:center">7+</td><td style="text-align:center">7+</td></tr><tr><td style="text-align:center">1.5.x</td><td style="text-align:center">6-8</td><td style="text-align:center">7+</td><td style="text-align:center">7+</td></tr><tr><td style="text-align:center">1.6.x</td><td style="text-align:center">6-8</td><td style="text-align:center">7+</td><td style="text-align:center">7+</td></tr><tr><td style="text-align:center">1.7.x</td><td style="text-align:center">6-8</td><td style="text-align:center">8+</td><td style="text-align:center">8+</td></tr><tr><td style="text-align:center">1.8.x</td><td style="text-align:center">6-8,9+</td><td style="text-align:center">8+</td><td style="text-align:center">8+</td></tr></tbody></table><h3 id="Base-兼容性"><a href="#Base-兼容性" class="headerlink" title="Base 兼容性"></a>Base 兼容性</h3><table><thead><tr><th style="text-align:center">Pinpoint 版本</th><th style="text-align:center">HBase 0.94.x</th><th style="text-align:center">HBase 0.98.x</th><th style="text-align:center">HBase 1.0.x</th><th style="text-align:center">HBase 1.1.x</th><th style="text-align:center">HBase 1.2.x</th></tr></thead><tbody><tr><td style="text-align:center">1.0.x</td><td style="text-align:center">√</td><td style="text-align:center">×</td><td style="text-align:center">×</td><td style="text-align:center">×</td><td style="text-align:center">×</td></tr><tr><td style="text-align:center">1.1.x</td><td style="text-align:center">×</td><td style="text-align:center">not tested</td><td style="text-align:center">√</td><td style="text-align:center">not tested</td><td style="text-align:center">not tested</td></tr><tr><td style="text-align:center">1.5.x</td><td style="text-align:center">×</td><td style="text-align:center">not tested</td><td style="text-align:center">√</td><td style="text-align:center">not tested</td><td style="text-align:center">not tested</td></tr><tr><td style="text-align:center">1.6.x</td><td style="text-align:center">×</td><td style="text-align:center">not tested</td><td style="text-align:center">not tested</td><td style="text-align:center">not tested</td><td style="text-align:center">√</td></tr><tr><td style="text-align:center">1.7.x</td><td style="text-align:center">×</td><td style="text-align:center">not tested</td><td style="text-align:center">not tested</td><td style="text-align:center">not tested</td><td style="text-align:center">√</td></tr><tr><td style="text-align:center">1.8.x</td><td style="text-align:center">×</td><td style="text-align:center">not tested</td><td style="text-align:center">not tested</td><td style="text-align:center">not tested</td><td style="text-align:center">√</td></tr></tbody></table><h3 id="Agent-Collector-兼容性"><a href="#Agent-Collector-兼容性" class="headerlink" title="Agent-Collector 兼容性"></a>Agent-Collector 兼容性</h3><table><thead><tr><th style="text-align:center">Agent 版本</th><th style="text-align:center">Collector 1.0.x</th><th style="text-align:center">Collector 1.1.x</th><th style="text-align:center">Collector 1.5.x</th><th style="text-align:center">Collector 1.6.x</th><th style="text-align:center">Collector 1.7.x</th><th style="text-align:center">Collector 1.8.x</th></tr></thead><tbody><tr><td style="text-align:center">1.0.x</td><td style="text-align:center">√</td><td style="text-align:center">√</td><td style="text-align:center">√</td><td style="text-align:center">√</td><td style="text-align:center">√</td><td style="text-align:center">√</td></tr><tr><td style="text-align:center">1.1.x</td><td style="text-align:center">not tested</td><td style="text-align:center">√</td><td style="text-align:center">√</td><td style="text-align:center">√</td><td style="text-align:center">√</td><td style="text-align:center">√</td></tr><tr><td style="text-align:center">1.5.x</td><td style="text-align:center">×</td><td style="text-align:center">×</td><td style="text-align:center">√</td><td style="text-align:center">√</td><td style="text-align:center">√</td><td style="text-align:center">√</td></tr><tr><td style="text-align:center">1.6.x</td><td style="text-align:center">×</td><td style="text-align:center">×</td><td style="text-align:center">not tested</td><td style="text-align:center">√</td><td style="text-align:center">√</td><td style="text-align:center">√</td></tr><tr><td style="text-align:center">1.7.x</td><td style="text-align:center">×</td><td style="text-align:center">×</td><td style="text-align:center">×</td><td style="text-align:center">×</td><td style="text-align:center">√</td><td style="text-align:center">√</td></tr><tr><td style="text-align:center">1.8.x</td><td style="text-align:center">×</td><td style="text-align:center">×</td><td style="text-align:center">×</td><td style="text-align:center">×</td><td style="text-align:center">×</td><td style="text-align:center">√</td></tr></tbody></table><h3 id="Flink-兼容性"><a href="#Flink-兼容性" class="headerlink" title="Flink 兼容性"></a>Flink 兼容性</h3><table><thead><tr><th style="text-align:center">Pinpoint 版本</th><th style="text-align:center">flink 1.3.x</th><th style="text-align:center">flink 1.4.x</th></tr></thead><tbody><tr><td style="text-align:center">1.7.x</td><td style="text-align:center">√</td><td style="text-align:center">×</td></tr></tbody></table><hr><h1 id="实例"><a href="#实例" class="headerlink" title="实例"></a>实例</h1><p>HBase 版本为 1.2.11，下载地址：<a href="http://mirrors.hust.edu.cn/apache/hbase/hbase-1.2.11/" target="_blank" rel="noopener">http://mirrors.hust.edu.cn/apache/hbase/hbase-1.2.11/</a><br>Pinpoint 版本为 1.7.3，下载地址：<a href="https://github.com/naver/pinpoint/releases/tag/1.7" target="_blank" rel="noopener">https://github.com/naver/pinpoint/releases/tag/1.7</a>.<br>Tomcat 版本为：8.x</p><p>其中，Pinpoint 需要下载 <code>agent</code>、<code>collector</code>、<code>web</code> 三个文件。</p><h2 id="HBase"><a href="#HBase" class="headerlink" title="HBase"></a>HBase</h2><h3 id="启动-HBase"><a href="#启动-HBase" class="headerlink" title="启动 HBase"></a>启动 HBase</h3><p>解压 HBase，修改 <code>config/hbase-env.sh</code> 中 JAVA 目录<br><img src="/images/spring-cloud/apm/hbase-havahome.png" alt="HBase Java home"></p><p>修改后启动 HBase： <code>./bin/start-hbase.sh</code><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">starting master, logging to /opt/hbase/bin/../logs/hbase-root-master-localhost.localdomain.out</span><br><span class="line">Java HotSpot(TM) 64-Bit Server VM warning: ignoring option PermSize=128m; support was removed in 8.0</span><br><span class="line">Java HotSpot(TM) 64-Bit Server VM warning: ignoring option MaxPermSize=128m; support was removed in 8.0</span><br></pre></td></tr></table></figure></p><p>稍等片刻后，<code>jps</code> 查看是否启动完成，若出现 <code>HMaster</code>，则启动完成：<br><img src="/images/spring-cloud/apm/hbase-setup.png" alt="hbase setup"></p><h3 id="加载-Pinpoint-HBase-脚本"><a href="#加载-Pinpoint-HBase-脚本" class="headerlink" title="加载 Pinpoint HBase 脚本"></a>加载 Pinpoint HBase 脚本</h3><p>在 <a href="https://github.com/naver/pinpoint/tree/master/hbase/scripts" target="_blank" rel="noopener">https://github.com/naver/pinpoint/tree/master/hbase/scripts</a> 中，获取 <code>hbase-create.hbase</code>、<code>hbase-drop.hbase</code> 文件，新建目录 <code>hbase-script</code>，执行脚本：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./bin/hbase shell /root/hbase-script/hbase-create.hbase</span><br></pre></td></tr></table></figure></p><p><img src="/images/spring-cloud/apm/hbase-shell.png" alt="HBase Shell"></p><h2 id="Pinpoint-1"><a href="#Pinpoint-1" class="headerlink" title="Pinpoint"></a>Pinpoint</h2><h3 id="启动-Collector、Web"><a href="#启动-Collector、Web" class="headerlink" title="启动 Collector、Web"></a>启动 Collector、Web</h3><p>将 tomcat 解压为2个包，分别为 <code>collector</code>、<code>web</code>，删除 tomcat 目录下 webapps 下除 <code>ROOT</code> 的文件夹，并删除 <code>ROOT</code> 下所有文件。<br>将 collector、web 分别解压至对应 tomcat 的 ROOT 目录下，解压命令：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">jar -xvf pinpoint-collector-1.7.3.war</span><br></pre></td></tr></table></figure></p><p>分别修改两个 tomcat 的 <code>config/server.xml</code> 文件，修改端口 <code>8005</code>、<code>8080</code>、<code>8443</code>、<code>8009</code> 端口，然后分别启动两个 tomcat。启动成功后访问 zipkin：<a href="http://192.168.67.136:28080/#/main" target="_blank" rel="noopener">http://192.168.67.136:28080/#/main</a><br><img src="/images/spring-cloud/apm/zipkin-dashboard.png" alt="zipkin"></p><h2 id="配置-Agent"><a href="#配置-Agent" class="headerlink" title="配置 Agent"></a>配置 Agent</h2><p>创建四个文件夹：<code>eureka</code>、<code>provider</code>、<code>consumer</code>、<code>zuul</code>，并将四个服务移入对应文件夹，解压 agent.tar.gz，将解压后的文件放入四个文件夹：<br><img src="/images/spring-cloud/apm/pinpoint-agent.png" alt="pinpoint agent"></p><p>配置 agent 中的 <code>pinpoint.config</code> 文件，修改 <code>profiler.collector.ip</code> 设置为 <code>pinpoint-collector</code> 的地址，如果在同一个服务器上，不用修改。<br><img src="/images/spring-cloud/apm/pinpoint-collectorr-ip.png" alt="pinpoint collector ip"></p><p>可以看到在 <code>pinpoint.config</code> 中监听了 <code>9994</code>、<code>9995</code>、<code>9996</code> 端口，这三个端口在 collector 启动后就开启了，默认即可。如果 collector 需要修改端口，需要修改 <code>$COLLECTOR_TOMCAT_HOME/webapps/ROOT/WEB-INF/classes/pinpoint-collector.properties</code> 文件。</p><h2 id="启动服务"><a href="#启动服务" class="headerlink" title="启动服务"></a>启动服务</h2><p>参数解释：<br><code>-Dpinpoint.agentId</code>：表示 agent 的唯一标识<br><code>-Dpinpoint.applicationName</code>：表示用用名称</p><p>eureka<br><code>java -javaagent:/usr/local/src/pinpoint/soft/eureka/pinpoint-agent-1.7.3/pinpoint-bootstrap-1.7.3.jar -Dpinpoint.agentId=eureka-server -Dpinpoint.applicationName=eureka-server -jar spring-cloud-eureka-server-simple-0.0.1-SNAPSHOT.jar</code></p><p>provider<br><code>java -javaagent:/usr/local/src/pinpoint/soft/eureka/pinpoint-agent-1.7.3/pinpoint-bootstrap-1.7.3.jar -Dpinpoint.agentId=provider -Dpinpoint.applicationName=provider -jar spring-cloud-apm-skywalking-provider-0.0.1-SNAPSHOT.jar</code></p><p>consumer<br><code>java -javaagent:/usr/local/src/pinpoint/soft/eureka/pinpoint-agent-1.7.3/pinpoint-bootstrap-1.7.3.jar -Dpinpoint.agentId=consumer -Dpinpoint.applicationName=consumer -jar spring-cloud-apm-skywlaking-consumer-0.0.1-SNAPSHOT.jar</code></p><p>zuul<br><code>java -javaagent:/usr/local/src/pinpoint/soft/eureka/pinpoint-agent-1.7.3/pinpoint-bootstrap-1.7.3.jar -Dpinpoint.agentId=zuul -Dpinpoint.applicationName=zuul -jar spring-cloud-apm-skywalking-zuul-0.0.1-SNAPSHOT.jar -Xms256m -Xmx256m</code></p><p>成功启动后，访问 pinpoint：<a href="http://192.168.67.136:28080/#/main" target="_blank" rel="noopener">http://192.168.67.136:28080/#/main</a><br><img src="/images/spring-cloud/apm/pinpoint-dashboard.png" alt="pinpoint dashboard"></p><p>通过 zuul 获取数据：<a href="http://192.168.67.136:9020/client/get-info" target="_blank" rel="noopener">http://192.168.67.136:9020/client/get-info</a><br><img src="/images/spring-cloud/apm/pinpoint-zuul.png" alt="pinpoint zuul"></p><p>再次查看 pinpoint，切换到 zuul 选项卡：<br><img src="/images/spring-cloud/apm/pinpoint-error.png" alt="pinpoint error"><br><img src="/images/spring-cloud/apm/pinpoint-error-1.png" alt="pinpoint error"><br>红色代表调用失败（第一次调用时需要从 eureka 获取数据，默认超时一秒）。数字代表调用次数</p><p><code>Inspector</code>：检查器，可以查看服务的调用信息。点击查看：<br><img src="/images/spring-cloud/apm/pinpoint-inspector.png" alt="inspector"></p><p>在 <code>Inspector</code> 中，Timeline 选项卡显示请求时间段，<code>information</code> 选项卡显示当前节点启动的信息，包括：应用名、<code>agentId</code>、启动时间等，<code>Heap Usage</code> 显示堆使用情况，<code>JVM/System Cpu Usage</code> 显示 CPU 使用情况，<code>Active Thread</code> 显示线程使用情况。<code>Response Time</code> 显示响应时间，<code>Data Source</code> 显示数据库使用情况</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;code&gt;Pinpoint&lt;/code&gt; 是韩国人编写的 APM 系统，是一个分析大规模分布式系统的平台，并提供处理大量跟踪数据的解决方案。&lt;/p&gt;
    
    </summary>
    
      <category term="spring-cloud" scheme="https://www.laiyy.top/categories/spring-cloud/"/>
    
    
      <category term="SpringCloud" scheme="https://www.laiyy.top/tags/SpringCloud/"/>
    
      <category term="APM" scheme="https://www.laiyy.top/tags/APM/"/>
    
  </entry>
  
  <entry>
    <title>Spring Cloud 微服务（33） --- APM(二) &lt;BR&gt; SkyWalking</title>
    <link href="https://www.laiyy.top/spring-cloud/spring-cloud-33.html"/>
    <id>https://www.laiyy.top/spring-cloud/spring-cloud-33.html</id>
    <published>2019-04-12T08:59:07.000Z</published>
    <updated>2019-04-12T08:59:07.000Z</updated>
    
    <content type="html"><![CDATA[<p>SkyWalking 是有个完整的 APM 系统，被用于追踪、监控、诊断分布式系统。</p><p>SkyWalking 整体由 4 个部分组成：<code>collector</code>、<code>agent</code>、<code>web</code>、<code>storage</code>。<br>应用级别的接入，可以使用 SDK 形式接入，也可以使用非侵入式的 <code>Agent</code> 形式接入。<code>agent</code> 将数据转化为 SkyWalking Trace 数据协议，通过 HTTP、gRPC 发送到 <code>collector</code>，<code>collector</code> 对收集到的数据进行分析、整合，最后存储到 es 或 H2 中，一般情况下，H2 用于测试。</p><a id="more"></a><h1 id="SkyWalking-特性"><a href="#SkyWalking-特性" class="headerlink" title="SkyWalking 特性"></a>SkyWalking 特性</h1><h2 id="SkyWalking-主要功能"><a href="#SkyWalking-主要功能" class="headerlink" title="SkyWalking 主要功能"></a>SkyWalking 主要功能</h2><ul><li>分布式只追踪、上下文传输</li><li>应用、实例、服务性能指标分析</li><li>根源分析</li><li>应用拓扑分析</li><li>应用于服务依赖分析</li><li>慢服务检测</li><li>性能优化</li></ul><h2 id="SkyWalking-主要特性"><a href="#SkyWalking-主要特性" class="headerlink" title="SkyWalking 主要特性"></a>SkyWalking 主要特性</h2><ul><li>多语言探针、类库<ol><li>Java 自动探针，追踪、监控程序时，无需修改源码</li><li>社区提供多语言探针：.NET、Node.js</li></ol></li><li>多种后端存储：Elasticsearch、H2 等<ol><li>支持 OpenTrancing：Java 自动探针和 OpenTracing API 协同工作</li></ol></li><li>轻量级、完善的后台聚合和分析功能</li><li>现代化 Web UI</li><li>日志集成</li><li>应用、实例、服务的告警</li><li>支持接受其他跟踪器数据格式<ol><li>Zipkin JSON、Thrift、Protobuf v1 和 v2 格式，由 OpenZipkin 库提供支持</li><li>Jaeger 采用 Zipkin Thrift 或 JSON v1/v2 格式</li></ol></li></ul><hr><h1 id="SkyWalking-测试用例代码"><a href="#SkyWalking-测试用例代码" class="headerlink" title="SkyWalking 测试用例代码"></a>SkyWalking 测试用例代码</h1><h2 id="Zuul"><a href="#Zuul" class="headerlink" title="Zuul"></a>Zuul</h2> <figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependencies</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.springframework.cloud<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spring-cloud-starter-netflix-eureka-client<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.springframework.cloud<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spring-cloud-starter-netflix-zuul<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependencies</span>&gt;</span></span><br></pre></td></tr></table></figure> <figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr"> spring:</span></span><br><span class="line"><span class="attr">  application:</span></span><br><span class="line"><span class="attr">    name:</span></span><br><span class="line">      <span class="string">spring-cloud-apm-skywalking-zuul</span></span><br><span class="line"><span class="attr">server:</span></span><br><span class="line"><span class="attr">  port:</span> <span class="number">9020</span></span><br><span class="line"><span class="attr">eureka:</span></span><br><span class="line"><span class="attr">  client:</span></span><br><span class="line"><span class="attr">    service-url:</span></span><br><span class="line"><span class="attr">      defaultZone:</span> <span class="attr">http://localhost:8761/eureka/</span></span><br><span class="line"><span class="attr">zuul:</span></span><br><span class="line"><span class="attr">  routes:</span></span><br><span class="line"><span class="attr">    spring-cloud-apm-skywlaking-consumer:</span></span><br><span class="line"><span class="attr">      path:</span> <span class="string">/client/**</span></span><br><span class="line"><span class="attr">      serviceId:</span> <span class="string">spring-cloud-apm-skywlaking-consumer</span></span><br><span class="line"></span><br><span class="line"><span class="attr">ribbon:</span></span><br><span class="line"><span class="attr">  eureka:</span></span><br><span class="line"><span class="attr">    enabled:</span> <span class="literal">true</span></span><br><span class="line"><span class="attr">  ReadTimeout:</span> <span class="number">30000</span></span><br><span class="line"><span class="attr">  ConnectionTimeout:</span> <span class="number">30000</span></span><br><span class="line"><span class="attr">  MaxAutoRetries:</span> <span class="number">0</span></span><br><span class="line"><span class="attr">  MaxAutoRetriesNextServer:</span> <span class="number">1</span></span><br><span class="line"><span class="attr">  OkToRetryOnAllOperations:</span> <span class="literal">false</span></span><br><span class="line"></span><br><span class="line"><span class="attr">hystrix:</span></span><br><span class="line"><span class="attr">  threadpool:</span></span><br><span class="line"><span class="attr">    default:</span></span><br><span class="line"><span class="attr">      coreSize:</span> <span class="number">1000</span></span><br><span class="line"><span class="attr">      maxQueueSize:</span> <span class="number">1000</span></span><br><span class="line"><span class="attr">      queueSizeRejectionThreshold:</span> <span class="number">500</span></span><br><span class="line"></span><br><span class="line"><span class="attr">  command:</span></span><br><span class="line"><span class="attr">    default:</span></span><br><span class="line"><span class="attr">      execution:</span></span><br><span class="line"><span class="attr">        isolation:</span></span><br><span class="line"><span class="attr">          thread:</span></span><br><span class="line"><span class="attr">            timeoutInMilliseconds:</span> <span class="number">120001</span></span><br></pre></td></tr></table></figure><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@SpringBootApplication</span></span><br><span class="line"><span class="meta">@EnableDiscoveryClient</span></span><br><span class="line"><span class="meta">@EnableZuulProxy</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">SpringCloudApmSkywalkingZuulApplication</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        SpringApplication.run(SpringCloudApmSkywalkingZuulApplication.class, args);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="Consumer"><a href="#Consumer" class="headerlink" title="Consumer"></a>Consumer</h2><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependencies</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.springframework.cloud<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spring-cloud-starter-netflix-eureka-client<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependencies</span>&gt;</span></span><br></pre></td></tr></table></figure><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">server:</span></span><br><span class="line"><span class="attr">  port:</span> <span class="number">9021</span></span><br><span class="line"><span class="attr">spring:</span></span><br><span class="line"><span class="attr">  application:</span></span><br><span class="line"><span class="attr">    name:</span> <span class="string">spring-cloud-apm-skywlaking-consumer</span></span><br><span class="line"><span class="attr">eureka:</span></span><br><span class="line"><span class="attr">  client:</span></span><br><span class="line"><span class="attr">    service-url:</span></span><br><span class="line"><span class="attr">      defaultZone:</span> <span class="attr">http://localhost:8761/eureka/</span></span><br></pre></td></tr></table></figure><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@SpringBootApplication</span></span><br><span class="line"><span class="meta">@EnableFeignClients</span></span><br><span class="line"><span class="meta">@EnableDiscoveryClient</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">SpringCloudApmSkywlakingConsumerApplication</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        SpringApplication.run(SpringCloudApmSkywlakingConsumerApplication.class, args);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">@FeignClient</span>(<span class="string">"spring-cloud-apm-skywalking-provider"</span>)</span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">SkyWalkingFeignService</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@RequestMapping</span>(value = <span class="string">"/get-send-info"</span>, method = RequestMethod.GET)</span><br><span class="line">    <span class="function">String <span class="title">getSendInfo</span><span class="params">(@RequestParam(<span class="string">"serviceName"</span>)</span> String serviceName)</span>;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">@RestController</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">SkyWalkingController</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> SkyWalkingFeignService feignService;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Autowired</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">SkyWalkingController</span><span class="params">(SkyWalkingFeignService feignService)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.feignService = feignService;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@GetMapping</span>(value = <span class="string">"/get-info"</span>)</span><br><span class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">getInfo</span><span class="params">()</span></span>&#123;</span><br><span class="line">        <span class="keyword">return</span> feignService.getSendInfo(<span class="string">"service"</span>);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="Provider"><a href="#Provider" class="headerlink" title="Provider"></a>Provider</h2><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependencies</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.springframework.cloud<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spring-cloud-starter-netflix-eureka-client<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependencies</span>&gt;</span></span><br></pre></td></tr></table></figure><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">server:</span></span><br><span class="line"><span class="attr">  port:</span> <span class="number">9022</span></span><br><span class="line"><span class="attr">spring:</span></span><br><span class="line"><span class="attr">  application:</span></span><br><span class="line"><span class="attr">    name:</span> <span class="string">spring-cloud-apm-skywalking-provider</span></span><br><span class="line"><span class="attr">eureka:</span></span><br><span class="line"><span class="attr">  client:</span></span><br><span class="line"><span class="attr">    service-url:</span></span><br><span class="line"><span class="attr">      defaultZone:</span> <span class="attr">http://localhost:8761/eureka/</span></span><br></pre></td></tr></table></figure><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@SpringBootApplication</span></span><br><span class="line"><span class="meta">@EnableDiscoveryClient</span></span><br><span class="line"><span class="meta">@RestController</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">SpringCloudApmSkywalkingProviderApplication</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        SpringApplication.run(SpringCloudApmSkywalkingProviderApplication.class, args);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@GetMapping</span>(value = <span class="string">"/get-send-info"</span>)</span><br><span class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">getSendInfo</span><span class="params">(@RequestParam(<span class="string">"serviceName"</span>)</span> String serviceName)</span>&#123;</span><br><span class="line">        <span class="keyword">return</span> serviceName + <span class="string">" --&gt; "</span> + <span class="string">"spring-cloud-apm-skywalking-provider"</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><hr><h1 id="SkyWalking-安装"><a href="#SkyWalking-安装" class="headerlink" title="SkyWalking 安装"></a>SkyWalking 安装</h1><p>SkyWalking 依赖环境：</p><ul><li>被监控的应用运行在 JDK6+</li><li>SkyWalking collector 和 WebUI 运行在 JDK8+</li><li>elasticsearch 5.x（集群可能不能使用）</li></ul><h2 id="下载-elasticsearch-5-6-10-版本"><a href="#下载-elasticsearch-5-6-10-版本" class="headerlink" title="下载 elasticsearch_5.6.10 版本"></a>下载 elasticsearch_5.6.10 版本</h2><p><strong><em>注意：一定要用 5.x 的 elasticsearch，否则会出现版本问题！</em></strong></p><p>解压安装后，进入 <code>config/elasticsearch.yml</code> 文件，修改 <code>network.host</code> 为 <code>0.0.0.0</code>。elasticsearch 不允许 root 用户启动，建立新用户并赋权：<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">useradd es</span><br><span class="line">chown -R es:es /path/to/es</span><br></pre></td></tr></table></figure></p><p>切换到 es 用户，启用 es<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./bin/elasticsearch</span><br></pre></td></tr></table></figure></p><p>控制台报错：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[1]: max file descriptors [4096] for elasticsearch process is too low, increase to at least [65536]</span><br><span class="line">[2]: max virtual memory areas vm.max_map_count [65530] is too low, increase to at least [262144]</span><br></pre></td></tr></table></figure></p><p>修改 <code>/etc/security/limits.conf</code>，增加如下配置：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">* soft nofile 819200</span><br><span class="line">* hard nofile 819200</span><br></pre></td></tr></table></figure></p><p>修改 <code>/etc/sysctl.conf</code>，增加配置：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vm.max_map_count=655360</span><br></pre></td></tr></table></figure></p><p>重新加载配置：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sysctl -p</span><br></pre></td></tr></table></figure></p><p>后台启动 es： <code>./bin/elasticsearch -d</code></p><p>查看 es 日志：<code>tail -f logs/elasticsearch.log</code>，正常启动。</p><p>浏览器访问 elasticsearch，可见，默认的 cluster name 为 <code>elasticsearch</code>：<br><img src="/images/spring-cloud/apm/elasticsearch.png" alt="elasticsearch"></p><h2 id="SkyWalking-目录结构"><a href="#SkyWalking-目录结构" class="headerlink" title="SkyWalking 目录结构"></a>SkyWalking 目录结构</h2><p><img src="/images/spring-cloud/apm/skywalking-dir-tree.png" alt="SkyWalking 目录结构"></p><ul><li>agent：探针相关</li><li>bin：collectorService、webappService 启动脚本，其中 startup.* 是同事启动两个脚本的合并命令</li><li>config：Collector 的相关配置信息</li><li>log：collector、web 的日志文件</li><li>webapp：存放 SkyWalking 展示 UI 的 jar 和配置文件</li></ul><p>SkyWalking 的默认端口为：8080、10800、11800、12800 等，如果要修改端口，需要修改 config 目录下的 application.yml、webapp 下的 webapp.yml。</p><p>修改 <code>config/application.yml</code> 文件，clusterName 与 elasticsearch 的 cluster name 一致，其余采用默认设置。<br><img src="/images/spring-cloud/apm/application.yml.png" alt="application.yml"></p><h2 id="启动-SkyWalking"><a href="#启动-SkyWalking" class="headerlink" title="启动 SkyWalking"></a>启动 SkyWalking</h2><p>启动 SkyWalking：<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./bin/startup.sh</span><br></pre></td></tr></table></figure></p><p><img src="/images/spring-cloud/apm/startup-success.png" alt="启动 SkyWalking"></p><p>访问 SkyWalking：<br><img src="/images/spring-cloud/apm/skywalking-login-page.png" alt="访问 SkyWalking"></p><p>默认 用户名/密码 为：admin/admin</p><p><img src="/images/spring-cloud/apm/skywalking-dashboard.png" alt="SkyWalking Dashboard"></p><hr><h1 id="监控项目"><a href="#监控项目" class="headerlink" title="监控项目"></a>监控项目</h1><h2 id="创建目录"><a href="#创建目录" class="headerlink" title="创建目录"></a>创建目录</h2><p>创建四个目录，分别对应：consumer、provider、zuul、eureka-server 四个应用，每个应用使用一个对应的 agent 进行启动，其中 agent 是 SkyWalking 的 agent 目录。</p><p>修改 <code>agent.config</code> 文件中 <code>agent.application_code</code>，这项配置代表应用。对应修改为 <code>consumer</code>、<code>provider</code>、<code>zuul</code>、<code>eureka</code>。将 eureka、zuul、consumer、provider 打包为 jar，上传到对应目录中。</p><h2 id="修改-es-内存配置"><a href="#修改-es-内存配置" class="headerlink" title="修改 es 内存配置"></a>修改 es 内存配置</h2><p>elasticsearch 默认 JVM 内存为 2g，如果虚拟机内存过小，无法启动。如果略大于 JVM 内存，启动后无法启动其他组件。所以需要修稿 elasticsearch 的默认 JVM 内存。修改 <code>$ES_HOME/config/jvm.options</code>:<br><img src="/images/spring-cloud/apm/es-jvm.png" alt="es jvm 参数"></p><p>修改后重启 es、SkyWalking</p><p>使用 <code>top</code> 命令查看使用内存最高的应用，使用 <code>free</code> 命令，查看内存总用量、剩余内存。<br><img src="/images/spring-cloud/apm/free-top.png" alt="free top 命令"></p><h2 id="依次启动四个应用"><a href="#依次启动四个应用" class="headerlink" title="依次启动四个应用"></a>依次启动四个应用</h2><p>启动时需要指定 JVM 内存，防止出现内存不够的情况。<br><code>-Xms</code> 指定最小内存，<code>-Xmx</code> 指定最大内存</p><p>eureka<br><code>java -javaagent:/usr/local/src/soft/eureka/agent/skywalking-agent.jar -jar /usr/local/src/soft/eureka/spring-cloud-eureka-server-simple-0.0.1-SNAPSHOT.jar -Xms256m -Xmx256m</code></p><p>provider<br><code>java -javaagent:/usr/local/src/soft/provider/agent/skywalking-agent.jar -jar /usr/local/src/soft/provider/spring-cloud-apm-skywalking-provider-0.0.1-SNAPSHOT.jar -Xms256m -Xmx256m</code></p><p>consumer<br><code>java -javaagent:/usr/local/src/soft/consumer/agent/skywalking-agent.jar -jar /usr/local/src/soft/consumer/spring-cloud-apm-skywalking-consumer-0.0.1-SNAPSHOT.jar -Xms256m -Xmx256m</code></p><p>zuul<br><code>java -javaagent:/usr/local/src/soft/zuul/agent/skywalking-agent.jar -jar /usr/local/src/soft/zuul/spring-cloud-apm-skywalking-zuul-0.0.1-SNAPSHOT.jar -Xms256m -Xmx256m</code></p><h2 id="确认启动成功"><a href="#确认启动成功" class="headerlink" title="确认启动成功"></a>确认启动成功</h2><p>使用 <code>jps</code> 命令查看启动进程：<br><img src="/images/spring-cloud/apm/jps.png" alt="jps"></p><p>查看剩余内存是否满足正常运行：<br><img src="/images/spring-cloud/apm/free.png" alt="free"></p><h2 id="验证-SkyWalking"><a href="#验证-SkyWalking" class="headerlink" title="验证 SkyWalking"></a>验证 SkyWalking</h2><p>启动成功后访问eureka： <a href="http://192.168.67.135:8761/" target="_blank" rel="noopener">http://192.168.67.135:8761/</a><br><img src="/images/spring-cloud/apm/eureka.png" alt="eureka"></p><p>访问 SkyWalking：<br><img src="/images/spring-cloud/apm/skywalking-dashboard-1.png" alt="SkyWalking"></p><p>可见 4 个 app 都启动成功了。使用 zuul 访问 consumer，调用 provider：<br><img src="/images/spring-cloud/apm/zuul.png" alt="zuul"></p><p>再次查看 SkyWalking：<br><img src="/images/spring-cloud/apm/skywalking-dashboard-2.png" alt="SkyWalking"></p><p>在 service 选项卡中可以看到每个 service 的具体调用情况<br><img src="/images/spring-cloud/apm/service.png" alt="service"></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;SkyWalking 是有个完整的 APM 系统，被用于追踪、监控、诊断分布式系统。&lt;/p&gt;
&lt;p&gt;SkyWalking 整体由 4 个部分组成：&lt;code&gt;collector&lt;/code&gt;、&lt;code&gt;agent&lt;/code&gt;、&lt;code&gt;web&lt;/code&gt;、&lt;code&gt;storage&lt;/code&gt;。&lt;br&gt;应用级别的接入，可以使用 SDK 形式接入，也可以使用非侵入式的 &lt;code&gt;Agent&lt;/code&gt; 形式接入。&lt;code&gt;agent&lt;/code&gt; 将数据转化为 SkyWalking Trace 数据协议，通过 HTTP、gRPC 发送到 &lt;code&gt;collector&lt;/code&gt;，&lt;code&gt;collector&lt;/code&gt; 对收集到的数据进行分析、整合，最后存储到 es 或 H2 中，一般情况下，H2 用于测试。&lt;/p&gt;
    
    </summary>
    
      <category term="spring-cloud" scheme="https://www.laiyy.top/categories/spring-cloud/"/>
    
    
      <category term="SpringCloud" scheme="https://www.laiyy.top/tags/SpringCloud/"/>
    
      <category term="APM" scheme="https://www.laiyy.top/tags/APM/"/>
    
  </entry>
  
  <entry>
    <title>Spring Cloud 微服务（32） --- APM(一) &lt;BR&gt; Sleuth</title>
    <link href="https://www.laiyy.top/spring-cloud/spring-cloud-32.html"/>
    <id>https://www.laiyy.top/spring-cloud/spring-cloud-32.html</id>
    <published>2019-04-10T13:19:14.000Z</published>
    <updated>2019-04-10T13:19:14.000Z</updated>
    
    <content type="html"><![CDATA[<p>在微服务架构下，服务按照不同的纬度进行拆分，一次请求可能会涉及到多个服务，并且有可能是由不同的团队开发，可能使用不同的编程语言实现，有可能部署在几百台、几千台服务器上，横跨多个不同的数据中心。因此，需要一些可以帮助理解系统行为、分析性能问题的工具，以便在发生故障时，快速定位、解决问题。此类工具称为 <code>APM</code></p><a id="more"></a><h1 id="APM"><a href="#APM" class="headerlink" title="APM"></a>APM</h1><p>最出名的 <code>APM</code> 是谷歌公开的论文中提到的 <code>Dapper</code>。Dapper 对分布式跟踪系统提出了如下需求：</p><ul><li>性能低损耗：分布式跟踪系统对服务的性能损耗应尽可能做到可以忽略不计，尤其是对性能敏感的应用不能产生损耗。</li><li>对应用透明：尽可能使用非侵入的方式实现跟踪，尽可能做到业务代码的低侵入，对业务开发人员做到透明化。</li><li>可伸缩性：是指不能随着微服务和集群规模的扩大而使用分布式跟踪系统瘫痪。</li><li>跟踪数据可视化、迅速反馈：要有可视化的监控界面，从跟踪数据收集、处理、到结果的展现，尽量做到快速，这样可以对系统的异常状况作出快速反应。</li><li>持续监控：要求分布式跟踪系统必须是 7X24 小时工作，否则很难定位到系统偶尔抖动的行为。</li></ul><p>在 APM 中的一些术语</p><ul><li>Span：基本工作单元。如：发送一次 RPC 请求，就是一个新的 Span。Span 通过一个 64 位的 ID 标识，还包含有描述、事件时间戳、标签、调用它的 Span 的 ID、处理器 ID（一般为 ip 地址）。注意：第一个 Span 是 root Span，它的 ID 和 Trace 的 ID 一样</li><li>Trace：一系列 Span 组成的树状结构，简单的说就是一次调用请求</li><li>Annotation：标注，用来描述事件的实时状态。有如下状态<blockquote><p>cs：Client Sent。客户端发起请求，表示一个 Span 开始<br>sr：Server Received。服务方接收到请求，并开始处理，其值减去 cs 时间，就是网络延迟时间<br>ss：Server Sent。表示请求处理完成，将响应数据返回给客户端。其值减去 sr 时间，就是服务方处理时间<br>cr：Client Received。客户端接收到服务方的返回值，是当前 Span 结束的信号。其值减去 cs，就是一次请求的完整处理时间。</p></blockquote></li></ul><hr><h1 id="Sleuth"><a href="#Sleuth" class="headerlink" title="Sleuth"></a>Sleuth</h1><p><code>Sleuth</code> 是 SpringCloud 的分布式跟踪系统，通过 Trace 定义一次业务调用链，根据它的信息，我们能知道有多少系统参与了该业务处理。而系统间的调用顺序、时间戳信息，通过 Span 记录。Trace 和 Span 整合，就能知道该业务的完整调用链。</p><h2 id="一个简单的-Sleuth"><a href="#一个简单的-Sleuth" class="headerlink" title="一个简单的 Sleuth"></a>一个简单的 Sleuth</h2><p><strong><em>源码：<a href="https://gitee.com/laiyy0728/spring-cloud/tree/master/spring-cloud-apm/spring-cloud-apm-sleuth" target="_blank" rel="noopener">https://gitee.com/laiyy0728/spring-cloud/tree/master/spring-cloud-apm/spring-cloud-apm-sleuth</a></em></strong></p><h3 id="通用-pom"><a href="#通用-pom" class="headerlink" title="通用 pom"></a>通用 pom</h3><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependencies</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.springframework.cloud<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spring-cloud-starter-sleuth<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.springframework.cloud<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spring-cloud-starter-openfeign<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependencies</span>&gt;</span></span><br></pre></td></tr></table></figure><h3 id="Provider"><a href="#Provider" class="headerlink" title="Provider"></a>Provider</h3><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">server:</span></span><br><span class="line"><span class="attr">  port:</span> <span class="number">8082</span></span><br><span class="line"><span class="attr">spring:</span></span><br><span class="line"><span class="attr">  application:</span></span><br><span class="line"><span class="attr">    name:</span> <span class="string">spring-cloud-apm-sleuth-provider</span></span><br></pre></td></tr></table></figure><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@SpringBootApplication</span></span><br><span class="line"><span class="meta">@RestController</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">SpringCloudApmSleuthProviderApplication</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        SpringApplication.run(SpringCloudApmSleuthProviderApplication.class, args);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> Logger LOGGER = LoggerFactory.getLogger(SpringCloudApmSleuthProviderApplication.class);</span><br><span class="line"></span><br><span class="line">    <span class="meta">@GetMapping</span>(value = <span class="string">"/say"</span>)</span><br><span class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">hello</span><span class="params">(String name)</span></span>&#123;</span><br><span class="line">        LOGGER.info(<span class="string">"&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; 接收到参数：&#123;&#125;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;"</span>, name);</span><br><span class="line">        String result = <span class="string">"你好啊~"</span> + name;</span><br><span class="line">        LOGGER.info(<span class="string">"&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; 返回值：&#123;&#125; &lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;"</span>, result);</span><br><span class="line">        <span class="keyword">return</span> result;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="Consumer"><a href="#Consumer" class="headerlink" title="Consumer"></a>Consumer</h3><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">server:</span></span><br><span class="line"><span class="attr">  port:</span> <span class="number">8081</span></span><br><span class="line"><span class="attr">spring:</span></span><br><span class="line"><span class="attr">  application:</span></span><br><span class="line"><span class="attr">    name:</span> <span class="string">spring-cloud-apm-aleuth-consumer</span></span><br></pre></td></tr></table></figure><p><strong>Feign</strong><br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@FeignClient</span>(name = <span class="string">"spring-cloud-apm-sleuth-provider"</span>, url = <span class="string">"localhost:8082"</span>)</span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">HelloService</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@RequestMapping</span>(value = <span class="string">"/say"</span>)</span><br><span class="line">    <span class="function">String <span class="title">sayHello</span><span class="params">(@RequestParam(<span class="string">"name"</span>)</span> String name)</span>;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p><strong>configuration</strong><br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Configuration</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ConsumerConfiguration</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> BeanFactory beanFactory;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Autowired</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">ConsumerConfiguration</span><span class="params">(BeanFactory beanFactory)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.beanFactory = beanFactory;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Bean</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> RestTemplate <span class="title">restTemplate</span><span class="params">()</span></span>&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">new</span> RestTemplate();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Bean</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> ExecutorService <span class="title">executorService</span><span class="params">()</span></span>&#123;</span><br><span class="line">        ExecutorService executorService = Executors.newFixedThreadPool(<span class="number">2</span>);</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">new</span> TraceableExecutorService(<span class="keyword">this</span>.beanFactory, executorService);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p><strong>Controller</strong><br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@RestController</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ConsumerController</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> Logger LOGGER = LoggerFactory.getLogger(ConsumerController.class);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> HelloService helloService;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> RestTemplate restTemplate;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> ExecutorService executorService;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Autowired</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">ConsumerController</span><span class="params">(HelloService helloService, RestTemplate restTemplate, ExecutorService executorService)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.helloService = helloService;</span><br><span class="line">        <span class="keyword">this</span>.restTemplate = restTemplate;</span><br><span class="line">        <span class="keyword">this</span>.executorService = executorService;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@GetMapping</span>(value = <span class="string">"/hello-feign"</span>)</span><br><span class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">helloByFeign</span><span class="params">(String name)</span></span>&#123;</span><br><span class="line">        LOGGER.info(<span class="string">"&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; feign 调用，参数：&#123;&#125; &lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;"</span>, name);</span><br><span class="line">        String result = helloService.sayHello(name);</span><br><span class="line">        LOGGER.info(<span class="string">"&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; feign 调用，结果：&#123;&#125; &lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;"</span>, result);</span><br><span class="line">        <span class="keyword">return</span> result;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@GetMapping</span>(value = <span class="string">"/hello-rest"</span>)</span><br><span class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">helloByRest</span><span class="params">(String name)</span></span>&#123;</span><br><span class="line">        LOGGER.info(<span class="string">"&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; rest 调用，参数：&#123;&#125; &lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;"</span>, name);</span><br><span class="line">        String url = <span class="string">"http://localhost:8082/say?name="</span> + name;</span><br><span class="line">        String result = restTemplate.getForObject(url, String.class);</span><br><span class="line">        LOGGER.info(<span class="string">"&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; rest 调用，结果：&#123;&#125; &lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;"</span>, result);</span><br><span class="line">        <span class="keyword">return</span> result;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@GetMapping</span>(value = <span class="string">"/hello-thread"</span>)</span><br><span class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">helloByThread</span><span class="params">(String name)</span> <span class="keyword">throws</span> ExecutionException, InterruptedException </span>&#123;</span><br><span class="line">        LOGGER.info(<span class="string">"&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; 线程 调用，参数：&#123;&#125; &lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;"</span>, name);</span><br><span class="line">        String url = <span class="string">"http://localhost:8082/say?name="</span> + name;</span><br><span class="line">        Future&lt;String&gt; future = executorService.submit(() -&gt; &#123;</span><br><span class="line">            LOGGER.info(<span class="string">"&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; 进入线程，参数：&#123;&#125; &lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;"</span>, name);</span><br><span class="line">            <span class="keyword">return</span> restTemplate.getForObject(url, String.class);</span><br><span class="line">        &#125;);</span><br><span class="line">        String result = future.get();</span><br><span class="line">        LOGGER.info(<span class="string">"&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; 线程 调用，结果：&#123;&#125; &lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;"</span>, result);</span><br><span class="line">        <span class="keyword">return</span> result;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p><strong>启动类</strong><br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@SpringBootApplication</span></span><br><span class="line"><span class="meta">@EnableFeignClients</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">SpringCloudApmSleuthConsumerApplication</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        SpringApplication.run(SpringCloudApmSleuthConsumerApplication.class, args);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><h2 id="验证"><a href="#验证" class="headerlink" title="验证"></a>验证</h2><h3 id="Fegin-访问验证"><a href="#Fegin-访问验证" class="headerlink" title="Fegin 访问验证"></a>Fegin 访问验证</h3><p>请求 <a href="http://localhost:8081/hello-feign?name=张三" target="_blank" rel="noopener">http://localhost:8081/hello-feign?name=张三</a> ，Consumer 控制台打印信息如下：</p><p><img src="/images/spring-cloud/apm/sleuth-feign-consumer.png" alt="feign 调用 consumer 打印"></p><p>Privider 打印信息如下：<br><img src="/images/spring-cloud/apm/sleuth-feign-provider.png" alt="feign 调用 provider 打印"></p><h3 id="RestTemplate-验证"><a href="#RestTemplate-验证" class="headerlink" title="RestTemplate 验证"></a>RestTemplate 验证</h3><p>请求 <a href="http://localhost:8081/hello-rest?name=张三" target="_blank" rel="noopener">http://localhost:8081/hello-rest?name=张三</a> ，Consumer 控制台打印信息如下：</p><p><img src="/images/spring-cloud/apm/sleuth-rest-consumer.png" alt="rest 调用 consumer 打印"></p><p>Privider 打印信息如下：<br><img src="/images/spring-cloud/apm/sleuth-rest-provider.png" alt="rest 调用 provider 打印"></p><h3 id="线程验证"><a href="#线程验证" class="headerlink" title="线程验证"></a>线程验证</h3><p>请求 <a href="http://localhost:8081/hello-thread?name=张三" target="_blank" rel="noopener">http://localhost:8081/hello-thread?name=张三</a> ，Consumer 控制台打印信息如下：</p><p><img src="/images/spring-cloud/apm/sleuth-thread-consumer.png" alt="thread 调用 consumer 打印"></p><p>Privider 打印信息如下：<br><img src="/images/spring-cloud/apm/sleuth-thread-provider.png" alt="thread 调用 provider 打印"></p><hr><h1 id="Sleuth-拦截器、链路"><a href="#Sleuth-拦截器、链路" class="headerlink" title="Sleuth 拦截器、链路"></a>Sleuth 拦截器、链路</h1><h2 id="TraceFilter"><a href="#TraceFilter" class="headerlink" title="TraceFilter"></a>TraceFilter</h2><p>Sleuth 通过 TraceFilter 获取 Span 信息。需要注意：如果需要对 Span 信息做自定义修改，需要实现自己的 Filter。<br>实现的 Filter 优先级需要比 TraceFilter 优先级低，否则无法拿到 TraceFilter 处理后的信息。</p><p><strong>Consumer</strong><br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Component</span></span><br><span class="line"><span class="meta">@Order</span>(TraceWebServletAutoConfiguration.TRACING_FILTER_ORDER + <span class="number">1</span>) <span class="comment">// 优先级低</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">SessionFilter</span> <span class="keyword">extends</span> <span class="title">GenericFilterBean</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> Pattern pattern = Pattern.compile(SleuthWebProperties.DEFAULT_SKIP_PATTERN);</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">doFilter</span><span class="params">(ServletRequest request, ServletResponse response, FilterChain filterChain)</span> <span class="keyword">throws</span> IOException, ServletException </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (!(request <span class="keyword">instanceof</span> HttpServletRequest) || !(response <span class="keyword">instanceof</span> HttpServletResponse)) &#123;</span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> ServletException(<span class="string">"只支持 Http 请求"</span>);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        HttpServletRequest httpServletRequest = (HttpServletRequest) request;</span><br><span class="line">        <span class="keyword">boolean</span> matches = pattern.matcher(httpServletRequest.getRequestURI()).matches();</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (!matches)&#123;</span><br><span class="line">            <span class="comment">// 向链路传入 SessionId，在 Provider 中获取</span></span><br><span class="line">            ExtraFieldPropagation.set(<span class="string">"SessionId"</span>, httpServletRequest.getSession().getId());</span><br><span class="line">        &#125;</span><br><span class="line">        filterChain.doFilter(request, response);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p><strong>Provider</strong><br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@GetMapping</span>(value = <span class="string">"/say"</span>)</span><br><span class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">hello</span><span class="params">(String name)</span></span>&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="string">"你好啊！"</span> + name + <span class="string">", 你的 session id 是："</span> + ExtraFieldPropagation.get(<span class="string">"SessionId"</span>);</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure></p><h2 id="Baggage"><a href="#Baggage" class="headerlink" title="Baggage"></a>Baggage</h2><p>Baggage 是存储在 Span 上下文中的一组 K/V 键值对，和 traceId、spanId 不同，baggage 不是必选项。<br>通过 Baggage 可以把一些信息像行李一样，挂在 sleuth 中，由 Sleuth 帮助沿着调用一直向下传递。<br>Baggage 相当于 Sleuth 暴露的一个功能接口，通过它，可以让数据跟着 Sleuth 一直往后接连传递，典型场景是登录信息的传递。</p><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">server:</span></span><br><span class="line"><span class="attr">  port:</span> <span class="number">8081</span></span><br><span class="line"><span class="attr">spring:</span></span><br><span class="line"><span class="attr">  sleuth:</span></span><br><span class="line"><span class="attr">    baggage-keys:</span></span><br><span class="line"><span class="bullet">      -</span> <span class="string">SessionId</span> <span class="comment"># 配置 Baggage 需要传递的参数名称，需要在传递端，接收端都配置。传递端不配置，不能向后传递；接收端不配置，获取不到数据。</span></span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;在微服务架构下，服务按照不同的纬度进行拆分，一次请求可能会涉及到多个服务，并且有可能是由不同的团队开发，可能使用不同的编程语言实现，有可能部署在几百台、几千台服务器上，横跨多个不同的数据中心。因此，需要一些可以帮助理解系统行为、分析性能问题的工具，以便在发生故障时，快速定位、解决问题。此类工具称为 &lt;code&gt;APM&lt;/code&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="spring-cloud" scheme="https://www.laiyy.top/categories/spring-cloud/"/>
    
    
      <category term="SpringCloud" scheme="https://www.laiyy.top/tags/SpringCloud/"/>
    
      <category term="APM" scheme="https://www.laiyy.top/tags/APM/"/>
    
  </entry>
  
  <entry>
    <title>Spring Cloud 微服务（31） --- Spring Cloud Config(五) &lt;BR&gt; 高可用</title>
    <link href="https://www.laiyy.top/spring-cloud/spring-cloud-31.html"/>
    <id>https://www.laiyy.top/spring-cloud/spring-cloud-31.html</id>
    <published>2019-03-07T02:29:50.000Z</published>
    <updated>2019-03-07T02:29:50.000Z</updated>
    
    <content type="html"><![CDATA[<p>对于线上的生产环境，通常对其都是有很高的要求，其中，高可用是不可或缺的一部分。必须保证服务是可用的，才能保证系统更好的运行，这是业务稳定的保证。<br>高可用一般分为两种：<code>客户端高可用</code>、<code>服务端高可用</code></p><a id="more"></a><h1 id="客户端高可用"><a href="#客户端高可用" class="headerlink" title="客户端高可用"></a>客户端高可用</h1><p><strong><em>源码：<a href="https://gitee.com/laiyy0728/spring-cloud/tree/master/spring-cloud-config/spring-cloud-config-ha/spring-cloud-config-ha-client" target="_blank" rel="noopener">https://gitee.com/laiyy0728/spring-cloud/tree/master/spring-cloud-config/spring-cloud-config-ha/spring-cloud-config-ha-client</a></em></strong></p><p><code>客户端高可用</code> 主要解决当前服务端不可用哪个的情况下，客户端依然可用正常启动。从客户端触发，不是增加配置中心的高可用性，而是降低客户端对配置中心的依赖程度，从而提高整个分布式架构的健壮性。</p><h2 id="实现"><a href="#实现" class="headerlink" title="实现"></a>实现</h2><h3 id="配置的自动装配"><a href="#配置的自动装配" class="headerlink" title="配置的自动装配"></a>配置的自动装配</h3><p><strong>pom.xml</strong><br><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependencies</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.springframework.cloud<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spring-cloud-config-client<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependencies</span>&gt;</span></span><br></pre></td></tr></table></figure></p><p><strong>配置文件解析</strong><br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Component</span></span><br><span class="line"><span class="meta">@ConfigurationProperties</span>(prefix = ConfigSupportProperties.CONFIG_PREFIX)</span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ConfigSupportProperties</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 加载的配置文件前缀</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> String CONFIG_PREFIX = <span class="string">"spring.cloud.config.backup"</span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 默认文件名</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> String DEFAULT_FILE_NAME = <span class="string">"fallback.properties"</span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 是否启用</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">boolean</span> enabled = <span class="keyword">false</span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 本地文件地址</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">private</span> String fallbackLocation;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">getFallbackLocation</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> fallbackLocation;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setFallbackLocation</span><span class="params">(String fallbackLocation)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (!fallbackLocation.contains(<span class="string">"."</span>)) &#123;</span><br><span class="line">            <span class="comment">// 如果只指定了文件路径，自动拼接文件名</span></span><br><span class="line">            fallbackLocation = fallbackLocation.endsWith(File.separator) ? fallbackLocation : fallbackLocation + File.separator;</span><br><span class="line">            fallbackLocation += DEFAULT_FILE_NAME;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">this</span>.fallbackLocation = fallbackLocation;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">isEnabled</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> enabled;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setEnabled</span><span class="params">(<span class="keyword">boolean</span> enabled)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.enabled = enabled;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p><strong>自动装配实现类</strong><br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Configuration</span></span><br><span class="line"><span class="meta">@EnableConfigurationProperties</span>(ConfigSupportProperties.class)</span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ConfigSupportConfiguration</span> <span class="keyword">implements</span> <span class="title">ApplicationContextInitializer</span>&lt;<span class="title">ConfigurableApplicationContext</span>&gt;, <span class="title">Ordered</span> </span>&#123;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> Logger logger = LoggerFactory.getLogger(getClass());</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 重中之重！！！！</span></span><br><span class="line"><span class="comment">     * 一定要注意加载顺序！！！</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * bootstrap.yml 加载类：org.springframework.cloud.bootstrap.config.PropertySourceBootstrapConfiguration 的加载顺序是 </span></span><br><span class="line"><span class="comment">     * HIGHEST_PRECEDENCE+10，</span></span><br><span class="line"><span class="comment">     * 如果当前配置类再其之前加载，无法找到 bootstrap 配置文件中的信息，继而无法加载到本地</span></span><br><span class="line"><span class="comment">     * 所以当前配置类的装配顺序一定要在 PropertySourceBootstrapConfiguration 之后！</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> Integer orderNumber = Ordered.HIGHEST_PRECEDENCE + <span class="number">11</span>;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Autowired</span>(required = <span class="keyword">false</span>)</span><br><span class="line">    <span class="keyword">private</span> List&lt;PropertySourceLocator&gt; propertySourceLocators = Collections.EMPTY_LIST;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Autowired</span></span><br><span class="line">    <span class="keyword">private</span> ConfigSupportProperties configSupportProperties;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 初始化操作</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">initialize</span><span class="params">(ConfigurableApplicationContext configurableApplicationContext)</span> </span>&#123;</span><br><span class="line">        <span class="comment">// 判断是否开启 config server 管理配置</span></span><br><span class="line">        <span class="keyword">if</span> (!isHasCloudConfigLocator(<span class="keyword">this</span>.propertySourceLocators)) &#123;</span><br><span class="line">            logger.info(<span class="string">"Config server 管理配置未启用"</span>);</span><br><span class="line">            <span class="keyword">return</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        logger.info(<span class="string">"&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; 检查 config Server 配置资源 &lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;"</span>);</span><br><span class="line">        ConfigurableEnvironment environment = configurableApplicationContext.getEnvironment();</span><br><span class="line">        MutablePropertySources propertySources = environment.getPropertySources();</span><br><span class="line">        logger.info(<span class="string">"&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; 加载 PropertySources 源："</span> + propertySources.size() + <span class="string">" 个"</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 判断配置备份功能是否启用</span></span><br><span class="line">        <span class="keyword">if</span> (!configSupportProperties.isEnabled()) &#123;</span><br><span class="line">            logger.info(<span class="string">"&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; 配置备份未启用，使用：&#123;&#125;.enabled 打开 &lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;"</span>, ConfigSupportProperties.CONFIG_PREFIX);</span><br><span class="line">            <span class="keyword">return</span>;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (isCloudConfigLoaded(propertySources)) &#123;</span><br><span class="line">            <span class="comment">// 可以从 spring cloud 中获取配置信息</span></span><br><span class="line">            PropertySource cloudConfigSource = getLoadedCloudPropertySource(propertySources);</span><br><span class="line">            logger.info(<span class="string">"&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; 获取 config service 配置资源 &lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;"</span>);</span><br><span class="line">            Map&lt;String, Object&gt; backupPropertyMap = makeBackupPropertySource(cloudConfigSource);</span><br><span class="line">            doBackup(backupPropertyMap, configSupportProperties.getFallbackLocation());</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            logger.info(<span class="string">"&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; 获取 config Server 资源配置失败 &lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;"</span>);</span><br><span class="line">            <span class="comment">// 不能获取配置信息，从本地读取</span></span><br><span class="line">            Properties backupProperty = loadBackupProperty(configSupportProperties.getFallbackLocation());</span><br><span class="line">            <span class="keyword">if</span> (backupProperty != <span class="keyword">null</span>) &#123;</span><br><span class="line">                Map backupSourceMap = <span class="keyword">new</span> HashMap&lt;&gt;(backupProperty);</span><br><span class="line">                PropertySource backupSource = <span class="keyword">new</span> MapPropertySource(<span class="string">"backupSource"</span>, backupSourceMap);</span><br><span class="line"></span><br><span class="line">                propertySources.addFirst(backupSource);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">getOrder</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> orderNumber;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 从本地加载配置</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">private</span> Properties <span class="title">loadBackupProperty</span><span class="params">(String fallbackLocation)</span> </span>&#123;</span><br><span class="line">        logger.info(<span class="string">"&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; 正在从本地加载！&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;"</span>);</span><br><span class="line">        PropertiesFactoryBean propertiesFactoryBean = <span class="keyword">new</span> PropertiesFactoryBean();</span><br><span class="line">        Properties properties = <span class="keyword">new</span> Properties();</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            FileSystemResource fileSystemResource = <span class="keyword">new</span> FileSystemResource(fallbackLocation);</span><br><span class="line">            propertiesFactoryBean.setLocation(fileSystemResource);</span><br><span class="line">            propertiesFactoryBean.afterPropertiesSet();</span><br><span class="line">            properties = propertiesFactoryBean.getObject();</span><br><span class="line">            <span class="keyword">if</span> (properties != <span class="keyword">null</span>)&#123;</span><br><span class="line">                logger.info(<span class="string">"&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; 读取成功！&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;"</span>);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;<span class="keyword">catch</span> (Exception e)&#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> properties;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 备份配置信息</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">doBackup</span><span class="params">(Map&lt;String, Object&gt; backupPropertyMap, String fallbackLocation)</span> </span>&#123;</span><br><span class="line">        FileSystemResource fileSystemResource = <span class="keyword">new</span> FileSystemResource(fallbackLocation);</span><br><span class="line">        File file = fileSystemResource.getFile();</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="keyword">if</span> (!file.exists())&#123;</span><br><span class="line">                file.createNewFile();</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">if</span> (!file.canWrite())&#123;</span><br><span class="line">                logger.info(<span class="string">"&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; 文件无法写入：&#123;&#125; &lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;"</span>, fileSystemResource.getPath());</span><br><span class="line">                <span class="keyword">return</span>;</span><br><span class="line">            &#125;</span><br><span class="line">            Properties properties = <span class="keyword">new</span> Properties();</span><br><span class="line">            Iterator&lt;String&gt; iterator = backupPropertyMap.keySet().iterator();</span><br><span class="line">            <span class="keyword">while</span> (iterator.hasNext()) &#123;</span><br><span class="line">                String key = iterator.next();</span><br><span class="line">                properties.setProperty(key, String.valueOf(backupPropertyMap.get(key)));</span><br><span class="line">            &#125;</span><br><span class="line">            FileOutputStream fileOutputStream = <span class="keyword">new</span> FileOutputStream(fileSystemResource.getFile());</span><br><span class="line">            properties.store(fileOutputStream, <span class="string">"backup cloud config"</span>);</span><br><span class="line">        &#125;<span class="keyword">catch</span> (Exception e)&#123;</span><br><span class="line">            logger.info(<span class="string">"&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; 文件操作失败！ &lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;"</span>);</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 将配置信息转换为 map</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">private</span> Map&lt;String, Object&gt; <span class="title">makeBackupPropertySource</span><span class="params">(PropertySource cloudConfigSource)</span> </span>&#123;</span><br><span class="line">        Map&lt;String, Object&gt; backupSourceMap = <span class="keyword">new</span> HashMap&lt;&gt;();</span><br><span class="line">        <span class="keyword">if</span> (cloudConfigSource <span class="keyword">instanceof</span> CompositePropertySource) &#123;</span><br><span class="line">            CompositePropertySource propertySource = (CompositePropertySource) cloudConfigSource;</span><br><span class="line">            <span class="keyword">for</span> (PropertySource&lt;?&gt; source : propertySource.getPropertySources()) &#123;</span><br><span class="line">                <span class="keyword">if</span> (source <span class="keyword">instanceof</span> MapPropertySource)&#123;</span><br><span class="line">                    MapPropertySource mapPropertySource = (MapPropertySource) source;</span><br><span class="line">                    String[] propertyNames = mapPropertySource.getPropertyNames();</span><br><span class="line">                    <span class="keyword">for</span> (String propertyName : propertyNames) &#123;</span><br><span class="line">                        <span class="keyword">if</span> (!backupSourceMap.containsKey(propertyName)) &#123;</span><br><span class="line">                            backupSourceMap.put(propertyName, mapPropertySource.getProperty(propertyName));</span><br><span class="line">                        &#125;</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> backupSourceMap;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * config server 管理配置是否开启</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="keyword">boolean</span> <span class="title">isHasCloudConfigLocator</span><span class="params">(List&lt;PropertySourceLocator&gt; propertySourceLocators)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">for</span> (PropertySourceLocator propertySourceLocator : propertySourceLocators) &#123;</span><br><span class="line">            <span class="keyword">if</span> (propertySourceLocator <span class="keyword">instanceof</span> ConfigServicePropertySourceLocator) &#123;</span><br><span class="line">                <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 获取 config service 配置资源</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">private</span> PropertySource <span class="title">getLoadedCloudPropertySource</span><span class="params">(MutablePropertySources propertySources)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (!propertySources.contains(PropertySourceBootstrapConfiguration.BOOTSTRAP_PROPERTY_SOURCE_NAME))&#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        PropertySource&lt;?&gt; propertySource = propertySources.get(PropertySourceBootstrapConfiguration.BOOTSTRAP_PROPERTY_SOURCE_NAME);</span><br><span class="line">        <span class="keyword">if</span> (propertySource <span class="keyword">instanceof</span> CompositePropertySource) &#123;</span><br><span class="line">            <span class="keyword">for</span> (PropertySource&lt;?&gt; source : ((CompositePropertySource) propertySource).getPropertySources()) &#123;</span><br><span class="line">                <span class="comment">// 如果配置源是 config service，使用此配置源获取配置信息</span></span><br><span class="line">                <span class="comment">// configService 是 bootstrapProperties 加载 spring cloud 的实现：ConfigServiceBootstrapConfiguration</span></span><br><span class="line">                <span class="keyword">if</span> (<span class="string">"configService"</span>.equals(source.getName()))&#123;</span><br><span class="line">                    <span class="keyword">return</span> source;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 判断是否可以从 spring cloud 中获取配置信息</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="keyword">boolean</span> <span class="title">isCloudConfigLoaded</span><span class="params">(MutablePropertySources propertySources)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> getLoadedCloudPropertySource(propertySources) != <span class="keyword">null</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p><strong>META-INF/spring.factories</strong><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">org.springframework.cloud.bootstrap.BootstrapConfiguration=\</span><br><span class="line">  com.laiyy.gitee.confog.springcloudconfighaclientautoconfig.ConfigSupportConfiguration</span><br></pre></td></tr></table></figure></p><h3 id="客户端实现"><a href="#客户端实现" class="headerlink" title="客户端实现"></a>客户端实现</h3><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependencies</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.springframework.cloud<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spring-cloud-config-client<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>com.laiyy.gitee.confog<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spring-cloud-config-ha-client-autoconfig<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">version</span>&gt;</span>0.0.1-SNAPSHOT<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependencies</span>&gt;</span></span><br></pre></td></tr></table></figure><p><strong>bootstrap.yml</strong><br><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">spring:</span></span><br><span class="line"><span class="attr">  cloud:</span></span><br><span class="line"><span class="attr">    config:</span></span><br><span class="line"><span class="attr">      label:</span> <span class="string">master</span></span><br><span class="line"><span class="attr">      uri:</span> <span class="attr">http://localhost:9090</span></span><br><span class="line"><span class="attr">      name:</span> <span class="string">config-simple</span></span><br><span class="line"><span class="attr">      profile:</span> <span class="string">dev</span></span><br><span class="line"><span class="attr">      backup:</span></span><br><span class="line"><span class="attr">        enabled:</span> <span class="literal">true</span> <span class="comment"># 自定义配置 -- 是否启用客户端高可用配置</span></span><br><span class="line"><span class="attr">        fallbackLocation:</span> <span class="attr">D:/cloud</span>  <span class="comment"># 自动备份的配置文档存放位置</span></span><br></pre></td></tr></table></figure></p><p><strong>application.yml</strong><br><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">server:</span></span><br><span class="line"><span class="attr">  port:</span> <span class="number">9015</span></span><br><span class="line"></span><br><span class="line"><span class="attr">spring:</span></span><br><span class="line"><span class="attr">  application:</span></span><br><span class="line"><span class="attr">    name:</span> <span class="string">spring-cloud-config-ha-client-config</span></span><br></pre></td></tr></table></figure></p><p><strong>启动类</strong><br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@SpringBootApplication</span></span><br><span class="line"><span class="meta">@RestController</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">SpringCloudConfigHaClientConfigApplication</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        SpringApplication.run(SpringCloudConfigHaClientConfigApplication.class, args);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Value</span>(<span class="string">"$&#123;com.laiyy.gitee.config&#125;"</span>)</span><br><span class="line">    <span class="keyword">private</span> String config;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@GetMapping</span>(value = <span class="string">"/config"</span>)</span><br><span class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">getConfig</span><span class="params">()</span></span>&#123;</span><br><span class="line">        <span class="keyword">return</span> config;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><h3 id="config-server"><a href="#config-server" class="headerlink" title="config server"></a>config server</h3><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependencies</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.springframework.cloud<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spring-cloud-config-server<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependencies</span>&gt;</span></span><br></pre></td></tr></table></figure><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">server:</span></span><br><span class="line"><span class="attr">  port:</span> <span class="number">9090</span></span><br><span class="line"><span class="attr">spring:</span></span><br><span class="line"><span class="attr">  cloud:</span></span><br><span class="line"><span class="attr">    config:</span></span><br><span class="line"><span class="attr">      server:</span></span><br><span class="line"><span class="attr">        git:</span></span><br><span class="line"><span class="attr">          uri:</span> <span class="attr">https://gitee.com/laiyy0728/config-repo.git</span></span><br><span class="line"><span class="attr">          search-paths:</span> <span class="string">config-simple</span></span><br></pre></td></tr></table></figure><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@EnableConfigServer</span></span><br><span class="line"><span class="meta">@SpringBootApplication</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">SpringCloudConfigHaClientConfigServerApplication</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        SpringApplication.run(SpringCloudConfigHaClientConfigServerApplication.class, args);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="验证"><a href="#验证" class="headerlink" title="验证"></a>验证</h2><p>先后启动 <code>config-server</code>、<code>config-client</code>，查看<code>config-client</code>控制台输出：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">Fetching config from server at : http://localhost:9090</span><br><span class="line">Located environment: name=config-simple, profiles=[dev], label=master, version=ee39bf20c492b27c2d1b1d0ff378ad721e79a758, state=null</span><br><span class="line">Located property source: CompositePropertySource &#123;name=&apos;configService&apos;, propertySources=[MapPropertySource &#123;name=&apos;configClient&apos;&#125;, MapPropertySource &#123;name=&apos;https://gitee.com/laiyy0728/config-repo.git/config-simple/config-simple-dev.yml&apos;&#125;]&#125;</span><br><span class="line">&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; 检查 config Server 配置资源 &lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;</span><br><span class="line">&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; 加载 PropertySources 源：11 个</span><br><span class="line">&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; 获取 config service 配置资源 &lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;</span><br><span class="line">No active profile set, falling back to default profiles: default</span><br></pre></td></tr></table></figure></p><p>查看 <code>d:/cloud</code>，可见存在 <code>fallback.properties</code> 文件，打开文件，可见配置信息如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">#backup cloud config</span><br><span class="line">#Wed Apr 10 14:49:36 CST 2019</span><br><span class="line">config.client.version=ee39bf20c492b27c2d1b1d0ff378ad721e79a758</span><br><span class="line">com.laiyy.gitee.config=dev \u73AF\u5883\uFF0Cgit \u7248 spring cloud config-----\!</span><br></pre></td></tr></table></figure></p><p>访问 <a href="http://localhost:9015/config" target="_blank" rel="noopener">http://localhost:9015/config</a> ，可见打印信息如下：<br><img src="/images/spring-cloud/config/client-ha-result.png" alt="config-client-ha-result"></p><hr><p>停止 <code>server</code>、<code>client</code>，删除 <code>d:/cloud/fallback.properties</code>，将 <code>ConfigSupportConfiguration</code> 的 orderNumber 改为 <code>Ordered.HIGHEST_PRECEDENCE + 9</code>，再次先后启动 <code>config-server</code>、<code>config-client</code>，查看控制 <code>client</code> 控制台输出如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; 检查 config Server 配置资源 &lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;</span><br><span class="line">&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; 加载 PropertySources 源：10 个</span><br><span class="line">&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; 获取 config Server 资源配置失败 &lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;</span><br><span class="line">Fetching config from server at : http://localhost:9090</span><br></pre></td></tr></table></figure></p><p>可见，<code>PropertySources</code> 源从原来的 11 个，变为 10 个。原因是 <code>bootstrap.yml</code> 的加载顺序问题。<br>在源码：<code>org.springframework.cloud.bootstrap.config.PropertySourceBootstrapConfiguration</code> 中，其加载顺序为：<code>Ordered.HIGHEST_PRECEDENCE + 10</code>，而 <code>ConfigSupportConfiguration</code> 的加载顺序为 <code>Ordered.HIGHEST_PRECEDENCE + 9</code>，先于 bootstrap.yml 配置文件加载执行，所以无法获取到远程配置信息，继而无法备份配置信息。</p><hr><p>重新进行第一步验证，然后将 <code>config-server</code>、<code>config-client</code> 停掉后，只启动 <code>config-client</code>，可见其控制台打印信息如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; 检查 config Server 配置资源 &lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;</span><br><span class="line">&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; 加载 PropertySources 源：10 个</span><br><span class="line">&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; 获取 config Server 资源配置失败 &lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;</span><br><span class="line">&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; 正在从本地加载！&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;</span><br><span class="line">&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; 读取成功！&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;</span><br></pre></td></tr></table></figure></p><p>访问 <a href="http://localhost:9015/config" target="_blank" rel="noopener">http://localhost:9015/config</a> 正常返回信息。</p><p>由此验证<code>客户端高可用</code>成功</p><hr><h1 id="服务端高可用"><a href="#服务端高可用" class="headerlink" title="服务端高可用"></a>服务端高可用</h1><p>服务端高可用，一般情况下是通过与注册中心结合实现。通过 Ribbon 的负载均衡选择 Config Server 进行连接，来获取配置信息。</p><p><strong><em>源码：<a href="https://gitee.com/laiyy0728/spring-cloud/tree/master/spring-cloud-config/spring-cloud-config-ha/spring-cloud-config-ha-server" target="_blank" rel="noopener">https://gitee.com/laiyy0728/spring-cloud/tree/master/spring-cloud-config/spring-cloud-config-ha/spring-cloud-config-ha-server</a></em></strong></p><p>eureka 选择使用 <code>spring-cloud-eureka-server-simple</code></p><h2 id="config-server-1"><a href="#config-server-1" class="headerlink" title="config server"></a>config server</h2><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependencies</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.springframework.cloud<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spring-cloud-starter-netflix-eureka-client<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.springframework.cloud<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spring-cloud-config-server<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependencies</span>&gt;</span></span><br></pre></td></tr></table></figure><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">spring:</span></span><br><span class="line"><span class="attr">  cloud:</span></span><br><span class="line"><span class="attr">    config:</span></span><br><span class="line"><span class="attr">      server:</span></span><br><span class="line"><span class="attr">        git:</span></span><br><span class="line"><span class="attr">          uri:</span> <span class="attr">https://gitee.com/laiyy0728/config-repo.git</span></span><br><span class="line"><span class="attr">          search-paths:</span> <span class="string">config-simple</span></span><br><span class="line"><span class="attr">  application:</span></span><br><span class="line"><span class="attr">    name:</span> <span class="string">spring-cloud-config-ha-server-app</span></span><br><span class="line"><span class="attr">server:</span></span><br><span class="line"><span class="attr">  port:</span> <span class="number">9090</span></span><br><span class="line"><span class="attr">eureka:</span></span><br><span class="line"><span class="attr">  client:</span></span><br><span class="line"><span class="attr">    service-url:</span></span><br><span class="line"><span class="attr">      defaultZone:</span> <span class="attr">http://localhost:8761/eureka/</span></span><br></pre></td></tr></table></figure><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@SpringBootApplication</span></span><br><span class="line"><span class="meta">@EnableConfigServer</span></span><br><span class="line"><span class="meta">@EnableDiscoveryClient</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">SpringCloudConfigHaServerConfigApplication</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        SpringApplication.run(SpringCloudConfigHaServerConfigApplication.class, args);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="config-client"><a href="#config-client" class="headerlink" title="config client"></a>config client</h2><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependencies</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.springframework.cloud<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spring-cloud-config-client<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.springframework.cloud<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spring-cloud-starter-netflix-eureka-client<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependencies</span>&gt;</span></span><br></pre></td></tr></table></figure><p><strong>application.yml</strong><br><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">server:</span></span><br><span class="line"><span class="attr">  port:</span> <span class="number">9016</span></span><br><span class="line"></span><br><span class="line"><span class="attr">spring:</span></span><br><span class="line"><span class="attr">  application:</span></span><br><span class="line"><span class="attr">    name:</span> <span class="string">spring-cloud-config-ha-server-client</span></span><br></pre></td></tr></table></figure></p><p><strong>bootstrap.yml</strong><br><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">spring:</span></span><br><span class="line"><span class="attr">  cloud:</span></span><br><span class="line"><span class="attr">    config:</span></span><br><span class="line"><span class="attr">      label:</span> <span class="string">master</span></span><br><span class="line"><span class="attr">      name:</span> <span class="string">config-simple</span></span><br><span class="line"><span class="attr">      profile:</span> <span class="string">dev</span></span><br><span class="line"><span class="attr">      discovery:</span></span><br><span class="line"><span class="attr">        enabled:</span> <span class="literal">true</span> <span class="comment"># 是否从注册中心获取 config server</span></span><br><span class="line"><span class="attr">        service-id:</span> <span class="string">spring-cloud-config-ha-server-app</span> <span class="comment"># 注册中心 config server 的 serviceId</span></span><br><span class="line"><span class="attr">eureka:</span></span><br><span class="line"><span class="attr">  client:</span></span><br><span class="line"><span class="attr">    service-url:</span></span><br><span class="line"><span class="attr">      defauleZone:</span> <span class="attr">http://localhost:8761/eureka/</span></span><br></pre></td></tr></table></figure></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@SpringBootApplication</span></span><br><span class="line"><span class="meta">@RestController</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">SpringCloudConfigHaServerClientApplication</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        SpringApplication.run(SpringCloudConfigHaServerClientApplication.class, args);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Value</span>(<span class="string">"$&#123;com.laiyy.gitee.config&#125;"</span>)</span><br><span class="line">    <span class="keyword">private</span> String config;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@GetMapping</span>(value = <span class="string">"/config"</span>)</span><br><span class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">getConfig</span><span class="params">()</span></span>&#123;</span><br><span class="line">        <span class="keyword">return</span> config;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>启用验证：访问 <a href="http://localhost:9016/config" target="_blank" rel="noopener">http://localhost:9016/config</a> ,返回值如下：<br><img src="/images/spring-cloud/config/client-ha-result.png" alt="config-client-ha-result"></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;对于线上的生产环境，通常对其都是有很高的要求，其中，高可用是不可或缺的一部分。必须保证服务是可用的，才能保证系统更好的运行，这是业务稳定的保证。&lt;br&gt;高可用一般分为两种：&lt;code&gt;客户端高可用&lt;/code&gt;、&lt;code&gt;服务端高可用&lt;/code&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="spring-cloud" scheme="https://www.laiyy.top/categories/spring-cloud/"/>
    
    
      <category term="SpringCloud" scheme="https://www.laiyy.top/tags/SpringCloud/"/>
    
      <category term="CloudConfig" scheme="https://www.laiyy.top/tags/CloudConfig/"/>
    
  </entry>
  
  <entry>
    <title>Spring Cloud 微服务（30） --- Spring Cloud Config(四) &lt;BR&gt;  Spring Cloud 配置、高可用</title>
    <link href="https://www.laiyy.top/spring-cloud/spring-cloud-30.html"/>
    <id>https://www.laiyy.top/spring-cloud/spring-cloud-30.html</id>
    <published>2019-03-06T03:31:06.000Z</published>
    <updated>2019-03-06T03:31:06.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="本地参数覆盖远程参数"><a href="#本地参数覆盖远程参数" class="headerlink" title="本地参数覆盖远程参数"></a>本地参数覆盖远程参数</h1><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">spring:</span></span><br><span class="line"><span class="attr">  cloud:</span></span><br><span class="line"><span class="attr">    config:</span></span><br><span class="line"><span class="attr">      allow-override:</span> <span class="literal">true</span></span><br><span class="line"><span class="attr">      override-none:</span> <span class="literal">true</span></span><br><span class="line"><span class="attr">      override-system-properties:</span> <span class="literal">false</span></span><br></pre></td></tr></table></figure><a id="more"></a><ul><li>allow-override：标识 <code>override-system-properties</code> 是否启用，默认为 true，设置为 false 时，意味着禁用用户的设置</li><li>override-none：当此项为 true，<code>override-override</code> 为 true，外部的配置优先级更低，而且不能覆盖任何存在的属性源。默认为 false</li><li>override-system-properties：用来标识外部配置是否能够覆盖系统配置，默认为 true</li></ul><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@ConfigurationProperties</span>(<span class="string">"spring.cloud.config"</span>)</span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">PropertySourceBootstrapProperties</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">boolean</span> overrideSystemProperties = <span class="keyword">true</span>;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">boolean</span> allowOverride = <span class="keyword">true</span>;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">boolean</span> overrideNone = <span class="keyword">false</span>;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">PropertySourceBootstrapProperties</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 省略 getter、setter</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><hr><h1 id="客户端功能扩展"><a href="#客户端功能扩展" class="headerlink" title="客户端功能扩展"></a>客户端功能扩展</h1><h2 id="客户端自动刷新"><a href="#客户端自动刷新" class="headerlink" title="客户端自动刷新"></a>客户端自动刷新</h2><p><strong><em>源码：<a href="https://gitee.com/laiyy0728/spring-cloud/tree/master/spring-cloud-config/spring-cloud-autoconfig" target="_blank" rel="noopener">https://gitee.com/laiyy0728/spring-cloud/tree/master/spring-cloud-config/spring-cloud-autoconfig</a></em></strong></p><p>在有些应用上，不需要再服务端批量推送的时候，客户端本身需要获取变化参数的情况下，使用客户端的自动刷新能完成此功能。</p><p><strong><em>config server</em></strong> 依然采用 <code>spring-cloud-config-simple-server</code>，基础配置不变，配置文件 repo 依然是 <a href="https://gitee.com/laiyy0728/config-repo" target="_blank" rel="noopener">https://gitee.com/laiyy0728/config-repo</a></p><h3 id="配置拉取、刷新二方库"><a href="#配置拉取、刷新二方库" class="headerlink" title="配置拉取、刷新二方库"></a>配置拉取、刷新二方库</h3><p>新建一个二方库（spring-cloud-autoconfig-refresh），用于其他项目引入，以自动刷新配置（用于多个子项目使用同一个配置中心，自动刷新）</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependencies</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.springframework.cloud<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spring-cloud-config-client<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.springframework.boot<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spring-boot-autoconfigure<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependencies</span>&gt;</span></span><br></pre></td></tr></table></figure><p>整个二方库只有这一个类，作用是获取定时刷新时间，并刷新配置<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Configuration</span></span><br><span class="line"><span class="meta">@ConditionalOnClass</span>(RefreshEndpoint.class)</span><br><span class="line"><span class="meta">@ConditionalOnProperty</span>(<span class="string">"spring.cloud.config.refreshInterval"</span>)</span><br><span class="line"><span class="meta">@AutoConfigureAfter</span>(RefreshAutoConfiguration.class)</span><br><span class="line"><span class="meta">@EnableScheduling</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">SpringCloudAutoconfigRefreshApplication</span> <span class="keyword">implements</span> <span class="title">SchedulingConfigurer</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> Logger LOGGER = LoggerFactory.getLogger(SpringCloudAutoconfigRefreshApplication.class);</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Autowired</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">SpringCloudAutoconfigRefreshApplication</span><span class="params">(RefreshEndpoint refreshEndpoint)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.refreshEndpoint = refreshEndpoint;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Value</span>(<span class="string">"$&#123;spring.cloud.config.refreshInterval&#125;"</span>)</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">long</span> refreshInterval;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> RefreshEndpoint refreshEndpoint;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">configureTasks</span><span class="params">(ScheduledTaskRegistrar scheduledTaskRegistrar)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">final</span> <span class="keyword">long</span> interval = getRefreshIntervalilliseconds();</span><br><span class="line">        LOGGER.info(<span class="string">"&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; 定时刷新延迟 &#123;&#125; 秒启动，每 &#123;&#125; 毫秒刷新一次配置 &lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;"</span>, refreshInterval, interval);</span><br><span class="line">        scheduledTaskRegistrar.addFixedDelayTask(<span class="keyword">new</span> IntervalTask(refreshEndpoint::refresh, interval, interval));</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 返回毫秒级时间间隔</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="keyword">long</span> <span class="title">getRefreshIntervalilliseconds</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> refreshInterval * <span class="number">1000</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p><strong><em>/resources/META-INF/spring.factories</em></strong><br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">org.springframework.boot.autoconfigure.EnableAutoConfiguration=\</span><br><span class="line">  com.laiyy.gitee.config.springcloudautoconfigrefresh.SpringCloudAutoconfigRefreshApplication</span><br></pre></td></tr></table></figure></p><h3 id="客户端引入二方库"><a href="#客户端引入二方库" class="headerlink" title="客户端引入二方库"></a>客户端引入二方库</h3><p>创建客户端项目(spring-cloud-autoconfig-client)</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependencies</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.springframework.cloud<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spring-cloud-config-client<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">&lt;!-- 将配置好的自刷刷新作为二方库引入 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>com.laiyy.gitee.config<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spring-cloud-autoconfig-refresh<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">version</span>&gt;</span>0.0.1-SNAPSHOT<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependencies</span>&gt;</span></span><br></pre></td></tr></table></figure><p><strong><em>bootstrap.yml</em></strong><br><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">spring:</span></span><br><span class="line"><span class="attr">  cloud:</span></span><br><span class="line"><span class="attr">    config:</span></span><br><span class="line"><span class="attr">      uri:</span> <span class="attr">http://localhost:9090</span></span><br><span class="line"><span class="attr">      label:</span> <span class="string">master</span></span><br><span class="line"><span class="attr">      name:</span> <span class="string">config-simple</span></span><br><span class="line"><span class="attr">      profile:</span> <span class="string">dev</span></span><br></pre></td></tr></table></figure></p><p><strong><em>application.yml</em></strong><br><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">server:</span></span><br><span class="line"><span class="attr">  port:</span> <span class="number">9091</span></span><br><span class="line"><span class="attr">spring:</span></span><br><span class="line"><span class="attr">  application:</span></span><br><span class="line"><span class="attr">    name:</span> <span class="string">spring-cloud-autoconfig-client</span></span><br><span class="line"><span class="attr">  cloud:</span></span><br><span class="line"><span class="attr">    config:</span></span><br><span class="line"><span class="attr">      refreshInterval:</span> <span class="number">10</span> <span class="comment"># 延迟时间、定时刷新时间</span></span><br></pre></td></tr></table></figure></p><p>其余配置与 <code>spring-cloud-config-simple-client</code> 一致</p><h3 id="验证"><a href="#验证" class="headerlink" title="验证"></a>验证</h3><p>启动项目，访问 <a href="http://localhost:9090/get-config-info" target="_blank" rel="noopener">http://localhost:9090/get-config-info</a> ，正常返回信息。修改 config repo 配置文件，等待 10 秒后，再次访问，可见返回信息已经变为修改后信息。<br>查看 client 控制台，可见定时刷新日志<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">Exposing 2 endpoint(s) beneath base path &apos;/actuator&apos;</span><br><span class="line">&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; 定时刷新延迟 10 秒启动</span><br><span class="line">No TaskScheduler/ScheduledExecutorService bean found for scheduled processing</span><br><span class="line">Tomcat started on port(s): 9091 (http) with context path &apos;&apos;</span><br><span class="line">Started SpringCloudAutoconfigClientApplication in 4.361 seconds (JVM running for 5.089)</span><br><span class="line">Initializing Spring DispatcherServlet &apos;dispatcherServlet&apos;</span><br><span class="line">Initializing Servlet &apos;dispatcherServlet&apos;</span><br><span class="line">Fetching config from server at : http://localhost:9090      ------------------ 第一次请求</span><br><span class="line">Completed initialization in 7 ms</span><br><span class="line">Located environment: name=config-simple, profiles=[dev], label=master, version=00324826262afd5178a648a469247f4fffea945e, state=null</span><br><span class="line">Bean &apos;org.springframework.cloud.autoconfigure.ConfigurationPropertiesRebinderAutoConfiguration&apos; of type [org.springframework.cloud.autoconfigure.ConfigurationPropertiesRebinderAutoConfiguration$$EnhancerBySpringCGLIB$$f67277ed] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)</span><br><span class="line">Fetching config from server at : http://localhost:9090       ------------------ 定时刷新配置</span><br><span class="line">Located environment: name=config-simple, profiles=[dev], label=master, version=00324826262afd5178a648a469247f4fffea945e, state=null</span><br><span class="line">Located property source: CompositePropertySource &#123;name=&apos;configService&apos;, propertySources=[MapPropertySource &#123;name=&apos;configClient&apos;&#125;, MapPropertySource &#123;name=&apos;https://gitee.com/laiyy0728/config-repo/config-simple/config-simple-dev.yml&apos;&#125;]&#125;</span><br><span class="line"></span><br><span class="line">... 省略其他多次刷新</span><br></pre></td></tr></table></figure></p><h2 id="客户端回退"><a href="#客户端回退" class="headerlink" title="客户端回退"></a>客户端回退</h2><p>客户端回退机制，可以在出现网络中断时、或者配置服务因维护而关闭时，使得客户端可以正常使用。当启动回退时，客户端适配器将配置“缓存”到计算机中。要启用回退功能，只需要指定缓存存储的位置即可。</p><p><strong><em>源码：<a href="https://gitee.com/laiyy0728/spring-cloud/tree/master/spring-cloud-config/spring-cloud-config-fallback" target="_blank" rel="noopener">https://gitee.com/laiyy0728/spring-cloud/tree/master/spring-cloud-config/spring-cloud-config-fallback</a></em></strong></p><p><strong><em>config server</em></strong> 依然采用 <code>spring-cloud-config-simple-server</code>，基础配置不变，配置文件 repo 依然是 <a href="https://gitee.com/laiyy0728/config-repo" target="_blank" rel="noopener">https://gitee.com/laiyy0728/config-repo</a></p><h3 id="二方库"><a href="#二方库" class="headerlink" title="二方库"></a>二方库</h3><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependencies</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.springframework.cloud<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spring-cloud-starter-config<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.springframework.security<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spring-security-rsa<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.0.7.RELEASE<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependencies</span>&gt;</span></span><br></pre></td></tr></table></figure><p><strong><em>config-client.properties</em></strong>：用于设置是否开启配置<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">spring.cloud.config.enabled=false</span><br></pre></td></tr></table></figure></p><p><strong><em>/resources/META-INF/spring.factories</em></strong><br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">org.springframework.cloud.bootstrap.BootstrapConfiguration=\</span><br><span class="line">  com.laiyy.gitee.config.springcloudconfigfallbackautorefresh.ConfigServerBootStrap</span><br></pre></td></tr></table></figure></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 用于拉取远程配置文件，并保存到本地</span></span><br><span class="line"><span class="meta">@Order</span>(<span class="number">0</span>)</span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">FallbackableConfigServerPropertySourceLocator</span> <span class="keyword">extends</span> <span class="title">ConfigServicePropertySourceLocator</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> Logger LOGGER = LoggerFactory.getLogger(FallbackableConfigServerPropertySourceLocator.class);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">boolean</span> fallbackEnabled;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> String fallbackLocation;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Autowired</span>(required = <span class="keyword">false</span>)</span><br><span class="line">    <span class="keyword">private</span> TextEncryptor textEncryptor;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">FallbackableConfigServerPropertySourceLocator</span><span class="params">(ConfigClientProperties defaultProperties, String fallbackLocation)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">super</span>(defaultProperties);</span><br><span class="line">        <span class="keyword">this</span>.fallbackLocation = fallbackLocation;</span><br><span class="line">        <span class="keyword">this</span>.fallbackEnabled = !StringUtils.isEmpty(fallbackLocation);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> PropertySource&lt;?&gt; locate(Environment environment)&#123;</span><br><span class="line">        PropertySource&lt;?&gt; propertySource = <span class="keyword">super</span>.locate(environment);</span><br><span class="line">        <span class="keyword">if</span> (fallbackEnabled &amp;&amp; propertySource != <span class="keyword">null</span>)&#123;</span><br><span class="line">            storeLocally(propertySource);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> propertySource;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 转换配置文件</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">storeLocally</span><span class="params">(PropertySource propertySource)</span></span>&#123;</span><br><span class="line">        StringBuilder builder = <span class="keyword">new</span> StringBuilder();</span><br><span class="line">        CompositePropertySource source = (CompositePropertySource) propertySource;</span><br><span class="line">        <span class="keyword">for</span> (String propertyName : source.getPropertyNames()) &#123;</span><br><span class="line">            Object property = source.getProperty(propertyName);</span><br><span class="line">            <span class="keyword">if</span> (textEncryptor != <span class="keyword">null</span>)&#123;</span><br><span class="line">                property = <span class="string">"&#123;cipher&#125;"</span> + textEncryptor.encrypt(String.valueOf(property));</span><br><span class="line">            &#125;</span><br><span class="line">            builder.append(propertyName).append(<span class="string">"="</span>).append(property).append(<span class="string">"\n"</span>);</span><br><span class="line">        &#125;</span><br><span class="line">        LOGGER.info(<span class="string">"&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; file content: &#123;&#125; &lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;"</span>, builder);</span><br><span class="line">        saveFile(builder.toString());</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 保存配置到本地</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> content 配置内容</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">saveFile</span><span class="params">(String content)</span></span>&#123;</span><br><span class="line">        File file = <span class="keyword">new</span> File(fallbackLocation + File.separator + ConfigServerBootStrap.FALLBACK_NAME);</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            FileCopyUtils.copy(content.getBytes(), file);</span><br><span class="line">        &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">// 用于判断从远程拉取配置文件，还是从本地拉取（spring boot 2.0，spring cloud F版）</span></span><br><span class="line"><span class="meta">@Configuration</span></span><br><span class="line"><span class="meta">@EnableConfigurationProperties</span></span><br><span class="line"><span class="meta">@PropertySource</span>(value = &#123;<span class="string">"config-client.properties"</span>,<span class="string">"file:&#123;spring.cloud.config.fallback-location:&#125;/fallback.properties"</span>&#125;, ignoreResourceNotFound = <span class="keyword">true</span>)</span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ConfigServerBootStrap</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> String FALLBACK_NAME = <span class="string">"fallback.properties"</span>;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> ConfigurableEnvironment configurableEnvironment;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Autowired</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">ConfigServerBootStrap</span><span class="params">(ConfigurableEnvironment configurableEnvironment)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.configurableEnvironment = configurableEnvironment;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Value</span>(<span class="string">"$&#123;spring.cloud.config.fallback-location:&#125;"</span>)</span><br><span class="line">    <span class="keyword">private</span> String fallbackLocation;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Bean</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> ConfigClientProperties <span class="title">configClientProperties</span><span class="params">()</span></span>&#123;</span><br><span class="line">        ConfigClientProperties configClientProperties = <span class="keyword">new</span> ConfigClientProperties(<span class="keyword">this</span>.configurableEnvironment);</span><br><span class="line">        configClientProperties.setEnabled(<span class="keyword">false</span>);</span><br><span class="line">        <span class="keyword">return</span> configClientProperties;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Bean</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> FallbackableConfigServerPropertySourceLocator <span class="title">fallbackableConfigServerPropertySourceLocator</span><span class="params">()</span></span>&#123;</span><br><span class="line">        ConfigClientProperties client = configClientProperties();</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">new</span> FallbackableConfigServerPropertySourceLocator(client, fallbackLocation);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>在 SpringBoot 1.0、Spring Cloud G 版中，会启动报错：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">***************************</span><br><span class="line">APPLICATION FAILED TO START</span><br><span class="line">***************************</span><br><span class="line"></span><br><span class="line">Description:</span><br><span class="line"></span><br><span class="line">The bean &apos;configClientProperties&apos;, defined in class path resource [com/laiyy/gitee/config/springcloudconfigfallbackautorefresh/ConfigServerBootStrap.class], could not be registered. A bean with that name has already been defined in class path resource [org/springframework/cloud/config/client/ConfigServiceBootstrapConfiguration.class] and overriding is disabled.</span><br><span class="line"></span><br><span class="line">Action:</span><br><span class="line"></span><br><span class="line">Consider renaming one of the beans or enabling overriding by setting spring.main.allow-bean-definition-overriding=true</span><br><span class="line"></span><br><span class="line">2019-03-07 10:10:11.230 ERROR 13828 --- [           main] o.s.boot.SpringApplication               : Application run failed</span><br><span class="line"></span><br><span class="line">org.springframework.beans.factory.support.BeanDefinitionOverrideException: Invalid bean definition with name &apos;configClientProperties&apos; defined in class path resource [com/laiyy/gitee/config/springcloudconfigfallbackautorefresh/ConfigServerBootStrap.class]: Cannot register bean definition [Root bean: class [null]; scope=; abstract=false; lazyInit=false; autowireMode=3; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=com.laiyy.gitee.config.springcloudconfigfallbackautorefresh.ConfigServerBootStrap; factoryMethodName=configClientProperties; initMethodName=null; destroyMethodName=(inferred); defined in class path resource [com/laiyy/gitee/config/springcloudconfigfallbackautorefresh/ConfigServerBootStrap.class]] for bean &apos;configClientProperties&apos;: There is already [Root bean: class [null]; scope=; abstract=false; lazyInit=false; autowireMode=3; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=org.springframework.cloud.config.client.ConfigServiceBootstrapConfiguration; factoryMethodName=configClientProperties; initMethodName=null; destroyMethodName=(inferred); defined in class path resource [org/springframework/cloud/config/client/ConfigServiceBootstrapConfiguration.class]] bound.</span><br><span class="line">at org.springframework.beans.factory.support.DefaultListableBeanFactory.registerBeanDefinition(DefaultListableBeanFactory.java:894) ~[spring-beans-5.1.2.RELEASE.jar:5.1.2.RELEASE]</span><br><span class="line">at org.springframework.context.annotation.ConfigurationClassBeanDefinitionReader.loadBeanDefinitionsForBeanMethod(ConfigurationClassBeanDefinitionReader.java:274) ~[spring-context-5.1.2.RELEASE.jar:5.1.2.RELEASE]</span><br><span class="line">    ....</span><br></pre></td></tr></table></figure></p><p>如果按照报错提示，增加了 <code>spring.main.allow-bean-definition-overriding=true</code> 的配置，没有任何作用；如果修改了 bean 名称<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Bean</span>(name=<span class="string">"clientProperties"</span>)</span><br><span class="line"><span class="function"><span class="keyword">public</span> ConfigClientProperties <span class="title">configClientProperties</span><span class="params">()</span></span>&#123;</span><br><span class="line">    ConfigClientProperties configClientProperties = <span class="keyword">new</span> ConfigClientProperties(<span class="keyword">this</span>.configurableEnvironment);</span><br><span class="line">    configClientProperties.setEnabled(<span class="keyword">false</span>);</span><br><span class="line">    <span class="keyword">return</span> configClientProperties;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>会有如下报错：<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">***************************</span><br><span class="line">APPLICATION FAILED TO START</span><br><span class="line">***************************</span><br><span class="line"></span><br><span class="line">Description:</span><br><span class="line"></span><br><span class="line">Method configClientProperties in org.springframework.cloud.config.client.ConfigClientAutoConfiguration required a single bean, but <span class="number">2</span> were found:</span><br><span class="line">- configClientProperties: defined by method 'configClientProperties' in class path resource [org/springframework/cloud/config/client/ConfigClientAutoConfiguration.class]</span><br><span class="line">- clientProperties: defined by method 'configClientProperties' in class path resource [com/laiyy/gitee/config/springcloudconfigfallbackautorefresh/ConfigServerBootStrap.class]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">Action:</span><br><span class="line"></span><br><span class="line">Consider marking one of the beans as <span class="meta">@Primary</span>, updating the consumer to accept multiple beans, or using <span class="meta">@Qualifier</span> to identify the bean that should be consumed</span><br></pre></td></tr></table></figure></p><p>原因：<code>ConfigClientProperties</code> 在初始化时已经默认单例加载。即：这个 bean 不能被重新注册到 spring 容器中。<br>解决办法：将 spring 容器已经加载的单例的 <code>ConfigClientProperties</code> 注入进来，并在构造中设置为 false 即可<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Configuration</span></span><br><span class="line"><span class="meta">@EnableConfigurationProperties</span></span><br><span class="line"><span class="meta">@PropertySource</span>(value = &#123;<span class="string">"configClient.properties"</span>, <span class="string">"file:$&#123;spring.cloud.config.fallbackLocation:&#125;/fallback.properties"</span>&#125;, ignoreResourceNotFound = <span class="keyword">true</span>)</span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ConfigServerBootStrap</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> String FALLBACK_NAME = <span class="string">"fallback.properties"</span>;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> ConfigurableEnvironment configurableEnvironment;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> ConfigClientProperties configClientProperties;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Autowired</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">ConfigServerBootStrap</span><span class="params">(ConfigurableEnvironment configurableEnvironment, ConfigClientProperties configClientProperties)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.configurableEnvironment = configurableEnvironment;</span><br><span class="line">        <span class="keyword">this</span>.configClientProperties = configClientProperties;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">this</span>.configClientProperties.setEnabled(<span class="keyword">false</span>);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Value</span>(<span class="string">"$&#123;spring.cloud.config.fallbackLocation:&#125;"</span>)</span><br><span class="line">    <span class="keyword">private</span> String fallbackLocation;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Bean</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> FallbackableConfigServerPropertySourceLocator <span class="title">fallbackableConfigServerPropertySourceLocator</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">new</span> FallbackableConfigServerPropertySourceLocator(configClientProperties, fallbackLocation);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><h3 id="config-client"><a href="#config-client" class="headerlink" title="config client"></a>config client</h3><p><strong><em>bootstrap.yml</em></strong><br><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">spring:</span></span><br><span class="line"><span class="attr">  cloud:</span></span><br><span class="line"><span class="attr">    config:</span></span><br><span class="line"><span class="attr">      uri:</span> <span class="attr">http://localhost:9090</span></span><br><span class="line"><span class="attr">      label:</span> <span class="string">master</span></span><br><span class="line"><span class="attr">      name:</span> <span class="string">config-simple</span></span><br><span class="line"><span class="attr">      profile:</span> <span class="string">dev</span></span><br><span class="line"><span class="attr">      fallbackLocation:</span> <span class="attr">E:\\springcloud</span></span><br></pre></td></tr></table></figure></p><p><strong><em>application.yml</em></strong><br><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">server:</span></span><br><span class="line"><span class="attr">  port:</span> <span class="number">9091</span></span><br><span class="line"><span class="attr">spring:</span></span><br><span class="line"><span class="attr">  application:</span></span><br><span class="line"><span class="attr">    name:</span> <span class="string">spring-cloud-autoconfig-client</span></span><br><span class="line"><span class="attr">  main:</span></span><br><span class="line"><span class="attr">    allow-bean-definition-overriding:</span> <span class="literal">true</span></span><br><span class="line"><span class="attr">management:</span></span><br><span class="line"><span class="attr">  endpoints:</span></span><br><span class="line"><span class="attr">    web:</span></span><br><span class="line"><span class="attr">      exposure:</span></span><br><span class="line"><span class="attr">        include:</span> <span class="string">'*'</span></span><br><span class="line"><span class="attr">  endpoint:</span></span><br><span class="line"><span class="attr">    health:</span></span><br><span class="line"><span class="attr">      show-details:</span> <span class="string">always</span></span><br></pre></td></tr></table></figure></p><p>其余配置、JAVA 类不变</p><h3 id="验证-1"><a href="#验证-1" class="headerlink" title="验证"></a>验证</h3><p>启动 config client，查看控制台，可见打印了 2 次远程拉取同步本地文件的信息：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; file content: config.client.version=ee39bf20c492b27c2d1b1d0ff378ad721e79a758</span><br><span class="line">com.laiyy.gitee.config=dev 环境，git 版 spring cloud config-----!</span><br><span class="line"> &lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;</span><br></pre></td></tr></table></figure></p><p>查看本地 E:\springcloud 文件夹，可见多了一个 <code>fallback.properties</code> 文件<br><img src="/images/spring-cloud/config/fallback-local-properties.png" alt="fallback local properties"></p><p>文件内容：<br><img src="/images/spring-cloud/config/fallback-local-properties-content.png" alt="fallback local properties content"></p><p>更新 config repo 的对应配置文件后，POST 访问 config client 刷新端口：<a href="http://localhost:9091/actuator/refresh" target="_blank" rel="noopener">http://localhost:9091/actuator/refresh</a> 可见控制台再次打印同步本地文件信息。此时停止 config server 访问，再次访问 <a href="http://localhost:9091/get-config-info" target="_blank" rel="noopener">http://localhost:9091/get-config-info</a> ，返回的信息是同步后的更新结果，由此验证客户端回退成功。</p>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;本地参数覆盖远程参数&quot;&gt;&lt;a href=&quot;#本地参数覆盖远程参数&quot; class=&quot;headerlink&quot; title=&quot;本地参数覆盖远程参数&quot;&gt;&lt;/a&gt;本地参数覆盖远程参数&lt;/h1&gt;&lt;figure class=&quot;highlight yml&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;attr&quot;&gt;spring:&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;attr&quot;&gt;  cloud:&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;attr&quot;&gt;    config:&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;attr&quot;&gt;      allow-override:&lt;/span&gt; &lt;span class=&quot;literal&quot;&gt;true&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;attr&quot;&gt;      override-none:&lt;/span&gt; &lt;span class=&quot;literal&quot;&gt;true&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;attr&quot;&gt;      override-system-properties:&lt;/span&gt; &lt;span class=&quot;literal&quot;&gt;false&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
    
    </summary>
    
      <category term="spring-cloud" scheme="https://www.laiyy.top/categories/spring-cloud/"/>
    
    
      <category term="SpringCloud" scheme="https://www.laiyy.top/tags/SpringCloud/"/>
    
      <category term="CloudConfig" scheme="https://www.laiyy.top/tags/CloudConfig/"/>
    
  </entry>
  
  <entry>
    <title>Spring Cloud 微服务（29） --- Spring Cloud Config(三) &lt;BR&gt; git 版 coofnig 配置、使用数据库实现配置中心</title>
    <link href="https://www.laiyy.top/spring-cloud/spring-cloud-29.html"/>
    <id>https://www.laiyy.top/spring-cloud/spring-cloud-29.html</id>
    <published>2019-03-05T03:28:06.000Z</published>
    <updated>2019-03-05T03:28:06.000Z</updated>
    
    <content type="html"><![CDATA[<p>除了使用 git 作为配置文件的管理中心外，也可以使用关系型数据库、非关系型数据库实现配置中心，以及配置中心的扩展。包括：客户端自动刷新、客户端回退、安全认证、客户端高可用、服务端高可用等。</p><a id="more"></a><hr><h1 id="服务端-git-配置详解"><a href="#服务端-git-配置详解" class="headerlink" title="服务端 git 配置详解"></a>服务端 git 配置详解</h1><p>git 的版 config 有多种配置：</p><ul><li>uri 占位符</li><li>模式匹配</li><li>多残酷</li><li>路径搜索占位符</li></ul><p><strong><em>源码：<a href="https://gitee.com/laiyy0728/spring-cloud/tree/master/spring-cloud-config/spring-cloud-placeholder" target="_blank" rel="noopener">https://gitee.com/laiyy0728/spring-cloud/tree/master/spring-cloud-config/spring-cloud-placeholder</a></em></strong></p><p>公共依赖<br><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependencies</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.springframework.boot<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spring-boot-starter-actuator<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependencies</span>&gt;</span></span><br></pre></td></tr></table></figure></p><h2 id="git-中-uri-占位符"><a href="#git-中-uri-占位符" class="headerlink" title="git 中 uri 占位符"></a>git 中 uri 占位符</h2><p>Spring Cloud Config Server 支持占位符的使用，支持 {application}、{profile}、{label}，这样的话就可以在配置 uri 的时候，通过占位符使用应用名称来区分应用对应的仓库进行使用。</p><p><strong><em> config server </em></strong><br><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">spring:</span></span><br><span class="line"><span class="attr">  cloud:</span></span><br><span class="line"><span class="attr">    config:</span></span><br><span class="line"><span class="attr">      server:</span></span><br><span class="line"><span class="attr">        git:</span></span><br><span class="line"><span class="attr">          uri:</span> <span class="attr">https://gitee.com/laiyy0728/&#123;application&#125;</span>        <span class="comment"># &#123;application&#125; 是匹配符，匹配项目名称</span></span><br><span class="line"><span class="attr">          search-paths:</span> <span class="string">config-simple</span></span><br><span class="line"><span class="attr">  application:</span></span><br><span class="line"><span class="attr">    name:</span> <span class="string">spring-cloud-placeholder-server</span></span><br><span class="line"><span class="attr">server:</span></span><br><span class="line"><span class="attr">  port:</span> <span class="number">9090</span></span><br></pre></td></tr></table></figure></p><p><strong><em> config client </em></strong></p><p>bootstrap.yml<br><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">spring:</span></span><br><span class="line"><span class="attr">  cloud:</span></span><br><span class="line"><span class="attr">    config:</span></span><br><span class="line"><span class="attr">      label:</span> <span class="string">master</span></span><br><span class="line"><span class="attr">      uri:</span> <span class="attr">http://localhost:9090</span></span><br><span class="line"><span class="attr">      name:</span> <span class="string">config-repo</span></span><br><span class="line"><span class="attr">      profile:</span> <span class="string">dev</span></span><br></pre></td></tr></table></figure></p><p>使用 <code>{application}</code> 时，需要注意，在 config client 中配置的 <code>name</code>，既是 config 管理中心的 git 名称，又是需要匹配的配置文件名称。即：远程的 config git 管理中心地址为：<a href="https://gitee.com/laiyy0728/config-repo" target="_blank" rel="noopener">https://gitee.com/laiyy0728/config-repo</a> ，在仓库中 <code>config-simple</code> 文件夹下，必须有一个 <code>config-simple.yml</code> 配置文件。否则 config client 会找不到配置文件。</p><h2 id="模式匹配、多存储库"><a href="#模式匹配、多存储库" class="headerlink" title="模式匹配、多存储库"></a>模式匹配、多存储库</h2><p><strong><em>config server</em></strong><br><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">spring:</span></span><br><span class="line"><span class="attr">  profiles:</span></span><br><span class="line"><span class="attr">    active:</span> <span class="string">native</span> <span class="comment"># 本地配置仓库，在测试本地配置仓库之前，需要注释掉这一行</span></span><br><span class="line"><span class="attr">  cloud:</span></span><br><span class="line"><span class="attr">    config:</span></span><br><span class="line"><span class="attr">      server:</span></span><br><span class="line"><span class="attr">        git:</span></span><br><span class="line"><span class="attr">          uri:</span> <span class="attr">https://gitee.com/laiyy0728/config-repo</span></span><br><span class="line"><span class="attr">          search-paths:</span> <span class="string">config-simple</span></span><br><span class="line"><span class="attr">          repos:</span></span><br><span class="line"><span class="attr">            simple:</span> <span class="attr">https://gitee.com/laiyy0728/simple</span></span><br><span class="line"><span class="attr">            special:</span></span><br><span class="line"><span class="attr">              pattern:</span> <span class="string">special*/dev*,*special*/dev*</span></span><br><span class="line"><span class="attr">              uri:</span> <span class="attr">https://gitee.com/laiyy0728/special</span></span><br><span class="line"><span class="attr">        native:</span></span><br><span class="line"><span class="attr">          search-locations:</span>  <span class="attr">C:/Users/laiyy/AppData/Local/Temp/config-simple</span> <span class="comment"># 本地配置仓库路径</span></span><br><span class="line"><span class="attr">  application:</span></span><br><span class="line"><span class="attr">    name:</span> <span class="string">spring-cloud-placeholder-server</span></span><br><span class="line"><span class="attr">server:</span></span><br><span class="line"><span class="attr">  port:</span> <span class="number">9090</span></span><br></pre></td></tr></table></figure></p><h2 id="路径搜索占位符"><a href="#路径搜索占位符" class="headerlink" title="路径搜索占位符"></a>路径搜索占位符</h2><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">spring:</span></span><br><span class="line"><span class="attr">  cloud:</span></span><br><span class="line"><span class="attr">    config:</span></span><br><span class="line"><span class="attr">      server:</span></span><br><span class="line"><span class="attr">        git:</span></span><br><span class="line"><span class="attr">          uri:</span> <span class="attr">https://gitee.com/laiyy0728/config-repo</span></span><br><span class="line"><span class="attr">          search-paths:</span> <span class="string">config-*</span> <span class="comment"># 匹配以 config 开头的文件夹</span></span><br><span class="line"><span class="attr">  application:</span></span><br><span class="line"><span class="attr">    name:</span> <span class="string">spring-cloud-placeholder-server</span></span><br><span class="line"><span class="attr">server:</span></span><br><span class="line"><span class="attr">  port:</span> <span class="number">9090</span></span><br></pre></td></tr></table></figure><hr><h1 id="关系型数据库实现配置中心"><a href="#关系型数据库实现配置中心" class="headerlink" title="关系型数据库实现配置中心"></a>关系型数据库实现配置中心</h1><p>架构图：<br><img src="/images/spring-cloud/config/config-db.png" alt="config server mysql"></p><p>公共依赖<br><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependencies</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.springframework.boot<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spring-boot-starter-actuator<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependencies</span>&gt;</span></span><br></pre></td></tr></table></figure></p><h2 id="mysql-config-server"><a href="#mysql-config-server" class="headerlink" title="mysql config server"></a>mysql config server</h2><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependencies</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.springframework.cloud<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spring-cloud-config-server<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.springframework.boot<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spring-boot-starter-jdbc<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>mysql<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>mysql-connector-java<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependencies</span>&gt;</span></span><br></pre></td></tr></table></figure><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">server:</span></span><br><span class="line"><span class="attr">  port:</span> <span class="number">9090</span></span><br><span class="line"><span class="attr">spring:</span></span><br><span class="line"><span class="attr">  application:</span></span><br><span class="line"><span class="attr">    name:</span> <span class="string">spring-cloud-customer-repo-mysql</span></span><br><span class="line"><span class="attr">  cloud:</span></span><br><span class="line"><span class="attr">    config:</span></span><br><span class="line"><span class="attr">      server:</span></span><br><span class="line"><span class="attr">        jdbc:</span></span><br><span class="line"><span class="attr">          sql:</span> <span class="string">SELECT</span> <span class="string">`KEY`,</span> <span class="string">`VALUE`</span> <span class="string">FROM</span> <span class="string">PROPERTIES</span> <span class="string">WHERE</span> <span class="string">application</span> <span class="string">=</span> <span class="string">?</span> <span class="string">NAD</span> <span class="string">profile</span> <span class="string">=</span> <span class="string">?</span> <span class="string">AND</span> <span class="string">label</span> <span class="string">=</span> <span class="string">?</span></span><br><span class="line"><span class="attr">      label:</span> <span class="string">master</span></span><br><span class="line"><span class="attr">  profiles:</span></span><br><span class="line"><span class="attr">    active:</span> <span class="string">jdbc</span></span><br><span class="line"><span class="attr">  datasource:</span></span><br><span class="line"><span class="attr">    url:</span> <span class="attr">jdbc:mysql:///springcloud?useUnicode=true&amp;charsetEncoding=UTF-8</span></span><br><span class="line"><span class="attr">    username:</span> <span class="string">root</span></span><br><span class="line"><span class="attr">    password:</span> <span class="number">123456</span></span><br><span class="line"><span class="attr">    driver-class-name:</span> <span class="string">com.mysql.cj.jdbc.Driver</span></span><br><span class="line"><span class="attr">logging:</span></span><br><span class="line"><span class="attr">  level:</span></span><br><span class="line">    <span class="string">org.springframework.jdbc.core:</span> <span class="string">debug</span></span><br><span class="line">    <span class="string">org.springframework.jdbc.core.StatementCreatorUtils:</span> <span class="string">Trace</span></span><br></pre></td></tr></table></figure><p>其余配置、config client 与之前一致即可。</p><h2 id="验证"><a href="#验证" class="headerlink" title="验证"></a>验证</h2><p>启动 config server、config client，可以看到，config server 打印日志如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">...</span><br><span class="line"></span><br><span class="line">Executing prepared SQL query</span><br><span class="line">Executing prepared SQL statement [SELECT `KEY`, `VALUE` FROM PROPERTIES WHERE application = ? AND profile = ? AND lable = ?]</span><br><span class="line">Setting SQL statement parameter value: column index 1, parameter value [config-simple], value class [java.lang.String], SQL type unknown</span><br><span class="line">Setting SQL statement parameter value: column index 2, parameter value [dev], value class [java.lang.String], SQL type unknown</span><br><span class="line">Setting SQL statement parameter value: column index 3, parameter value [master], value class [java.lang.String], SQL type unknown</span><br><span class="line">Executing prepared SQL query</span><br><span class="line">Executing prepared SQL statement [SELECT `KEY`, `VALUE` FROM PROPERTIES WHERE application = ? AND profile = ? AND lable = ?]</span><br><span class="line">Setting SQL statement parameter value: column index 1, parameter value [config-simple], value class [java.lang.String], SQL type unknown</span><br><span class="line">Setting SQL statement parameter value: column index 2, parameter value [default], value class [java.lang.String], SQL type unknown</span><br><span class="line">Setting SQL statement parameter value: column index 3, parameter value [master], value class [java.lang.String], SQL type unknown</span><br><span class="line">Executing prepared SQL query</span><br><span class="line">Executing prepared SQL statement [SELECT `KEY`, `VALUE` FROM PROPERTIES WHERE application = ? AND profile = ? AND lable = ?]</span><br><span class="line">Setting SQL statement parameter value: column index 1, parameter value [application], value class [java.lang.String], SQL type unknown</span><br><span class="line">Setting SQL statement parameter value: column index 2, parameter value [dev], value class [java.lang.String], SQL type unknown</span><br><span class="line">Setting SQL statement parameter value: column index 3, parameter value [master], value class [java.lang.String], SQL type unknown</span><br><span class="line">Executing prepared SQL query</span><br><span class="line">Executing prepared SQL statement [SELECT `KEY`, `VALUE` FROM PROPERTIES WHERE application = ? AND profile = ? AND lable = ?]</span><br><span class="line">Setting SQL statement parameter value: column index 1, parameter value [application], value class [java.lang.String], SQL type unknown</span><br><span class="line">Setting SQL statement parameter value: column index 2, parameter value [default], value class [java.lang.String], SQL type unknown</span><br><span class="line">Setting SQL statement parameter value: column index 3, parameter value [master], value class [java.lang.String], SQL type unknown</span><br><span class="line"></span><br><span class="line">...</span><br></pre></td></tr></table></figure></p><p>访问 <a href="http://localhost:9091/get-config-info" target="_blank" rel="noopener">http://localhost:9091/get-config-info</a> ，返回数据如下：<br><img src="/images/spring-cloud/config/config-mysql-repo.png" alt="spring cloud config mysql"></p><hr><h1 id="非关系数据库实现配置中心"><a href="#非关系数据库实现配置中心" class="headerlink" title="非关系数据库实现配置中心"></a>非关系数据库实现配置中心</h1><p>以 mongodb 为例，需要 spring cloud config server mongodb 依赖，github 地址：<a href="https://github.com/spring-cloud-incubator/spring-cloud-config-server-mongodb" target="_blank" rel="noopener">https://github.com/spring-cloud-incubator/spring-cloud-config-server-mongodb</a></p><h2 id="config-server-monngodb"><a href="#config-server-monngodb" class="headerlink" title="config server monngodb"></a>config server monngodb</h2><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependencies</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.springframework.cloud<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spring-cloud-config-server<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">&lt;!-- mongogdb 在 spring cloud config server 的依赖，这个依赖是快照依赖，需要指定 spring 的仓库 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.springframework.cloud<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spring-cloud-config-server-mongodb<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">version</span>&gt;</span>0.0.3.BUILD-SNAPSHOT<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependencies</span>&gt;</span></span><br></pre></td></tr></table></figure><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">server:</span></span><br><span class="line"><span class="attr">  port:</span> <span class="number">9090</span></span><br><span class="line"><span class="attr">spring:</span></span><br><span class="line"><span class="attr">  application:</span></span><br><span class="line"><span class="attr">    name:</span> <span class="string">spring-cloud-customer-repo-mongodb</span></span><br><span class="line"><span class="attr">  data:</span></span><br><span class="line"><span class="attr">    mongodb:</span></span><br><span class="line"><span class="attr">      uri:</span> <span class="attr">mongodb://192.168.67.133/springcloud</span> <span class="comment"># mongo 数据库地址</span></span><br></pre></td></tr></table></figure><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@SpringBootApplication</span></span><br><span class="line"><span class="meta">@EnableMongoConfigServer</span>  <span class="comment">// 一定注意，不能写为 EnableConfigServer，一定要是 MongooConfigServer</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">SpringCloudCustomerRepoMongodbApplication</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        SpringApplication.run(SpringCloudCustomerRepoMongodbApplication.class, args);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="mongo-测试数据"><a href="#mongo-测试数据" class="headerlink" title="mongo 测试数据"></a>mongo 测试数据</h2><p>collection 名称：springcloud</p><p>数据：<br><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line"><span class="attr">"label"</span>: <span class="string">"master"</span>,</span><br><span class="line"><span class="attr">"profile"</span>: <span class="string">"prod"</span>,</span><br><span class="line"><span class="attr">"source"</span>: &#123;</span><br><span class="line"><span class="attr">"com"</span>: &#123;</span><br><span class="line"><span class="attr">"laiyy"</span>: &#123;</span><br><span class="line"><span class="attr">"gitee"</span>: &#123;</span><br><span class="line"><span class="attr">"config"</span>: <span class="string">"I am the mongdb configuration file from dev environment. I will edit."</span></span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><h2 id="config-client"><a href="#config-client" class="headerlink" title="config client"></a>config client</h2><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">spring:</span></span><br><span class="line"><span class="attr">  cloud:</span></span><br><span class="line"><span class="attr">    config:</span></span><br><span class="line"><span class="attr">      label:</span> <span class="string">master</span></span><br><span class="line"><span class="attr">      uri:</span> <span class="attr">http://localhost:9090</span></span><br><span class="line"><span class="attr">      name:</span> <span class="string">springcloud</span> <span class="comment"># 这里指定的是 collection name</span></span><br><span class="line"><span class="attr">      profile:</span> <span class="string">prod</span></span><br></pre></td></tr></table></figure><h2 id="验证-1"><a href="#验证-1" class="headerlink" title="验证"></a>验证</h2><p><strong><em>config client 与之前的一致</em></strong></p><p>访问 <a href="http://localhost:9091/get-config-info" target="_blank" rel="noopener">http://localhost:9091/get-config-info</a> ，返回值为：<br><img src="/images/spring-cloud/config/mongo-result.png" alt="mongo result"></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;除了使用 git 作为配置文件的管理中心外，也可以使用关系型数据库、非关系型数据库实现配置中心，以及配置中心的扩展。包括：客户端自动刷新、客户端回退、安全认证、客户端高可用、服务端高可用等。&lt;/p&gt;
    
    </summary>
    
      <category term="spring-cloud" scheme="https://www.laiyy.top/categories/spring-cloud/"/>
    
    
      <category term="SpringCloud" scheme="https://www.laiyy.top/tags/SpringCloud/"/>
    
      <category term="CloudConfig" scheme="https://www.laiyy.top/tags/CloudConfig/"/>
    
  </entry>
  
</feed>
