<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Spring Cloud 微服务（十三） --- Hystrix]]></title>
    <url>%2Fjava%2F2019%2F01-31%2Fspring-cloud-13.html</url>
    <content type="text"></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>SpringCloud</tag>
        <tag>Hystrix</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring Cloud 微服务（12） --- Ribbon(二) 工作原理]]></title>
    <url>%2Fjava%2F2019%2F01-31%2Fspring-cloud-12.html</url>
    <content type="text"><![CDATA[Ribbon 核心接口 接口 描述 默认实现类 IClientConfig 定义 Ribbon 中管理配置的接口 DefaultClientConfigImpl IRule 定义 Ribbon 中负载均衡策略的接口 RoundRobinRule IPing 定义定期 ping 服务检查可用性的接口 DummyPing ServerList 定义获取服务列表方法的接口 ConfigurationBasedServerList ServerListFilter 定义特定期望获取服务列表方法的接口 ZonePreferenceServerListFilter ILoadBalanacer 定义负载均衡选择服务的核心方法的接口 BaseLoadBalancer ServerListUpdater 为 DynamicServerListLoadBalancer 定义动态更新服务列表的接口 PollingServerListUpdater Ribbon 的运行原理Ribbon 实现负载均衡，基本用法是注入一个 RestTemplate，并在 RestTemplate 上使用 @LoadBalanced，才能使 RestTemplate 具备负载均衡能力。 @LoadBalanced1234567891011/** * Annotation to mark a RestTemplate bean to be configured to use a LoadBalancerClient * @author Spencer Gibb */@Target(&#123; ElementType.FIELD, ElementType.PARAMETER, ElementType.METHOD &#125;)@Retention(RetentionPolicy.RUNTIME)@Documented@Inherited@Qualifierpublic @interface LoadBalanced &#123;&#125; 这个注解标注一个 RestTemplate，使用 LoadBalancerClient，那么 LoadBalancerClient 又是什么？ LoadBalancerClient123456789101112/** * Represents a client side load balancer * @author Spencer Gibb */public interface LoadBalancerClient extends ServiceInstanceChooser &#123; &lt;T&gt; T execute(String serviceId, LoadBalancerRequest&lt;T&gt; request) throws IOException; &lt;T&gt; T execute(String serviceId, ServiceInstance serviceInstance, LoadBalancerRequest&lt;T&gt; request) throws IOException; URI reconstructURI(ServiceInstance instance, URI original);&#125; LoadBalancerClient 又扩展了 ServiceInstanceChooser 接口1234public interface ServiceInstanceChooser &#123; ServiceInstance choose(String serviceId);&#125; 方法解释 ServiceInstance choose(String serviceId)：根据 serviceId，结合负载均衡器，选择一个服务实例 &lt;T&gt; T execute(String serviceId, LoadBalancerRequest&lt;T&gt; request)：使用 LoadBalancer 的 serviceInstance 为置顶的服务执行请求 &lt;T&gt; T execute(String serviceId, ServiceInstance serviceInstance, LoadBalancerRequest&lt;T&gt; request)：使用来自 LoadBalancer 的 ServiceInstance 为指定的服务执行请求，是上一个方法的重载，是上一个方法的细节实现 URI reconstructURI(ServiceInstance instance, URI original)：使用主机 ip、port 构建特定的 URI，供 RIbbon 内部使用。Ribbon 使用服务名称的 URI 作为host。如：http://instance-id/path/to/service LoadBalancer 初始化LoadBalancerAutoConfiguration 是 Ribbon 负载均衡初始化加载类，启动的关键核心代码如下： 1234567891011121314151617181920212223242526272829303132333435@Configuration@ConditionalOnClass(RestTemplate.class)@ConditionalOnBean(LoadBalancerClient.class)@EnableConfigurationProperties(LoadBalancerRetryProperties.class)public class LoadBalancerAutoConfiguration &#123; @Bean @ConditionalOnMissingBean public LoadBalancerRequestFactory loadBalancerRequestFactory( LoadBalancerClient loadBalancerClient) &#123; return new LoadBalancerRequestFactory(loadBalancerClient, transformers); &#125; @Configuration @ConditionalOnMissingClass("org.springframework.retry.support.RetryTemplate") static class LoadBalancerInterceptorConfig &#123; @Bean public LoadBalancerInterceptor ribbonInterceptor( LoadBalancerClient loadBalancerClient, LoadBalancerRequestFactory requestFactory) &#123; return new LoadBalancerInterceptor(loadBalancerClient, requestFactory); &#125; @Bean @ConditionalOnMissingBean public RestTemplateCustomizer restTemplateCustomizer( final LoadBalancerInterceptor loadBalancerInterceptor) &#123; return restTemplate -&gt; &#123; List&lt;ClientHttpRequestInterceptor&gt; list = new ArrayList&lt;&gt;( restTemplate.getInterceptors()); list.add(loadBalancerInterceptor); restTemplate.setInterceptors(list); &#125;; &#125; &#125;&#125; 可以看到，在类注解上，@ConditionalOnClass(RestTemplate.class)、@ConditionalOnBean(LoadBalancerClient.class)，必须在当前工程下有 RestTemplate 的实例、必须已经初始化了 LoadBalancerClient 的实现类，才会加载 LoadBalancer 的自动装配。 其中 LoadBalancerRequestFactory 用于创建 LoadBalancerRequest，以供 LoadBalancerInterceptor 使用(在低版本没有)，LoadBalancerInterceptorConfig 中维护了 LoadBalancerInterceptor、RestTemplateCustomizer 的实例。 LoadBalancerInterceptor：拦截每一次 HTTP 请求，将请求绑定进 Ribbon 负载均衡的生命周期 RestTemplateCustomizer：为每个 RestTemplate 绑定 LoadBalancerInterceptor 拦截器 LoadBalancerInterceptor123456789101112131415161718192021222324public class LoadBalancerInterceptor implements ClientHttpRequestInterceptor &#123; private LoadBalancerClient loadBalancer; private LoadBalancerRequestFactory requestFactory; public LoadBalancerInterceptor(LoadBalancerClient loadBalancer, LoadBalancerRequestFactory requestFactory) &#123; this.loadBalancer = loadBalancer; this.requestFactory = requestFactory; &#125; public LoadBalancerInterceptor(LoadBalancerClient loadBalancer) &#123; // for backwards compatibility this(loadBalancer, new LoadBalancerRequestFactory(loadBalancer)); &#125; @Override public ClientHttpResponse intercept(final HttpRequest request, final byte[] body, final ClientHttpRequestExecution execution) throws IOException &#123; final URI originalUri = request.getURI(); String serviceName = originalUri.getHost(); Assert.state(serviceName != null, "Request URI does not contain a valid hostname: " + originalUri); return this.loadBalancer.execute(serviceName, requestFactory.createRequest(request, body, execution)); &#125;&#125; LoadBalancerInterceptor 利用 ClientHttpRequestInterceptor 对每次 HTTP 请求进行拦截，这个类是 Spring 中维护的请求拦截器。可以看到，拦截的请求使用了 LoadBalancerClient 的 execute 方法处理请求(由于 RestTemplate 中使用服务名当做 host，所以此时 getHosts() 获取到的服务名)，LoadBalancerClient 只有一个实现类：RibbonLoadBalancerClient，具体是 execute 方法如下： 123456789101112@Overridepublic &lt;T&gt; T execute(String serviceId, LoadBalancerRequest&lt;T&gt; request) throws IOException &#123; ILoadBalancer loadBalancer = getLoadBalancer(serviceId); Server server = getServer(loadBalancer); if (server == null) &#123; throw new IllegalStateException("No instances available for " + serviceId); &#125; RibbonServer ribbonServer = new RibbonServer(serviceId, server, isSecure(server, serviceId), serverIntrospector(serviceId).getMetadata(server)); return execute(serviceId, ribbonServer, request);&#125; 可以看到，源码中首先获取一个 LoadBalancer，再去获取一个 Server，那么，这个 Server 就是具体服务实例的封装了。既然 Server 是一个具体的服务实例，那么， getServer(loadBalancer) 就是发生负载均衡的地方。 123456protected Server getServer(ILoadBalancer loadBalancer) &#123; if (loadBalancer == null) &#123; return null; &#125; return loadBalancer.chooseServer("default"); // TODO: better handling of key&#125; 查看 chooseServer 方法具体实现（BaseLoadBalancer）：12345678910111213141516public Server chooseServer(Object key) &#123; if (counter == null) &#123; counter = createCounter(); &#125; counter.increment(); if (rule == null) &#123; return null; &#125; else &#123; try &#123; return rule.choose(key); &#125; catch (Exception e) &#123; logger.warn("LoadBalancer [&#123;&#125;]: Error choosing server for key &#123;&#125;", name, key, e); return null; &#125; &#125;&#125; rule.choose(key) 的中的 rule，就是 IRule，而 IRule 就是 Ribbon 的负载均衡策略。由此可以证明，HTTP 请求域负载均衡策略关联起来了。 IRuleIRule 源码：123456789101112131415public interface IRule&#123; /* * choose one alive server from lb.allServers or * lb.upServers according to key * * @return choosen Server object. NULL is returned if none * server is available */ public Server choose(Object key); public void setLoadBalancer(ILoadBalancer lb); public ILoadBalancer getLoadBalancer(); &#125; IRule 中一共定义了 3 个方法，实现类实现 choose 方法，会加入具体的负载均衡策略逻辑，另外两个方法与 ILoadBalancer 关联起来。在调用过程中，Ribbon 通过 ILoadBalancer 关联 IRule，ILoadBalancer 的 chooseServer 方法会转为为调用 IRRule 的 choose 方法，抽象类 AbstractLoadBalancerRule 实现了这两个方法，从而将 ILoadBalancer 与 IRule 关联起来。]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>SpringCloud</tag>
        <tag>Ribbon</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring Cloud 微服务（11） --- Ribbon(一) 负载均衡与 Ribbon]]></title>
    <url>%2Fjava%2F2019%2F01-25%2Fspring-cloud-11.html</url>
    <content type="text"><![CDATA[通常所说的负载均衡，一般来说都是在服务器端使用 Ngnix 或 F5 做 Server 的负载均衡策略，在 Ribbon 中提到的负载均衡，一般来说是指的客户端负载均衡，即 ServiceA 调用 ServiceB，有多个 ServiceB 的情况下，由 ServiceA 选择调用哪个 ServiceB。 负载均衡与 Ribbon负载均衡(Load Balance)，是一种利用特定方式，将流量分摊到多个操作单元上的手段，它对系统吞吐量、系统处理能力有着质的提升。最常见的负载均衡分类方式有：软负载、硬负载，对应 Ngnix、F5；集中式负载均衡、进程内负载均衡。集中式负载均衡是指位于网络和服务提供者之间，并负责把忘了请求转发到各个提供单位，代表产品有 Ngnix、F5；进程负载均衡是指从一个实例库选取一个实例进行流量导入，在微服务范畴，实例库一般是存储在 Eureka、Consul、Zookeeper 等注册中心，此时的负载均衡器类似 Ribbon 的 IPC（进程间通信）组件，因此进程内负载均衡也叫做客户端负载均衡。 Ribbon 是一个客户端负载均衡器，赋予了应用一些支配 HTTP 与 TCP 行为的能力，由此可以得知，这里的客户端负载均衡也是进程内负载均衡的一周。 Ribbon 在 SpringCloud 生态内的不可缺少的组件，没有了 Ribbon，服务就不能横向扩展。Feign、Zuul 已经集成了 Ribbon。 示例Eureka Server 不再赘述，可以直接使用 spring-cloud-eureka-server-simple。 Consumeryml：1234567891011121314spring: application: name: spring-cloud-ribbon-consumerserver: port: 9999eureka: client: service-url: defaultZone: http://localhost:8761/eureka instance: prefer-ip-address: true instance-id: $&#123;spring.application.name&#125;:$&#123;server.port&#125; 配置类：12345@Bean@LoadBalancedpublic RestTemplate restTemplate()&#123; return new RestTemplate();&#125; @LoadBalanced：对 RestTemplate 启动负载均衡 Consumer Controller12345678910111213141516@RestControllerpublic class ConsumerController &#123; private final RestTemplate restTemplate; @Autowired public ConsumerController(RestTemplate restTemplate) &#123; this.restTemplate = restTemplate; &#125; @GetMapping(value = "/check") public String checkRibbonProvider()&#123; return restTemplate.getForObject("http://spring-cloud-ribbon-provider/check", String.class); &#125;&#125; providerpom 依赖：1234567891011&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-ribbon&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 配置文件：1234567891011spring: application: name: spring-cloud-ribbon-providereureka: client: service-url: defaultZone: http://localhost:8761/eureka instance: prefer-ip-address: true instance-id: $&#123;spring.application.name&#125;:$&#123;server.port&#125; ProviderContr1234567891011@RestControllerpublic class ProviderController &#123; @Value("$&#123;server.port&#125;") private int port; @GetMapping(value = "/check") public String providerPort()&#123; return "Provider Port: " + port; &#125;&#125; 验证分别启动 Eureka Server、Consumer、Provider，其中，Provider 以 mvn 形式启动，绑定不同的端口号：12mvn spring-boot:run -Dserver.port=8080mvn spring-boot:run -Dserver.port=8081 postman 访问 Consumer 可以看到，Provider 两次返回值不一样，验证了负载均衡成功。 负载均衡策略Ribbon 中提供了 七种 负载均衡策略 策略类 命名 描述 RandomRule 随机策略 随机选择 Server RoundRobinRule 轮询策略 按照顺序循环选择 Server RetryRule 重试策略 在一个配置时间段内，当选择的 Server 不成功，则一直尝试选择一个可用的 Server BestAvailableRule 最低并发策略 逐个考察 Server，如果 Server 的断路器被打开，则忽略，在不被忽略的 Server 中选择并发连接最低的 Server AvailabilityFilteringRule 可用过滤测试 过滤掉一直连接失败，并被标记未 circuit tripped（即不可用） 的 Server，过滤掉高并发的 Server ResponseTimeWeightedRule 响应时间加权策略 根据 Server 的响应时间分配权重，响应时间越长，权重越低，被选择到的几率就越低 ZoneAvoidanceRule 区域权衡策略 综合判断 Server 所在区域的性能和 Server 的可用性轮询选择 Server，并判定一个 AWS Zone 的运行性能是否可用，剔除不可用的 Zone 中的所有 Server Ribbon 默认的负载均衡策略是 轮询策略。 设置负载均衡策略设置全局负载均衡创建一个声明式配置，即可实现全局负载均衡配置： 1234567891011@Configurationpublic class RibbonConfig &#123; /** * 全局负载均衡配置：随机策略 */ @Bean public IRule ribbonRule()&#123; return new RandomRule(); &#125;&#125; 重启 Consumer，访问测试 基于注解的配置空注解声明一个空注解，用于使用注解配置 Ribbon 负载均衡 12public @interface RibbonAnnotation &#123;&#125; 负载均衡配置类12345678910111213141516@Configuration@RibbonAnnotationpublic class RibbonAnnoConfig &#123; private final IClientConfig clientConfig; @Autowired(required = false) public RibbonAnnoConfig(IClientConfig clientConfig) &#123; this.clientConfig = clientConfig; &#125; @Bean public IRule ribbonRule(IClientConfig clientConfig)&#123; return new RandomRule(); &#125;&#125; 启动类123456789101112131415161718@SpringBootApplication@EnableDiscoveryClient@RibbonClient(name = "spring-cloud-ribbon-provider", configuration = RibbonAnnoConfig.class)@ComponentScan(excludeFilters = &#123;@ComponentScan.Filter(type = FilterType.ANNOTATION, value = RibbonAnnotation.class)&#125;)public class SpringCloudRibbonConsumerApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(SpringCloudRibbonConsumerApplication.class, args); &#125; @Bean @LoadBalanced public RestTemplate restTemplate()&#123; return new RestTemplate(); &#125;&#125; @RibbonClient：针对 spring-cloud-ribbon-provider 服务，使用负载均衡，配置类是 configuration 标注的类。@ComponentScan：让 Spring 不去扫描被 @RibbonAnnotation 类标记的配置类，因为我们的配置对单个服务生效，不能应用于全局，如果不排除，启动就会报错 如果需要对多个服务进行配置，可以使用 @RibbonClients 注解123@RibbonClients(value = &#123; @RibbonClient(name = "spring-cloud-ribbon-provider", configuration = RibbonAnnoConfig.class) &#125;) 重启 Consumer，验证基于注解的负载均衡是否成功 基于配置文件的负载均衡策略语法：123&#123;instance-id&#125;: # instance-id 即被调用服务名称 ribbon: NFLoadBalancerRuleClassName: com.netflix.loadbalancer.RandomRule Ribbon 配置超时与重试HTTP 请求难免会出现请求超时，此时对调用进行时限的控制以及在时限之后的重试尤为重要。对于超时重试的配置如下：1234567&#123;instance-id&#125;: # instance-id 指的是被调用者的服务名称 ribbon: ConnectTimeout: 30000 # 链接超时时间 ReadTimeout: 30000 # 读超时时间 MaxAutoRetries: 1 # 对第一次请求的服务的重试次数 MaxAutoRetriesNextServer: 1 # 要重试的下一个服务的最大数量（不包括第一个服务） OkToRetryOnAllOperations: true # 是否对 连接超时、读超时、写超时 都进行重试 Ribbon 饥饿加载Ribbon 在进行负载均衡时，并不是启动时就加载上线文，而是在实际的请求发送时，才去请求上下文信息，获取被调用者的 ip、端口，这种方式在网络环境较差时，往往会使得第一次引起超时，导致调用失败。此时需要指定 Ribbon 客户端，进行饥饿加载，即：在启动时就加载好上下文。 1234ribbon: eager-load: enabled: true clients: spring-cloid-ribbon-provider 此时启动 consumer，会看到控制打印信息如下：123Client: spring-cloid-ribbon-provider instantiated a LoadBalancer: DynamicServerListLoadBalancer:&#123;NFLoadBalancer:name=spring-cloid-ribbon-provider,current list of Servers=[],Load balancer stats=Zone stats: &#123;&#125;,Server stats: []&#125;ServerList:nullUsing serverListUpdater PollingServerListUpdaterDynamicServerListLoadBalancer for client spring-cloid-ribbon-provider initialized: DynamicServerListLoadBalancer:&#123;NFLoadBalancer:name=spring-cloid-ribbon-provider,current list of Servers=[],Load balancer stats=Zone stats: &#123;&#125;,Server stats: []&#125;ServerList:org.springframework.cloud.netflix.ribbon.eureka.DomainExtractingServerList@79e7188e 可以看到启动时就加载了 spring-cloid-ribbon-provider，并绑定了LoadBalancer Ribbon 常用配置 配置项 说明 {instance-id}:ribbon.NFLoadBalancerClassName 指负载均衡器类路径 {instance-id}:ribbon:NFLoadBalancerRuleClassName 指定负载均衡算法类路径 {instance-id}:ribbom:NFLoadBalancerPingClassName 指定检测服务存活的类路径 {instance-id}:ribbon:NIWSServerListClassName 指定获取服务列表的实现类路径 {instance-id}:ribbon:NIWSServerListFilterClassName 指定服务的 Filter 实现类路径 Ribbon 脱离 Eureka默认情况下，Ribbon 客户端会从 Eureka Server 读取服务注册信息列表，达到动态负载均衡的功能。如果 Eureka 是一个提供多人使用的公共注册中心(如 SpringCloud 中文社区公益 Eureka：http://eureka.springcloud.cn)，此时极易产生服务侵入问题，此时就不能从 Eureka 中读取服务列表，而应该在 Ribbon 客户端自行制定源服务地址 1234567ribbon: eureka: enabled: false # Ribbon 脱离 Eureka 使用&#123;instance-id&#125;: ribbon: listOfServers: http://localhost:8888 # 制定源服务地址]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>SpringCloud</tag>
        <tag>Ribbon</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring Cloud 微服务 （10） --- Feign(四) 文件上传、首次调用失败问题]]></title>
    <url>%2Fjava%2F2019%2F01-24%2Fspring-cloud-10.html</url>
    <content type="text"><![CDATA[Feign 在远程调用时，除了 GET 方式传递 POJO 外，还有几个很重要的功能：文件上传、调用返回图片流、传递 Token 等 文件上传Feign 的子项目 feign-form(https://github.com/OpenFeign/feign-form) 支持文件上传，其中实现了上传所需要的 Encoder 模拟文件上传：spring-cloud-feign-file-server、spring-cloud-feign-file-client，其中 server 模拟文件服务器，作为服务提供者；client 模拟文件上传，通过 FeignClient 发送文件到文件服务器 FileClientpom 依赖1234567891011121314151617181920212223&lt;!-- eureka client --&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt;&lt;/dependency&gt;&lt;!-- feign --&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-openfeign&lt;/artifactId&gt;&lt;/dependency&gt;&lt;!-- Feign文件上传依赖--&gt;&lt;dependency&gt; &lt;groupId&gt;io.github.openfeign.form&lt;/groupId&gt; &lt;artifactId&gt;feign-form&lt;/artifactId&gt; &lt;version&gt;3.0.3&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;io.github.openfeign.form&lt;/groupId&gt; &lt;artifactId&gt;feign-form-spring&lt;/artifactId&gt; &lt;version&gt;3.0.3&lt;/version&gt;&lt;/dependency&gt; 配置文件12345678910111213spring: application: name: spring-cloud-feign-file-clienteureka: client: service-url: defaultZone: http://localhost:8761/eureka/ instance: instance-id: $&#123;spring.application.name&#125;:$&#123;server.port&#125; prefer-ip-address: trueserver: port: 8888 启动类、FeignClient、配置、Controller1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162// 启动类@SpringBootApplication@EnableDiscoveryClient@EnableFeignClientspublic class SpringCloudFeignFileClientApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(SpringCloudFeignFileClientApplication.class, args); &#125;&#125;// FeignClient@FeignClient(value = "spring-cloud-feign-file-server", configuration = FeignMultipartConfiguration.class)public interface FileUploadFeignClient &#123; /** * feign 上传图片 * * produces、consumes 必填 * 不要将 @RequestPart 写成 @RequestParam * * @param file 上传的文件 * @return 上传的文件名 */ @RequestMapping(value = "/upload-file", method = RequestMethod.POST, produces = MediaType.APPLICATION_JSON_UTF8_VALUE, consumes = MediaType.MULTIPART_FORM_DATA_VALUE) String fileUpload(@RequestPart(value = "file")MultipartFile file);&#125;// configuration@Configurationpublic class FeignMultipartConfiguration &#123; /** * Feign Spring 表单编码器 * @return 表单编码器 */ @Bean @Primary @Scope("prototype") public Encoder multipartEncoder()&#123; return new SpringFormEncoder(); &#125;&#125;// Controller@RestControllerpublic class FileUploadController &#123; private final FileUploadFeignClient feignClient; @Autowired public FileUploadController(FileUploadFeignClient feignClient) &#123; this.feignClient = feignClient; &#125; @PostMapping(value = "upload") public String upload(MultipartFile file)&#123; return feignClient.fileUpload(file); &#125;&#125; FileServerpom1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt;&lt;/dependency&gt; 配置文件1234567891011121314spring: application: name: spring-cloud-feign-file-servereureka: instance: prefer-ip-address: true instance-id: $&#123;spring.application.name&#125;:$&#123;server.port&#125; client: service-url: defaultZone: http://localhost:8761/eureka/server: port: 8889 启动类、Controller1234567891011121314151617181920@SpringBootApplication@EnableDiscoveryClientpublic class SpringCloudFeignFileServerApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(SpringCloudFeignFileServerApplication.class, args); &#125;&#125;// Controller 模拟文件上传的处理@RestControllerpublic class FileUploadController &#123; @PostMapping(value = "/upload-file") public String fileUpload(MultipartFile file) &#123; return file.getOriginalFilename(); &#125;&#125; 验证文件上传POST MAN 调用 client 上传接口 图片流通过 Feign 返回图片，一般是字节数组 在文件上传代码的基础上，再加上图片获取 FeignClient123456789101112/** * 获取图片 * @return 图片 */@RequestMapping(value = "/get-img")ResponseEntity&lt;byte[]&gt; getImage();@GetMapping(value = "/get-img")public ResponseEntity&lt;byte[]&gt; getImage()&#123; return feignClient.getImage();&#125; FeignServer12345678@GetMapping(value = "/get-img")public ResponseEntity&lt;byte[]&gt; getImages() throws IOException &#123; FileSystemResource resource = new FileSystemResource(getClass().getResource("/").getPath() + "Spring-Cloud.png"); HttpHeaders headers = new HttpHeaders(); headers.add("Content-Type", MediaType.APPLICATION_OCTET_STREAM_VALUE); headers.add("Content-Disposition", "attachment; filename=Spring-Cloud.png"); return ResponseEntity.status(HttpStatus.OK).headers(headers).body(FileCopyUtils.copyToByteArray(resource.getInputStream()));&#125; 验证在浏览器访问：http://localhost:8888/get-img ，实现图片流下载 Feign 传递 Headers在认证、鉴权中，无论是哪种权限控制框架，都需要传递 header，但在使用 Feign 的时候，会发现外部请求 ServiceA 时，可以获取到 header，但是在 ServiceA 调用 ServiceB 时，ServiceB 无法获取到 Header，导致 Header 丢失。 在 spring-cloud-feign-multi-params 基础上，实现传递 Header。 验证 Header 无法传递问题 consumer 打印 header provider 打印 header HeaderInterceptor在 Consumer 增加 HeaderInterceptor，做 header 传递 12345678910111213141516171819202122232425262728293031@Componentpublic class FeignHeaderInterceptor implements RequestInterceptor &#123; @Override public void apply(RequestTemplate template) &#123; if (null == getRequest())&#123; return; &#125; template.header("oauth-token", getHeaders(getRequest()).get("oauth-token")); &#125; private HttpServletRequest getRequest()&#123; try &#123; return ((ServletRequestAttributes) RequestContextHolder.currentRequestAttributes()).getRequest(); &#125;catch (Exception e)&#123; return null; &#125; &#125; private Map&lt;String, String&gt; getHeaders(HttpServletRequest request) &#123; Map&lt;String, String&gt; headers = new HashMap&lt;&gt;(); Enumeration&lt;String&gt; headerNames = request.getHeaderNames(); while (headerNames.hasMoreElements()) &#123; String key = headerNames.nextElement(); String value = request.getHeader(key); headers.put(key, value); &#125; return headers; &#125;&#125; 验证 header用 postman 重新请求一遍，查看 provider 控制台打印：]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>SpringCloud</tag>
        <tag>Feign</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring Cloud 微服务（9） --- Feign(三) http client 替换、GET 方式传递 POJO等]]></title>
    <url>%2Fjava%2F2019%2F01-23%2Fspring-cloud-9.html</url>
    <content type="text"><![CDATA[在了解了 FeignClient 的配置、请求响应的压缩后，基本的调用已经没有问题。接下来就需要了解 Feign 多参数传递、文件上传、header 传递 token、请求失败、图片流 等问题的解决，以及 HTTP Client 替换的问题。 Http Client 替换Feign 默认情况下使用的是 JDK 原生的 URLConnection 发送 HTTP 请求，没有连接池，但是对每个地址都会保持一个长连接。可以利用 Apache HTTP Client 替换原始的 URLConnection，通过设置连接池、超时时间等，对服务调用进行调优。 在类 feign/Client$Default.java 中，可以看到，默认执行 http 请求的是 URLConnection12345678public static class Default implements Client &#123; @Override public Response execute(Request request, Options options) throws IOException &#123; HttpURLConnection connection = convertAndSend(request, options); return convertResponse(connection).toBuilder().request(request).build(); &#125;&#125; 在类 org/springframework/cloud/openfeign/ribbon/FeignRibbonClientAutoConfiguration.java 中，可以看到引入了三个类：HttpClientFeignLoadBalancedConfiguration、OkHttpFeignLoadBalancedConfiguration、DefaultFeignLoadBalancedConfiguration 可以看到在 DefaultFeignLoadBalancedConfiguration 中，使用的是 Client.Default，即使用 URLConnection 使用 Apache Http Client 替换 URLConnectionpom 依赖123456789101112&lt;!-- 引入 httpclient --&gt;&lt;dependency&gt; &lt;groupId&gt;org.apache.httpcomponents&lt;/groupId&gt; &lt;artifactId&gt;httpclient&lt;/artifactId&gt;&lt;/dependency&gt;&lt;!-- 引入 feign 对 httpclient 的支持 --&gt;&lt;dependency&gt; &lt;groupId&gt;com.netflix.feign&lt;/groupId&gt; &lt;artifactId&gt;feign-httpclient&lt;/artifactId&gt; &lt;version&gt;8.18.0&lt;/version&gt;&lt;/dependency&gt; 配置文件123feign: httpclient: enabled: true 查看验证配置在类 HttpClientFeignLoadBalancedConfiguration 上，有注解：@ConditionalOnClass(ApacheHttpClient.class)、@ConditionalOnProperty(value = &quot;feign.httpclient.enabled&quot;, matchIfMissing = true)：在 ApacheHttpClient 类存在且 feign.httpclient.enabled 为 true 时启用配置。 在 HttpClientFeignLoadBalancedConfiguration 123 行打上断点，重新启动项目，可以看到确实进行了 ApacheHttpClient 的声明。在将 feign.httpclient.enabled 设置为 false 后，断点就进不来了。由此可以验证 ApacheHttpClient 替换成功。 使用 OkHttp 替换 URLConnectionpom 依赖12345&lt;dependency&gt; &lt;groupId&gt;io.github.openfeign&lt;/groupId&gt; &lt;artifactId&gt;feign-okhttp&lt;/artifactId&gt; &lt;version&gt;10.1.0&lt;/version&gt;&lt;/dependency&gt; 配置文件12345feign: httpclient: enabled: false okhttp: enabled: true 验证配置在 OkHttpFeignLoadBalancedConfiguration 第 84 行打断点，重新启动项目，可以看到成功进入断点；当把 feign.okhttp.enabled 设置为 false 后，重新启动项目，没进入断点。证明 OkHttp 替换成功。 GET 方式传递 POJO等SpringMVC 是支持 GET 方法直接绑定 POJI 的，但是 Feign 的实现并未覆盖所有 SpringMVC 的功能，常用的解决方式： 把 POJO 拆散成一个一个单独的属性放在方法参数里 把方法参数变成 Map 传递 使用 GET 传递 @RequestBody，这种方式有违 RESTFul。 实现 Feign 的 RequestInterceptor 中的 apply 方法，统一拦截转换处理 Feign 中 GET 方法传递 POJO 问题。而 Feign 进行 POST 多参数传递要比 Get 简单。 providerprovider 用于模拟用户查询、修改操作，作为服务生产者 pom 依赖：123456789 &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt;&lt;/dependency&gt; 配置文件：1234567891011eureka: client: service-url: defaultZone: http://localhost:8761/eureka/ instance: instance-id: $&#123;spring.application.name&#125;:$&#123;server.port&#125;spring: application: name: spring-cloud-feign-multi-params-providerserver: port: 8888 实体、启动类、Controller1234567891011121314151617181920212223242526272829303132333435363738394041// 实体@Data@NoArgsConstructor@AllArgsConstructorpublic class User &#123; private int id; private String name;&#125;// 启动类@SpringBootApplication@EnableDiscoveryClientpublic class SpringCloudFeignMultiParamsProviderApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(SpringCloudFeignMultiParamsProviderApplication.class, args); &#125;&#125;// Controller@RestController@RequestMapping(value = "/user")public class UserController &#123; @GetMapping(value = "/add") public String addUser(User user)&#123; return "hello!" + user.getName(); &#125; @PostMapping(value = "/update") public String updateUser(@RequestBody User user)&#123; return "hello! modifying " + user.getName(); &#125;&#125; consumerconsumer 用于模拟服务调用，属于服务消费者，调用 provider 的具体实现 pom 依赖：1234567891011121314&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-openfeign&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt;&lt;/dependency&gt; 配置文件：1234567891011121314151617181920eureka: client: service-url: defaultZone: http://localhost:8761/eureka/ instance: instance-id: $&#123;spring.application.name&#125;:$&#123;server.port&#125;spring: application: name: spring-cloud-feign-multi-params-consumerserver: port: 8889feign: client: config: spring-cloud-feign-multi-params-provider: loggerLevel: fulllogging: level: com.laiyy.gitee.feign.multi.params.springcloudfeignmultiparamscomsumer.MultiParamsProviderFeignClient: debug 实体、启动类、Controller、FeignClient1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859// 实体与 provider 一致，不再赘述// 启动类@SpringBootApplication@EnableDiscoveryClient@EnableFeignClientspublic class SpringCloudFeignMultiParamsComsumerApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(SpringCloudFeignMultiParamsComsumerApplication.class, args); &#125;&#125;// Controller@RestControllerpublic class UserController &#123; private final MultiParamsProviderFeignClient feignClient; @Autowired public UserController(MultiParamsProviderFeignClient feignClient) &#123; this.feignClient = feignClient; &#125; @GetMapping(value = "add-user") public String addUser(User user)&#123; return feignClient.addUser(user); &#125; @PostMapping(value = "update-user") public String updateUser(@RequestBody User user)&#123; return feignClient.updateUser(user); &#125;&#125;// FeignClient@FeignClient(name = "spring-cloud-feign-multi-params-provider")public interface MultiParamsProviderFeignClient &#123; /** * GET 方式 * @param user user * @return 添加结果 */ @RequestMapping(value = "/user/add", method = RequestMethod.GET) String addUser(User user); /** * POST 方式 * @param user user * @return 修改结果 */ @RequestMapping(value = "/user/update", method = RequestMethod.POST) String updateUser(@RequestBody User user);&#125; 验证调用使用 POST MAN 测试工具，调用 consumer 接口，利用 Feign 进行远程调用 调用 update-user，验证调用成功 调用 add-user，验证调用失败 控制台报错：12345678&#123;&quot;timestamp&quot;:&quot;2019-01-24T08:24:42.887+0000&quot;,&quot;status&quot;:405,&quot;error&quot;:&quot;Method Not Allowed&quot;,&quot;message&quot;:&quot;Request method &apos;POST&apos; not supported&quot;,&quot;path&quot;:&quot;/user/add&quot;&#125;] with root causefeign.FeignException: status 405 reading MultiParamsProviderFeignClient#addUser(User); content:&#123;&quot;timestamp&quot;:&quot;2019-01-24T08:24:42.887+0000&quot;,&quot;status&quot;:405,&quot;error&quot;:&quot;Method Not Allowed&quot;,&quot;message&quot;:&quot;Request method &apos;POST&apos; not supported&quot;,&quot;path&quot;:&quot;/user/add&quot;&#125; at feign.FeignException.errorStatus(FeignException.java:62) ~[feign-core-9.5.1.jar:na] at feign.codec.ErrorDecoder$Default.decode(ErrorDecoder.java:91) ~[feign-core-9.5.1.jar:na] at feign.SynchronousMethodHandler.executeAndDecode(SynchronousMethodHandler.java:138) ~[feign-core-9.5.1.jar:na] ... 命名是 GET 调用，为什么到底层就变成了 POST 调用？ GET 传递 POJO 解决方案Feign 的远程调用中，GET 是不能传递 POJO 的，否则就是 POST，为了解决这个错误，可以实现 RequestInterceptor，解析 POJO，传递 Map 即可解决 在 consumer 中，增加一个实体类，用于解析 POJO 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566/** * @author laiyy * @date 2019/1/24 10:33 * @description 实现 Feign Request 拦截器，实现 GET 传递 POJO */@Componentpublic class FeignRequestInterceptor implements RequestInterceptor &#123; private final ObjectMapper objectMapper; @Autowired public FeignRequestInterceptor(ObjectMapper objectMapper) &#123; this.objectMapper = objectMapper; &#125; @Override public void apply(RequestTemplate template) &#123; if ("GET".equals(template.method()) &amp;&amp; template.body() != null) &#123; try &#123; JsonNode jsonNode = objectMapper.readTree(template.body()); template.body(null); Map&lt;String, Collection&lt;String&gt;&gt; queries = new HashMap&lt;&gt;(); // 构建 Map buildQuery(jsonNode, "", queries); // queries 就是 POJO 解析为 Map 后的数据 template.queries(queries); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; &#125; private void buildQuery(JsonNode jsonNode, String path, Map&lt;String, Collection&lt;String&gt;&gt; queries) &#123; if (!jsonNode.isContainerNode()) &#123; // 如果是叶子节点 if (jsonNode.isNull()) &#123; return; &#125; Collection&lt;String&gt; values = queries.get(path); if (CollectionUtils.isEmpty(values)) &#123; values = new ArrayList&lt;&gt;(); queries.put(path, values); &#125; values.add(jsonNode.asText()); return; &#125; if (jsonNode.isArray())&#123; // 如果是数组节点 Iterator&lt;JsonNode&gt; elements = jsonNode.elements(); while (elements.hasNext()) &#123; buildQuery(elements.next(), path, queries); &#125; &#125; else &#123; Iterator&lt;Map.Entry&lt;String, JsonNode&gt;&gt; fields = jsonNode.fields(); while (fields.hasNext()) &#123; Map.Entry&lt;String, JsonNode&gt; entry = fields.next(); if (StringUtils.hasText(path)) &#123; buildQuery(entry.getValue(), path + "." + entry.getKey(), queries); &#125; else &#123; // 根节点 buildQuery(entry.getValue(), entry.getKey(), queries); &#125; &#125; &#125; &#125;&#125; 重新启动 consumer，再次调用 add-user，验证结果： 由此验证，GET 方式传递 POJO 成功。]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>SpringCloud</tag>
        <tag>Feign</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring Cloud 微服务（8） --- Feign(二) GZIP、配置]]></title>
    <url>%2Fjava%2F2019%2F01-23%2Fspring-cloud-8.html</url>
    <content type="text"><![CDATA[在理解了 Feign 的运行原理之后，可以很轻松的搭建起一个基于 Feign 的微服务调用。 Feign 是通过 http 调用的，那么就牵扯到一个数据大小的问题。如果不经过压缩就发送请求、获取响应，那么会因为流量过大导致浪费流量，这时就需要使用数据压缩，将大流量压缩成小流量。 Feign GZIP 压缩Spring Cloud Feign 支持对请求和响应进行 GZIP 压缩，以调高通信效率。 开启 gzip 压缩application.yml 12345678910111213feign: compression: request: enabled: true mime-type: text/html,application/xml,application/json min-request-size: 2048 response: enabled: true# 开启日志logging: level: com.laiyy.gitee.feign.springcloudfeigngzip.feign.GiteeFeignClient: debug 由于使用 gzip 压缩，压缩后的数据是二进制，那么在获取 Response 的时候，就不能和之前一样直接使用 String 来接收了，需要使用 ResponseEntity&lt;byte[]&gt; 接收 1234567@FeignClient(name = "gitee-client", url = "https://www.gitee.com/", configuration = GiteeFeignConfiguration.class)public interface GiteeFeignClient &#123; @RequestMapping(value = "/search", method = RequestMethod.GET) ResponseEntity&lt;byte[]&gt; searchRepo(@RequestParam("q") String query);&#125; 对应的 Controller 也需要改为 ResponseEntity&lt;byte[]&gt;1234@GetMapping(value = "feign-gitee")public ResponseEntity&lt;byte[]&gt; feign(String query)&#123; return giteeFeignClient.searchRepo(query);&#125; 验证 gzip 压缩开启 FeignClient 日志 没有使用 GZIP 压缩在 spring-cloud-feign-simple 项目中，开启日志： 123logging: level: com.laiyy.gitee.feign.springcloudfeignsimple.feign.GiteeFeignClient: debug 访问：http://localhost:8080/feign-gitee?query=spring-cloud-openfeign ，可以看到，在控制台中打印了日志信息： 使用了 GZIP 压缩在 spring-cloud-feign-gzip 中开启日志：123logging: level: com.laiyy.gitee.feign.springcloudfeigngzip.feign.GiteeFeignClient: debug 访问：http://localhost:8080/feign-gitee?query=spring-cloud-openfeign ，可以看到，在控制台中打印了日志信息： 对比Request 对比经过对比，可以看到在没有开启 gzip 之前，request 是：12---&gt; GET https://www.gitee.com/search?q=spring-cloud-openfeign HTTP/1.1---&gt; END HTTP (0-byte body) 开启 gzip 之后，request 是：1234---&gt; GET https://www.gitee.com/search?q=spring-cloud-openfeign HTTP/1.1Accept-Encoding: gzipAccept-Encoding: deflate---&gt; END HTTP (0-byte body) 可以看到，request 中增加了 Accept-Encoding: gzip，证明 request 开启了 gzip 压缩。 Response 对比在没有开启 gzip 之前，response 是：12345678910111213141516171819202122232425262728293031cache-control: no-cacheconnection: keep-alivecontent-type: text/html; charset=utf-8date: Wed, 23 Jan 2019 07:22:45 GMTexpires: Sun, 1 Jan 2000 01:00:00 GMTpragma: must-revalidate, no-cache, privateserver: nginxset-cookie: gitee-session-n=BAh7CEkiD3Nlc3Npb25faWQGOgZFVEkiJTIyM2VlNjhkMWVmZGJlMWY5YmIxN2M5MGVlODEzY2Q5BjsAVEkiF21vYnlsZXR0ZV9vdmVycmlkZQY7AEY6CG5pbEkiEF9jc3JmX3Rva2VuBjsARkkiMTlsSDZmQk1CWXpWWVFTSTFtbkwzb0VJTjZjbVdVKzhYZjE0ako0djIvRUk9BjsARg%3D%3D--97ef4dc9c69d79b8f6ca42b9d0b6eaeb121d8048; domain=.gitee.com; path=/; HttpOnlyset-cookie: oschina_new_user=false; path=/; expires=Sun, 23-Jan-2039 07:22:44 GMTset-cookie: user_locale=; path=/; expires=Sun, 23-Jan-2039 07:22:44 GMTset-cookie: aliyungf_tc=AQAAAAq0GH/W3wsAygAc2kkmdVRPGWZs; Path=/; HttpOnlystatus: 200 OKtransfer-encoding: chunkedx-rack-cache: missx-request-id: 437df6eccbd8a2b93912a7b84644b33dx-runtime: 0.646640x-ua-compatible: IE=Edge,chrome=1x-xss-protection: 1; mode=block&lt;!DOCTYPE html&gt;&lt;html lang=&apos;zh-CN&apos;&gt;&lt;head&gt;&lt;title&gt;spring-cloud-openfeign · Search - Gitee&lt;/title&gt;&lt;link href=&quot;https://assets.gitee.com/assets/favicon-e87ded4710611ed62adc859698277663.ico&quot; rel=&quot;shortcut icon&quot; type=&quot;image/vnd.microsoft.icon&quot; /&gt;&lt;meta charset=&apos;utf-8&apos;&gt;&lt;meta content=&apos;always&apos; name=&apos;referrer&apos;&gt;&lt;meta content=&apos;Gitee&apos; property=&apos;og:site_name&apos;&gt;...&lt;/html&gt;&lt;--- END HTTP (48623-byte body) 在开启 gzip 之后，response 是：1234567891011121314151617181920212223&lt;--- HTTP/1.1 200 OK (987ms)cache-control: no-cacheconnection: keep-alivecontent-encoding: gzip ----------------------------- 第一处不同content-type: text/html; charset=utf-8date: Wed, 23 Jan 2019 07:20:59 GMTexpires: Sun, 1 Jan 2000 01:00:00 GMTpragma: must-revalidate, no-cache, privateserver: nginxset-cookie: gitee-session-n=BAh7CEkiD3Nlc3Npb25faWQGOgZFVEkiJTVmYmMwNTQyNWU4OGMzMmYyN2M3MDQ1ZmZiNjY5ZDIzBjsAVEkiF21vYnlsZXR0ZV9vdmVycmlkZQY7AEY6CG5pbEkiEF9jc3JmX3Rva2VuBjsARkkiMVdaQ2tqYTVuTjd6WU1UKzU5R1hNbnRlbUNQaXhoSzRLRmJreXduTU51cUU9BjsARg%3D%3D--8843239d46616524d58af2611f2db9614b8518b1; domain=.gitee.com; path=/; HttpOnlyset-cookie: oschina_new_user=false; path=/; expires=Sun, 23-Jan-2039 07:20:58 GMTset-cookie: user_locale=; path=/; expires=Sun, 23-Jan-2039 07:20:58 GMTset-cookie: aliyungf_tc=AQAAAHojVAEggQsAygAc2ugaNNgiXCKR; Path=/; HttpOnlystatus: 200 OKtransfer-encoding: chunkedx-rack-cache: missx-request-id: 53b45c93d5062be2c5643d9402d0a6dex-runtime: 0.412080x-ua-compatible: IE=Edge,chrome=1x-xss-protection: 1; mode=blockBinary data -------------------------------- 第二处不同&lt;--- END HTTP (11913-byte body) ---------------------------- 第三处不同 对比可以发现： 在 response 的 content-type 上面多了一个 content-encoding: gzip 在没有开启 gzip 之前控制台打印了 html 信息，开启后没有打印，换成了 Binary data 二进制 END HTTP 在没开启 gzip 之前为 48623 byte，开启后为 11913 byte 由此可以证明，response 开启 gzip 成功 Feign 配置对单个指定特定名称的 Feign 进行配置在之前的例子中，在对 FeignClient 的配置中，使用的是 @FeignClient 的 configuration 属性指定的配置类，也可以使用配置文件对 @FeignClient 注解的接口进行配置 FeignClient1234567@FeignClient(name = "gitee-client", url = "https://www.gitee.com")public interface GiteeFeignClient &#123; @RequestMapping(value = "/search", method = RequestMethod.GET) ResponseEntity&lt;byte[]&gt; searchRepo(@RequestParam("q") String query);&#125; application.yml1234567891011121314151617181920feign: client: config: gitee-client: # 这里指定的是 @FeignClient 的 name/value 属性的值 connectTimeout: 5000 # 链接超时时间 readTimeout: 5000 # 读超时 loggerLevel: none # 日志级别 # errorDecoder: # 错误解码器（类路径） # retryer: # 重试机制（类路径） # requestInterceptors: 拦截器配置方式 一：多个拦截器， 需要注意如果有多个拦截器，"-" 不能少 # - Intecerptor1 类路径， # - Interceptpt2 类路径 # requestInterceptors: 拦截器配置方式 二：多个拦截器，用 [Interceptor, Interceptor] 配置，需要配置类路径 # decode404: false 是否 404 解码 # encoder： 编码器（类路径） # decoder： 解码器（类路径） # contract： 契约（类路径）logging: level: com.laiyy.gitee.feign.springcloudfeignconfig.feign.GiteeFeignClient: debug 验证此时配置的 loggerLevel 为 none，不打印日志，访问： http://localhost:8080/feign-gitee?query=spring-cloud-openfeign ，可以看到控制台没有任何消息 将 loggerLevel 改为 full，再次访问可以看到打印日志消息。 将 loggerLevel 改为 feign.Logger.Level 中没有的级别，再次测试：loggerLevel: haha，可以看到控制启动报错： 123456789101112131415161718192021***************************APPLICATION FAILED TO START***************************Description:Failed to bind properties under &apos;feign.client.config.gitee-client.logger-level&apos; to feign.Logger$Level: Property: feign.client.config.gitee-client.loggerlevel Value: haha Origin: class path resource [application.yml]:7:22 Reason: failed to convert java.lang.String to feign.Logger$LevelAction:Update your application&apos;s configuration. The following values are valid: BASIC FULL HEADERS NONE 可以验证此配置是正确的。 对全部 FeignClient 配置对全部 FeignClient 启用配置的方法也有两种：1、@EnableFeignClients 注解有一个 defaultConfiguration 属性，可以指定全局 FeignClient 的配置。2、使用配置文件对全局 FeignClient 进行配置 application.yml1234567feign: client: config: defautl: # 全局的配置需要把 client-name 指定为 default connectTimeout: 5000 # 链接超时时间 readTimeout: 5000 # 读超时 loggerLevel: full # 日志级别 如果有多个 FeignClient，每个 FeignClient 都需要单独配置，如果有一样的配置，可以提取到全局配置中，需要注意：全局配置需要放在最后一位。]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>SpringCloud</tag>
        <tag>Feign</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring Cloud 微服务 (7) --- Feign(一) 远程调用、RestTemplate、Feign]]></title>
    <url>%2Fjava%2F2019%2F01-22%2Fspring-cloud-7.html</url>
    <content type="text"><![CDATA[在使用 SpringCloud 时，远程服务都是以 HTTP 接口形式对外提供服务，因此服务消费者在调用服务时，需要使用 HTTP Client 方式访问。在通常进行远程 HTTP 调用时，可以使用 RestTemplate、HttpClient、URLConnection、OkHttp 等，也可以使用 SpringCloud Feign 进行远程调用 RestTemplate脱离 Eureka 的使用在脱离 Eureka 使用 RestTemplate 调用远程接口时，只需要引入 web 依赖即可。 在使用 RestTemplate 时，需要先将 RestTemplate 交给 Spring 管理 123456789@Configurationpublic class RestTemplateConfiguration &#123; @Bean public RestTemplate restTemplate()&#123; return new RestTemplate(); &#125;&#125; 编写一个 Controller，注入 RestTemplate，调用远程接口 12345678910111213141516@RestControllerpublic class RestTemplateController &#123; private final RestTemplate restTemplate; @Autowired public RestTemplateController(RestTemplate restTemplate) &#123; this.restTemplate = restTemplate; &#125; @GetMapping(value = "rest-get", produces = "text/html;charset=utf-8") public String restTemplateGet()&#123; return restTemplate.getForObject("https://gitee.com", String.class); &#125;&#125; 访问 http://localhost:8080/rest-get 关联 Eureka 使用将服务注册到 Eureka Server，并使用 RestTemplate 调用远程 Eureka Client 服务 此时，只需要按照一个标准的 Eureka Client 编写步骤，将项目改造成一个 Eureka Client，并编写另外一个 Client。将要使用 RestTemplate 的 Client 当做服务消费者，另外一个当做服务提供者。在进行远程调用时，只需要将 getForObject 的 url，改为 http://service-id 即可，具体传入参数使用 ?、&amp;、= 拼接即可。 在注册到 Eureka Server 后，进行 RestTemplate 远程调用时，service-id 会被 Eureka Client 解析为 Server 中注册的 ip、端口，以此进行远程调用。 Rest TemplateRestTemplate 提供了 11 个独立的方法，这 11 个方法对应了各种远程调用请求 方法名 http 动作 说明 getForEntity() GET 发送 GET 请求，返回的 ResponseEntity 包含了响应体所映射成的对象 getForObject() GET 发送 GET 请求，返回的请求体将映射为一个对象 postForEntity() POST 发送 POST 请求，返回包含一个对象的 ResponseEntity，这个对象是从响应体中映射得到的 postForObject() POST 发送 POST 请求，返回根据响应体匹配形成的对象 postForLocation() POST 发送 POST 请求，返回新创建资源的 URL put() PUT PUT 资源到指定 URL delete() DELETE 发送 DELETE 请求，执行删除操作 headForHeaders() HEAD 发送 HEAD 请求，返回包含指定资源 URL 的 HTTP 头 optionsFOrAllow() OPTIONS 发送 OPTIONS 请求，返回指定 URL 的 Allow 头信息 execute() 执行非响应 ResponseEntity 的请求 exchange() 执行响应 ResponseEntity 的请求 Feign使用 RestTemplate 进行远程调用，非常方便，但是也有一个致命的问题：硬编码。 在 RestTemplate 调用中，我们每个调用远程接口的方法，都将远程接口对应的 ip、端口，或 service-id 硬编码到了 URL 中，如果远程接口的 ip、端口、service-id 有修改的话，需要将所有的调用都修改一遍，这样难免会出现漏改、错改等问题，且代码不便于维护。为了解决这个问题，Netflix 推出了 Feign 来统一管理远程调用。 什么是 FeignFeign 是一个声明式的 Web Service 客户端，只需要创建一个接口，并加上对应的 Feign Client 注解，即可进行远程调用。Feign 也支持编码器、解码器，Spring Cloud Open Feign 也对 Feign 进行了增强，支持了 SpringMVC 注解，可以像 SpringMVC 一样进行远程调用。 Feign 是一种声明式、模版化的 HTTP 客户端，在 Spring Cloud 中使用 Feign，可以做到使用 HTTP 请求访问远程方法就像调用本地方法一样简单，开发者完全感知不到是在进行远程调用。 Feign 的特性： 可插拔的注解支持 可插拔的 HTTP 编码器、解码器 支持 Hystrix 断路器、Fallback 支持 Ribbon 负载均衡 支持 HTTP 请求、响应压缩 简单示例使用 Feign 进行 github 接口调用 pom 依赖123456&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-openfeign&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 配置文件只是进行一个简单的远程调用，不需要注册 Eureka、不需要配置文件。 启动类123456789@SpringBootApplication@EnableFeignClientspublic class SpringCloudFeignSimpleApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(SpringCloudFeignSimpleApplication.class, args); &#125;&#125; Feign Client 配置123456789101112131415161718192021@Configurationpublic class GiteeFeignConfiguration &#123; /** * 配置 Feign 日志级别 * &lt;p&gt; * NONE：没有日志 * BASIC：基本日志 * HEADERS：header * FULL：全部 * &lt;p&gt; * 配置为打印全部日志，可以更方便的查看 Feign 的调用信息 * * @return Feign 日志级别 */ @Bean public Logger.Level feignLoggerLevel() &#123; return Logger.Level.FULL; &#125; &#125; FeignClient1234567@FeignClient(name = "gitee-client", url = "https://www.gitee.com/", configuration = GiteeFeignConfiguration.class)public interface GiteeFeignClient &#123; @RequestMapping(value = "/search", method = RequestMethod.GET) String searchRepo(@RequestParam("q") String query);&#125; @FeignClient：声明为一个 Feign 远程调用name：给远程调用起个名字url：指定要调用哪个 urlconfiguration：指定配置信息 @RequestMapping：如同 SpringMVC 一样调用。 Feign Controller12345678910111213141516@RestControllerpublic class FeignController &#123; private final GiteeFeignClient giteeFeignClient; @Autowired public FeignController(GiteeFeignClient giteeFeignClient) &#123; this.giteeFeignClient = giteeFeignClient; &#125; @GetMapping(value = "feign-gitee") public String feign(String query)&#123; return giteeFeignClient.searchRepo(query); &#125;&#125; 验证调用结果在浏览器中访问： http://localhost:8080/feign-gitee?query=spring-cloud-openfeign @FeignClient、@RequestMapping在 Feign 中使用 MVC 注解的注意事项在 FeignClient 中使用 @RequestMapping 注解调用远程接口，需要注意： 注解必须为 @RequestMapping，不能为组合注解 @GetMapping 等，否则解析不到 必须指定 method，否则会出问题 value 必须指定被调用方的 url，不能包含域名、ip 等 使用 @FeignClient 的注意事项 在启动类上必须加上 @FeignClients 注解，开启扫描 在 FeignClient 接口上必须指定 @FeignClient 注解，声明是一个 Feign 远程调用 @FeignClient源码 123456789101112131415161718192021222324252627282930@Target(&#123;ElementType.TYPE&#125;)@Retention(RetentionPolicy.RUNTIME)@Documentedpublic @interface FeignClient &#123; @AliasFor("name") String value() default ""; /** @deprecated */ @Deprecated String serviceId() default ""; @AliasFor("value") String name() default ""; String qualifier() default ""; String url() default ""; boolean decode404() default false; Class&lt;?&gt;[] configuration() default &#123;&#125;; Class&lt;?&gt; fallback() default void.class; Class&lt;?&gt; fallbackFactory() default void.class; String path() default ""; boolean primary() default true;&#125; 字段名 含义 name 指定 FeignClient 的名称，如果使用到了 Eureka，且使用了 Ribbon 负载均衡，则 name 为被调用者的微服务名称，用于服务发现 url 一般用于调试，可以手动指定 feign 调用的地址 decode404 当 404 时，如果该字段为 true，会调用 decoder 进行解码，否则会抛出 FeignException configuration Feign 配置类，可以自定义 Feign 的 Encoder、Decoder、LogLevel、Contract 等 fallback 容错处理类，当远程调用失败、超时时，会调用对应接口的容错逻辑。Fallback 指定的类，必须实现 @FeignClient 标记的接口 fallbackFactory 工厂类，用于生成 fallback 类的示例，可以实现每个接口通用的容错逻辑，减少重复代码 path 定义当前 FeignClient 的统一前缀 Feign 的运行原理 在启动类上加上 @EnableFeignClients 注解，开启对 Feign Client 扫描加载 在启用时，会进行包扫描，扫描所有的 @FeignClient 的注解的类，并将这些信息注入 Spring IOC 容器，当定义的 Feign 接口中的方法被调用时，通过 JDK 的代理方式，来生成具体的 RestTemplate。当生成代理时，Feign 会为每个接口方法创建一个 RestTemplate 对象，该对象封装了 HTTP 请求需要的全部信息，如：参数名、请求方法、header等 然后由 RestTemplate 生成 Request，然后把 Request 交给 Client 处理，这里指的 Client 可以是 JDK 原生的 URLConnection、Apache 的 HTTP Client、OkHttp。最后 Client 被封装到 LoadBalanceClient 类，结合 Ribbon 负载均衡发起服务间的调用。]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>SpringCloud</tag>
        <tag>Feign</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring Cloud 微服务（6） --- Eureka(四) Https]]></title>
    <url>%2Fjava%2F2019%2F01-20%2Fspring-cloud-6.html</url>
    <content type="text"><![CDATA[在生产环境下，一般来说都是 https 协议访问，现在的 http 协议访问可能会出现问题，在 Eureka Server、Client 中开启 Https 访问。 HTTP Basic 基于 base64 编码，容易被抓包，如果暴露在公网会非常不安全，可以通过开启 https 达到保护数据的目的。 Server 证书生成1keytool -genkeypair -alias server -storetype PKCS12 -keyalg RSA -keysize 2048 -keystore server.p12 -validity 3650 密码为：123456 在当前目录生成了一个 server.p12 文件 Client 证书生成1keytool -genkeypair -alias client -storetype PKCS12 -keyalg RSA -keysize 2048 -keystore client.p12 -validity 3650 密码为：654321 在当前目录生成了一个 client.p12 文件 导出 p12 文件12keytool -export -alias server -file server.crt --keystore server.p12keytool -export -alias client -file client.crt --keystore client.p12 信任证书Client 信任 Server 证书将 server.crt 导入 client.p12 1keytool -import -alias server -file server.crt -keystore client.p12 秘钥口令是 client.p12 的口令 Server 信任 Client 证书将 client.crt 导入 server.p12 1keytool -import -alias client -file client.crt -keystore server.p12 秘钥口令是 server.p12 的口令 Eureka Server将生成的最后的 server.p12 文件放在 resources 下 application.yml12345678910111213141516171819202122server: port: 8761 ssl: enabled: true key-store-type: PKCS12 # type 与 keytool 的 storetype 一致 key-alias: server # 与 keytool 的 alias 一致 key-store: classpath:server.p12 # p12 文件地址 key-store-password: 123456 # server.p12 口令eureka: instance: hostname: localhost secure-port: $&#123;server.port&#125; # https 端口 secure-port-enabled: true # 是否开启 https port non-secure-port-enabled: false home-page-url: https://$&#123;eureka.instance.hostname&#125;:$&#123;server.port&#125; # https 协议 status-page-url: https://$&#123;eureka.instance.hostname&#125;:$&#123;server.port&#125; # https 协议 client: register-with-eureka: false fetch-registry: false service-url: defaultZone: https://$&#123;eureka.instance.hostname&#125;:$&#123;server.port&#125;/eureka/ # https 协议 验证 Eureka Server访问 http://localhost:8761 访问 https://localhost:8761 Eureka ClientClient 只在连接 Eureka Server 的时候使用 https 协议，如果要全局都使用 https，则和 Server 的 https 配置一致，只需要将配置换成 client.p12 的配置即可。 application.yml123456789101112131415server: port: 8081spring: application: name: client1eureka: client: securePortEnabled: true ssl: key-store: client.p12 key-store-password: 654321 serviceUrl: defaultZone: https://localhost:8761/eureka/ Https 连接配置123456789101112131415161718192021222324252627@Configurationpublic class EurekaHttpsClientConfiguration &#123; @Value("$&#123;eureka.client.ssl.key-store&#125;") private String ketStoreFileName; @Value("$&#123;eureka.client.ssl.key-store-password&#125;") private String ketStorePassword; @Bean public DiscoveryClient.DiscoveryClientOptionalArgs discoveryClientOptionalArgs() throws CertificateException, NoSuchAlgorithmException, KeyStoreException, IOException, KeyManagementException &#123; EurekaJerseyClientImpl.EurekaJerseyClientBuilder builder = new EurekaJerseyClientImpl.EurekaJerseyClientBuilder(); builder.withClientName("eureka-https-client"); URL url = this.getClass().getClassLoader().getResource(ketStoreFileName); SSLContext sslContext = new SSLContextBuilder() .loadTrustMaterial(url, ketStorePassword.toCharArray()).build(); builder.withCustomSSL(sslContext); builder.withMaxTotalConnections(10); builder.withMaxConnectionsPerHost(10); DiscoveryClient.DiscoveryClientOptionalArgs optionalArgs = new DiscoveryClient.DiscoveryClientOptionalArgs(); optionalArgs.setEurekaJerseyClient(builder.build()); return optionalArgs; &#125;&#125; 验证 Client访问 https://localhost:8761 使用 http 注册]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>SpringCloud</tag>
        <tag>Eureka</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring Cloud（5） --- Eureka(三) 集群、Region Zone、Http Basic]]></title>
    <url>%2Fjava%2F2019%2F01-19%2Fspring-cloud-5.html</url>
    <content type="text"><![CDATA[在了解了 Euerka 的 REST API、核心类、核心操作、参数调优等概念之后，在实际的项目中来验证这些概念。 Eureka Server 集群扩展在之前的例子中，和 SpringCloud 中文社区的公益 Eureka Server 都是单节点的，如果 Server 挂掉了，那么整个微服务的注册将不在可用。在这时，就需要搭建 Eureka Server 高可用集群，保证整个微服务不会因为一个 Server 挂掉而导致整个微服务不可用。 使用 profile，搭建高可用集群有两种常用的方式启动多个 eureka server 在一个配置文件中，指定多个配置可以使用如下配置，在一个 application.yml 文件中，配置多个 Eureka Server，相互注册指定 defaultZone，并使用 profile 区别每个 Server 的配置。 1234567891011121314151617181920212223242526272829303132333435363738394041spring: application: name: spring-cloud-eureka-server-ha---server: port: 8761eureka: client: fetch-registry: false register-with-eureka: false service-url: defaultZone: http://localhost:8762/eureka,http://localhost:8763/eurekaspring: profiles: peer1---spring: profiles: peer2server: port: 8762eureka: client: fetch-registry: false register-with-eureka: false service-url: defaultZone: http://localhost:8761/eureka,http://localhost:8763/eureka---spring: profiles: peer3server: port: 8763eureka: client: fetch-registry: false register-with-eureka: false service-url: defaultZone: http://localhost:8761/eureka,http://localhost:8762/eureka 验证多 Server 启动使用 mvn spring-boot:run -Dspring.profiles.active=peer1peer1 可以换为 peer2、peer3，启动其他的 profile 在浏览器中输入： http://localhost:8761、http://localhost:8762、http://localhost:8763，都可以访问到 Eureka Server 使用这种方式启动存在的问题： 在一个配置文件中存在多个 Server 的配置，太过杂乱无章，不好管理如果 Server 在不同的机器上，由于 ip 地址不同，在第一个 Server 启动时由于找不到注册中心，必报错，当第二个 Server 启动后正常 使用多配置文件将 application.yml 复制多份，改名为 application-peer1.yml、application-peer2.yml、application-peer3.yml，然后使用 mvn spring-boot:run -Dspring.profiles.active=peer1 启动项目。 为验证此种配置方式可用，将 peer3 的端口该为 8764，启动测试 使用这种方式的问题： 可能存在同样的配置在多个配置文件都存在，需要修改时需要修改每个文件，太过冗余Server 在不同机器上的时候，出现的问题和 在一个配置文件中，指定多个配置 的问题一致 接口验证12345678910111213141516171819@SpringBootApplication@EnableEurekaServer@RestControllerpublic class SpringCloudEurekaServerHaApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(SpringCloudEurekaServerHaApplication.class, args); &#125; @Autowired private EurekaClientConfigBean eurekaClientConfigBean; @GetMapping(value = "eureka-service-url") public Object getEurekaServerUrl() &#123; return eurekaClientConfigBean.getServiceUrl(); &#125;&#125; 重启 3 个Server，浏览器访问 http://localhost:8764/eureka-service-url 可以看到，peer3 中注册了两个 eureka server。 Eureka Client 注册到多 ServerClient 注册到多 Server，只需要在配置文件中指定对应 Server 的 defauleZone 即可。 1234567891011121314spring: application: name: eureka-client server: port: 8001 eureka: instance: hostname: localhost client: service-url: defaultZone: http://localhost:8761/eureka/,http://localhost:8762/eureka/,http://localhost:8764/eureka/, server: enable-self-preservation: false 使用 Region、Zone 搭建高可用集群配置文件 application-zone1a.yml：1234567891011121314151617181920spring: application: name: spring-cloud-eureka-server-region-zoneserver: port: 8761eureka: client: fetch-registry: false register-with-eureka: false service-url: zone1: http://localhost:8761/eureka/,http://localhost:8762/eureka/ zone2: http://localhost:8763/eureka/,http://localhost:8764/eureka/ region: region-east # 设置 region availability-zones: region-east: zone1,zone2 # 设置可用 region-zone instance: hostname: localhost prefer-ip-address: true metadata-map: zone: zone1 # 设置 zone application-zone1b.yml： 将 server.port 修改为 8762application-zone2a.yml： 将 server.port 修改为 8763，eureka.instance.metadata-map.zone 修改为 zone2application-zone2b.yml： 将 server.port 修改为 8764，eureka.instance.metadata-map.zone 修改为 zone2 验证 Eureka Server在浏览器访问 http://localhost:8761 创建 Eureka Client创建两个 Eureka Client，分别对应两个 Zone application-zone1.yml12345678910111213141516server: port: 8081spring: application: name: spring-cloud-eureka-client-region-zoneeureka: instance: metadata-map: zone: zone1 client: region: region-east availability-zones: region-east: zone1,zone2 service-url: zone1: http://localhost:8761/eureka/,http://localhost:8762/eureka/ zone2: http://localhost:8763/eureka/,http://localhost:8764/eureka/ application-zone2.yml：修改 server.port=8082，eureka.instance.metadata-map.zone=zone2 暴露服务端点application.yml：12345management: endpoints: web: exposure: include: '*' 引入 pom 依赖：123456789101112&lt;dependencies&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt;&lt;/dependency&gt;&lt;!-- 暴露端点 --&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt;&lt;/dependency&gt;&lt;/dependencies&gt; 验证 region、zone访问 client 暴露的环境端点，验证 region、zone http://localhost:8081/actuator/env、http://localhost:8082/actuator/env 由此，可以验证 client1、client2 的 zone 是指定的 zone。 开启 Http Basic现在的实例中，访问 Eureka Server 是不需要用户名、密码的，不需要安全验证。为了防止微服务暴露，可以开启 Http Basic 安全教研。 Eureka Server 开启 Http Basic引入 pom 依赖1234567891011&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-server&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-security&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 创建配置文件1234567891011121314server: port: 8761spring: security: user: name: laiyy # 访问 Eureka Server 的用户名 password: 123456 # 访问 Eureka Server 的密码eureka: client: service-url: defaultZone: http://localhost:$&#123;server.port:8761&#125;/eureka/ register-with-eureka: false fetch-registry: false 访问 http://localhost:8761 Eureka Client 开启 Http Basic引入 pom 依赖1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt;&lt;/dependency&gt; 配置文件123456789101112131415161718spring: application: name: spring-cloud-eureka-client-http-basiceureka: client: security: basic: user: laiyy password: 123456 service-url: defaultZone: http://$&#123;eureka.client.security.basic.user&#125;:$&#123;eureka.client.security.basic.password&#125;@localhost:8761/eureka instance: prefer-ip-address: true instance-id: $&#123;spring.application.name&#125;:$&#123;server.port&#125;server: port: 8081 需要注意，defaultZone 需要设置为： http://user:password@ip:port/eureka/ 启动 Eureka Client，验证 Http Basic在启动 Client 后，观察日志，可以看到出现了 403 错误： 明明已经指定了 Eureka Server 的用户名、密码、ip、端口，为什么还是注册失败？是因为 Http Basic 默认是同源的，而 client、server 的 ip、端口不一致，会出现跨域访问请求，导致 403. 解决办法：在 Eureka Server 端关闭 csrf 访问。 123456789@EnableWebSecuritypublic class HttpBasicConfiguration extends WebSecurityConfigurerAdapter &#123; @Override protected void configure(HttpSecurity http) throws Exception &#123; super.configure(http); http.csrf().disable(); &#125;&#125; 重新启动 Server、Client，访问 Server，可以看到 Client 注册成功]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>SpringCloud</tag>
        <tag>Eureka</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring Cloud 微服务（4） --- Eureka(二) REST API、核心类、调优]]></title>
    <url>%2Fjava%2F2019%2F01-18%2Fspring-cloud-4.html</url>
    <content type="text"><![CDATA[在上一篇已经了解到了服务注册与发现、Eureka、Eureka 简单示例、Eureka Server 中查看 Client 状态等。接下来需要了解 Eureka 的 REST API、核心类、调优等惭怍。 REST API在 Eureka Server 的可视化页面中，我们可以看到每个微服务的注册信息。在 Server、Client 的配置文件中，都指定了一个 defaultZone: ip:port/eureka/，那么这个配置的作用是什么？为什么在 ip、端口 后面要加上一个 /eureka ？ /eureka 就是 Eureka 的 REST API 的端点地址。 /eureka/ 端点启动 Eureka Server、Client，在浏览器中输入： http://localhost:8761/eureka/apps ，可以看到如下信息： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657&lt;!-- 所有工程 --&gt;&lt;applications&gt; &lt;versions__delta&gt;1&lt;/versions__delta&gt; &lt;apps__hashcode&gt;UP_1_&lt;/apps__hashcode&gt; &lt;application&gt; &lt;!-- 单个实例的名称 --&gt; &lt;name&gt;SPRING-CLOUD-EUREKA-CLIENT-SIMPLE&lt;/name&gt; &lt;instance&gt; &lt;!-- 单个实例的 instance-id --&gt; &lt;instanceId&gt;spring-cloud-eureka-client-simple:8081&lt;/instanceId&gt; &lt;!-- 实例的 hostname，没有指定时用 ip --&gt; &lt;hostName&gt;10.10.10.141&lt;/hostName&gt; &lt;app&gt;SPRING-CLOUD-EUREKA-CLIENT-SIMPLE&lt;/app&gt; &lt;!-- 实例的ip --&gt; &lt;ipAddr&gt;10.10.10.141&lt;/ipAddr&gt; &lt;!-- 实例状态 --&gt; &lt;status&gt;UP&lt;/status&gt; &lt;overriddenstatus&gt;UNKNOWN&lt;/overriddenstatus&gt; &lt;!-- 端口 --&gt; &lt;port enabled="true"&gt;8081&lt;/port&gt; &lt;!-- https --&gt; &lt;securePort enabled="false"&gt;443&lt;/securePort&gt; &lt;countryId&gt;1&lt;/countryId&gt; &lt;dataCenterInfo class="com.netflix.appinfo.InstanceInfo$DefaultDataCenterInfo"&gt; &lt;name&gt;MyOwn&lt;/name&gt; &lt;/dataCenterInfo&gt; &lt;leaseInfo&gt; &lt;!-- 每多长时间续约一次，单位 秒 --&gt; &lt;renewalIntervalInSecs&gt;30&lt;/renewalIntervalInSecs&gt; &lt;!-- 续约过期时间，单位秒。规定时间内没有续约会剔除 Eureka Server --&gt; &lt;durationInSecs&gt;90&lt;/durationInSecs&gt; &lt;!-- 注册时间 --&gt; &lt;registrationTimestamp&gt;1547800471059&lt;/registrationTimestamp&gt; &lt;!-- 上一次续约时间 --&gt; &lt;lastRenewalTimestamp&gt;1547800471059&lt;/lastRenewalTimestamp&gt; &lt;evictionTimestamp&gt;0&lt;/evictionTimestamp&gt; &lt;serviceUpTimestamp&gt;1547800471059&lt;/serviceUpTimestamp&gt; &lt;/leaseInfo&gt; &lt;metadata&gt; &lt;management.port&gt;8081&lt;/management.port&gt; &lt;jmx.port&gt;10235&lt;/jmx.port&gt; &lt;/metadata&gt; &lt;!-- 主页面 --&gt; &lt;homePageUrl&gt;http://10.10.10.141:8081/&lt;/homePageUrl&gt; &lt;!-- 实例信息 --&gt; &lt;statusPageUrl&gt;http://10.10.10.141:8081/actuator/info&lt;/statusPageUrl&gt; &lt;!-- 实例健康检查 --&gt; &lt;healthCheckUrl&gt;http://10.10.10.141:8081/actuator/health&lt;/healthCheckUrl&gt; &lt;vipAddress&gt;spring-cloud-eureka-client-simple&lt;/vipAddress&gt; &lt;secureVipAddress&gt;spring-cloud-eureka-client-simple&lt;/secureVipAddress&gt; &lt;isCoordinatingDiscoveryServer&gt;false&lt;/isCoordinatingDiscoveryServer&gt; &lt;lastUpdatedTimestamp&gt;1547800471059&lt;/lastUpdatedTimestamp&gt; &lt;lastDirtyTimestamp&gt;1547800470997&lt;/lastDirtyTimestamp&gt; &lt;actionType&gt;ADDED&lt;/actionType&gt; &lt;/instance&gt; &lt;/application&gt; &lt;/applications&gt; 此时看到的信息，是在 Eureka Server 中注册的所有Client 的信息。如果想要查询单个 Client 的信息，可以访问 http://localhost:8761/eureka/apps/{application.name} ，如：http://localhost:8761/eureka/apps/SPRING-CLOUD-EUREKA-CLIENT-SIMPLE 常用的 REST API常用的 Eureka REST API 除了 /eureka/apps 之外，还有如下接口 操作 http 动作 接口 描述 注册新的应用实例 POST /eureka/apps/{appId} 可以输入 json 或者 xml 格式的 body，成功返回 204 注销实例 DELETE /eureka/apps/{appId}/{instanceId} 成功返回 200 发送心跳 PUT /eureka/apps/{appId}/{instanceId} 成功返回 200，instanceId 不存在返回 404 查询所有实例 GET /eureka/apps 成功返回 200，输出 json 或 xml 格式的 body 查询单个实例 GET /eureka/apps/{appId} 成功返回 200，输出json 或 xml 格式的 body 根据 appId、instanceId 查询 GET /eureka/apps/{appId}/{instanceId} 成功返回 200，输出 json 或 xml 格式的 body 暂停某个实例 PUT /eureka/apps/{appId}/{instanceId}/status?value=OUT_OF_SERVICE 成功返回 200，失败返回 500 恢复某个实例 DELETE /eureka/apps/{appId}/{instanceId}/status?vlaue=UP(value 可不传) 成功返回 200，失败返回 500 更新元数据 PUT /euerka/apps/{appId}/{instanceId}/metadata?key=value 成功返回 200，失败返回 500 根据虚拟 ip 查询 GET /eureka/vip/{vipAddr} 成功返回 200，输出 json 或 xml 格式的 body 根据基于 htpps 的虚拟 ip 查询 GET /eureka/svip/{svipAddr} 成功返回 200，输出 json 或 xml 格式的 body 在进行新实例的注册时，传入的 json、xml 的格式需要与调用获取单个实例所返回的数据格式一致。具体的数据需要自己指定，需要注意的是，如果要注册的实例的ip、端口已经存在的话，不会再次注册，需要修改 instanceId。 Eureka 核心类Eureka 提供了一些核心的类，这些类中保存了 Eureka Server、Client 的注册信息、运行时的信息等。 InstanceInfoInstanceInfo 代表了注册的服务实例(位置： com/netflix/appinfo/InstanceInfo.java) 字段 说明 app 应用名称 appGroupName 应用所属群组 ipAddr ip 地址 sid 已废弃，默认 na port 端口号 securePort https 端口 homePageUrl 应用实例的首页 url statusPageUrl 应用实例的状态页 url healthPageUrl 应用实例的健康检查 url secureHealthPageUrl 应用实例的健康检查 https url vipAddress 虚拟 ip 地址 secureVipAddress https 的虚拟 ip 地址 countryId 已废弃，默认 1，代表 US dataCenterI dataCenter 信息，Netflix、Amazon、MyOwen hostName 主机名称（默认 ip status 状态，如：UP、DOWN、STATING、OUT_OF_SERVICE、UNKNOWN overrideenstatus 外界需要强制覆盖的状态，默认为 UNKNOWN leaseInfo 租约信息 isCorrdinatindDiscoveryServer 首先标示是否是 DiscoveryServer，其次标示该 DiscoveryServer 是否是响应你请求的实例 metadata 应用实例的元数据信息 lastUpdateTimestamp 状态信息最后更新时间 lastDirtyTimestamp 实例信息的最新过期时间，在 Client 端用于标志该实例信息是否与 Eureka Server 一致，在 Server 端则与多个 Server 之间进行信息同步 actionType 标示 Server 对该实例进行的操作，包括：ADDED、MODIFIED、DELETED args 在 AWS 的 autoscaling group 名称 可以看出，整个 InstanceInfo 的返回值信息，就是访问 /eureka/apps/{appId} 的返回值，也是通过 REST API 向 Eureka Server 注册时的 body。 LeaseInfoLeaseInfo 标识应用实例的租约信息(位置： com/netflix/appinfo/LeaseInfo.java) 字段 说明 renewalIntervalInSecs Client 续约时间间隔(秒) durationInSecs Client 的租约有效时间长(秒) registreationTimestamp 第一次注册时间(毫秒时间戳) laseRenewalTimestamp 最后一次续约时间(毫秒时间戳) evicationTimestamp 租约被剔除时间(毫秒时间戳) serviceUpTimestamp Client 被标记为 UP 状态的时间(毫秒时间戳) ServiceInstanceInfoServiceInstanceInfo 是一个标识一个应用实例的接口，约定了服务的发现的实例应用有哪些通用信息(位置： org/springframework/cloud/client/ServiceInstanceInfo.java) 方法 说明 getSercieId() 获取服务 id getHost() 获取实例的 HOST getPort() 获取实例的端口 isSecure() 是否开启 https getUri() 实例的 uri 地址 getMetadata() 实例的元数据信息 getScheme() 实例的 scheme 对于 ServiceInstanceInfo 接口的实现为：EurekaRegistration(位置：org/springframework/cloud/netflix/eureka/serviceregistry/EurekaRegistration.java)，EurekaRegistration 同时还实现了 Closeable 接口，这个接口的作用之一是在 close 的时候调用 eurekaClient.shutdown() 方法，实现优雅关闭 Eureka Client。 InstanceStatusInstanceStatus 是一个枚举类型，源码如下：12345678910111213141516171819202122public static enum InstanceStatus &#123; UP, DOWN, STARTING, OUT_OF_SERVICE, UNKNOWN; private InstanceStatus() &#123; &#125; public static InstanceInfo.InstanceStatus toEnum(String s) &#123; if (s != null) &#123; try &#123; return valueOf(s.toUpperCase()); &#125; catch (IllegalArgumentException var2) &#123; InstanceInfo.logger.debug("illegal argument supplied to InstanceStatus.valueOf: &#123;&#125;, defaulting to &#123;&#125;", s, UNKNOWN); &#125; &#125; return UNKNOWN; &#125;&#125; 其中定义了 5 种状态，对应 Client 的 5 种状态。 服务的核心操作对于服务发现来说，一般都是围绕几个核心的概念进行设计： 服务发现（register）服务下线（cancel）服务租约（renew）服务剔除（evict） 围绕这几个概念，Eureka 设计了一些核心的操作类： com/netflix/eureka/lease/LeaseManager.java com/netflix/discovery/shared/LookupService.java com/netflix/eureka/registry/InstanceRegistry.java com/netflix/eureka/registry/AbstractInstanceRegistry.java com/netflix/eureka/registry/PeerAwareInstanceRegistry.java 在 Netflix Eureka 的基础上，Spring Cloud 抽象或定义了几个核心类: org/springframewor/cloud/netflix/eureka/server/InstanceRegistry.java org/springframewor/cloud/client/serviceregistry/ServiceRegistry.kava org/springframewor/cloud/netflix/eureka/serviceregistry/EurekaServiceRegistry.java org/springframewor/cloud/netflix/eureka/serviceregistry/EurekaRegistration.java org/springframewor/cloud/netflix/eureka/EurekaClientAutoConfiguration.java org/springframewor/cloud/netflix/eureka/EurekaClientConfigBean.java org/springframewor/cloud/netflix/eureka/EurekaInstanceConfigBean.java 其中：LeaseManager、LookupService 是 Eureka 关于服务发现相关操作操作定义的接口类，LeaseManager 定义了服务写操作相关方法，LookupService 定义查询操作的相关方法。 LeaseManager12345678910public interface LeaseManager&lt;T&gt; &#123; void register(T r, int leaseDuration, boolean isReplication); boolean cancel(String appName, String id, boolean isReplication); boolean renew(String appName, String id, boolean isReplication); void evict();&#125;、 register：用于注册服务实例信息 cancel：用于删除服务实例信息 renew：用于和 Eureka Server 进行心跳操作，维持租约 evict：Server 端的方法，用于剔除租约过期的服务实例。 LoopupService12345678910public interface LookupService&lt;T&gt; &#123; Application getApplication(String appName); Applications getApplications(); List&lt;InstanceInfo&gt; getInstancesById(String id); InstanceInfo getNextServerFromEureka(String virtualHostname, boolean secure);&#125; getApplication：根据 appName 获取服务信息 getApplications：获取所有注册的服务信息 getInstancesById：根据 appid，获取所有实例 getNextServerFromEureka：根据虚拟hostname、是否是 https，获取下一个服务实例方法（默认轮训获取） Eureka 参数调优Client 端基本参数 参数 默认值 说明 eureka.client.avaliability-zones 告知 Client 有哪些 regin 和 zone，支持配置修改运行时生效 eureka.client.filter-only-up-instances true 是否滤出 InstanceStatus 为 UP 的实例 eureka.clint.region us-east-1 指定 region，当 datacenters 为 AWS 时适用 eureka.client.register-with-eureka true 是否将实例注册到 Eureka Server eureka.client.prefer-same-zone-eureka true 是否优先使用和该应用实例处于相同 Zone 的 Eureka Server eureka.client.on-demand-update-status-change trye 是否将本地实例状态的更新，通过 ApplicationInfoManager 实时同步到 Eureka Server(这个同步请求有流量限制) eureka.instance.matadata-map 指定实例的元数据信息 eureka.instance.prefer-ip-address false 是否优先使用 ip 地址来代替 hostname 作为实例的 hostname 字段值 eureka.instance.lease-exporation-duration-in-seconds 90 指定 Eureka Client 间隔多久向 Server 发送心跳 定时任务参数 参数 默认值(时间单位：秒，非时间单位：个) 说明 eureka.client.cache-refresh-executor-thread-pool-size 2 刷新缓存的 CacheRefreshThread 线程池大小 eureka.client.cache-refresh-executor-exponential-back-off-bound 10 调度任务执行时，下次调度的延迟时间 eureka.client.heartbeat-executor-thread-pool-size 2 执行心跳 HeartbeatThread 的线程池大小 eureka.client.heartbeat-executor-exponential-back-off-bound 10 调度任务执行时，下次调度的延迟时间 eureka.client.registry-fetch-interval-seconds 30 CachaRefreshThread 线程调度频率 eureka.client.eureka-service-url-poll-interval-seconds 5*60 AsyncResolver.updateTask 刷新 Eureka Server 地址的时间间隔 eureka.client.initial-instance-info-replication-interval-seconds 40 InstanceInfoReplicator 将实例信息变更同步到 Eureka Server 的初始延时时间 eureka.client.instance-infi-replication-interval-seconds 30 InstanceInfiReplicator 将实例信息变更同步到 Eureka Server 的时间间隔 eureka.client.lease-renewal-interval-in-seconds 30 Eureka Client 向 Eureka Server 发送心跳的时间间隔 http 参数Eureka Client 底层使用 HttpClient 与 Eureka Server 通信。 参数 默认值 说明 eureka.client.eureka-server-connect-timeout-seconds 5 连接超时时间 eureka.client.eureka-server-read-timeout-seconds 8 读超时时间 eureka.client.eureka-server-total-connections 200 连接池最大连接数 eureka.client.eureka-server-total-connections-per-host 50 每个 host 能使用的最大链接数 eureka.client.eureka-connection-idle-timeout-seconds 30 连接池空闲连接时间 Server 端Server 端的参数调优分为：基本参数，Response Cache、Peer、Http 等 基本参数 参数 默认值 说明 eureka.server.enable-self-preservation true 是否开启自我保护模式 eureka.server.renewal-percent-threshold 0.85 每分钟需要收到的续约次数阈值(心跳数/client实例数) eureka.instance.registry.expected-number-of-renews-per-min 1 指定每分钟需要收到的续约次数，实际上，在源码中被写死为 count * 2 eureka.server-renrewal-threshold-update-interval-ms 15 分钟 指定 updateRenewalThreshold 定时任务的调度频率，动态更新 expectedNumberOfRenewsMin 以及 numberOfNewsPerMinThreshold 的值 eureka.server.evication-interval-timer-in-ms 60*1000 指定 EvicationTask 定时任务调度频率，用于剔除过期的实例 Response Cache 参数Eureka Server 为了提升自身 REST API 接口的性能，提供了两个缓存：一个是基于 ContioncurrentMap 的 readOnlyCacheMap，一个是基于 Guava Chahe 的 readWriteCacheMap。 参数 默认值 说明 eureka.server.use-read-only-response-cache true 是否使用只读的 Response Cache eureka.server.response-cache-update-interval-ms 30 * 1000 设置 CacheUpdateTask 的调度时间间隔，用于从 readWriteCacheMap 更新数据到 readOnlyCacheMap。仅在 eureka.server.use-read-only-response-cache 为 true 时生效 eureka.server.response-cache-auto-expiration-in-seconds 180 设置 readWriteCacheMap 的过期时间 peer 参数 参数 默认值 说明 eureka.server.peer.eureka-nodes-update-interval-ms 10分钟 指定 peersUpdateTask 调度的时间间隔，用于配置文件刷新 peerEurekaNodes 节点的配置信息 eureka.server.peer-eureka-status-refresh-time-interval-ms 30*1000 指定更新 Peer nodes 状态的时间间隔 http 参数 参数 默认值 说明 eureka.server.peer-node-connect-timeout-ms 200 链接超时时间 eureka.server.peer-node-read-timeout-ms 200 读超时时间 eureka.server.peer-node-total-connections 1000 连接池最大连接数 eureka.server.peer-node-total-connections-per-host 500 每个 host 能使用的最大连接数 eureka.server.peer-node-connection-idle-timeout-seconds 30 连接池中链接的空闲时间]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>SpringCloud</tag>
        <tag>Eureka</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring Cloud 微服务（3） --- Eureka(一) 注册中心与 Eureka]]></title>
    <url>%2Fjava%2F2019%2F01-17%2Fspring-cloud-3.html</url>
    <content type="text"><![CDATA[Eureka 最初是针对 AWS 不提供中间服务层的负载均衡的限制开发的。 Eureka 一方面给内部服务做服务发现，另一方面可以结合 Ribbon 组件提供各种个性化的负载均衡算法。 Spring Cloud 微服务系列版本 Spring Boot 版本： 2.1.0.RELEASESpring Cloud 版本：Finchley.RELEASE 服务发现的技术选型方案 名称 类型 CAP 语言 依赖 集成 一致性算法 Zookeeper General CP Java JVM Client Binding Paxos Doozer General CP Go Client Binding Paxos Consul General CP GO HTTP/DNS Library Raft Etcd General CP or Mixed(1) Go Client Binding/HTTP Raft SmartStack Dedicated AP Ruby Haproxy/Zookeeper Sidekick(nerve/synapse) Eureka Dedicated AP Java JVM Java Client NSQ(lookupd) Dedicated AP Go Client Binding Serf Dedicated AP Go Local CLI Spotify(DNS) 15973840029 AP N/A Bind DNS Library SkyDNS 808376 Mixed(2) Go HTTP/DNS Library Eureka 的设计理念服务实例注册到服务中心服务的注册，本质上就是在服务启动的时候，调用 Eureka Server 的 REST API 的 Registrer 方法，注册应用实例的信息。对于 Java 应用，可以使用 Netflix 的 Eureka Client 封装 API 调用；对于 Spring Cloud 应用，可以使用 spring-cloud-starter-netflix-eureka-client 基于 Spring Boot 自动配置，自动注册服务。 服务实体从服务中心剔除正常情况下，服务实例在关闭应用的时候，应该通过钩子方法或其他生命周期回调方法，调用 Eureka Server 的 REST API 的 de-register 方法，来删除自身服务实例的信息。另外，为了解决服务挂掉，或网络中断等其他异常情况没有及时删除自身信息的问题，Eureka Server 要求 Client 定时进行续约，也就是发送心跳，来证明自己是存活的、健康的、可调用的。如果超过一定时间没有续约，则认为 Client 停掉了，Server 端会主动剔除。 服务实例一致性问题由于注册中心（Eureka Server）通常来说是一个集群，就需要 Client 在集群中保持一致。Eureka 通过 CAP、Peer to Peer、Zone + Region、SELF PRESERVATION 四个方面保证一致性。 CAP在 微服务与 Spring Cloud、 服务发现技术选型、服务一致性 都提到了 CAP、CP、AP，那么 CAP 到底是个啥 C：Consistency，数据一致性。即数据在存在多个副本的情况下，可能由于网络、机器故障、软件系统等问题早上数据写入部分副本成功，副本副本失败，进而造成副本之间数据不一致，存在冲突。满足一致性则要求对数据的更新操作成功后，多副本的数据保持一致。 A：Availablility，服务可用性。在任何时候，客户端对集群进行读写操作时，请求能够正常响应，即，在一定的时间内完成。 P：Partition Tolerance，分区容忍性，即发生通信故障的时候，整个集群被分隔成多个无法相互通信的分区时，集群仍然可用。 在分布式系统中，网络条件一般是不可控的，网络分区是不可避免的，因此分布式系统必须满足分区容忍性，所以分布式系统的设计需要在 AP、CP 之间进行选择。 Zookeeper 是 “C”P 的，C 之所以加引号，是因为 Zookeeper 默认并不说严格的强一致性。如：A 进行写操作，Zookeeper 在过半节点数操作成功就返回，此时如果 B 读取到的是 A 写操作没有同步到的节点，那么就读取不到 A 写入的数据。如果需要在使用的时候强一致，需要在读取的时候先执行 sync 操作，与 leader 节点先同步数据，才能保证强一致。 Eureka 在大规模部署的情况下，失败是不可避免的，可能会因为 Eureka 自身部署的失败，导致注册的服务不可用，或者由于网络分区，导致服务不可用。Eureka 服务注册、发现中心，保留了可用及过期的数据，以此来实现在网络分区的时候，还能正常提供服务注册发现功能。 Peer to Peer分布式系统的数据在多个副本直接的复制方式，可分为：主从复制、对等复制 主从复制主从复制，就是 Master-Slave 模式，有一个主副本，其他为从副本。所有的对数据的写操作，都提交到主副本，然后由主副本更新到其他的从副本。具体的更新方式有：同步更新、异步更新、同步异步混合更新。对于主从复制的模式，写操作都要经过主副本，所有主副本的压力会很大。但是，从副本会分担主副本的读请求，而一个系统最大的请求都是读请求，所有可以一般情况下都是一主多从的架构。 对等复制即 Peer to Peer 模式。副本之间不分主从，任何副本都能接收写操作，然后每个副本之间相互进行数据更新。对于对等复制模式来说，由于任何副本都可以接收到写操作，所以不存在写操作的压力瓶颈。但是由于每个副本都能进行写操作，各个副本之间的数据同步及冲突处理是一个比较棘手的问题。 Eureka 采用的就是 Peer to Peer Zone 及 RegionNetflix 的服务大部分在 Amazon Video 上，因此 Eureka 的设计有一部分也是基于 Amazon 的 Zone、Region 基础上托管。 每个 Region 下，还分了几个 Zone，一个 Region 对应多个 Zone，每个 Region 之间是相互独立及隔离的，默认情况下，资源只在单个 Region 之间的 Zone 进行复制，跨 Region 之间不会进行资源复制。 SELF PRESERVATION在分布式系统中，通常需要对应用实例的存活进行健康检查，需要处理好网络抖动或短暂的不可用造成的误判；另外，Eureka Server 和 Client 之间如果存在网络分区，在极端情况下可能会导致 Eureka Server 情况部分服务的实例列表，这个将严重影响到 Eureka Server 的高可用。因此，Eureka 引入了自我保护机制(SELF PRESERVATION)。 Client 与 Server 之间有租约，Client 需要定时发送心跳维持租约，表示自己存活。Eureka 通过当前注册的实例数，计算每分钟应该从应用实例接收到的心跳数，如果最近一分钟接收到的续约次数小于指定的阈值的话，则关闭租约失效剔除，进制定时任务剔除失效的实例，从而保护注册信息。 Eureka 入门案例父 pom123456789101112131415161718192021222324252627282930313233&lt;packaging&gt;pom&lt;/packaging&gt;&lt;!-- 父工程是 2.1.0.RELEASE 版本的 boot --&gt;&lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.1.0.RELEASE&lt;/version&gt;&lt;/parent&gt;&lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;!-- 设置全局 SpringCloud 依赖版本为 F.RELEASE --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt; &lt;version&gt;Finchley.RELEASE&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/dependencyManagement&gt;&lt;!-- 设置全局依赖 SpringBoot、Web --&gt;&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 建立 Eureka Server 子项目在父pom中建立 Eureka Server 子项目 module：spring-cloud-eureka-server pom 依赖1234567891011121314&lt;!-- 父工程 --&gt;&lt;parent&gt; &lt;groupId&gt;com.laiyy.gitee&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;&lt;/parent&gt;&lt;dependencies&gt; &lt;!-- 引入 eureka server 依赖，注意不能少了 starter --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-server&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 启动类1234567@SpringBootApplication@EnableEurekaServer // 开启 Eureka Server public class SpringCloudEurekaServerApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(SpringCloudEurekaServerApplication.class, args); &#125;&#125; 配置文件12345678910111213141516spring: application: name: eureka-server # 服务名称server: port: 8761 # 服务端口eureka: instance: hostname: localhost # host name client: fetch-registry: false # 是否获取注册表 service-url: defaultZone: http://localhost:$&#123;server.port:8761&#125;/eureka/ # 默认 Zone register-with-eureka: false # 是否注册自己 server: enable-self-preservation: false # 是否开启自我保护，默认 true。在本机测试可以使用 false，但是在生产环境下必须为 true 验证 Eureka Server 启动结果在浏览器输入： http://localhost:8761 ，进入 Eureka Server 可视化页面 Eureka Server UI 提示信息在 Eureka Server 检测到异常时，会在中间以红色加粗字体提示信息。 在没有 Eureka Client 或 Eureka Server 检测心跳的阈值小于指定阈值，且关闭自我保护时： RENEWALS ARE LESSER THAN THE THRESHOLD. THE SELF PRESERVATION MODE IS TURNED OFF.THIS MAY NOT PROTECT INSTANCE EXPIRY IN CASE OF NETWORK/OTHER PROBLEMS.提示说明了：1、eureka client 的心跳发送次数小于阈值(没有client，肯定小于)；2、自我保护被关闭了 在有 Eureka Client，且关闭了自我保护时： THE SELF PRESERVATION MODE IS TURNED OFF.THIS MAY NOT PROTECT INSTANCE EXPIRY IN CASE OF NETWORK/OTHER PROBLEMS. 在没有 Eureka Client 或 Eureka Server 检测心跳的阈值小于指定阈值，且开启了自我保护时： EMERGENCY! EUREKA MAY BE INCORRECTLY CLAIMING INSTANCES ARE UP WHEN THEY’RE NOT. RENEWALS ARE LESSER THAN THRESHOLD AND HENCE THE INSTANCES ARE NOT BEING EXPIRED JUST TO BE SAFE. 在有 Eureka Client 且 Eureka Server 检测心跳的阈值大于指定阈值，且开启了自我保护时，Eureka Server 会认为整个服务正常，不会有任何信息提示。 建立 Eureka Client 项目在 在父pom中建立 Eureka Server 子项目 module：spring-cloud-eureka-client-simple，建立一个简单的 eureka client 工程 pom12345678&lt;!-- parent 都和 Eureka Server 一致，不再赘述 --&gt;&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 启动类123456789// EurekaClient、DiscoveryClient 本质上都是注册到服务中心的实现，EurekaClient 只针对 Eureka 使用，// DiscoveryClient 针对不同的注册中心都可以使用。可以说 DiscoveryClient 的 EurekaClient 的一个抽象@SpringBootApplication@EnableDiscoveryClient //@EnableEurekaClient public class SpringCloudEurekaClientSimpleApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(SpringCloudEurekaClientSimpleApplication.class, args); &#125;&#125; 配置文件1234567891011121314spring: application: name: spring-cloud-eureka-client-simple # 工程名称，也是注册到 server 后的实例名称eureka: client: service-url: defaultZone: http://localhost:8761/eureka # 指定 Zone，需要与 Eureka Server 一样 instance: prefer-ip-address: true # 使用 ip 注册，默认为 false。为 false 时是 机器名 instance-id: $&#123;spring.application.name&#125;:$&#123;server.port&#125; # 注册到 server 后显示的名字，默认是 机器名:name:端口server: port: 8081 # 端口 在 Eureka Server 验证服务注册 可以看到，eureka client 已经注册成功。 status 大致有 5 个状态：UP(正常运行)、DOWN(停机)、STATING(正在启动)、OUT_OF_SERVICE(下线)、UNKNOWN(为止) 公益 Eureka Server如果不想在本机启动 Eureka Server，SpringCloud 中文社区提供了一个公益的 Eureka Server：http://eureka.springcloud.cn/，在使用时只需要将 defaultZone 替换为 http://eureka.springcloud.cn/eureka 即可。 不过需要注意的是，虽然省去了启动 Eureka Server 的时间，节省了维护 Eureka Server 的资源，但是这个 Eureka Server 是一个单节点的，如果想要测试 Eureka Server 的集群高可用，还是需要在本机启动多个 Eureka Server。 公益的 Eureka Server 只能使用在本机测试中，禁止在测试环境、成产环境上使用，否则将暴露 ip、端口，造成严重的安全隐患。]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>SpringCloud</tag>
        <tag>Eureka</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring Cloud 微服务（2） 微服务与 Spring Cloud]]></title>
    <url>%2Fjava%2F2019%2F01-16%2Fspring-cloud-2.html</url>
    <content type="text"><![CDATA[应用是可以独立运行的程序代码，提供相对完善的业务功能。架构分为：业务架构、应用架构、技术架构。业务架构决定应用架构，技术架构支撑应用架构。架构的发展历程：单体架构 --&gt; 分布式架构 --&gt; SOA 架构 --&gt; 微服务架构 微服务概述单体应用架构单体架构可以理解为一个 Java Web 工程，包含：表现成、业务层、数据访问层。从 Controller 到 Service 到 Dao，没有任何应用拆分，开发完毕后打包成一个大型的 war 部署。 优点 便于发开：开发人员使用当前开发工具在短时间内就可以完成开发 便于测试：不需要依赖其他接口，节约时间 便于部署：只需将 war 部署到运行环境即可 缺点 灵活度不够：如果程序有任何修改，需要自上而下全部修改，测试的时候也不要整个程序部署完才能看到效果。在开发过程中，可能会需要等待其他开发人员开发完成才能进行自己开发的内容。 降低系统性能：原本可以直接访问数据库，但多出了一个 Service 层 启动慢：一个进程中包含了所以的业务逻辑，涉及的模块过多 扩展性差：增加新的功能不能针对单个点增加，要全局性的增加，牵一发动全身 分布式架构按照业务垂直切分，每个应用都是单体架构，通过 API 互相调用 面向服务的 SOA 架构SOA 架构有两个主要角色：服务的提供者（provider）、服务的消费者（consumer）。阿里的 Dubbo 的 SOA 的一个典型实现 优点 模块拆分，使用接口通信，降低了模块之间的耦合度 把一个大项目拆分成多个子项目，可以并行开发 增加功能时只需要增加一个子项目，调用其他系统接口即可 可以灵活分布式部署 缺点 系统之间需要远程通信，增加了开发的工作量 微服务架构微服务架构是一种架构风格，对于大型复杂的业务系统，可以将业务功能拆分成多个相互独立的微服务，各个微服务之间是松耦合的，通过各种远程协议进行同步/异步通信，各个微服务可单独部署，扩容/缩容以及升级/降级。 微服务技术选型对比 Spring Cloud Dubbo Motan MSEC 其他 功能 微服务完整方案 服务治理框架 服务治理框架 服务开发运营框架 略 通信方式 REST / http RPC 协议 RPC / Hessian2 Protocol Buffers gRPC、thrift 服务发现 / 注册 Eureka（AP） ZK、Nacos ZK / Consul 只有服务发现 Etcd 负载均衡 Ribbon 客户端负载 客户端负载 客户端负载 Ngnix + Lua 容错机制 6 种 6 种 2 种 自动容错 keepalived、heartbeat 熔断机制 Hystrix 无 无 过载保护 无 配置中心 Spring Cloud Config Nacos 无 无 Apollo、Nacos 网关 Zuul、Gateway 无 无 无 Kong、自研 服务监控 Hystrix + Turbine Dubbo + Monitor 无 Monitor ELK 链路监控 Sleuth + Zipkik 无 无 无 Pinpoint 多语言 REST 支持多语言 Java Java Java、C++、PHP Java、PHP、Node.js 社区活跃度 高（Spring） 高（阿里） 一般 未知 略 基于 Spring Cloud 的微服务解决方案 组件方案1方案2方案3服务发现EurekaConsuletcd、Nacos共用组件服务调用：Feign、负载均衡：Ribbon、熔断器：Hystrix网关Zuul：性能低，SpringCloud Gateway：性能高自研配置中心SpringCloud Config、携程 Apollo、阿里 Nacos全链路监控Zipkin、Pinpoint、SkyWalking（推荐）其他分布式事务、Docker、gRPC、领域驱动 Halo 基于 Dubbo 的解决方案使用 Dubbo + Nacos。Nacos 是阿里开源的一个构建云原生应用的动态服务发现、配置、服务管理平台。 Spring CloudSpring Cloud 介绍中间件：中间件是一种独立的系统软件或服务程序，分布式应用软件借助这种软件在不同的技术之间共享资源。中间件位于客户机/ 服务器的操作系统之上，管理计算机资源和网络通讯。是连接两个独立应用程序或独立系统的软件。常见的中间件分别是：服务治理(如 RPC)、配置中心、全链路监控、分布式事务、分布式定时任务、消息中间件、API 网关、分布式缓存、数据库中间件等。 Spring Cloud 像是一个中间件，基于 Spring Boot 开发，提供一套完整的微服务解决方案。包括服务注册与发现、配置中心、全链路监控、API 网关、熔断器 等选型的中立的开源组件，可以随需扩展和替换组装。 Spring Cloud 项目模块 组件名称 所属项目 组件分类 Eureka spring-cloud-netflix 注册中心 Zuul spring-cloud-netflix 第一代网关 Sidecar spring-cloud-netflix 多语言支持 Ribbon spring-cloud-netflix 负载均衡 Hystrix spring-cloud-netflix 熔断器 Turbine spring-cloud-netflix 集群监控 Feign spring-cloud-openfeign 声明式的 HTTP 客户端 Consul spring-cloud-consul 注册中心 Gateway spring-cloud-gateway 第二代网关 Sleuth spring-cloud-sleuth 链路监控 Config spring-cloud-config 配置中心 Bus spring-cloud-bus 总线 Pipeline spring-cloud-pipelines 部署管道 Dataflow spring-cloud-dataflow 数据处理 Stream spring-cloud-stream 消息驱动 服务治理中间件服务治理中间件包含：服务注册与发现、服务路由、负载均衡、自我保护、管理机制等。其中，服务路由包含：服务上下线、在线测试、机房就近选择、AB测试、灰度发布等。负载均衡包含：支持根据目标状态和目标权重进行负载均衡。自我保护包含：服务降级、优雅降级、流量控制 注册中心对比 特性 Consul Zookeeper etcd Eureka 服务健康检查 服务状态、内存、硬盘等 (弱)长连接、keepalive 连接心跳 可配置支持 多数据中心 支持 - - - kv 存储服务 支持 支持 支持 - 一致性 raft paxos raft - CAP CA CP CP AP 多语言支持 https、dns 客户端 http/grpc http(sidecar) watch支持 全量/支持long polling 支持 支持long polling 支持 long polling/大部分增量 自身健康 metrics - metrics metrics 安全 acl/https acl https支持(弱) - Spring Cloud 集成 支持 支持 支持 支持 Spring Cloud 配置中心功能需求场景支持： 面向全公司，充分考虑各部门需求，支持不同语言接入，充分考虑兼容性 运维集成： 统一数据源标准化运维流程 权限管理： 接入权限、审核权限、下发权限… Spring Cloud API 网关API 网关是出现在系统边界上的一个面向 API 的、串行集中式的强管控服务，可以理解为应用的防火墙，主要起隔离外部访问与内部系统的作用。主要为了解决访问认证、报文转发、访问统计等问题。 API 网关需要提供的功能： 统一接入功能：为各种服务提供统一接入服务，提供三高(高可用、高并发、高可靠)的网关服务，还需要支持负载均衡、容灾切换、异地多活协议适配：对外提供 HTTP、HTTPS 访问，对内提供各种协议，如：HTTP、HTTPS、RPC、REST 等流量监控：当大流量请求时，进行流量监控、流量挑拨；当后端出现异常时，需要进行服务熔断、服务降级；在异地多活中，需要进行流量分片等。网关防护：所有请求进行安全过滤，对 IP 黑名单、URL 黑名单封禁、风控防刷、防恶意攻击等。 Zuul、Gateway 的比较||Zuul|Gateway||:-:|:-:|:-:||实现难度|低|高||底层|http、https、rest|Netty||灰度、降级、标签路由、限流、WAF封禁|需要自定义 Filter|配置||安全、监控/埋点|自定义 Intercepter|自定义配置| Spring Cloud 全链路监控全链路监控需要包含的功能： 定位慢调用：慢 web 服务、慢 rest/rpc 服务、慢 SQL定位错误：4XX、5XX、Service Error定位异常：Error Exception、Fatal Exception展现依赖和拓扑：域拓扑、服务拓扑、trace 拓扑trace 调用链：将端到端的调用以及附加的上下文信息、异常日志信息、每个调用点的耗时都进行展示应用警告：根据设置的警告规则，扫描指标数据，并进行信息上报]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>SpringCloud</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring Cloud 微服务（1） 思维导图]]></title>
    <url>%2Fjava%2F2019%2F01-16%2Fspring-cloud-1.html</url>
    <content type="text"><![CDATA[Spring Cloud 微服务系列脑图：点此查看]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>SpringCloud</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring Batch 学习（8） JobLauncher、JobOperator、事务处理]]></title>
    <url>%2Fjava%2F2018%2F12-24%2Fspring-batch-study-8.html</url>
    <content type="text"><![CDATA[现在是所有实例，都是在 SpringBoot 中，在启动项目的同时，进行任务、步骤的构建，任务的启动。但是有时需要在一个 Controoler、或者一个 Scheduler 中进行任务的调度，这时使用现在的方式就不合适了。 在 SpringBoot 中禁用 batch 自启动在 application.yml 文件中，将 spring.batch.job.enabked 设置为 false，即可禁用自启动 SpringBatch，但是任务仍然会构造，只是不会自动执行。 JobLauncherJobLaunch 是手动启动 SpringBatch 任务的启动类。需要参数：任务实例、任务执行中的参数(JobParameters) 实现方式：在需要启动任务的地方，如：Controoler 中注入 JobLauncher，构建 JobParameters，启动指定的任务 1234567891011121314151617181920212223242526@RestControllerpublic class JobController &#123; @Autowired private JobLauncher jobLauncher; @Autowired private Job job; @GetMapping(value = "/job/&#123;msg&#125;") public String jobRun1(@PathVariable String msg)&#123; // 构建 JobParameters JobParameters jobParameters = new JobParametersBuilder() .addString("msg", msg) .toJobParameters(); // 启动任务，并把参数传给任务 try &#123; jobLauncher.run(jobLauncherDemoJob, jobParameters); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; return "job success"; &#125;&#125; 需要注意的点： 构建的 JobParameters 会在调用 jobLauncher.run 时，实例化到数据库中，如果执行过一次之后，再次执行需要保证参数不一样，否则会任务该任务已经执行过，不能再次执行。 如果有多个 Job，需要使用 @Qualifier 指定要注入的 Job 这种方式启动任务，任务的运行是 同步 的，不是异步的。 异步 JobLauncher：异步的 JobLauncher 需要手动设置线程池、任务执行的 repository 持久化123456789101112@Autowiredprivate JobRepository jobRepository;@Beanpublic JobLauncher jobLauncher() &#123; SimpleJobLauncher jobLauncher = new SimpleJobLauncher(); // jobRepository 需要注入 jobLauncher.setJobRepository(jobRepository); // 使用 Spring 线程池，可以自定义 jobLauncher.setTaskExecutor(new SimpleAsyncTaskExecutor()); return jobLauncher;&#125; 自定义线程池：12345678910111213@Beanpublic Executor getExecutor()&#123; ThreadPoolTaskExecutor executor = new ThreadPoolTaskExecutor(); executor.setCorePoolSize(20); executor.setMaxPoolSize(100); executor.setQueueCapacity(150); executor.setWaitForTasksToCompleteOnShutdown(true); executor.setAwaitTerminationSeconds(60); executor.setThreadNamePrefix("batch-"); executor.setRejectedExecutionHandler(new DiscardOldestPolicy()); executor.initialize(); return executor;&#125; JobOperatorJobOperator 可以任务是对 JobLauncher 的再次封装，所有在 JobOperator 中需要注入 JobLauncher 构建 JobOperator123456789101112131415161718192021222324252627 @Autowiredprivate JobLauncher jobLauncher;@Autowiredprivate JobRepository jobRepository;@Autowiredprivate JobExplorer jobExplorer;@Autowiredprivate JobRegistry jobRegistry;@Beanpublic JobOperator jobOperator()&#123; SimpleJobOperator jobOperator = new SimpleJobOperator(); // 注入 JobLauncher jobOperator.setJobLauncher(jobLauncher); // 设置参数转换器 jobOperator.setJobParametersConverter(new DefaultJobParametersConverter()); // 注入 jobRepository 持久化 jobOperator.setJobRepository(jobRepository); // 注入 任务注册器 jobOperator.setJobRegistry(jobRegistry); // 注入任务探测器 jobOperator.setJobExplorer(jobExplorer); return jobOperator;&#125; 构建 jobRegistry Processor12345678910111213141516171819202122public class JobOperatorConfig implements ApplicationContextAware &#123; private ApplicationContext applicationContext; @Bean public JobRegistryBeanPostProcessor jobRegistry()&#123; JobRegistryBeanPostProcessor processor = new JobRegistryBeanPostProcessor(); processor.setJobRegistry(jobRegistry); processor.setBeanFactory(applicationContext.getAutowireCapableBeanFactory()); try &#123; processor.afterPropertiesSet(); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; return processor; &#125; @Override public void setApplicationContext(ApplicationContext applicationContext) throws BeansException &#123; this.applicationContext = applicationContext; &#125;&#125; 执行任务12345try &#123; jobOperator.start("jobName", "msg="+msg);&#125; catch (NoSuchJobException | JobInstanceAlreadyExistsException | JobParametersInvalidException e) &#123; e.printStackTrace();&#125; JobLauncher 与 JobOperator 的比较 执行方法： JobLauncher 使用 run 方法执行，JobOperator 使用 start 方法执行任务注入： JobLauncher 使用 Job 实例注入，JobOperator 使用任务名称注入参数传递： JobLauncher 使用 JobParameters 传递，JobOperator 使用字符串传递、且参数传递方式为 key1=value1&amp;key2=value2…参数转换： JobLauncher 不需要转换，JobOperator 需要设置参数转换器才能转换为 JobParameters 事务处理 – 重中之重在一些批处理任务重，可能会需要用到数据库。如果用到了数据库的读、写操作，就一定会牵扯到事务问题。 在 SpringBoot 中的事务处理在构建 Job 时，需要显式注入需要使用的事务处理器，并传入 Step。 12345678910111213141516171819@Beanpublic Job jobDemo(PlatformTransactionManager transactionManager)&#123; return jobBuilderFactory.get("jobDemo") .start(steoDemo(transactionManager)) .build();&#125;@Beanpublic Step steoDemo(PlatformTransactionManager transactionManager) &#123; return stepBuilderFactory.get("steoDemo") .transactionManager(transactionManager) .tasklet(new Tasklet() &#123; @Override public RepeatStatus execute(StepContribution stepContribution, ChunkContext chunkContext) throws Exception &#123; System.out.println("childJobStep1"); return RepeatStatus.FINISHED; &#125; &#125;).build();&#125; 这种方式是使用 SpringBatch 的自带事务处理器进行事务处理，但是在一些集成了 Hibernate、MyBatis 的系统中，需要用到 Hibernate、MyBatis 的事务处理器。如果此时，使用的是 SpringBoot 项目，且事务处理器没有自定义的话，是没有用问题的。如果是使用的 SpringMVC 进行任务调用，且自定义了事务处理器，这时可能出现问题。 在 SpringMVC 自定义事务处理器的问题自定义事务处理器：123456789101112131415161718192021&lt;!-- 定义事务 --&gt;&lt;bean id="txAdvice" class="org.springframework.orm.hibernate5.HibernateTransactionManager"&gt; &lt;property name="sessionFactory" ref="sessionFactory" /&gt;&lt;/bean&gt;&lt;tx:annotation-driven transaction-manager="txAdvice"/&gt;&lt;!-- 拦截器方式配置事物 --&gt;&lt;tx:advice id="transactionAdvice" transaction-manager="txAdvice"&gt; &lt;tx:attributes&gt; &lt;tx:method name="update*" propagation="REQUIRED" /&gt; &lt;tx:method name="add*" propagation="REQUIRED" /&gt; &lt;tx:method name="save*" propagation="REQUIRED" /&gt; &lt;tx:method name="edit*" propagation="REQUIRED" /&gt; &lt;tx:method name="delete*" propagation="REQUIRED" /&gt; &lt;tx:method name="del*" propagation="REQUIRED"/&gt; &lt;tx:method name="remove*" propagation="REQUIRED" /&gt; &lt;tx:method name="repair*" propagation="REQUIRED"/&gt; &lt;tx:method name="*" read-only="true" /&gt; &lt;/tx:attributes&gt;&lt;/tx:advice&gt; 在批处理任务中，没有显示注入事务处理器，此时在执行批处理时，会有如下问题： 控制台错误打印12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788892018-12-24 15:05:11.809 WARN [NettyClientWorkerThread_1][NettyRemotingAbstract.java:258] - RemotingCommand [code=17, language=JAVA, version=252, opaque=10, flag(B)=1, remark=No topic route info in name server for the topic: TBW102See http://rocketmq.apache.org/docs/faq/ for further details., extFields=null, serializeTypeCurrentRPC=JSON]2018-12-24 15:05:11.811 ERROR [SimpleAsyncTaskExecutor-2][AbstractStep.java:229] - Encountered an error executing step firstStepOfFindSite in job batchGenerateChannelJoborg.springframework.transaction.CannotCreateTransactionException: Could not open Hibernate Session for transaction; nested exception is java.lang.IllegalStateException: Already value [org.springframework.jdbc.datasource.ConnectionHolder@76ce6385] for key [&#123; CreateTime:"2018-12-24 15:01:21", ActiveCount:2, PoolingCount:18, CreateCount:20, DestroyCount:0, CloseCount:30, ConnectCount:32, Connections:[ &#123;ID:428371115, ConnectTime:"2018-12-24 15:01:21", UseCount:0, LastActiveTime:"2018-12-24 15:01:21"&#125;, ... &#123;ID:1832136599, ConnectTime:"2018-12-24 15:01:22", UseCount:0, LastActiveTime:"2018-12-24 15:01:22"&#125; ]&#125;[ &#123; ID:428371115, poolStatements:[ ] &#125;, ... &#123; ID:1832136599, poolStatements:[ ] &#125;]] bound to thread [SimpleAsyncTaskExecutor-2] at org.springframework.orm.hibernate5.HibernateTransactionManager.doBegin(HibernateTransactionManager.java:542) ~[spring-orm-4.3.18.RELEASE.jar:4.3.18.RELEASE] at org.springframework.transaction.support.AbstractPlatformTransactionManager.getTransaction(AbstractPlatformTransactionManager.java:377) ~[spring-tx-4.3.18.RELEASE.jar:4.3.18.RELEASE] at org.springframework.transaction.interceptor.TransactionAspectSupport.createTransactionIfNecessary(TransactionAspectSupport.java:461) ~[spring-tx-4.3.18.RELEASE.jar:4.3.18.RELEASE] at org.springframework.transaction.interceptor.TransactionAspectSupport.invokeWithinTransaction(TransactionAspectSupport.java:277) ~[spring-tx-4.3.18.RELEASE.jar:4.3.18.RELEASE] at org.springframework.transaction.interceptor.TransactionInterceptor.invoke(TransactionInterceptor.java:96) ~[spring-tx-4.3.18.RELEASE.jar:4.3.18.RELEASE] at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179) ~[spring-aop-4.3.18.RELEASE.jar:4.3.18.RELEASE] at com.alibaba.druid.support.spring.stat.DruidStatInterceptor.invoke(DruidStatInterceptor.java:72) ~[druid-1.1.6.jar:1.1.6] at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179) ~[spring-aop-4.3.18.RELEASE.jar:4.3.18.RELEASE] at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:213) ~[spring-aop-4.3.18.RELEASE.jar:4.3.18.RELEASE] at com.sun.proxy.$Proxy79.getOne(Unknown Source) ~[?:?] at com.dahe.wang.batch.BatchGenerateConfig$2.execute(BatchGenerateConfig.java:195) ~[classes/:?] at org.springframework.batch.core.step.tasklet.TaskletStep$ChunkTransactionCallback.doInTransaction(TaskletStep.java:406) ~[spring-batch-core-3.0.9.RELEASE.jar:3.0.9.RELEASE] at org.springframework.batch.core.step.tasklet.TaskletStep$ChunkTransactionCallback.doInTransaction(TaskletStep.java:330) ~[spring-batch-core-3.0.9.RELEASE.jar:3.0.9.RELEASE] at org.springframework.transaction.support.TransactionTemplate.execute(TransactionTemplate.java:133) ~[spring-tx-4.3.18.RELEASE.jar:4.3.18.RELEASE] at org.springframework.batch.core.step.tasklet.TaskletStep$2.doInChunkContext(TaskletStep.java:272) ~[spring-batch-core-3.0.9.RELEASE.jar:3.0.9.RELEASE] at org.springframework.batch.core.scope.context.StepContextRepeatCallback.doInIteration(StepContextRepeatCallback.java:81) ~[spring-batch-core-3.0.9.RELEASE.jar:3.0.9.RELEASE] at org.springframework.batch.repeat.support.RepeatTemplate.getNextResult(RepeatTemplate.java:374) ~[spring-batch-infrastructure-3.0.9.RELEASE.jar:3.0.9.RELEASE] at org.springframework.batch.repeat.support.RepeatTemplate.executeInternal(RepeatTemplate.java:215) ~[spring-batch-infrastructure-3.0.9.RELEASE.jar:3.0.9.RELEASE] at org.springframework.batch.repeat.support.RepeatTemplate.iterate(RepeatTemplate.java:144) ~[spring-batch-infrastructure-3.0.9.RELEASE.jar:3.0.9.RELEASE] at org.springframework.batch.core.step.tasklet.TaskletStep.doExecute(TaskletStep.java:257) ~[spring-batch-core-3.0.9.RELEASE.jar:3.0.9.RELEASE] at org.springframework.batch.core.step.AbstractStep.execute(AbstractStep.java:200) [spring-batch-core-3.0.9.RELEASE.jar:3.0.9.RELEASE] at org.springframework.batch.core.job.SimpleStepHandler.handleStep(SimpleStepHandler.java:148) [spring-batch-core-3.0.9.RELEASE.jar:3.0.9.RELEASE] at org.springframework.batch.core.job.AbstractJob.handleStep(AbstractJob.java:392) [spring-batch-core-3.0.9.RELEASE.jar:3.0.9.RELEASE] at org.springframework.batch.core.job.SimpleJob.doExecute(SimpleJob.java:135) [spring-batch-core-3.0.9.RELEASE.jar:3.0.9.RELEASE] at org.springframework.batch.core.job.AbstractJob.execute(AbstractJob.java:306) [spring-batch-core-3.0.9.RELEASE.jar:3.0.9.RELEASE] at org.springframework.batch.core.launch.support.SimpleJobLauncher$1.run(SimpleJobLauncher.java:135) [spring-batch-core-3.0.9.RELEASE.jar:3.0.9.RELEASE] at java.lang.Thread.run(Thread.java:748) [?:1.8.0_171]Caused by: java.lang.IllegalStateException: Already value [org.springframework.jdbc.datasource.ConnectionHolder@76ce6385] for key [&#123; CreateTime:"2018-12-24 15:01:21", ActiveCount:2, PoolingCount:18, CreateCount:20, DestroyCount:0, CloseCount:30, ConnectCount:32, Connections:[ &#123;ID:428371115, ConnectTime:"2018-12-24 15:01:21", UseCount:0, LastActiveTime:"2018-12-24 15:01:21"&#125;, ... &#123;ID:1832136599, ConnectTime:"2018-12-24 15:01:22", UseCount:0, LastActiveTime:"2018-12-24 15:01:22"&#125; ]&#125;[ &#123; ID:428371115, poolStatements:[ ] &#125;, ... &#123; ID:1832136599, poolStatements:[ ] &#125;]] bound to thread [SimpleAsyncTaskExecutor-2] at org.springframework.transaction.support.TransactionSynchronizationManager.bindResource(TransactionSynchronizationManager.java:190) ~[spring-tx-4.3.18.RELEASE.jar:4.3.18.RELEASE] at org.springframework.orm.hibernate5.HibernateTransactionManager.doBegin(HibernateTransactionManager.java:516) ~[spring-orm-4.3.18.RELEASE.jar:4.3.18.RELEASE] ... 26 more 使用 debeug，在第一个进行数据库操作的位置打断点，可以看到 debugger 下的如下错误： debugger 显示：不能创建事务。 错误原因： SpringBatch 默认使用 jdbc 的事务管理器，而没有使用自定义的 Hibernate 事务管理器。这时，在整个项目中，同时存在 Hibernate 和 Jdbc 的事务管理器，SpringBatch 无法判断使用哪个事务管理器，导致事务嵌套，从而抛出异常。 SpringBatch 会使用名为 transactionManager 的事务管理器，而在本例中， xml 设置的事务管理器，名为 txAdvice，从而导致出现多事务。 解决办法： 将声明式事务 txAdvice 名称修改为 transactionManager 即可。 在 Spring + SpringBatch 项目中，要严防出现事务嵌套！！！]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>SpringBatch</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Activiti 工作流引擎（7） 流程分支、排他网关、动态处理人]]></title>
    <url>%2Fjava%2F2018%2F12-17%2Factiviti-7.html</url>
    <content type="text"><![CDATA[除了一个流程进行到底的工作流之外，还有一些有分支的工作流。如：下属在申报审批一条信息的时候，如果这条信息不算太重要，可以由经理审批；如果这条信息重要，需要由老板进行审批。 这时，就需要有流程分支。流程分支的作用就是处理一个流程中存在多个子分支时，根据不同的子分支条件，进行不同的子分支处理。 在流程图连线中确定条件依照上图做出一个有分支的流程，在这个流程中，处理当天信息有 2 个分支，一个是 不重要 的信息交给经理处理，而 重要 的分支交给老板处理。无论谁处理过，这个流程都结束。 流程图中确定条件点击分支流程：处理当天信息 —&gt; 经理(老板) 的连线， 在Name中填入备注信息，在Condition中填入条件信息。需要注意： 1、Condition必须为布尔类型；2、判断条件必须作为参数在执行中传入；3、尽量不使用中文 Condition：满足这个条件的时候，走这一步流程。即：满足 ${message==&#39;no&#39;} 走经理流程；满足${message==&#39;yes&#39;}走老板流程。 代码示例流程部署、启动不再示例。直接从流程分支开始。12345String taskId = "85005";Map&lt;String, Object&gt; params = new HashMap&lt;&gt;();params.put("message", "yes");processEngine.getTaskService().complete(taskId, params);System.out.println("执行“老板”分支，执行完毕"); 在执行任务时，直接传入 message，需要保证 message 与 Condition 一致。如果在传入message时，指定的值与Contidition不一致，在本例中即message传入值不是 yes/no，这时在执行时，由于判断条件错误，会导致后台报错，但流程不会进行。 错误信息：1234567891011121314org.activiti.engine.ActivitiException: No outgoing sequence flow of element '_4' could be selected for continuing the process at org.activiti.engine.impl.agenda.TakeOutgoingSequenceFlowsOperation.leaveFlowNode(TakeOutgoingSequenceFlowsOperation.java:172) at org.activiti.engine.impl.agenda.TakeOutgoingSequenceFlowsOperation.handleFlowNode(TakeOutgoingSequenceFlowsOperation.java:87) at org.activiti.engine.impl.agenda.TakeOutgoingSequenceFlowsOperation.run(TakeOutgoingSequenceFlowsOperation.java:75) at org.activiti.engine.impl.interceptor.CommandInvoker.executeOperation(CommandInvoker.java:73) at org.activiti.engine.impl.interceptor.CommandInvoker.executeOperations(CommandInvoker.java:57) at org.activiti.engine.impl.interceptor.CommandInvoker.execute(CommandInvoker.java:42) at org.activiti.engine.impl.interceptor.TransactionContextInterceptor.execute(TransactionContextInterceptor.java:48) at org.activiti.engine.impl.interceptor.CommandContextInterceptor.execute(CommandContextInterceptor.java:63) at org.activiti.engine.impl.interceptor.LogInterceptor.execute(LogInterceptor.java:29) at org.activiti.engine.impl.cfg.CommandExecutorImpl.execute(CommandExecutorImpl.java:44) at org.activiti.engine.impl.cfg.CommandExecutorImpl.execute(CommandExecutorImpl.java:39) at org.activiti.engine.impl.TaskServiceImpl.complete(TaskServiceImpl.java:186) at com.laiyy.activiti.config.SequenceFlow.sequenceFlowStart(SequenceFlow.java:40) _4 是执行这个任务的流程id，bpmn 文件中指定的处理当天信息这个步骤的 id。即在执行流程分支时，由于判断条件出错，导致流程不能往下执行。 排他网关排他网关主要用于在一个流程中，存在多个分支流程，但是无默认分支的情况。可以解决上面例子中出现的Condition不匹配的问题。在不能匹配Condition时进入默认流程分支。 如在银行办理业务时，有 普通窗口、VIP窗口 和银行的 后台窗口，在申请办理业务人为后台用户时，走 后台窗口，为 VIP 用户时，走 VIP窗口，其余默认走 普通窗口。与上例中的 经理/老板 流程不同的是，在 普通窗口 的流程中，是没有判断条件的。这是一个简单的排他网关。 此时按照上例中的代码继续执行时，会发现，如果 visitor 满足 3，则进入后台窗口，满足 2 则进入 vip窗口，否则都进入普通窗口 动态指定处理人可以使用类似于el表达式的方式：$userId，设置一个变量，在处理过程中动态的给这个变量赋值，即可实现动态指定。 设置处理人在进行流程处理时，设置下一步执行人1234567891011121314151617181920Map&lt;String, Object&gt; params =~ new HashMap&lt;&gt;();params.put("userId", "zhangsan");ProcessInstance processInstance = processEngine.getRuntimeService() .startProcessInstanceByKey(processDefikey, params);// 执行结束后，根据处理人查看任务信息String user = "zhangsan";// 获取任务服务TaskService taskService = processEngine.getTaskService();// 创建任务查询对象TaskQuery taskQuery = taskService.createTaskQuery();// 指定办理人，获取办理人的任务列表List&lt;Task&gt; list = taskQuery.taskAssignee(user).list();// 连理任务列表if (!CollectionUtils.isEmpty(list)) &#123;for (Task task : list) &#123; System.out.println("任务办理人：" + task.getAssignee() + " --&gt; 任务id：" + task.getId() + " --&gt; 任务名称：" + task.getName());&#125;]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Activiti</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Activiti 工作流引擎（6） 历史流程、流程变量]]></title>
    <url>%2Fjava%2F2018%2F12-14%2Factiviti-6.html</url>
    <content type="text"><![CDATA[Activiti 不仅仅能执行流程、获取到当前流程的信息，也可以获取到已经执行过的流程信息、任务信息。历史任务：流程执行的每一步都是一个任务，历史任务列表是所有流程的每一步执行情况。需要用到的表：act_hi_taskinst、act_hi_procinst 查询历史流程 查看历史执行实例： 代码示例1234567891011HistoryService historyService = processEngine.getHistoryService();List&lt;HistoricProcessInstance&gt; list = historyService.createHistoricProcessInstanceQuery().list();if (!CollectionUtils.isEmpty(list)) &#123; list.forEach(item -&gt; &#123; System.out.println("流程实例id" + item.getId()); System.out.println("流程实例定义id" + item.getProcessDefinitionId()); System.out.println("流程开始时间" + item.getStartTime()); System.out.println("流程结束时间" + item.getEndTime()); System.out.println("================="); &#125;);&#125; 查看历史任务（每一步） 代码实例1234567891011HistoryService historyService = processEngine.getHistoryService();List&lt;HistoricTaskInstance&gt; list = historyService.createHistoricTaskInstanceQuery().list();if (!CollectionUtils.isEmpty(list))&#123; list.forEach(item -&gt; &#123; System.out.println("历史流程实例id：" + item.getId()); System.out.println("历史流程定义id：" + item.getTaskDefinitionKey()); System.out.println("任务名称：" + item.getName()); System.out.println("处理人：" + item.getAssignee()); System.out.println("================"); &#125;);&#125; 流程变量如：在支付流程中，支付 —&gt; 填写金额 —&gt; 确认/取消，在确认/取消时，需要查看到当前支付金额，这个金额就是在支付流程中的变量。 流程变量设计到的表：1、act_ru_variable：正在执行的流程变量表2、act_hi_varinst：流程变量历史表 设置流程变量值可以设置普通的 POJO，但是需要实现序列化接口 通过 taskService 设置变量 通过 setVariable 设置12345678910111213141516/** * 通过 set 设置 */// taskId 任务id，范围比 runtime 小// variableName 变量名// value 变量值taskService.setVariable(taskId, variableName, value);// 设置本执行对象的变量，该对象的作用域只在当前的执行对象taskService.setVariableLocal(taskId, variableName, value);// 设置多个变量，values： Map&lt;String, Object&gt;taskService.setVariables(taskId, values);/** * 完成任务时设置 */taskService.complete(taskId, values [, localScope]) 通过 runtimeService 设置1234567891011121314151617/** * 通过 set 设置 */// executionId 执行对象id// variableName 变量名// value 变量值runtimeService.setVariable(executionId, variableName, value);// 设置本执行对象的变量，该对象的作用域只在当前的执行对象runtimeService.setVariableLocal(executionId, variableName, value);// 设置多个变量，values： Map&lt;String, Object&gt;runtimeService.setVariables(executionId, values);/** * 启动时设置 */// processKey 任务 key， values Map&lt;String, Object&gt;runtimeService.startProcessInstanceByKey(processKey, values) 获取流程变量使用 taskService 获取流程变量123runtimeService.getVariable(executionId, key) 去单个变量runtimeService.getVariableLocal(executionId, key) 取本执行对象的单个变量runtimeService.getVariables(executionId) // 取多个变量 使用 runtimeService 获取流程变量123taskService.getVariable(taskId, key)taskService.getVariableLocal(taskId, key)taskService.getVariables(taskId) 变量支持的类型 简单类型 String、boolean、Integer、double、Date 等 自定义对象 自定义的 POJO]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Activiti</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Activiti 工作流引擎（5） 流程定义]]></title>
    <url>%2Fjava%2F2018%2F12-07%2Factiviti-5.html</url>
    <content type="text"><![CDATA[在上两篇博文中，已经介绍了如何创建、启动、完成一个流程，以及在流程运转过程中的一些注意点和需要用到的表结构的分析。那么，一个流程定义该如何管理？比如流程删除、流程中变量的使用、指定任务处理人等操作该如何操作？ 流程定义管理涉及对象、表 流程定义中涉及到的对象主要是 ProcessEngine、RepositoryService、Deployment、ProcessDefinition，即：Activiti 核心类和仓库服务。ProcessDefinition：解析 .bpmn 文件后得到的流程定义规则信息，工作流就是按照流程定义的规则执行的。Deployment：部署对象，一次部署多个文件的信息。对于不需要的流程可以删除和修改。涉及到的表结构主要有： act_re_deployment：部署对象表 act_re_procdef：流程定义表 act_ge_bytearray：资源文件表 act_ge_property：主键生成策略表 查询流程、资源新建一个采购审批流程，如图： 以 Zip 形式上传并自解压12345678InputStream inputStream = getClass().getClassLoader().getResourceAsStream("BuyBill.zip");RepositoryService repositoryService = processEngine.getRepositoryService();Deployment deploy = repositoryService.createDeployment() .name("采购流程") // 以 zip 形式上传 bpmn 文件 .addZipInputStream(new ZipInputStream(inputStream)) .deploy();System.out.println(deploy.getId() + " --&gt; " + deploy.getName()); 查看流程定义信息1234567891011121314151617181920212223// 查看流程定义ProcessDefinitionQuery query = processEngine.getRepositoryService().createProcessDefinitionQuery();// 查询（类比 SQL 的 where 条件）// 流程定义的id，myProcess_1:2:22503，组成方式： key + 版本 + 自动生成的id// query = query.processDefinitionId("myProcess_1:2:22503");// 流程定义的 key，有 bpmn 文件的 key 决定query.processDefinitionKey("myProcess_1");// 流程定义名称// query.processDefinitionName("");// 流程定义版本// query.processDefinitionVersion(1);// 最新版本// query.latestVersion();// 版本降序排序List&lt;ProcessDefinition&gt; list = query.orderByProcessDefinitionVersion().desc() // 总数// .count() // 列表 .list();if (!CollectionUtils.isEmpty(list))&#123; list.forEach( temp -&gt; System.out.println("流程定义id：" + temp.getId() + " ---&gt; 流程定义key：" + temp.getKey() + " ---&gt; 流程版本：" + temp.getVersion() + " 部署id：" + temp.getDeploymentId() + " 流程定义名称：" + temp.getName()));&#125; 查询资源文件并拷贝到本地123456789101112// 通过部署资源的 deployment id 获取资源String resourceName = "";String deploymentId = "22501";List&lt;String&gt; resourceNames = processEngine.getRepositoryService().getDeploymentResourceNames(deploymentId);if (!CollectionUtils.isEmpty(resourceNames)) &#123; resourceName = resourceNames.get(0); // 读取资源，根据 deploy id 和 资源名称 InputStream inputStream = processEngine.getRepositoryService().getResourceAsStream(deploymentId, resourceName); // 拷贝到本地 File file = new File("d:/" + resourceName); FileUtils.copyInputStreamToFile(inputStream, file);&#125; 删除流程定义 通过部署 id 删除流程定义 12String deployId = "2501";processEngine.getRepositoryService().deleteDeployment(deployId); 操作成功后，act_re_deploy、act_ge_bytearray、act_re_procdef 表中会级联删除相关数据。但是 act_hi_* 中保存的是历史记录，历史记录不会删除。 流程实例、任务的执行主要核心类：Execution、ProcessInstance、Task Execution：执行对象，按照流程定义的规则执行一次的过程。 对应的表： act_ru_exection：正在执行的信息 act_hi_procinst：已经执行完的历史流程实例信息 act_hi_actinst：存放历史所有完成的活动 ProcessInstance：流程实例，特质流程从开始导结束的最大执行分支。一个执行的流程中，流程实例只有一个。 需要注意： 如果是单例流程，执行对象 id 就是流程实例 id 如果一个流程有分值和聚合，那么执行对象 id 和流程实例 id 就不相同 一个流程中，流程实例只有一个，执行对象可以存在多个 Task 任务：执行到某任何环节时生成的任务信息。 对应的表： act_ru_task：正在执行的任务 act_hi_taskinst：已经执行完的历史任务信息 理解流程实例和执行对象流程实例和执行对象是两个不通的概念，可以粗略理解为，执行对象是由流程实例创建的。在一个流程中，流程的实例只能有一个，即：一个流程就是一个实例。但是执行对象可以有多个，即：一个流程可以委派给多个执行对象去执行这个流程。 举个例子：一个人执行跑步 —&gt; 打球 —&gt; 回家 流程，如果此时在 跑步 完成之后，有一个快递需要拿，拿完直接回家的话，就是一个 跑步 —&gt; 拿快递 —&gt; 回家 流程。在这个流程里面，此人只能执行其中一个流程，但是 打球、拿快递 都在主流程：跑步 —&gt;… —&gt; 回家 中。但是如果在 拿快递 这个流程执行的时候，把这个流程交给了一个朋友去执行，自己还可以继续去打球的。在这个例子里面，跑步 —&gt; 打球(拿快递) —&gt; 回家 是一个流程实例。 执行打球、拿快递 的是执行对象。 即：一个流程只能有一个实例，但是可以交给多个对象去执行。]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Activiti</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Activiti 工作流引擎（4） 启动流程]]></title>
    <url>%2Fjava%2F2018%2F12-06%2Factiviti-4.html</url>
    <content type="text"><![CDATA[ProcessEngine 的几个重要的 Service RepositoryService：管理流程的定义 RuntimeService：执行管理，包括流程的启动、推进、删除流程实例等操作 TaskService：任务管理 HistoryService：历史管理（执行完的数据管理） IdentityService：可选服务，任务表单管理 启动流程在上一篇末尾，已经实现了使用 RepositoryService 定义、部署一个流程。部署完成的流程需要使用 RuntimeService 来启动 代码示例12345678// 执行流程 -- 执行流程属于运行，需要获取运行时服务 RuntimeServiceRuntimeService runtimeService = processEngine.getRuntimeService();// startProcessInstanceById 使用 act_re_procdef 中的 ID_ 字段，该字段自动生成，不便于理解// startProcessInstanceByKey 使用 act_re_procdef 中的 KEY_ 字段，该字段手动执行，便于理解，但是需要格外注意不能重复// 如果一个流程进行了多次修改，那么 KEY_ 和 NAME_ 必须一样，且运行时执行最后一个 VERSION_ 版本// 取得流程实例ProcessInstance instance = runtimeService.startProcessInstanceByKey("levelBill");System.out.println("流程实例id：" + instance.getId() + " ---&gt; 流程定义id： " + instance.getProcessDefinitionId()); 控制台打印结果为：1流程实例id：5001 ---&gt; 流程定义id： levelBill:2:2503 查看 act_ru_execution PROC_INST_ID_：对应 act_ge_property 中的 next.dbid 的值 PARENT_ID_：对应上一步的 act_ru_execution 的 ID_ ROOT_PROC_INST_ID_：对应运行实例的 id ACT_ID_：对应当前流程进行到哪一步了 PROC_DEF_ID_：对应流程定义的 id(act_re_procdef 中的 ID_) 任务查询在第一步启动任务后，任务流程自动进入第一步中。在本例中，相当于 请假流程已经开始，需要 zhangsan 进行审批。那么，就需要获取 zhangsan 的任务列表。 获取任务列表，顾名思义就需要任务服务，通过任务服务查询出任务列表 代码示例1234567891011121314// 任务办理人（第一步是zhangsan办理）String user = "zhangsan";// 获取任务服务TaskService taskService = processEngine.getTaskService();// 创建任务查询对象TaskQuery taskQuery = taskService.createTaskQuery();// 指定办理人，获取办理人的任务列表List&lt;Task&gt; list = taskQuery.taskAssignee(user).list();// 连理任务列表if (!CollectionUtils.isEmpty(list))&#123; for (Task task : list) &#123; System.out.println("任务办理人：" + task.getAssignee() + " --&gt; 任务id：" + task.getId() + " --&gt; 任务名称：" + task.getName()); &#125;&#125; 在控制台中可以看到，需要张三办理的任务完整打印：12任务办理人：zhangsan --&gt; 任务id：5005 --&gt; 任务名称：first任务办理人：zhangsan --&gt; 任务id：7505 --&gt; 任务名称：first 对照数据库查询 act_ru_task 表，可以看到当前正在执行的流程数据 EXECUTION_ID：流程实例的id，对应 act_ru_exection 的 ID_ PROC_DEF_ID_：流程定义的id，对应 act_re_procdef 的 ID_ TASK_DEF_KEY_：当前流程 id，对应 act_ru_exection 的 ACT_ID_ ASSIGNEE_：执行人，对应 BPMN 文件中指定的当前流程执行人 NAME_：任务名称，对应 BPMN 文件中指定的当前流程的名称 任务完成完成一个任务，即结束当前步骤，进入下一个步骤（并不是完成整改流程） 代码示例123456// 完成这个任务，即：当前步骤完成，进行下一个步骤String taskId = "5005"; // 指定需要完成的任务 id// 完成任务，也需要任务服务TaskService taskService = processEngine.getTaskService();// 完成任务taskService.complete(taskId); 对照数据库查询 act_ru_task 表 与上面任务执行后获取到的表进行对比，可以看到，ID_、NAME_、TASK_DEK_KEY_、ASSIGENEE_ 均已变更为当前步骤的数据，而上一步的数据已经自动删除。 自动删除执行过的步骤，可以保证正在运行的任务表足够小，无冗余，可以更大程度的保证流程处理的效率 任务结束如果修改 taskId，运行任务完成操作，在最后一步以后，会自动完成流程。完成后的流程，在 act_ru_task、act_ru_execution 是没有记录的，因为这些流程已经完成，不是进行中的状态。这样做可以保证运行中的任务表足够小，效率足够快。 任务结束后，历史流程可以在 act_hi_* 中查看到。]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Activiti</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Activiti 工作流引擎（3） 添加一个简单的工作流]]></title>
    <url>%2Fjava%2F2018%2F12-06%2Factiviti-3.html</url>
    <content type="text"><![CDATA[创建一个简单的工作流引擎，需要准备：数据库、工作流文件（BPMN）。创建工作流的基本流程： 构建 ProcessEngineConfiguration 对象 –&gt; 设置数据库连接 –&gt; 设置数据库表创建属性 –&gt; 构建一个流程引擎。其中：ProcessEngineConfiguration 对象，是构建一个简单工作流的核心 API。为了简单的示例操作，使用 Junit 创建测试用例创建即可。 创建简单的工作流引擎创建工作流引擎的三个方法： 使用 ProcessEngineConfiguration 硬编码配置数据库连接创建 使用 ProcessEngineConfiguration + activiti.cfg.xml 文件创建 使用 ProcessEngines 默认配置创建 使用 ProcessEngineConfiguration 创建使用 ProcessEngineConfiguration 创建工作流引擎时，需要指定好数据库、库表创建策略等1234567891011121314151617// 1、取得 ProcessEngineConfiguration 对象ProcessEngineConfiguration configuration = ProcessEngineConfiguration.createStandaloneProcessEngineConfiguration();// 2、设置数据库属性configuration.setJdbcDriver("com.mysql.jdbc.Driver");configuration.setJdbcUrl("jdbc:mysql:///activiti?createDatabaseIfNotExist=true&amp;useUnicode=true&amp;charsetEncoding=utf8&amp;serverTimezone=Hongkong");configuration.setJdbcUsername("root");configuration.setJdbcPassword("123456");// 3、设置创建表的策略，没有表时自动创建// DB_SCHEMA_UPDATE_TRUE 没有表时自动创建// DB_SCHEMA_UPDATE_FALSE 不自动创建// DB_SCHEMA_UPDATE_CREATE_DROP 先删除表再自动创建configuration.setDatabaseSchemaUpdate(ProcessEngineConfiguration.DB_SCHEMA_UPDATE_TRUE);// 创建流程引擎processEngine = configuration.buildProcessEngine();System.out.println("流程创建成功"); 使用 ProcessEngineConfiguration + activiti.cfg.xml 文件创建此种创建方式，实际上是将数据库的链接配置，设置在了 xml 文件中。 activiti.cfg.xml 文件1234567891011121314&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd"&gt; &lt;!-- ProcessEngineConfiguration 是一个抽象类，不能作为一个 Bean，需要指定具体的实现类作为 Bean --&gt; &lt;bean id="processEngineConfiguration" class="org.activiti.engine.impl.cfg.StandaloneProcessEngineConfiguration"&gt; &lt;property name="jdbcUrl" value="jdbc:mysql:///activiti?createDatabaseIfNotExist=true&amp;amp;useUnicode=true&amp;amp;charsetEncoding=utf8&amp;amp;serverTimezone=Hongkong" /&gt; &lt;property name="jdbcDriver" value="com.mysql.jdbc.Driver" /&gt; &lt;property name="jdbcUsername" value="root" /&gt; &lt;property name="jdbcPassword" value="123456" /&gt; &lt;property name="databaseSchemaUpdate" value="true" /&gt; &lt;/bean&gt;&lt;/beans&gt; 代码示例123ProcessEngineConfiguration configuration = ProcessEngineConfiguration.createProcessEngineConfigurationFromResource("activiti.cfg.xml");processEngine = configuration.buildProcessEngine();System.out.println("流程创建成功"); 使用 ProcessEngines 默认配置创建使用 ProcessEngines 默认配置，实际上和 使用 xml 配置是一样的，因为使用 ProcessEngines 时会默认读取 activiti.cfg.xml 文件 12processEngine = ProcessEngines.getDefaultProcessEngine();System.out.println("流程创建成功"); ProcessEngines 重点源码分析：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374// 默认配置ProcessEngines.getDefaultProcessEngine();// 获取默认配置public static ProcessEngine getDefaultProcessEngine() &#123; return getProcessEngine("default");&#125;// 是否已经初始化public static boolean isInitialized() &#123; return isInitialized;&#125;// 获取默认配置public static ProcessEngine getProcessEngine(String processEngineName) &#123; // 此时调用肯定是没有初始化的，所以会调用 init 方法 if (!isInitialized()) &#123; init(); &#125; return processEngines.get(processEngineName);&#125;// 初始化方法public synchronized static void init() &#123; // 此时 isInitialized 为 false if (!isInitialized()) &#123; // 如果 processEngines 为空，重新构造 if (processEngines == null) &#123; // Create new map to store process-engines if current map is // null processEngines = new HashMap&lt;String, ProcessEngine&gt;(); &#125; ClassLoader classLoader = ReflectUtil.getClassLoader(); Enumeration&lt;URL&gt; resources = null; try &#123; // 获取默认的 activiti.cfg.xml 配置 resources = classLoader.getResources("activiti.cfg.xml"); &#125; catch (IOException e) &#123; // 如果获取不到会报错 throw new ActivitiIllegalArgumentException("problem retrieving activiti.cfg.xml resources on the classpath: " + System.getProperty("java.class.path"), e); &#125; // Remove duplicated configuration URL's using set. Some // classloaders may return identical URL's twice, causing duplicate // startups // 解析 xml 文件 Set&lt;URL&gt; configUrls = new HashSet&lt;URL&gt;(); while (resources.hasMoreElements()) &#123; configUrls.add(resources.nextElement()); &#125; for (Iterator&lt;URL&gt; iterator = configUrls.iterator(); iterator.hasNext();) &#123; URL resource = iterator.next(); log.info("Initializing process engine using configuration '&#123;&#125;'", resource.toString()); initProcessEngineFromResource(resource); &#125; try &#123; // 获取 activiti-context.xml（和 activiti.cfg.xml 一样，不过是名字规定的不一样） resources = classLoader.getResources("activiti-context.xml"); &#125; catch (IOException e) &#123; throw new ActivitiIllegalArgumentException("problem retrieving activiti-context.xml resources on the classpath: " + System.getProperty("java.class.path"), e); &#125; while (resources.hasMoreElements()) &#123; URL resource = resources.nextElement(); log.info("Initializing process engine using Spring configuration '&#123;&#125;'", resource.toString()); initProcessEngineFromSpringResource(resource); &#125; // 设置 isInitialized 为 true，标记为已初始化 setInitialized(true); &#125; else &#123; log.info("Process engines already initialized"); &#125;&#125; 部署一个简单的工作流在创建工作流成功，并且创建 BPMN 文件后，可以进行流程的部署。流程部署需要用到仓库服务，即 RepositoryService 部署操作代码示例123456789// 获取仓库服务：管理定义流程RepositoryService repositoryService = processEngine.getRepositoryService();// 创建部署Deployment deploy = repositoryService.createDeployment() // 返回部署的构建器 .addClasspathResource("LevelBill.bpmn") // 从类路径下添加资源 .name("LevelBill：请假单流程") // 设置部署的名字 .category("办公类别") // 设置类别 .deploy(); // 部署System.out.println("部署成功后返回的 id：" + deploy.getId() + "，部署的名称：" + deploy.getName()); 查看部署结果 查看 act_re_deployment 表 查看 act_re_prrocdef 表 bpmn 文件：1&lt;process id="levelBill" isClosed="false" isExecutable="true" name="LevelBill" processType="None"&gt; 其中： KEY_ 指向 BPMN 文件中 的 id， NAME_ 指向 BPMN 文件中的 name，_DEPLOYMENT_ID_ 指向 act_re_deployment 表的 id，RESOURCE_NAME_ 指向 构建 deploy 时的 classpathResource 的值 查看 act_ge_property 表 其中：next.dbid 的值VALUE_ 即为下一步运行部署操作时，act_re_deployment 的 id。 再次运行部署操作再次运行部署操作，查看 act_ge_property 和 act_re_deployment 表，可以看到 act_ge_property 的 next.dbid 的值变了，且 act_re_deployment 的中 id 变为上一次运行后 act_ge_property 的 next.dbid 的值。]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Activiti</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Activiti 工作流引擎（2） 使用 IDEA 创建工作流]]></title>
    <url>%2Fjava%2F2018%2F12-06%2Factiviti-2.html</url>
    <content type="text"><![CDATA[安装 actiBPM 插件在 IDEA 中选择： File –&gt; Setting –&gt; Plugins –&gt; Browse repositories –&gt; 查询 actiBPM 并下载安装 创建一个 BPM 文件 在 resources（静态文件存储路径）上右键新建，选择 BpmnFile 或者 BPMN File 进行创建 设置流程一个已经设置好的流程： 常用的几个控制器： startEvent：流程开始 endEvent：流程结束 UserTask：用户操作任务 ScriptTask：脚本操作任务 ServiceTask：业务操作任务 MailTask：邮件任务 将右侧控制器拖拽至中间白板上，即可设置控制器属性。然后将鼠标放在控制器中央位置，会有一个圆点，选中圆点下拉至另外一个控制器，即可设置流程顺序。 设置整个 bpmn 文件属性点击空白处，可在右侧看到整个 bpmn 文件属性，可以根据自己的实际需求进行设置 常用属性： Id：可以看做 BPMN 在整个流程中的文件唯一标识 Name： 可以看做 BPMN 文件的别名（实际名称是创建 BPMN 文件时的名称） 设置开始、结束控制器点击开始、结束控制器，可根据自己实际需求设置控制器属性 常用属性： Id：这个开始、结束控制器的 id，尽量不要更改 Name：这个开始、结束控制器的名称，更改后可以在中间图标出立即显示；也可以双击图标进行更改 设置中间流程控制器点击中间流程控制器，设置控制器属性 常用属性： Id：流程控制器 Id，尽量不要更改 Name： 控制器的名称，更改后可以在中间图标出立即显示；也可以双击图标进行更改 Assignee：谁管理这个流程控制器（可以是用户、角色等） 设置 BPMN 需要注意的点：在流程控制器中，Id 尽量不要更改。如果更改的话，必须要保证 id 不能重复，否则会出现同一个 id 对应两个流程控制，导致无法确定进行哪一步的流程，这样会出现错误。 bpmn 文件将 bpmn 文件以文本形式打开，可以发现，bpmn 文件实际上是一个 xml 文件。以刚才创建好的 bpmn 文件为例123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687&lt;?xml version="1.0" encoding="UTF-8" standalone="yes"?&gt;&lt;definitions xmlns="http://www.omg.org/spec/BPMN/20100524/MODEL" xmlns:activiti="http://activiti.org/bpmn" xmlns:bpmndi="http://www.omg.org/spec/BPMN/20100524/DI" xmlns:dc="http://www.omg.org/spec/DD/20100524/DC" xmlns:di="http://www.omg.org/spec/DD/20100524/DI" xmlns:tns="http://www.activiti.org/testm1544000001944" xmlns:xsd="http://www.w3.org/2001/XMLSchema" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" expressionLanguage="http://www.w3.org/1999/XPath" id="m1544000001944" name="" targetNamespace="http://www.activiti.org/testm1544000001944" typeLanguage="http://www.w3.org/2001/XMLSchema"&gt; &lt;!-- id 即为刚才设置的 “整个 BPMN 文件” 的 id， name 为 Name --&gt; &lt;process id="levelBill" isClosed="false" isExecutable="true" name="LevelBill" processType="None"&gt; &lt;!-- 开始节点， id 为 _2， name 为 start --&gt; &lt;startEvent id="_2" name="start"/&gt; &lt;!-- 用户操作节点，id 为 _3，name 为 first，操作人为 zhangsan --&gt; &lt;userTask activiti:assignee="zhangsan" activiti:exclusive="true" id="_3" name="first"/&gt; &lt;userTask activiti:assignee="lsii" activiti:exclusive="true" id="_5" name="second"/&gt; &lt;userTask activiti:assignee="wangwu" activiti:exclusive="true" id="_7" name="third"/&gt; &lt;!-- 结束节点，id为 _9，name 为 end --&gt; &lt;endEvent id="_9" name="end"/&gt; &lt;!-- 流程控制（即两个控制器之间的箭头连线），从 _2 步骤指向 _3 步骤，即第一步为 _2：start，第二步为 _3：first --&gt; &lt;sequenceFlow id="_4" sourceRef="_2" targetRef="_3"/&gt; &lt;sequenceFlow id="_6" sourceRef="_3" targetRef="_5"/&gt; &lt;sequenceFlow id="_8" sourceRef="_5" targetRef="_7"/&gt; &lt;!-- 流程控制，从 _7 步骤执行 _9，即最后一步为 从 _7：third 向 _9：end 流通 --&gt; &lt;sequenceFlow id="_10" sourceRef="_7" targetRef="_9"/&gt; &lt;/process&gt; &lt;!-- 下方为 bpmn 各节点样式、坐标等，通过拖拽自动生成，可改文件微调 --&gt; &lt;bpmndi:BPMNDiagram documentation="background=#3C3F41;count=1;horizontalcount=1;orientation=0;width=842.4;height=1195.2;imageableWidth=832.4;imageableHeight=1185.2;imageableX=5.0;imageableY=5.0" id="Diagram-_1" name="New Diagram"&gt; &lt;bpmndi:BPMNPlane bpmnElement="levelBill"&gt; &lt;!-- 每个节点的位置、宽高等调整，bpmnElement 指向节点 id --&gt; &lt;bpmndi:BPMNShape bpmnElement="_2" id="Shape-_2"&gt; &lt;dc:Bounds height="32.0" width="32.0" x="450.0" y="70.0"/&gt; &lt;bpmndi:BPMNLabel&gt; &lt;dc:Bounds height="32.0" width="32.0" x="0.0" y="0.0"/&gt; &lt;/bpmndi:BPMNLabel&gt; &lt;/bpmndi:BPMNShape&gt; &lt;bpmndi:BPMNShape bpmnElement="_3" id="Shape-_3"&gt; &lt;dc:Bounds height="55.0" width="85.0" x="425.0" y="160.0"/&gt; &lt;bpmndi:BPMNLabel&gt; &lt;dc:Bounds height="55.0" width="85.0" x="0.0" y="0.0"/&gt; &lt;/bpmndi:BPMNLabel&gt; &lt;/bpmndi:BPMNShape&gt; &lt;bpmndi:BPMNShape bpmnElement="_5" id="Shape-_5"&gt; &lt;dc:Bounds height="55.0" width="85.0" x="425.0" y="260.0"/&gt; &lt;bpmndi:BPMNLabel&gt; &lt;dc:Bounds height="55.0" width="85.0" x="0.0" y="0.0"/&gt; &lt;/bpmndi:BPMNLabel&gt; &lt;/bpmndi:BPMNShape&gt; &lt;bpmndi:BPMNShape bpmnElement="_7" id="Shape-_7"&gt; &lt;dc:Bounds height="55.0" width="85.0" x="425.0" y="370.0"/&gt; &lt;bpmndi:BPMNLabel&gt; &lt;dc:Bounds height="55.0" width="85.0" x="0.0" y="0.0"/&gt; &lt;/bpmndi:BPMNLabel&gt; &lt;/bpmndi:BPMNShape&gt; &lt;bpmndi:BPMNShape bpmnElement="_9" id="Shape-_9"&gt; &lt;dc:Bounds height="32.0" width="32.0" x="455.0" y="465.0"/&gt; &lt;bpmndi:BPMNLabel&gt; &lt;dc:Bounds height="32.0" width="32.0" x="0.0" y="0.0"/&gt; &lt;/bpmndi:BPMNLabel&gt; &lt;/bpmndi:BPMNShape&gt; &lt;!-- 两个节点之间的链接，bpmnElement 指向流程链接 id --&gt; &lt;bpmndi:BPMNEdge bpmnElement="_4" id="BPMNEdge__4" sourceElement="_2" targetElement="_3"&gt; &lt;di:waypoint x="466.0" y="102.0"/&gt; &lt;di:waypoint x="466.0" y="160.0"/&gt; &lt;bpmndi:BPMNLabel&gt; &lt;dc:Bounds height="0.0" width="0.0" x="0.0" y="0.0"/&gt; &lt;/bpmndi:BPMNLabel&gt; &lt;/bpmndi:BPMNEdge&gt; &lt;bpmndi:BPMNEdge bpmnElement="_6" id="BPMNEdge__6" sourceElement="_3" targetElement="_5"&gt; &lt;di:waypoint x="467.5" y="215.0"/&gt; &lt;di:waypoint x="467.5" y="260.0"/&gt; &lt;bpmndi:BPMNLabel&gt; &lt;dc:Bounds height="0.0" width="0.0" x="0.0" y="0.0"/&gt; &lt;/bpmndi:BPMNLabel&gt; &lt;/bpmndi:BPMNEdge&gt; &lt;bpmndi:BPMNEdge bpmnElement="_8" id="BPMNEdge__8" sourceElement="_5" targetElement="_7"&gt; &lt;di:waypoint x="467.5" y="315.0"/&gt; &lt;di:waypoint x="467.5" y="370.0"/&gt; &lt;bpmndi:BPMNLabel&gt; &lt;dc:Bounds height="0.0" width="0.0" x="0.0" y="0.0"/&gt; &lt;/bpmndi:BPMNLabel&gt; &lt;/bpmndi:BPMNEdge&gt; &lt;bpmndi:BPMNEdge bpmnElement="_10" id="BPMNEdge__10" sourceElement="_7" targetElement="_9"&gt; &lt;di:waypoint x="471.0" y="425.0"/&gt; &lt;di:waypoint x="471.0" y="465.0"/&gt; &lt;bpmndi:BPMNLabel&gt; &lt;dc:Bounds height="0.0" width="0.0" x="0.0" y="0.0"/&gt; &lt;/bpmndi:BPMNLabel&gt; &lt;/bpmndi:BPMNEdge&gt; &lt;/bpmndi:BPMNPlane&gt; &lt;/bpmndi:BPMNDiagram&gt;&lt;/definitions&gt;]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Activiti</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Activiti 工作流引擎（1） 工作流基础了解]]></title>
    <url>%2Fjava%2F2018%2F12-05%2Factiviti-1.html</url>
    <content type="text"><![CDATA[什么是工作流工作流（Workflow），指“业务过程的部分或整体在计算机应用环境下的自动化”。是对工作流程及其各操作步骤之间业务规则的抽象、概括描述。在计算机中，工作流属于计算机支持的协同工作（CSCW）的一部分。后者是普遍地研究一个群体如何在计算机的帮助下实现协同工作的。工作流主要解决的主要问题是：为了实现某个业务目标，利用计算机在多个参与者之间按某种预定规则自动传递文档、信息或者任务。 常见的工作流的地方 OA 审批功能 电子政务上传下达 物流运输流程记录 … 使用工作流和不使用工作流的区别以学校请假为例，如果一个学生请假需要经过以下流程： 填写请见条 –&gt; 提交给老师 –&gt; 老师审批（通过，不通过） –&gt; 提交到年级处 –&gt; 年级处审批（通过，不通过） –&gt; 提交给教务处 –&gt; 教务处审批 （通过，不通过） –&gt; 提交到校长 –&gt; 校长审批（通过，不通过） –&gt; 结束 Activiti 工作流常见的开源工作流引擎框架有：OSWrokFlow、jBPM（jboss business process management）、Activiti（对 jBPM 的升级）、Spring WorkFlow 等 Activiti 的简单认识ProcessEngineProcessEngine 是 Activiti 的核心工作类，可以由该类获取到其他服务（历史服务、仓库服务、任务服务、角色 / 参与者服务） 历史服务：之前运行过的所有流程即为历史服务仓库服务：定义好的流程需要保存到一个仓库中（一般为数据库），该数据库中保存的流程，解析该流程的服务即为仓库服务任务服务：定义好的流程中的每一步即为一个任务服务角色 / 参与者服务：执行流程中步骤的人、角色，即为一个 角色 / 参与者服务 BPMNBPMN： 业务流程建模与标注（Business Process Model and Notation），描述流程的基本符号，包括这些土元如果组成一个业务流程图（Business Process Diagram） 以一个简单的业务流程图为例： 第一个圆圈代表流程开始，审批流程为： 提交 -&gt; 经纪人 -&gt; 老总，最后一个加粗的圆圈代表流程结束。每一个起始点、流程审批点、结束点，都是一个最基本的 BPMN，这些点组合在一起，整个图可以称为一个最基本的 业务流程图。 配置文件activiti.cfg.xml： Activiti 核心配置文件，配置流程引擎创建工具的基本参数和数据库连接参数 logging.properties： log4j 日志打印 数据库表Activiti 数据库总共有 23 张表，所有表都是以 ACT_ 开头，第二部分表示表的用途，一般用两个字母标示，用于和服务的 API 对应。 act_ge_* ： 通用数据，用于不同场景下，如：存放资源文件 act_hi_* ： hi 代表 history。包含历史数据，比如：历史流程实例、变量、任务等 act_re_* ： re 代表 repository。这个前缀的表包含了定义流程和流程静态资源（图片、规则等） act_ru_* ： ru 代表 runtime。包含了流程实例、任务、变量、异步任务等运行中的数据。Activiti 只在了流程实例执行过程中保存这些数据，在流程结束后就会删除这些记录，这样可以保证运行时表一直很小，速度很快） act_id_* ： id 代表 identity。包含身份信息，比如：用户、组等 流程规则表: act_re_* 表名 作用 act_re_deployment 部署信息 act_re_model 流程设计模型部署表 act_re_procdef 流程定义数据表 运行时数据库表：act_ru_* 表名 作用 act_ru_execution 运行时流程执行实例表 act_ru_identitylink 运行时流程人员表，主要存储任务节点与参与者的相关信息 act_ru_task 运行时任务节点表 act_ru_variable 运行时流程变量数据表 历史数据库表： act_hi_* 表名 作用 act_hi_actinst 历史节点表 act_hi_attachment 历史附件表 act_hi_comment 历史意见表 act_hi_identitylink 历史流程人员表 act_hi_detail 历史详情表，提供历史变量的查询 act_hi_procinst 历史流程实例表（常用） act_hi_taskinst 历史任务实例表（常用） act_hi_varinst 历史变量表（常用） 组织结构表：act_id_* 表名 作用 act_id_group 用户组信息 act_id_info 用户扩展信息 act_id_membership 用户与用户组队员信息 act_id_user 用户信息 通用数据表： act_ge_* 表名 作用 act_ge_bytearray 二进制数据表 act_ge_property 属性数据表，存储整个流程引擎级别的数据，初始化时会默认插入三条数据]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Activiti</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring Batch 学习（7） 错误处理]]></title>
    <url>%2Fjava%2F2018%2F12-03%2Fspring-batch-study-7.html</url>
    <content type="text"><![CDATA[SpringBatch 错误处理SpringBatch 的错误处理，大致分为：错误中断，重启后继续执行，错误重试，错误跳过 等 错误中断，重启后继续执行：在每次 chunk 后在 ExecutionContext 中打入标记，在重启执行该任务时，判断 ExecutionContext 中是否存在标记，如果存在，则从标记位重新读取执行 错误重试：在出现错误时，根据指定的需要重试的异常，进行重新读写处理，需要指定：需要重试的异常、重试次数 错误跳过：在出现错误时，根据指定的需要跳过的异常，跳过该条数据，需要指定：需要跳过的异常，跳过次数 错误中断，重启后继续执行在 读、处理、写 操作中任何一环出现问题都可以将任务中断 此项操作，需要 ItemReader、ItemWriter 实现 ItemStreamReader、ItemStreamWriter 接口，在实现类中定义规则 ItemStreamReader、ItemStreamWriter实现接口后有以下几个方法需要重写： read()：读取 / 写入 数据的规则 open(ExecutionContext executionContext)：在开始读取 / 写入 之前调用，用于第一次执行 或 重启后继续执行时的判断 update(ExecutionContext executionContext)：在 chunk 后执行，用于修改数据库中对 ExecutionContext 的记录 close()：读取 / 写入 结束后执行 代码示例数据来源(file1.txt)：1234&quot;1&quot;,&quot;Kabul&quot;,&quot;AFG&quot;,&quot;Kabol&quot;,&quot;1780000&quot;&quot;2&quot;,&quot;Qandahar&quot;,&quot;AFG&quot;,&quot;Qandahar&quot;,&quot;237500&quot;&quot;3&quot;,&quot;Herat&quot;,&quot;AFG&quot;,&quot;Herat&quot;,&quot;186800&quot;&quot;4&quot;,&quot;Mazar-e-Sharif&quot;,&quot;AFG&quot;,&quot;Balkh&quot;,&quot;127800&quot; 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108public class RestartReader implements ItemStreamReader&lt;City&gt; &#123; /** * 文件读取 */ private FlatFileItemReader&lt;City&gt; reader = new FlatFileItemReader&lt;&gt;(); /** * 当前读到第几行 */ private Long curLine = 0L; /** * 是否重启 */ private boolean restart = false; /** * 执行的上下文 */ private ExecutionContext executionContext; public RestartReader() &#123; reader.setResource(new ClassPathResource("file1.txt")); DelimitedLineTokenizer tokenizer = new DelimitedLineTokenizer(); tokenizer.setNames("id", "name", "countryCode", "district", "population"); // 解析后的数据映射为对象 DefaultLineMapper&lt;City&gt; mapper = new DefaultLineMapper&lt;&gt;(); mapper.setLineTokenizer(tokenizer); mapper.setFieldSetMapper(new FieldSetMapper&lt;City&gt;() &#123; @Override public City mapFieldSet(FieldSet fieldSet) throws BindException &#123; City city = new City(); city.setCountryCode(fieldSet.readString("countryCode")); city.setDistrict(fieldSet.readString("district")); city.setId(fieldSet.readInt("id")); city.setName(fieldSet.readString("name")); city.setPopulation(fieldSet.readLong("population")); return city; &#125; &#125;); // 数据校验 mapper.afterPropertiesSet(); // 绑定映射 reader.setLineMapper(mapper); &#125; @Override public City read() throws Exception, UnexpectedInputException, ParseException, NonTransientResourceException &#123; City city = null; // 每次读取数据，当前行 +1 this.curLine++; if (restart) &#123; // 如果是重启（出现错误之后），则从 chunk 记录行开始读取 reader.setLinesToSkip(this.curLine.intValue() - 1); // 将重启值置为 false，否则将会重复读取 restart = false; System.out.println("Start reading from line: " + this.curLine); &#125; reader.open(this.executionContext); city = reader.read();// 模拟出现错误：读到第 100 行数据时出错// if (city != null &amp;&amp; this.curLine == 100) &#123;// throw new RuntimeException("Something Wrong!");// &#125; return city; &#125; /** * 在开始读取之前调用 */ @Override public void open(ExecutionContext executionContext) throws ItemStreamException &#123; // 获取当前执行上下文 this.executionContext = executionContext; if (executionContext.containsKey("curLine")) &#123; // 如果执行上下文存在 cutLine，则证明执行为 重启后执行 this.curLine = executionContext.getLong("curLine"); // 将重启值置为 true this.restart = true; &#125; else &#123; // 第一次执行，向执行上下文中打入 curLine 记录（会记录进数据库） this.curLine = 0L; executionContext.put("curLine", 0L); System.out.println("Start reading from line: " + (this.curLine + 1)); &#125; &#125; /** * 在每次读取 chunk 条数据后调用 */ @Override public void update(ExecutionContext executionContext) throws ItemStreamException &#123; // 每次 chunk 后，重新打入 curLine 为当前行（会记录进数据库） executionContext.put("curLine", this.curLine); System.out.println("Reading line: " + (this.curLine + 1)); &#125; @Override public void close() throws ItemStreamException &#123; &#125;&#125; 错误重试 在 读、处理、写 操作中任何一环出现问题都可以重新执行出现错误的 chunk 代码示例模拟在 Processor 中出现错误123456789101112131415161718192021@Componentpublic class RetryProcessor implements ItemProcessor&lt;String, String&gt; &#123; private int attemptCount = 0; @Override public String process(String item) throws Exception &#123; System.out.println("processing item :" + item); // 模拟错误：如果需要处理的数据为字符串 26，判断重试次数，如果重试次数大于等于 3 次，则数据处理成功，否则抛出异常，处理处理失败 if ("26".equalsIgnoreCase(item)) &#123; attemptCount++; if (attemptCount &gt;= 3) &#123; System.out.println("Retried " + attemptCount + "times success"); return String.valueOf(Integer.valueOf(item) * -1); &#125; System.out.println("Processed the " + attemptCount + " times fail"); throw new RuntimeException("Process failed. Attempt: " + attemptCount); &#125; return String.valueOf(Integer.valueOf(item) * -1); &#125;&#125; 在 Step 中进行错误重试操作1234567891011121314151617181920212223242526@Bean@StepScopepublic ListItemReader&lt;String&gt; reader()&#123; List&lt;String&gt; items = new ArrayList&lt;&gt;(); for (int index = 0; index&lt; 60; index++)&#123; items.add(""+index); &#125; return new ListItemReader&lt;&gt;(items);&#125;@Beanpublic Step retryDemoStep()&#123; return stepBuilderFactory.get("retryDemoStep") .&lt;String, String&gt;chunk(10) .reader(reader()) .processor(retryItemProcessor) .writer(retryItemWriter) // 容错 .faultTolerant() // 发生哪个异常时进行重试 .retry(RuntimeException.class) // 重试几次 .retryLimit(10) .build();&#125; 在此时，运行程序后，会发现控制台打印 0-20，30-60 都正常，但是在带引 20 - 30 的数据时，由于在 26 处出现了错误，会多次打印 20-25，和错误信息：”Processed the “ + attemptCount + “ times fail” 由此可证明错误重试 成功 错误跳过 在 读、处理、写 操作中任何一环出现问题都可以重新执行出现错误的 chunk 代码示例出现的错误还是以上例中的错误为本例错误 123456789101112131415@Beanpublic Step skipDemoStep()&#123; return stepBuilderFactory.get("skipDemoStep") .&lt;String, String&gt;chunk(10) .reader(reader()) .processor(retryItemProcessor) .writer(retryItemWriter) // 容错 .faultTolerant() // 跳过 .skip(RuntimeException.class) // 跳过次数 .skipLimit(10) .build();&#125; 此时运行代码，可以发现，当 26 错误错误时，processor 自动略过，在 ItemWriter 中并没有打印信息，控制台打印信息为： … 23 24 25 27 29 … 由此可看出 26 被成功跳过，则错误跳过成功 错误处理监听器错误处理监听器：可以在执行批处理时，在出现错误的地方通过监听器，监听错误信息，如：read error、write error、processor error 常见的错误处理监听器 SkipListener：错误跳过监听 RetryListener：错误重试监听，该 listener 本身不提供操作，由以下几个子 Listener 提供操作 RetryProcessListener：processor error 消息监听 RetryWriteListener：write error 消息监听 RetryReadListener：read error 消息监听 代码示例出现错误的方式还是以上例中的 字符串 26 错误为例 以 SkipListener 为例 1234567891011121314151617181920212223242526272829303132@Componentpublic class MySkipListener implements SkipListener&lt;String, String&gt; &#123; /** * 读取跳过 * @param throwable 发生的异常 */ @Override public void onSkipInRead(Throwable throwable) &#123; &#125; /** * 写入错误 * @param s 写入的数据 * @param throwable 发生的异常 */ @Override public void onSkipInWrite(String s, Throwable throwable) &#123; &#125; /** * 在处理流程中出现的异常 * @param s 出现异常的数据 * @param throwable 出现的异常 */ @Override public void onSkipInProcess(String s, Throwable throwable) &#123; System.out.println(s + " ----&gt; " + throwable.getLocalizedMessage()); &#125;&#125; Listener 使用：1234567891011121314@Beanpublic Step skipListenerStep()&#123; return stepBuilderFactory.get("skipListenerStep") .&lt;String, String&gt;chunk(10) .reader(reader()) .writer(skipItemWriter) .processor(skipItemProcessor) .faultTolerant() .skip(RuntimeException.class) // 指定错误处理 Listener .listener(skipListener) .skipLimit(10) .build();&#125;]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>SpringBatch</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring Batch 学习（6） ItemWriter]]></title>
    <url>%2Fjava%2F2018%2F12-03%2Fspring-batch-study-6.html</url>
    <content type="text"><![CDATA[ItemWriterItemWriter：批处理之后的数据需要做怎样的写操作（写入文件、数据库、mongodb等） 常用的几个 ItemWriter JdbcItemWriter：使用 jdbc 写入数据库 HibernateWriter：使用 Hibernate 写入数据库 JpaItemWriter：使用 JPA 写入数据库 JsonFileItemWriter：将数据转为 JSON 写入文本文件 FlatFileItemWriter：将数据转为合适格式的字符串，写入文本文件 StaxEventItemWriter：将数据通过 oxm 框架的 XStream 写入 xml 文件 CompositeItemWriter：写入多个文件 ClassifierCompositeItemWriter：文件分类写入 …. ItemWriter 简单示例（控制台打印数据）123456789public class MyWriter implements ItemWriter&lt;String&gt; &#123; @Override public void write(List&lt;? extends String&gt; list) throws Exception &#123; // 打印数据长度 System.out.println(list.size()); // 遍历打印信息 list.stream().forEach(System.out::println); &#125;&#125; FlatFileItemWriterFlatFileItemWriter：将数据转为一定格式的字符串，将转换后的字符串写入文本文件中 代码示例使用 Jackson，将数据实体转为 Json 字符串，写入文本（数据来源：1234567891011121314151617181920212223@Beanpublic FlatFileItemWriter&lt;City&gt; cityItemWriter()&#123; FlatFileItemWriter&lt;City&gt; writer = new FlatFileItemWriter&lt;&gt;(); String path = "d:\\city.txt"; writer.setResource(new FileSystemResource(path)); writer.setLineAggregator(new LineAggregator&lt;City&gt;() &#123; @Override public String aggregate(City city) &#123; try &#123; return new ObjectMapper().writeValueAsString(city); &#125; catch (JsonProcessingException e) &#123; e.printStackTrace(); &#125; return ""; &#125; &#125;); try &#123; writer.afterPropertiesSet(); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; return writer;&#125; StaxEventItemWriterStaxEventItemWriter 结合 oxm 框架的 XStream，可以将数据转换位 xml 文件输出 代码示例12345678910111213141516171819202122232425262728@Beanpublic StaxEventItemWriter&lt;City&gt; xmlItemWriter()&#123; StaxEventItemWriter&lt;City&gt; writer = new StaxEventItemWriter&lt;&gt;(); // xml 处理器 XStreamMarshaller marshaller = new XStreamMarshaller(); // 指定根节点 Map&lt;String, Class&gt; aliases = new HashMap&lt;&gt;(1); aliases.put("city", City.class); marshaller.setAliases(aliases); // setMarshaller：写为 xml，setUnMarshaller：读 xml writer.setMarshaller(marshaller); // 文件路径 String path = "d:\\city.xml"; writer.setResource(new FileSystemResource(path)); try &#123; // 参数校验 writer.afterPropertiesSet(); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; return writer;&#125; CompositeItemWriter、ClassifierCompositeItemWriterCompositeItemWriter 可以将多个文本文件的写入方式结合在一起，实现写入多个文件的操作ClassifierCompositeItemWriter 可以自定义数据分类 代码示例1、写入多个文件1234567891011/** * 实现数据写入到多个文件 */@Beanpublic CompositeItemWriter&lt;City&gt; multiFileWriter() throws Exception &#123; CompositeItemWriter&lt;City&gt; writer = new CompositeItemWriter&lt;&gt;(); writer.setDelegates(Arrays.asList(cityItemWriter(), xmlItemWriter())); writer.afterPropertiesSet(); return writer;&#125; 2、文件分类1234567891011121314151617@Beanpublic ClassifierCompositeItemWriter&lt;City&gt; multiFileWriter() &#123; ClassifierCompositeItemWriter&lt;City&gt; writer = new ClassifierCompositeItemWriter&lt;&gt;(); writer.setClassifier(new Classifier&lt;City, ItemWriter&lt;? super City&gt;&gt;() &#123; @Override public ItemWriter&lt;? super City&gt; classify(City city) &#123; // 按照 City 的 id 进行分类 if (city.getId() % 2 == 0)&#123; return cityItemWriter(); &#125; else &#123; return xmlItemWriter(); &#125; &#125; &#125;); return writer;&#125; 多文件、分类写入注意点 在进行多文件写入时，需要将 ItemWriter 转为 ItemStreamWriter ：即 在注入时，由注入 ItemWriter 改为 ItemStreamWriter，然后将注入的 ItemWriter 放入 stream 中 示例：123456789101112131415161718@Autowiredprivate ItemStreamWriter&lt;City&gt; xmlItemWriter;@Autowiredprivate final ItemStreamWriter&lt;City&gt; cityItemWriter;@Beanpublic Step multiFileItemWriterStep()&#123; return stepBuilderFactory.get("multiFileItemWriterStep2") .&lt;City, City&gt;chunk(10) .reader(multiFileReader) .writer(multiFileWriter) // 将 ItemWriter 放入 stream .stream(xmlItemWriter) .stream(cityItemWriter) .build();&#125; JdbcBatchItemWriterJdbcBatchItemWriter 使用 jdbc 将数据批量写入数据库 代码示例123456789@Beanpublic JdbcBatchItemWriter&lt;City&gt; flatFileItemWriter()&#123; JdbcBatchItemWriter&lt;City&gt; writer = new JdbcBatchItemWriter&lt;&gt;(); writer.setDataSource(dataSource); writer.setSql("INSERT INTO t_city( id, name, countryCode, district, population) VALUES (:id, :name, :countryCode, :district, :population)"); // 使用实体属性自动映射到占位符 writer.setItemSqlParameterSourceProvider(new BeanPropertyItemSqlParameterSourceProvider&lt;&gt;()); return writer;&#125; ProcessorProcessor 是在 ItemReader 到 ItemWriter 之间的一个数据转换操作，如将需要处理的数字转换为字符串等操作 ItemProcessor&lt;T, O&gt;，其中： T 代表输入类型，即 ItemReader 的泛型，O 代表输出类型，即 ItemWriter 的类型 代码示例12345678910111213141516171819202122// 输入类型为 City，输出类型为 City，转换操作为：将城市名称转为大写。public class NameLowerProcessor implements ItemProcessor&lt;City, City&gt; &#123; @Override public City process(City city) throws Exception &#123; String name = city.getName().toUpperCase(); city.setName(name); return city; &#125;&#125;// 输入类型为 City，输出类型为 City，转换操作为：如果城市 id 可以被 2 整除，则继续执行，否则跳过public class IdFilterProcessor implements ItemProcessor&lt;City, City&gt; &#123; @Override public City process(City city) throws Exception &#123; if (city.getId() %2 == 0)&#123; return city; &#125; // 如果返回 null，相当于把对象过滤掉 return null; &#125;&#125; ItemProcessor 使用ItemProcessor 使用在 Step 域中，尽量书写在 Reader、Writer 中间 CompositeItemProcessor：关联多个 Processor 代码示例12345678910111213141516171819202122@Beanpublic CompositeItemProcessor&lt;City, City&gt; processListener() &#123; CompositeItemProcessor&lt;City, City&gt; processor = new CompositeItemProcessor&lt;&gt;(); List&lt;ItemProcessor&lt;City, City&gt;&gt; list = new ArrayList&lt;&gt;(2); list.add(nameLowerProcessor); list.add(idFiltterProcessor); // 关联多个 Processor processor.setDelegates(list); return processor;&#125;@Beanpublic Step itemProcessorStep() &#123; return stepBuilderFactory.get("itemProcessorStep2") .&lt;City, City&gt;chunk(10) .reader(multiFileReader) // 增加 Processor .processor(processListener()) .writer(cityItemWriter) .build();&#125;]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>SpringBatch</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring Batch 学习（5） ItemReader]]></title>
    <url>%2Fjava%2F2018%2F11-30%2Fspring-batch-study-5.html</url>
    <content type="text"><![CDATA[ItemReaderItemReader 可以理解为：在批处理中，需要处理的数据。这些数据通常是在 文本文件， xml 文件， 数据库 中存储。在进行批处理的时候，需要从文件中获取数据。可以说，ItemReader 是整个批处理的入口。 几个常用的 ItemReader ListItemReader：从集合中获取数据 FlatFileItemReader：从文本文件中获取数据 MultiResourceItemReader：从多个文件中获取数据 StaxEventItemReader：从 xml 文件中获取数据 AbstractPagingItemReader：从数据库中获取数据： JdbcPagingItemReader：使用基础的 jdbc 获取数据 HibernatePagingItemReader：使用 Hibernate 获取数据 JpaPagingItemReader：使用 JPA 获取数据 ListItemReaderListItemReader：声明一个集合作为数据的输入，通常用于数据量较小，内存可以处理的批处理操作；数据量过大的话，放入 ListItemReader 中可能造成内存溢出。 示例：1234@Beanpublic ItemReader&lt;String&gt; itemReader()&#123; return new ListItemReader&lt;&gt;(Arrays.asList("Java", "Python", "Swift", "MyBatis"));&#125; FlatFileItemReaderFlatFileItemReader：从文本文件中获取数据，这个文本文件可以是 txt、csv 等纯文本文件。DelimitedLineTokenizer：配置数据解析方式。默认以英文逗号为数据分隔符。 示例文本数据(任意增加，但需要保持格式)：12327,2018-01-28 11:09:26,测试数据1,4500000001,1,1,1,laiyy,1,4500000001021540518164563728,2018-01-27 01:48:45,测试数据2,4500000001,1,2,1,laiyy,1,4500000001021540518164574429,2018-01-27 01:48:51,测试数据3,4500000001,1,3,1,laiyy,1,45000000010215405181645843 声明一个实体作为每一行文本数据的映射关系：1234567891011121314public class Template &#123; private int id; private String date; private String name; private String siteId; private int status; private int type; private int userId; private String username; private int share; private String markId; // 省略 get、set&#125; 使用 FlatFileItemReader 读取数据1234567891011121314151617181920212223242526272829303132333435363738394041@Bean@StepScopepublic FlatFileItemReader&lt;Template&gt; flatFileReader() &#123; FlatFileItemReader&lt;Template&gt; reader = new FlatFileItemReader&lt;&gt;(); reader.setResource(new ClassPathResource("data.txt")); // 跳过第几行 reader.setLinesToSkip(0); // 声明数据解析 DelimitedLineTokenizer tokenizer = new DelimitedLineTokenizer(); // 声明数据分隔符，默认为英文逗号，如果使用其他分隔符需要重新设置 // tokenizer.setDelimiter(","); // 声明每一行分隔符分隔的每个数据代表实体的哪个字段--需要与实体字段名一致 tokenizer.setNames("id", "date", "name", "siteId", "status", "type", "userId", "username", "share", "markId"); // 解析后的数据映射为对象 DefaultLineMapper&lt;Template&gt; mapper = new DefaultLineMapper&lt;&gt;(); mapper.setLineTokenizer(tokenizer); mapper.setFieldSetMapper(new FieldSetMapper&lt;Template&gt;() &#123; @Override public Template mapFieldSet(FieldSet fieldSet) throws BindException &#123; Template template = new Template(); // 数据映射 template.setId(fieldSet.readInt("id")); template.setDate(fieldSet.readString("date")); template.setName(fieldSet.readString("name")); template.setSiteId(fieldSet.readString("siteId")); template.setStatus(fieldSet.readInt("status")); template.setType(fieldSet.readInt("type")); template.setUserId(fieldSet.readInt("userId")); template.setUsername(fieldSet.readString("username")); template.setShare(fieldSet.readInt("share")); template.setMarkId(fieldSet.readString("markId")); return template; &#125; &#125;); // 数据校验 mapper.afterPropertiesSet(); // 绑定映射 reader.setLineMapper(mapper); return reader;&#125; StaxEventItemReaderStaxEventItemReader：用于从 xml 文件中读取数据，常常和 spring-oxm 结合使用，极大提高效率 代码示例需要读取的 xml 数据 123456789101112131415161718192021222324252627&lt;?xml version="1.0" standalone="yes"?&gt;&lt;RECORDS&gt; &lt;RECORD&gt; &lt;id&gt;20&lt;/id&gt; &lt;createDate&gt;2018/5/10 16:23:09&lt;/createDate&gt; &lt;createUserId&gt;34&lt;/createUserId&gt; &lt;label&gt;标签1&lt;/label&gt; &lt;siteId&gt;4500000001&lt;/siteId&gt; &lt;status&gt;0&lt;/status&gt; &lt;type&gt;8&lt;/type&gt; &lt;username&gt;张三&lt;/username&gt; &lt;seq&gt;20&lt;/seq&gt; &lt;userId&gt;0&lt;/userId&gt; &lt;/RECORD&gt; &lt;RECORD&gt; &lt;id&gt;21&lt;/id&gt; &lt;createDate&gt;2018/5/10 16:24:02&lt;/createDate&gt; &lt;createUserId&gt;34&lt;/createUserId&gt; &lt;label&gt;标签2&lt;/label&gt; &lt;siteId&gt;4500000001&lt;/siteId&gt; &lt;status&gt;1&lt;/status&gt; &lt;type&gt;8&lt;/type&gt; &lt;username&gt;李四&lt;/username&gt; &lt;seq&gt;22&lt;/seq&gt; &lt;userId&gt;0&lt;/userId&gt; &lt;/RECORD&gt;&lt;/RECORDS&gt; 1234567891011121314151617181920212223242526272829303132333435363738394041// 数据实体public class Label &#123; private int id; private String label = ""; private int type; private String labelType = ""; private int userId; private int createUserId; private String createDate; private String username = ""; private int status = 1; private String siteId = ""; private int seq; // 省略 get、set&#125;// 数据读取@Bean@StepScopepublic StaxEventItemReader&lt;Label&gt; xmlFileReader()&#123; StaxEventItemReader&lt;Label&gt; reader = new StaxEventItemReader&lt;&gt;(); // 要读取的文件 reader.setResource(new ClassPathResource("label.xml")); // 指定需要处理的根标签 reader.setFragmentRootElementName("RECORD"); // 把读取到的 xml 格式转为 Label XStreamMarshaller unmarshaller = new XStreamMarshaller(); // 设置要读取的 xml 根节点 --- Map&lt;String, Class&gt; map = new HashMap&lt;&gt;(1); map.put("RECORD", Label.class); unmarshaller.setAliases(map); // marshaller ：写 xml // unmarshaller： 读 xml reader.setUnmarshaller(unmarshaller); return reader;&#125; MultiResourceItemReaderMultiResourceItemReader：可以包含多个 ResourceAwareItemReaderItemStream 的子类、实现类 所构建的文件读取 ItemReader，由此可以一次性读取多个文件。 ResourceAwareItemReaderItemStream 的几个常用实现类： FlatFileItemReader：上一例中的文本文件读取 JsonItemReader：从 json 文件中获取数据 StaxEventItemReader：从 xml 文件中获取数据 代码示例FlatFileItemWriter 数据来源：1234&quot;1&quot;,&quot;Kabul&quot;,&quot;AFG&quot;,&quot;Kabol&quot;,&quot;1780000&quot;&quot;2&quot;,&quot;Qandahar&quot;,&quot;AFG&quot;,&quot;Qandahar&quot;,&quot;237500&quot;&quot;3&quot;,&quot;Herat&quot;,&quot;AFG&quot;,&quot;Herat&quot;,&quot;186800&quot;... 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647/** 声明一个 txt 文件读取*/@Bean@StepScopepublic FlatFileItemReader&lt;City&gt; flatFileReader() &#123; FlatFileItemReader&lt;City&gt; reader = new FlatFileItemReader&lt;&gt;(); // 解析数据 DelimitedLineTokenizer tokenizer = new DelimitedLineTokenizer(); tokenizer.setNames("id", "name", "countryCode", "district", "population"); // 解析后的数据映射为对象 DefaultLineMapper&lt;City&gt; mapper = new DefaultLineMapper&lt;&gt;(); mapper.setLineTokenizer(tokenizer); mapper.setFieldSetMapper(new FieldSetMapper&lt;City&gt;() &#123; @Override public City mapFieldSet(FieldSet fieldSet) throws BindException &#123; City city = new City(); city.setCountryCode(fieldSet.readString("countryCode")); city.setDistrict(fieldSet.readString("district")); city.setId(fieldSet.readInt("id")); city.setName(fieldSet.readString("name")); city.setPopulation(fieldSet.readLong("population")); return city; &#125; &#125;); // 数据校验 mapper.afterPropertiesSet(); // 绑定映射 reader.setLineMapper(mapper); return reader;&#125;// 引入 classpath下的所有以 file 开头的 txt 文件@Value("classpath:file*.txt")private Resource[] fileResources;@Bean@StepScopepublic MultiResourceItemReader&lt;City&gt; multiFileReader() &#123; MultiResourceItemReader&lt;City&gt; reader = new MultiResourceItemReader&lt;&gt;(); // 文件读取 reader.setDelegate(flatFileReader()); // 将所有文件放入 resources 中，即可实现多文件读取 reader.setResources(fileResources); return reader;&#125; AbstractPagingItemReader所有从数据库中分页读取数据的 主抽象类 ，用于定义分页结构、分页参数等 JdbcPagingItemReader以 jdbc 方式分页读取数据（最原生，但是不能自动映射字段，需要自定义） 代码示例12345678910111213141516171819202122232425262728293031323334353637/*** 注解 @StepScope 表示，该数据只在 Step 执行* JdbcPagingItemReader 从 jdbc 中，使用分页获取数据*/@Bean@StepScopepublic JdbcPagingItemReader&lt;User&gt; userItemReader()&#123; JdbcPagingItemReader&lt;User&gt; reader = new JdbcPagingItemReader&lt;&gt;(); reader.setDataSource(dataSource); reader.setFetchSize(2); // 把读取到的记录转换为 User 对象 reader.setRowMapper(new RowMapper&lt;User&gt;() &#123; @Override public User mapRow(ResultSet resultSet, int rowNum) throws SQLException &#123; User user = new User(); user.setId(resultSet.getInt("id")); user.setUsername(resultSet.getString("username")); user.setPassword(resultSet.getString("password")); user.setAge(resultSet.getInt("age")); return user; &#125; &#125;); // 指定 SQL 语句 MySqlPagingQueryProvider provider = new MySqlPagingQueryProvider(); // 查询哪些字段 provider.setSelectClause("id, username, password, age"); // 查询哪个表 provider.setFromClause("from t_user"); // 根据那个字段进行排序 Map&lt;String, Order&gt; sortMap = new HashMap&lt;&gt;(2); sortMap.put("id", Order.ASCENDING); sortMap.put("username", Order.DESCENDING); provider.setSortKeys(sortMap); reader.setQueryProvider(provider); return reader;&#125; HibernatePagingItemReader以 Hibernate 方式分页读取数据（可根据 Hibernate 注解自动映射字段） 代码示例123456789101112131415161718192021222324252627282930313233343536/*** HibernatePagingItemReader 实现*/@Bean@StepScopepublic ItemReader&lt;News&gt; hibernatePagingItemReader() &#123;HibernatePagingItemReader&lt;News&gt; reader = new HibernatePagingItemReader&lt;&gt;(); // 每页查询多少条 reader.setPageSize(500); reader.setSessionFactory(sessionFactory); HibernateNativeQueryProvider&lt;News&gt; provider = new HibernateNativeQueryProvider&lt;&gt;(); // 自动映射解析到哪个实体（该实体需要 @Entity 注解） provider.setEntityClass(News.class); String siteId = parameterMap.get("4500000001").toString(); int channelId = Integer.valueOf(parameterMap.get("2016").toString()); StringBuilder sql = new StringBuilder("SELECT * FROM zw_news where site_id ="); sql.append(siteId); if (channelId != 0) &#123; sql.append(" and channel_id = ").append(channelId); &#125; sql.append(" and status = 150 and del_status != 500"); sql.append(" order by news_weight desc, seq desc, pub_date desc, id desc "); provider.setSqlQuery(sql.toString()); try &#123; // 参数校验 provider.afterPropertiesSet(); &#125; catch (Exception e) &#123; e.printStackTrace(); throw new RuntimeException("获取 Hibernate 数据失败"); &#125; reader.setQueryProvider(provider); // 可有可无 reader.setQueryName(" News"); reader.setUseStatelessSession(true); return reader;&#125;]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>SpringBatch</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring Batch 学习（4） Step 的另一种方式、Listener]]></title>
    <url>%2Fjava%2F2018%2F11-29%2Fspring-batch-study-4.html</url>
    <content type="text"><![CDATA[创建步骤的另外一种方式ItemReader 可以理解为：数据获取。在 Step 中除了可以使用 Tasklet 创建简单的步骤，也可以使用 chunk + itemReader + itemWriter 创建一个复杂的步骤。其中： chunk 表示每几条数据进行一次批量处理 itemReader 表示批量获取的数据怎么获取 itemWriter 表示 chunk 中的数据进行怎样的输出（到文件、数据库或其他） 在使用这种方式创建步骤的时候，需要注意以下几点： chunk 需要指定：输入类型，输出类型、每多少条处理一次，如： &lt;String, String&gt;chunk(10); 表示 ItemReader 的输入类型为 String，ItemWriter 的输出类型为 String，每 10 条处理一次 ItemReader 需要指定输入类型，如：ItemReader，指明获取到的数据为 String 类型 ItemWriter 需要指定输出类型，如：ItemWriter，指明输出（到文件、数据库或其他）的类型为 String 类型 创建一个 String 集合类型的 ItemReader，并进行输出1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859/*** @author laiyy* @date 2018/11/16 9:37* @description*/@Configurationpublic class ItemReaderDemo &#123; private final JobBuilderFactory jobBuilderFactory; private final StepBuilderFactory stepBuilderFactory; @Autowired public ItemReaderDemo(JobBuilderFactory jobBuilderFactory, StepBuilderFactory stepBuilderFactory) &#123; this.jobBuilderFactory = jobBuilderFactory; this.stepBuilderFactory = stepBuilderFactory; &#125; @Bean public Job itemReaderDemoJob() &#123; return jobBuilderFactory.get("itemReaderDemoJob") .start(itemReaderDemoStep()) .build(); &#125; @Bean public Step itemReaderDemoStep()&#123; return stepBuilderFactory.get("itemReaderDemoStep") // 指定数据输入为 String，数据输出为 String，每 2 条执行一次 .&lt;String, String&gt;chunk(2) // 指定数据来源 itemReader .reader(myStringItemReader()) // 指定数据数据为打印数据 .writer( list -&gt; &#123; list.forEach(System.err::println); &#125;) .build(); &#125; /** * 声明一个 String 集合，作为数据的输入 */ @Bean public MyStringItemReader myStringItemReader()&#123; List&lt;String&gt; data = Arrays.asList("Cat", "Dog", "Pig", "Duck"); return new MyStringItemReader(data); &#125;&#125;public class MyStringItemReader implements ItemReader&lt;String&gt; &#123; private Iterator&lt;String&gt; iterator; public MyStringItemReader(List&lt;String&gt; data) &#123; this.iterator = data.iterator(); &#125; @Override public String read() throws Exception, UnexpectedInputException, ParseException, NonTransientResourceException &#123; // 一个数据一个数据的读 if (iterator.hasNext()) &#123; return iterator.next(); &#125; return null; &#125;&#125; Listener几个常用的 Listener在上一篇博客中提到了 StepExecutionListener，这个 Listener 可以在 Step 执行前后获取执行上下文。除此之外还有几个比较常用的 Listener： JobExecutionListener：在 Job 执行前后获取执行上下文 ChunkListener：在 chunk 执行前后获取执行上下文 ItemReadListener：在 ItemReader 执行前后获取执行上下文 ItemWriterListener：在 ItemWriter 执行前后获取执行上下文 ItemProcessListener：在 Processor 执行前后获取执行上下文（数据处理器） 在这些 Listener 中，都有 before、after 方法，便于在执行前后获取信息，在实现这些接口，并生成为 Spring bean 后，在需要的地方引入即可。 比较特殊的几个 Listener 方法： ChunkListsner：afterChunkError，在 chunk 发生错误时调用 ItemReaderListener：onReadError，在 itemReader 发生错误时调用 ItemWriterListener：onWriteError，在 ItemWriter 发生错误时调用 ItemProcessListener：onProcessError，在处理器发生错误时调用 另外一种 Listener 实现方式除了上述实现 xxListener 接口创建 Listener 之外，还有一种更为简单的方式实现 Listener：注解 实现 StepExecutionListener 可以使用： @BeforeStep、@AfterStep 实现 JobExecutionListener 可以使用：@BeforeJob、@AfterJob … 在这些注解中也有对应 Listener 特殊方法的注解：@AfterChunkError、@OnReadError、@OnWriteError、@OnProcessError 代码示例实现接口方式创建 Listener123456789101112131415161718192021/** * @author laiyy * @date 2018/11/15 17:27 * @description * * 接口实现监听 * */public class MyJobListener implements JobExecutionListener &#123; @Override public void beforeJob(JobExecution jobExecution) &#123; // 在 job 执行之前执行 System.out.println("Job 执行之前，Job 名称：" + jobExecution.getJobInstance().getJobName()); &#125; @Override public void afterJob(JobExecution jobExecution) &#123; // 在 job 执行之后执行 System.out.println("Job 执行之后，Job 名称：" + jobExecution.getJobInstance().getJobName()); &#125;&#125; 注解方式创建 Listener12345678910111213public class MyChunkListener &#123; @BeforeChunk public void before(ChunkContext chunkContext)&#123; System.out.println("Step 执行之前，Step 名称：" + chunkContext.getStepContext().getStepName()); &#125; @AfterChunk public void after(ChunkContext chunkContext)&#123; System.out.println("Step 执行之后，Step 名称：" + chunkContext.getStepContext().getStepName()); &#125;&#125; 使用方式123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172/** * @author laiyy * @date 2018/11/15 17:30 * @description * * 执行结果 * Job 执行之前，Job 名称：listenerJob * Step 执行之前，Step 名称：listenerStep1 * （Chunk 设置为2，所以一次拿 2 个数据） * Java * Python * Step 执行之后，Step 名称：listenerStep1 * Step 执行之前，Step 名称：listenerStep1 * （两条数据取出来后，step 执行结束，开始获取下一个两条信息） * Swift * MyBatis * Step 执行之后，Step 名称：listenerStep1 * Step 执行之前，Step 名称：listenerStep1 * （数据全部取出执行结束） * Step 执行之后，Step 名称：listenerStep1 * Job 执行之后，Job 名称：listenerJob * */@Configurationpublic class ListenerDemo &#123; private final JobBuilderFactory jobBuilderFactory; private final StepBuilderFactory stepBuilderFactory; @Autowired public ListenerDemo(JobBuilderFactory jobBuilderFactory, StepBuilderFactory stepBuilderFactory) &#123; this.jobBuilderFactory = jobBuilderFactory; this.stepBuilderFactory = stepBuilderFactory; &#125; @Bean public Job listenerJob()&#123; return jobBuilderFactory.get("listenerJob") .start(listenerStep1()) // 以创建对象方式引入 JobListener，也可以注入 .listener(new MyJobListener()) .build(); &#125; @Bean public Step listenerStep1() &#123; return stepBuilderFactory.get("listenerStep1") // 以 Chunk 方式设置为每读取 2 个数据做一次相应的处理 // read、process、write；&lt;String, String&gt; 读取为 String，输出为 String .&lt;String, String&gt;chunk(2) // 容错 .faultTolerant() // 以创建对象方式引入 chunkListener，也可以注入。 // 设置 Chunk 监听 .listener(new MyChunkListener()) // 读取数据 .reader(itemReader()) // 输出数据 .writer(itemWriter()) .build(); &#125; @Bean public ItemWriter&lt;String&gt; itemWriter()&#123; return new ItemWriter&lt;String&gt;() &#123; @Override public void write(List&lt;? extends String&gt; items) throws Exception &#123; items.forEach(System.err::println); &#125; &#125;; &#125; @Bean public ItemReader&lt;String&gt; itemReader()&#123; return new ListItemReader&lt;&gt;(Arrays.asList("Java", "Python", "Swift", "MyBatis")); &#125;&#125;]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>SpringBatch</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring Batch 学习（3） 决策器、JobParameters、Step 监听器]]></title>
    <url>%2Fjava%2F2018%2F11-29%2Fspring-batch-study-3.html</url>
    <content type="text"><![CDATA[决策器一些业务比较复杂的批处理操作中，可能会存在如下的需求：如在 微博抽奖 中，进行批量处理挑选中间人的时候，需要根据 活跃度，发帖量，粉丝数 的不同，进行不同筛选操作。这时就需要一个 决策器 ，决策器的作用：根据不同的条件，返回不同的状态码（自定义状态码），根据状态码的不同，选择不同的步骤进行批量处理操作。 代码示例自定义一个决策器自定义一个决策器，当输入值为 奇数 的时候，返回 “odd”，当输入值为 偶数 的时候，返回 “even” 12345678910111213141516171819202122232425/*** @author laiyy* @date 2018/11/15 16:23* @description** 自实现的决策器*/public class MyDecider implements JobExecutionDecider &#123; // 总处理条数 private int count; @Override public FlowExecutionStatus decide(JobExecution jobExecution, StepExecution stepExecution) &#123; // 每次进入决策器，则处理条数加 1 count++; if (count % 2 == 0) &#123; // 如果总条数能被 2 整除，返回 even return new FlowExecutionStatus("even"); &#125;else &#123; // 否则返回 odd return new FlowExecutionStatus("odd"); &#125; &#125;&#125; 使用自定义的决策器，进行步骤选择12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273/** * @author laiyy * @date 2018/11/15 16:10 * @description */@Configuration@EnableBatchProcessingpublic class DeciderDemo &#123; private final JobBuilderFactory jobBuilderFactory; private final StepBuilderFactory stepBuilderFactory; @Autowired public DeciderDemo(JobBuilderFactory jobBuilderFactory, StepBuilderFactory stepBuilderFactory) &#123; this.jobBuilderFactory = jobBuilderFactory; this.stepBuilderFactory = stepBuilderFactory; &#125; /** * 创建任务2 */ @Bean public Job deciderDemoJob()&#123; return jobBuilderFactory.get("deciderDemoJob") .start(deciderDemoStep1()) .next(myDecider()) // 如果决策器返回的是 even，进入 step2 .from(myDecider()).on("even").to(deciderDemoStep2()) // 如果决策器返回的是 odd，进入 step3 .from(myDecider()).on("odd").to(deciderDemoStep3()) // 由于先执行的是 step3，那么无论决策器返回值是什么都重新进入决策器，即：进入 next(myDecider())，这时会进入 step2 执行。 // 如果不加这句，则只会执行 step3，不会执行 step2 .from(deciderDemoStep3()).on("*").to(myDecider()) .end().build(); &#125; /** * 决策器 */ @Bean public JobExecutionDecider myDecider()&#123; return new MyDecider(); &#125; @Bean public Step deciderDemoStep3() &#123; return stepBuilderFactory.get("deciderDemoStep3") .tasklet(new Tasklet() &#123; @Override public RepeatStatus execute(StepContribution stepContribution, ChunkContext chunkContext) throws Exception &#123; System.out.println("odd"); return RepeatStatus.FINISHED; &#125; &#125;).build(); &#125; @Bean public Step deciderDemoStep2() &#123; return stepBuilderFactory.get("deciderDemoStep2") .tasklet(new Tasklet() &#123; @Override public RepeatStatus execute(StepContribution stepContribution, ChunkContext chunkContext) throws Exception &#123; System.out.println("even"); return RepeatStatus.FINISHED; &#125; &#125;).build(); &#125; @Bean public Step deciderDemoStep1() &#123; return stepBuilderFactory.get("deciderDemoStep1") .tasklet(new Tasklet() &#123; @Override public RepeatStatus execute(StepContribution stepContribution, ChunkContext chunkContext) throws Exception &#123; System.out.println("deciderDemoStep1"); return RepeatStatus.FINISHED; &#125; &#125;).build(); &#125;&#125; JobParamtersJobParameters，就是Job运行时的参数。它在bath中有两个作用：一是标示不同的 JobInstance 实例，二是作为 job 中用到的信息，以参数的形式传给job。 通常每个 Job 都会有不通的启动方式，或者启动参数等信息，所以一般来说，在一个 Job 中，会公用一个 JobParamters。 一般来说，不会在 Job 中使用 JobParamters，大部分情况下，是在 Job 的执行步骤中使用，即在 Step 中使用 JobParamters。在不同的 Step 中获取需要的 JobParamters，更加便于 Step 的执行（比如需要判断 JobParamerts 的内容是否是正在执行的 Step 所需要的，如果需要就获取执行，如果不需要就略过）。 StepExecutionListener在 Step 中获取 JobParameters，通常使用 StepExecutionListener 监听器。这个监听器的作用是：在某个 Step 中传入监听器，这个监听器就可以获取到这个 Step 的所有上下文信息。在监听器的是实现方法中，进行上下文信息的获取、JobParameters 的获取、Step 执行前后的上下文处理等操作。 StepExecutionListener 需要实现 2 个方法： beforeStep(StepExecution stepExecution)：在 Step 执行前获取 Step 的上下文信息 afterStep(StepExecution stepExecution)：在 Step 执行后获取 Step 的上下文信息 代码示例1234567891011121314151617181920212223242526272829/** * @author laiyy * @date 2018/11/15 17:27 * @description * * 接口实现监听 * */public class MyStepListener implements StepExecutionListener &#123; /** * 存储 Job 的参数 */ private Map&lt;String, JobParameter&gt; parameterMap; @Override public void beforeStep(SteoExecution stepExecution) &#123; // 在 Step 执行之前执行 System.out.println(" 执行之前，Step 名称：" + stepExecution.getStepName()); // 获取 JobParameters parameterMap = stepExecution.getJobParameters().getParameters(); &#125; @Override public void afterStep(StepExecution stepExecution) &#123; // 在 Step 执行之后执行 System.out.println(" 执行之后，Step 名称：" + stepExecution.getStepName()); &#125;&#125; 在 Job 运行期间获取 JobParameters在 Job 运行期间获取 JobParameters，有两种方法： Map&lt;String, JobParameter&gt; 声明为公开静态变量，在 Listener 中使用 声明 Job 的类实现 StepExecutionListener 接口，直接在本类中使用私有变量调用 代码示例（以第二种为例）123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263/** * @author laiyy * @date 2018/11/16 9:22 * @description */@Configurationpublic class ParametersDemo implements StepExecutionListener &#123; private final JobBuilderFactory jobBuilderFactory; private final StepBuilderFactory stepBuilderFactory; /** * 存储 Job 的参数 */ private Map&lt;String, JobParameter&gt; parameterMap; @Autowired public ParametersDemo(JobBuilderFactory jobBuilderFactory, StepBuilderFactory stepBuilderFactory) &#123; this.jobBuilderFactory = jobBuilderFactory; this.stepBuilderFactory = stepBuilderFactory; &#125; @Bean public Job parameterJob()&#123; return jobBuilderFactory.get("parameterJob") .start(parameterStep()) .build(); &#125; /** * Job 执行的是 Step，所以 Job 的参数是在 Step 中使用 * 所以需要给 Step 传递参数即可 * 可以使用监听的方式传递数据：即使用 Step 级别的监听在 Step 执行之前传递数据 */ @Bean public Step parameterStep()&#123; return stepBuilderFactory.get("parameterStep") // 使用 this 关键字，即使用 ParametersDemo 的实例作为 Listener .listener(this) .tasklet(new Tasklet() &#123; @Override public RepeatStatus execute(StepContribution stepContribution, ChunkContext chunkContext) throws Exception &#123; System.out.println("【parameterStep】接收到的参数：" + parameterMap.get("info")); return RepeatStatus.FINISHED; &#125; &#125;).build(); &#125; @Override public void beforeStep(StepExecution stepExecution) &#123; System.out.println("在 Step 执行之前传入参数"); // stepExecution.getJobParameters().getParameters() 是在项目执行时传入的参数，即：项目运行参数 parameterMap = stepExecution.getJobParameters().getParameters(); &#125; @Override public ExitStatus afterStep(StepExecution stepExecution) &#123; System.out.println("在 Step 执行之后处理结果"); return null; &#125;&#125;]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>SpringBatch</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring Batch 学习（2） 多步骤、步骤嵌套、跳步]]></title>
    <url>%2Fjava%2F2018%2F11-29%2Fspring-batch-study-2.html</url>
    <content type="text"><![CDATA[SpringBatch 一个任务包含 N 个步骤在前一篇博客这种，学习到了 SpringBatch 的一个简单的小示例，这个小示例中只包含了一个 Job 任务，这个 Job 也只包含了一个 Step 步骤。但是有些时候我们需要在一个 Job 中分步骤的处理一些事务，比如：在第一个步骤中需要 计算所有用户的总资产，第二个步骤中需要 计算用户的平均余额，第三个步骤需要 筛选男性用户，第四个步骤…. 这时，就需要在一个 统计任务 中分步骤的获取信息。 代码示例在上一步（启动一个 Step）的基础上，增加第二个步骤12345678910111213141516171819202122232425262728293031323334353637383940414243444546/** * @author laiyy * @date 2018/11/15 16:49 * @description */@Configurationpublic class ChildJob2 &#123; private final JobBuilderFactory jobBuilderFactory; private final StepBuilderFactory stepBuilderFactory; @Autowired public ChildJob2(StepBuilderFactory stepBuilderFactory, JobBuilderFactory jobBuilderFactory) &#123; this.stepBuilderFactory = stepBuilderFactory; this.jobBuilderFactory = jobBuilderFactory; &#125; @Bean public Job childJobTwo()&#123; return jobBuilderFactory.get("childJobTwo") // 启动步骤 childJobStep2 .start(childJobStep2()) // 在 上一步执行完之后，执行 next 方法，调用下一个步骤 .next(childJobStep3()) .build(); &#125; @Bean public Step childJobStep3() &#123; return stepBuilderFactory.get("childJobStep3") .tasklet(new Tasklet() &#123; @Override public RepeatStatus execute(StepContribution stepContribution, ChunkContext chunkContext) throws Exception &#123; System.out.println("childJobStep3"); return RepeatStatus.FINISHED; &#125; &#125;).build(); &#125; @Bean public Step childJobStep2() &#123; return stepBuilderFactory.get("childJobStep2") .tasklet(new Tasklet() &#123; @Override public RepeatStatus execute(StepContribution stepContribution, ChunkContext chunkContext) throws Exception &#123; System.out.println("childJobStep2"); return RepeatStatus.FINISHED; &#125; &#125;).build(); &#125;&#125; 一个步骤里面包含多个子步骤在有些业务场景中，可能出现一个任务有多个步骤，而某些步骤又需要包含多个子步骤，如：12306 订票的时候，启动订票任务，订票任务包含：查询票，订票，付款，出票几个步骤，而在查询票的时候，又包含：总余票查询，起始站与终点站间的余票查询，锁定余票等操作。这时就需要在一个步骤里面包含多个子步骤。 在进行子步骤嵌套的时候需要额外注意 一定要严格审核步骤间的前后关系，防止出现步骤死循环嵌套、前后关系错乱等造成的系统崩溃 SpringBatch 中通过使用 Flow 来管理多个子步骤。Flow 可以算是一个步骤，也可以不算一个步骤。 说它算一个步骤，是因为它可以通过 Job 的 start、next 方法，像一个 Step 一个被调用；说它不算一个步骤，是因为 Flow 只起到包含多个子步骤，并按照 Flow 中规定的顺序执行 Step 的作用。 代码示例1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465/** * @author laiyy * @date 2018/11/15 15:21 * @description */@Configuration@EnableBatchProcessingpublic class FlowDemo &#123; @Autowired private JobBuilderFactory jobBuilderFactory; @Autowired private StepBuilderFactory stepBuilderFactory; @Bean public Job flowDemoJob()&#123; return jobBuilderFactory.get("flowDemoJob") // flow 包含了 step1、step3， 则先执行 step1，再执行 step3, .start(flowDemoFlow()) // 再执行 step2 .next(flowDemoStep2()) .end() .build(); &#125; /** * 一个 Flow 含有多个 Step * 指明 Flow 对象包含哪些 Step */ @Bean public Flow flowDemoFlow()&#123; return new FlowBuilder&lt;Flow&gt;("flowDemoFlow") .start(flowDemoStep1()) .next(flowDemoStep3()) .build(); &#125; @Bean public Step flowDemoStep1()&#123; return stepBuilderFactory.get("flowDemoStep1").tasklet(new Tasklet() &#123; @Override public RepeatStatus execute(StepContribution stepContribution, ChunkContext chunkContext) throws Exception &#123; System.out.println("flowDemoStep1"); return RepeatStatus.FINISHED; &#125; &#125;).build(); &#125; @Bean public Step flowDemoStep2()&#123; return stepBuilderFactory.get("flowDemoStep2").tasklet(new Tasklet() &#123; @Override public RepeatStatus execute(StepContribution stepContribution, ChunkContext chunkContext) throws Exception &#123; System.out.println("flowDemoStep2"); return RepeatStatus.FINISHED; &#125; &#125;).build(); &#125; @Bean public Step flowDemoStep3()&#123; return stepBuilderFactory.get("flowDemoStep1").tasklet(new Tasklet() &#123; @Override public RepeatStatus execute(StepContribution stepContribution, ChunkContext chunkContext) throws Exception &#123; System.out.println("flowDemoStep3"); return RepeatStatus.FINISHED; &#125; &#125;).build(); &#125;&#125; 执行跳步有一些业务场景会有如下需求：前期步骤执行顺序 1-&gt;2-&gt;3-&gt;4-&gt;5，但是在运行一段时间之后，需要调整执行顺序为： 1-&gt;3-&gt;2-&gt;5-&gt;4，即：当执行完第一个步骤后，执行第三个步骤；然后从第三个步骤开始执行，当第三个步骤执行结束后，执行第二个步骤；当第二个步骤执行结束后，执行第五个步骤；当第五个步骤执行结束后，执行第四个步骤；当第四个步骤执行结束后，任务结束。 这时有两种解决办法，最简单的就是重新给 start、next 赋值。另外一种就是：手动设置步骤执行顺序 代码示例123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081/** * @author laiyy * @date 2018/11/15 15:06 * @description */@Configuration@EnableBatchProcessingpublic class JobDemo &#123; // 执行成功后会返回的结果 private static final String COMPLETED = "COMPLETED"; private final JobBuilderFactory jobBuilderFactory; private final StepBuilderFactory stepBuilderFactory; @Autowired public JobDemo(JobBuilderFactory jobBuilderFactory, StepBuilderFactory stepBuilderFactory) &#123; this.jobBuilderFactory = jobBuilderFactory; this.stepBuilderFactory = stepBuilderFactory; &#125; @Bean public Job jobDemoJob() &#123; return jobBuilderFactory.get("jobDemo")// 重新给 start、next 赋值// .start(stepDemo1())// .next(stepDemo2())// .next(stepDemo3())// .next(stepDemo4())// .build();// 手动设置执行顺序 // 从 step1, 开始，当 结束 后，到 step2 .start(stepDemo1()).on(COMPLETED).to(stepDemo2()) // 从 step2 开始，当结束后，到 step3 .from(stepDemo2()).on(COMPLETED).to(stepDemo3()) .from(stepDemo3()).on(COMPLETED).to(stepDemo4()) // 从 step4 开始，到结束 .from(stepDemo4()).end().build(); &#125; @Bean public Step stepDemo4() &#123; return stepBuilderFactory.get("stepDemo4") .tasklet(new Tasklet() &#123; @Override public RepeatStatus execute(StepContribution stepContribution, ChunkContext chunkContext) throws Exception &#123; System.out.println(" stepDemo 4"); return RepeatStatus.FINISHED; &#125; &#125;).build(); &#125; @Bean public Step stepDemo3() &#123; return stepBuilderFactory.get("stepDemo3") .tasklet(new Tasklet() &#123; @Override public RepeatStatus execute(StepContribution stepContribution, ChunkContext chunkContext) throws Exception &#123; System.out.println(" stepDemo 3"); return RepeatStatus.FINISHED; &#125; &#125;).build(); &#125; @Bean public Step stepDemo2() &#123; return stepBuilderFactory.get("stepDemo2") .tasklet(new Tasklet() &#123; @Override public RepeatStatus execute(StepContribution stepContribution, ChunkContext chunkContext) throws Exception &#123; System.out.println(" stepDemo 2"); return RepeatStatus.FINISHED; &#125; &#125;).build(); &#125; @Bean public Step stepDemo1() &#123; return stepBuilderFactory.get("stepDemo1") .tasklet(new Tasklet() &#123; @Override public RepeatStatus execute(StepContribution stepContribution, ChunkContext chunkContext) throws Exception &#123; System.out.println(" stepDemo 1"); return RepeatStatus.FINISHED; &#125; &#125;).build(); &#125;&#125;]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>SpringBatch</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring Batch 学习（1） 简单示例]]></title>
    <url>%2Fjava%2F2018%2F11-27%2Fspring-batch-study-1.html</url>
    <content type="text"><![CDATA[Spring Batch – 一个基于 Spring 架构的批处理框架什么是批处理在现代企业应用当中，面对复杂的业务以及海量的数据，除了通过庞杂的人机交互界面进行各种处理外，还有一类工作，不需要人工干预，只需要定期读入大批量数据，然后完成相应业务处理并进行归档。这类工作即为“批处理”。如：银行、移动、电信等公司需要每个月的月底统一处理用户的剩余金额、流量、话费等，这是一个很大的工程。如果全部使用人工操作的话，可能几个月都统计不了，这时就需要一套已经制定好规则的处理方案，按照制定好的方案，程序进行自动处理。 从上面的描述可以看出，批处理应用有如下几个特点： 数据量大，少则百万，多则上亿的数量级。 不需要人工干预，由系统根据配置自动完成。 与时间相关，如每天执行一次或每月执行一次。 同时，批处理应用又明显分为三个环节： 读数据，数据可能来自文件、数据库或消息队列等 数据处理，如电信支撑系统的计费处理 写数据，将输出结果写入文件、数据库或消息队列等 因此，从系统架构上，应重点考虑批处理应用的事务粒度、日志监控、执行、资源管理（尤其存在并发的情况下）。从系统设计上，应重点考虑数据读写与业务处理的解耦，提高复用性以及可测试性。 SpringBatch 的业务场景 周期性的提交批处理 把一个任务并行处理 消息驱动应用分级处理 大规模并行批处理 手工或调度使用任务失败之后重新启动 有依赖步骤的顺序执行（使用工作流驱动扩展） 处理时跳过部分记录（错误记录或不需要处理的记录） 成批事务：为小批量的或有的存储过程/脚本的场景使用 SpringBatch 集成操作### Spring 官方推荐使用 SpringBoot 作为 SpringBatch 的容器框架。SpringBoot 作为 Spring 官方提供的一款轻量级的 Spring 全家桶整合框架，基于 习惯优于配置 的特点，有以下几个重点特征: 基本没有或极少的配置即可启动 Spring 容器 创建独立的Spring应用程序 嵌入的Tomcat，无需部署WAR文件 简化Maven配置 自动配置Spring 提供生产就绪型功能，如指标，健康检查和外部配置 绝对没有代码生成并且对XML也没有配置要求 SpringBoot 集成 SpringBatch 简单实例（使用 IDEA）创建一个 SpringBoot 项目File –&gt; new –&gt; project –&gt; Spring Initialzer 填写 groupId、artifactId 选择需要的依赖（由于是简单实例，所以只需要 batch 的依赖即可) 完整 pom.xml 文件1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;com.laiyy&lt;/groupId&gt; &lt;artifactId&gt;batch&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;packaging&gt;jar&lt;/packaging&gt; &lt;name&gt;batch&lt;/name&gt; &lt;description&gt;Demo project for Spring Boot&lt;/description&gt; &lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.1.0.RELEASE&lt;/version&gt; &lt;relativePath/&gt; &lt;!-- lookup parent from repository --&gt; &lt;/parent&gt; &lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;project.reporting.outputEncoding&gt;UTF-8&lt;/project.reporting.outputEncoding&gt; &lt;java.version&gt;1.8&lt;/java.version&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-batch&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.batch&lt;/groupId&gt; &lt;artifactId&gt;spring-batch-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt;&lt;/project&gt; 开始第一个简单示例demo 示例编码步骤 引入 JobBuilderFactory、StepBuilderFactory，用于创建任务、任务执行的步骤 使用 JobBuilderFactory 创建一个任务 使用 StepBuilderFactory 创建这个任务要执行的步骤 启动项目，查看运行结果 需要注意的地方： 将所有操作在一个类中完成，便于理解代码 需要在这个类上加入 @Configuration、@EnableBatchProcessing 注解 直接启动主进程即可在控制台查看到运行结果 注解 @Configuration 等价于在 spring-context.xml 中声明一个 &lt;bean&gt; 节点注解 @EnableBatchProcessing 用于告诉 Spring 容易自动装配 SpringBatch 相关默认配置 具体代码：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849/** * @author laiyy * @date 2018/11/15 16:49 * @description */@EnableBatchProcessing@Configurationpublic class ChildJob1 &#123; private final JobBuilderFactory jobBuilderFactory; private final StepBuilderFactory stepBuilderFactory; @Autowired public ChildJob1(StepBuilderFactory stepBuilderFactory, JobBuilderFactory jobBuilderFactory) &#123; this.stepBuilderFactory = stepBuilderFactory; this.jobBuilderFactory = jobBuilderFactory; &#125; @Bean public Job childJobOne()&#123; // 创建一个名为 childJobOne 的任务 return jobBuilderFactory.get("childJobOne") // 启动 childJobStep1 步骤 .start(childJobStep1()) // 开始构建 Job .build(); &#125; @Bean public Step childJobStep1() &#123; // 创建一个名为 childJobStep1 的步骤 return stepBuilderFactory.get("childJobStep1") // 示例没有逻辑处理，只做一个简单的演示输出，使用 Tasklet 匿名内部类即可 .tasklet(new Tasklet() &#123; @Override public RepeatStatus execute(StepContribution stepContribution, ChunkContext chunkContext) throws Exception &#123; // 如果控制台打印了这条信息，则证明 SpringBatch 运行成功 System.out.println("childJobStep1"); // 此处有两个值：FINISHED 步骤结束，CONTINUABLE 步骤继续执行 return RepeatStatus.FINISHED; &#125; // 构建 Step &#125;).build(); &#125;&#125; 验证运行结果启用 Application 主进程，查看控制台，发现报错如下：12345678910111213141516171819Error starting ApplicationContext. To display the conditions report re-run your application with &apos;debug&apos; enabled.2018-11-28 22:48:24.326 ERROR 9226 --- [ main] o.s.b.d.LoggingFailureAnalysisReporter : ***************************APPLICATION FAILED TO START***************************Description:Failed to configure a DataSource: &apos;url&apos; attribute is not specified and no embedded datasource could be configured.Reason: Failed to determine a suitable driver classAction:Consider the following: If you want an embedded database (H2, HSQL or Derby), please put it on the classpath. If you have database settings to be loaded from a particular profile you may need to activate it (no profiles are currently active). 错误原因：SpringBatch 运行任务、Step 的时候，会进行持久化（可能是内存中、或者是数据库中，默认是数据库），所以再次我们需要引入一个数据库。作为一个 示例程序，引入内存级数据库 h2 即可 需要在 pom.xml 中加入如下配置：12345&lt;dependency&gt; &lt;groupId&gt;com.h2database&lt;/groupId&gt; &lt;artifactId&gt;h2&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt;&lt;/dependency&gt; 再次启动项目，查看控制台，可以看到控制台打印信息如下12345678910111213 . ____ _ __ _ _ /\\ / ___&apos;_ __ _ _(_)_ __ __ _ \ \ \ \( ( )\___ | &apos;_ | &apos;_| | &apos;_ \/ _` | \ \ \ \ \\/ ___)| |_)| | | | | || (_| | ) ) ) ) &apos; |____| .__|_| |_|_| |_\__, | / / / / =========|_|==============|___/=/_/_/_/ :: Spring Boot :: (v2.1.0.RELEASE)...childJobStep1... 此时可以看到，我们在 Tasklet 中输出的字符串成功打印在了控制台中，证明 SpringBatch 的简单示例启动、验证成功。]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>SpringBatch</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用 Python Requests 爬取并下载小说 以 耳根 的小说 《一念永恒》 为例]]></title>
    <url>%2Fpython%2F2018%2F11-22%2Fpython-download-novel.html</url>
    <content type="text"><![CDATA[使用 Python Requests 爬取 笔趣看 小说网站 使用工具： Python 3.6 + Requests 2.20 + 需要爬取的小说主站地址： http://www.biqukan.com/1_1094 页面分析1. 分析列表页面布局使用浏览器审查元素，查找章节列表所在位置的 dom、class、id 等属性，可以看到所有的章节列表都在一个 class 为 “listmain” 的 div 中包含着，由此可以得出结论，该 div 即是我们需要定位的章节列表所在位置。 2、分析章节名称、链接、第一章起始位置根据列表布局，可以看到，每个章节的章节名称、链接，都在 a 标签中，而小说的第一章，是在第 16 个 a 标签中。分析章节链接、名称、第一章起始位置 3、分析章节内容页进入第一章节，利用浏览器审查元素，可以看到文章的内容都在一个 id 为 content，class 为 showtxt 的 div 中，由此我们可以获取到章节内容 代码实例创建下载类，声明存放章节名称、章节链接、章节数的数组12345678910class download(object): def __init__(self): self.server = 'https://www.biqukan.com' self.target = self.server + '/1_1094' # 存放章节名称 self.names = [] # 存放章节链接 self.urls = [] # 存放章节数 self.nums = 0 在下载类中新建获取章节列表的方法12345678910111213141516171819202122# 获取下载链接def get_download_url(self): # verify 绕过 https，self.target 即为：https://www.biqukan.com/1_1094 req = requests.get(url=self.target, verify=False) # 获取请求到的文本内容 html = req.text # 将文本内容转为流 div_bf = BeautifulSoup(html) # 获取所有 class 为 listmain 的 div div = div_bf.find_all('div', class_='listmain') # 取第一个 div 转为流 a_bf = BeautifulSoup(str(div[0])) # 获取所有 a 标签 a = a_bf.find_all('a') # 由第二步得知，第一章节为第 16 个 a 标签，所以去除不必要的前 15 个章节 self.nums = len(a[15:]) # 转换 a 标签内容 for href in a[15:]: # 获取 a 标签中的文本，放入章节名称数组 self.names.append(href.string) # 获取 a 标签中的列表，放入章节链接数组（由于链接没有域名，需要拼接域名） self.urls.append(self.server + href.get('href')) 获取章节内容1234567891011121314# 获取章节内容，target 为章节内容链接def get_content(self, target): # verify 绕过 https req = requests.get(url=target, verify=False) # 获取请求到的内容 html = req.text bf = BeautifulSoup(html) # 获取 class 为 showtxt 的 div 的内容（即小说章节内容） texts = bf.find_all('div', class_='showtxt') # 将 &amp;nbsp; 转换为空字符串 texts = texts[0].text.replace('\xa0' * 8, '') # 压缩一下，把两个换行转换为一个换行 texts = texts.replace('\n\n','\n') return texts 将内容写入到 txt 文件中1234567891011""" name：文章名称 path：文章保存路径 text：文章内容"""def write(self, name, path, text): write_flag = True with open(path, 'a', encoding='utf-8') as f: f.write(name + '\n') f.writelines(text) f.write('\n') 开始下载1234567891011121314151617181920if __name__ == '__main__': """ 压制由于忽略 HTTPS，导致的运行时警告 from requests.packages.urllib3.exceptions import InsecureRequestWarning requests.packages.urllib3.disable_warnings(InsecureRequestWarning) """ from requests.packages.urllib3.exceptions import InsecureRequestWarning requests.packages.urllib3.disable_warnings(InsecureRequestWarning) dl = download() dl.get_download_url() print('开始下载') for i in range(dl.nums): dl.write(dl.names[i], '一念永恒.txt', dl.get_content(dl.urls[i])) # 计算下载百分比 sys.stdout.write('正在下载 %s，已下载：%.3f%% \r' % (dl.names[i], float(i / dl.nums))) # 刷新打印消息 sys.stdout.flush() print('下载完成')]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[常用 IDEA 插件]]></title>
    <url>%2Fjava%2F2018%2F11-21%2Fidea-plugins.html</url>
    <content type="text"><![CDATA[RestfulToolkit在之前定位方法、Controoler 时，使用 Ctrl + Shift + F 查找只能输入方法上面的 @RequestMapping 的 value 路径，而且如果有多个相同的方法时，或者代码里面有对应的单词时，会全部匹配出来。如：查找 UserController 的 add 方法，如果在搜索框输入 add 查找的话，可能会查找出很多信息，不便于定位。使用这个插件，可以使用 ctrl + \，在弹出的搜索框输入 /user/add 直接定位到 Controoler 的 add 方法 lombok使用 lombok 注解，省略 get、set、toString、equals 等 String Manipulation转换字符串。快捷键：Alt + M Grep Console定义控制台打印日志格式、颜色 Alibaba java Coding Guidelinesalibaba 代码规约扫描器 .ignore快速生成、定义 ignore 文件 Rainbow Brackets修改括号颜色，便于定位同域内容 GsonFormat直接把 JSON 生成实体类。快捷键： Alt + S]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>IdeaPlugins</tag>
      </tags>
  </entry>
</search>
