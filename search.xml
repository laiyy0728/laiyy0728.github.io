<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Hive(八) DML]]></title>
    <url>%2Fhive%2Fdml%2Fhive-8.html</url>
    <content type="text"><![CDATA[DDL 是数据定义语言，DML 是数据操作语言。 数据导入load 方式语法： load data [local] inpath &#39;&#39; [overwrite] into table table_name [partition(partition_name=partition_value)] load data：表示加载数据local：表示从本地加载，如果没有则是从 hdfs 加载inpath：表示加载数据的路径overwrite：表示覆盖表中已有数据，没有则是追加into table：追加数据table_name：具体的表名partition：分区信息 insert 方式 基本插入 语法：insert into table_name values (value1, value2..) 查询插入 语法：insert into table_name select field from_table where params 覆盖插入 语法：insert overwrite table_name 多模式查询（根据多张表查询结果） 语法：from table_name insert overwrite|into table table_name [partition] select fields [where params] 其中：insert overwrite|into table_name [partition] select fields [where params] 可以多次书写。 注意点：from table_name 在最前面，后面的 select 是不需要带 from table_name 的。 创建并插入 方式一：从其他表中查询数据并创建 语法：create table if not exists table_name as select fields from table_name 方式二：通过 location 指定从哪加载数据并创建 语法：create table if not exists table_name(column column_type) location &#39;/data/path&#39; import 方式注意：此操作必须先用 export 导出后，再将数据导入 语法：import table table_name [partition(partition_name=partition_value)] from &#39;/file/path&#39; 导入到一个已存在的表中（空表无结构） 123456hive (default)&gt; import table test from &apos;/export&apos;;Copying data from hdfs://hadoop02:9000/export/dataCopying file: hdfs://hadoop02:9000/export/data/dept.txtLoading data to table default.testOKTime taken: 0.436 seconds 导入到一个已存在的表中（空表有结构） 12hive (default)&gt; import table people from &apos;/export&apos;;FAILED: SemanticException [Error 10120]: The existing table is not compatible with the import spec. Column Schema does not match 此时会报 schema 不匹配，原因：import 导入的是 export 的数据，此数据是带有元数据的。 导入到一个不存在的表中 123456hive (default)&gt; import table people1 from &apos;/export&apos;;Copying data from hdfs://hadoop02:9000/export/dataCopying file: hdfs://hadoop02:9000/export/data/dept.txtLoading data to table default.people1OKTime taken: 0.32 seconds 数据导出insert 导出 将查询结果导出的本地 语法：insert overwrite local directory &#39;/local/file/path&#39; select fields from table_name 1234567891011121314151617181920hive (default)&gt; insert overwrite local directory &apos;/opt/module/hive/tmp_data/dept&apos; select * from dept;Query ID = root_20191231145413_67fa5115-2833-40fb-91bd-911b288dea6fTotal jobs = 1Launching Job 1 out of 1Number of reduce tasks is set to 0 since there&apos;s no reduce operatorStarting Job = job_1577759600542_0001, Tracking URL = http://hadoop03:8088/proxy/application_1577759600542_0001/Kill Command = /opt/module/hadoop-2.7.2/bin/hadoop job -kill job_1577759600542_0001Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 02019-12-31 14:54:51,880 Stage-1 map = 0%, reduce = 0%2019-12-31 14:55:19,855 Stage-1 map = 100%, reduce = 0%, Cumulative CPU 9.6 secMapReduce Total cumulative CPU time: 9 seconds 600 msecEnded Job = job_1577759600542_0001Copying data to local directory /opt/module/hive/tmp_data/deptCopying data to local directory /opt/module/hive/tmp_data/deptMapReduce Jobs Launched: Stage-Stage-1: Map: 1 Cumulative CPU: 9.6 sec HDFS Read: 2961 HDFS Write: 69 SUCCESSTotal MapReduce CPU Time Spent: 9 seconds 600 msecOKdept.deptno dept.dname dept.locTime taken: 68.597 seconds 1234[root@hadoop02 tmp_data]# cd dept/[root@hadoop02 dept]# ll总用量 4-rw-r--r-- 1 root root 69 12月 31 14:55 000000_0 12345[root@hadoop02 dept]# cat 000000_0 10ACCOUNTING170020RESEARCH180030SALES190040OPERATIONS1700 可以看到此时导出的数据是没有格式的 将查询结果格式化后导出到本地 语法：insert overwrite local directory &#39;/local/file/path&#39; ROW FORMAT DELIMITED FIELDS TERMINATED BY &#39;\t&#39; select * from table_name 12345678910111213141516171819hive (default)&gt; insert overwrite local directory &apos;/opt/module/hive/tmp_data/dept&apos; ROW FORMAT DELIMITED FIELDS TERMINATED BY &apos;\t&apos; select * from dept;Query ID = root_20191231150022_adc3b27c-0666-40f8-9577-9689dec1e4baTotal jobs = 1Launching Job 1 out of 1Number of reduce tasks is set to 0 since there&apos;s no reduce operatorStarting Job = job_1577759600542_0002, Tracking URL = http://hadoop03:8088/proxy/application_1577759600542_0002/Kill Command = /opt/module/hadoop-2.7.2/bin/hadoop job -kill job_1577759600542_0002Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 02019-12-31 15:00:28,451 Stage-1 map = 0%, reduce = 0%2019-12-31 15:00:46,034 Stage-1 map = 100%, reduce = 0%, Cumulative CPU 3.3 secMapReduce Total cumulative CPU time: 3 seconds 300 msecEnded Job = job_1577759600542_0002Copying data to local directory /opt/module/hive/tmp_data/deptCopying data to local directory /opt/module/hive/tmp_data/deptMapReduce Jobs Launched: Stage-Stage-1: Map: 1 Cumulative CPU: 3.3 sec HDFS Read: 3144 HDFS Write: 69 SUCCESSTotal MapReduce CPU Time Spent: 3 seconds 300 msecOKdept.deptno dept.dnam 12345[root@hadoop02 tmp_data]# cat dept/000000_0 10 ACCOUNTING 170020 RESEARCH 180030 SALES 190040 OPERATIONS 1700 将查询结果打出到 HDFS 语法：insert overwrite directory &#39;/hdfs/file/path&#39; ROW FORMAT DELIMITED FIELDS TERMINATED BY &#39;\t&#39; select * from table_name 1234567891011121314151617181920212223hive (default)&gt; insert overwrite directory &apos;/dept&apos; ROW FORMAT DELIMITED FIELDS TERMINATED BY &apos;\t&apos; select * from dept;Query ID = root_20191231150613_00f90db5-63a6-4f64-be64-615787dfa988Total jobs = 3Launching Job 1 out of 3Number of reduce tasks is set to 0 since there&apos;s no reduce operatorStarting Job = job_1577759600542_0003, Tracking URL = http://hadoop03:8088/proxy/application_1577759600542_0003/Kill Command = /opt/module/hadoop-2.7.2/bin/hadoop job -kill job_1577759600542_0003Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 02019-12-31 15:06:23,590 Stage-1 map = 0%, reduce = 0%2019-12-31 15:06:27,736 Stage-1 map = 100%, reduce = 0%, Cumulative CPU 1.21 secMapReduce Total cumulative CPU time: 1 seconds 210 msecEnded Job = job_1577759600542_0003Stage-3 is selected by condition resolver.Stage-2 is filtered out by condition resolver.Stage-4 is filtered out by condition resolver.Moving data to: hdfs://hadoop02:9000/dept/.hive-staging_hive_2019-12-31_15-06-13_809_519050561514978017-1/-ext-10000Moving data to: /deptMapReduce Jobs Launched: Stage-Stage-1: Map: 1 Cumulative CPU: 1.21 sec HDFS Read: 3080 HDFS Write: 69 SUCCESSTotal MapReduce CPU Time Spent: 1 seconds 210 msecOKdept.deptno dept.dname dept.locTime taken: 15.096 seconds 其他方式导出 hadoop 命令导出 语法：hadoop fs -get /hdfs/file/path /hdfs|local/file/path Hive shell 导出 语法： bin/hive -e &#39;select * from table_name;&#39; &gt; /local/file/path export 导出到 hdfs 语法：hive (default)&gt; export table table_name to /hdfs/file/path 1234567hive (default)&gt; export table dept to &apos;/export&apos;;Copying data from file:/tmp/root/de98917c-077b-4ec5-a8f5-479a75cc3c12/hive_2019-12-31_15-14-28_860_4397941394477204195-1/-local-10000/_metadataCopying file: file:/tmp/root/de98917c-077b-4ec5-a8f5-479a75cc3c12/hive_2019-12-31_15-14-28_860_4397941394477204195-1/-local-10000/_metadataCopying data from hdfs://hadoop02:9000/user/hive/warehouse/deptCopying file: hdfs://hadoop02:9000/user/hive/warehouse/dept/dept.txtOKTime taken: 0.376 seconds 清空表语法： truncate table table_name 此操作只能删除管理表，不能删除外部表中的数据]]></content>
      <categories>
        <category>hive</category>
        <category>dml</category>
      </categories>
      <tags>
        <tag>hive</tag>
        <tag>dml</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hive(七) DDL 3 分区表、修改表]]></title>
    <url>%2Fhive%2Fddl%2Fhive-7.html</url>
    <content type="text"><![CDATA[除了管理表、内部表外，常用的表还有分区表。分区表实际上是一个 HDFS 文件夹，文件夹下存放的是对应分区的数据 分区表分区表实际上就是对应一个 HDFS 文件系统上的独立的文件夹，该文件夹下是该分区的所有数据。Hive 中的分区就是分目录，把一个大的数据集根据业务需要，分隔成小的数据集。在查询的时候，通过 WHERE 字句中的表达式选择查询所需要的指定分区，这样的查询效率会提高很多。 基本操作 创建一个表，指定分区 12345create table dept_partition( deptno int, dname string, loc string)partitioned by (month string)row format delimited fields terminated by '\t'; 加载数据查看问题 12hive (default)&gt; load data local inpath &apos;/opt/module/hive/tmp_data/dept.txt&apos; into table dept_partition;FAILED: SemanticException [Error 10062]: Need to specify partition columns because the destination table is partitioned 可以看到，数据加载失败了。原因是我们创建表的时候，设置了根据 month 分区，而在加载数据的时候没有指定分区列造成的。 按照分区加载数据 12345hive (default)&gt; load data local inpath &apos;/opt/module/hive/tmp_data/dept.txt&apos; into table dept_partition partition(month=&apos;2019-07&apos;);Loading data to table default.dept_partition partition (month=2019-07)Partition default.dept_partition&#123;month=2019-07&#125; stats: [numFiles=1, numRows=0, totalSize=71, rawDataSize=0]OKTime taken: 0.464 seconds 再次加载两个分区 查询数据 12345678910111213141516hive (default)&gt; select * from dept_partition;OKdept_partition.deptno dept_partition.dname dept_partition.loc dept_partition.month10 ACCOUNTING 1700 2019-0720 RESEARCH 1800 2019-0730 SALES 1900 2019-0740 OPERATIONS 1700 2019-0710 ACCOUNTING 1700 2019-0820 RESEARCH 1800 2019-0830 SALES 1900 2019-0840 OPERATIONS 1700 2019-0810 ACCOUNTING 1700 2019-0920 RESEARCH 1800 2019-0930 SALES 1900 2019-0940 OPERATIONS 1700 2019-09Time taken: 0.226 seconds, Fetched: 12 row(s) 可以看到，三个分区的数据都能查到，且把分区参数当做了一列 dept_partition.month 利用 where 字句查询某分区的数据 12345678hive (default)&gt; select * from dept_partition where month=&apos;2019-08&apos;;OKdept_partition.deptno dept_partition.dname dept_partition.loc dept_partition.month10 ACCOUNTING 1700 2019-0820 RESEARCH 1800 2019-0830 SALES 1900 2019-0840 OPERATIONS 1700 2019-08Time taken: 1.148 seconds, Fetched: 4 row(s) 查看元数据 增加分区123hive (default)&gt; alter table dept_partition add partition(month='2019-10');OKTime taken: 0.202 seconds 同时添加多个分区 1alter table dept_partition add partition(month='2019-11') partition(month='2019-12'); 删除分区1234hive (default)&gt; alter table dept_partition drop partition(month='2019-12');Dropped the partition month=2019-12OKTime taken: 0.376 seconds 同时删除多个分区 12345hive (default)&gt; alter table dept_partition drop partition(month='2019-11'), partition(month='2019-10');Dropped the partition month=2019-10Dropped the partition month=2019-11OKTime taken: 0.371 seconds 注意：添加多个分区时，分区与分区之间用 空格 隔开；删除多个分区时，分区与分区之间用 英文逗号 隔开！！ 查看分区表有多少分区1234567hive (default)&gt; show partitions dept_partition;OKpartitionmonth=2019-07month=2019-08month=2019-09Time taken: 0.055 seconds, Fetched: 3 row(s) 查看分区结构123456789101112131415161718hive (default)&gt; desc formatted dept_partition;OKcol_name data_type comment# col_name data_type comment deptno int dname string loc string # Partition Information # col_name data_type comment month string # 此处即是分区的结构 # Detailed Table Information Database: default # 省略 Time taken: 0.062 seconds, Fetched: 34 row(s) 分区表的注意事项创建二级分区表12345create table dept_partition2( deptno int, dname string, loc string)partitioned by (month string, day string)row format delimited fields terminated by '\t'; 与一级分区的区别是 partitioned by 中定义两个字段。 加载数据到二级分区12345hive (default)&gt; load data local inpath &apos;/opt/module/hive/tmp_data/dept.txt&apos; into table dept_partition2 partition(month=&apos;2019-10&apos;, day=&apos;30&apos;);Loading data to table default.dept_partition2 partition (month=2019-10, day=30)Partition default.dept_partition2&#123;month=2019-10, day=30&#125; stats: [numFiles=1, numRows=0, totalSize=71, rawDataSize=0]OKTime taken: 0.358 seconds 查看分区数据12345678hive (default)&gt; select * from dept_partition2 where month=&apos;2019-10&apos; and day=&apos;30&apos;;OKdept_partition2.deptno dept_partition2.dname dept_partition2.loc dept_partition2.month dept_partition2.day10 ACCOUNTING 1700 2019-10 3020 RESEARCH 1800 2019-10 3030 SALES 1900 2019-10 3040 OPERATIONS 1700 2019-10 30Time taken: 0.104 seconds, Fetched: 4 row(s) 分区表与数据产生关联的三种方式上传数据后修复适用场景：在 HDFS 上存在分区目录，且目录中存在文件，但是元数据中没有对应的分区信息。 以 dept_partition 为例，此时这个分区表只有三个分区 创建一个 2019-11 文件夹，上传 dept.txt 数据。 12[root@hadoop02 tmp_data]# hadoop fs -mkdir -p /user/hive/warehouse/dept_partition/month=2019-10[root@hadoop02 tmp_data]# hadoop fs -put dept.txt /user/hive/warehouse/dept_partition/month=2019-10 查询 month=2019-10 分区的数据。 1234hive (default)&gt; select * from dept_partition where month=&apos;2019-10&apos;;OKdept_partition.deptno dept_partition.dname dept_partition.loc dept_partition.monthTime taken: 0.134 seconds 此时，执行分区修复 12345hive (default)&gt; msck repair table dept_partition;OKPartitions not in metastore: dept_partition:month=2019-10Repair: Added partition to metastore dept_partition:month=2019-10Time taken: 0.201 seconds, Fetched: 2 row(s) 再次查询分区12345678hive (default)&gt; select * from dept_partition where month=&apos;2019-10&apos;;OKdept_partition.deptno dept_partition.dname dept_partition.loc dept_partition.month10 ACCOUNTING 1700 2019-1020 RESEARCH 1800 2019-1030 SALES 1900 2019-1040 OPERATIONS 1700 2019-10Time taken: 0.088 seconds, Fetched: 4 row(s) 修改表分区只需要将上述第三步修改为： alter table dept_partition where month=&#39;2019-10&#39; load 数据将第一种方式的前三步合并为一步： load data local inpath &#39;/file/path&#39; into table table_name partition(partition_name=partition_value) 修改表表重命名语法：alter table table_name rename to new_table_name; 此操作会修改元数据和 HDFS 的文件夹名称 123hive (default)&gt; alter table test rename to rename_table;OKTime taken: 0.185 seconds 12345678910hive (default)&gt; show tables;OKtab_namedeptdept_partitiondept_partition2emppeoplerename_tableTime taken: 0.016 seconds, Fetched: 6 row(s) 增加/修改/替换列信息修改列语法：alter table table_name CHANGE [column] col_old_name col_new_name column_type [COMMENT col_coment] [FIRST | AFTER column_name] 12345678910hive (default)&gt; alter table test CHANGE column name sex int;OKTime taken: 0.082 secondshive (default)&gt; desc test;OKcol_name data_type commentid int sex int Time taken: 0.054 seconds, Fetched: 2 row(s) 增加、替换列信息语法：alter table table_name ADD | REPLACE COLUMNS (col_name data_type [COMMENT col_comment], ...) 123456789101112hive (default)&gt; alter table test add columns (name string);OKTime taken: 0.132 secondshive (default)&gt; select * from test;OKtest.id test.name1 NULL2 NULL3 NULL4 NULL5 NULLTime taken: 0.288 seconds, Fetched: 5 row(s) 注意：ADD 表示增加一个字段，字段位置在所有列的后面（partition列的前面）REPLACE 是替换表中的 所有字段！不能只替换一个字段 12345678hive (default)&gt; alter table test replace columns (name string);OKTime taken: 0.083 secondshive (default)&gt; desc test;OKcol_name data_type commentname string Time taken: 0.051 seconds, Fetched: 1 row(s) 删除表123hive (default)&gt; drop table test;OKTime taken: 0.206 seconds]]></content>
      <categories>
        <category>hive</category>
        <category>ddl</category>
      </categories>
      <tags>
        <tag>hive</tag>
        <tag>ddl</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hive(六) DDL 2]]></title>
    <url>%2Fhive%2Fddl%2Fhive-6.html</url>
    <content type="text"><![CDATA[创建表的时候，分为 管理表 和 外部表。管理表也称为 内部表。 管理表默认创建的表都是管理表（内部表）。Hive 会控制表中数据的生命周期，Hive 默认情况下会将这些表的数据存储在由配置项 hive.metastore.warehouse.dir 所定义的目录的子目录下。当我们删除一个管理表时，Hive 也会删除这个表中的数据。管理表不适合和其他工具共享数据。 测试创建普通表123456create table if not exists students( id int, name string) row format delimited fields terminated by '\t'stored as textfilelocation '/user/hive/warehouse/student2' 根据查询结果创建表（查询的结果会添加的新创建的表中）1create table if not exists people2 as select name, friends, children, address from people; 123456789101112131415161718192021222324hive (default)&gt; create table if not exists people2 as select name, friends, children, address from people;Query ID = root_20191230143721_e7ecd58e-3605-4e64-a4d5-daa161afdc82Total jobs = 3Launching Job 1 out of 3Number of reduce tasks is set to 0 since there&apos;s no reduce operatorStarting Job = job_1577671926689_0001, Tracking URL = http://hadoop03:8088/proxy/application_1577671926689_0001/Kill Command = /opt/module/hadoop-2.7.2/bin/hadoop job -kill job_1577671926689_0001Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 02019-12-30 14:37:32,362 Stage-1 map = 0%, reduce = 0%2019-12-30 14:37:42,730 Stage-1 map = 100%, reduce = 0%, Cumulative CPU 1.55 secMapReduce Total cumulative CPU time: 1 seconds 550 msecEnded Job = job_1577671926689_0001Stage-4 is selected by condition resolver.Stage-3 is filtered out by condition resolver.Stage-5 is filtered out by condition resolver.Moving data to: hdfs://hadoop02:9000/user/hive/warehouse/.hive-staging_hive_2019-12-30_14-37-21_922_8266176305010522642-1/-ext-10001Moving data to: hdfs://hadoop02:9000/user/hive/warehouse/people2Table default.people2 stats: [numFiles=1, numRows=2, totalSize=116, rawDataSize=114]MapReduce Jobs Launched: Stage-Stage-1: Map: 1 Cumulative CPU: 1.55 sec HDFS Read: 3867 HDFS Write: 188 SUCCESSTotal MapReduce CPU Time Spent: 1 seconds 550 msecOKname friends children addressTime taken: 22.204 seconds 123456hive (default)&gt; select * from people2;OKpeople2.name people2.friends people2.children people2.addressiyy [&quot;liyl&quot;,&quot;nixy&quot;] &#123;&quot;xiao lai&quot;:18,&quot;xiao yang&quot;:19&#125; &#123;&quot;street&quot;:&quot;zheng zhou&quot;,&quot;city&quot;:&quot;henan&quot;&#125;lierg [&quot;cuihua&quot;,&quot;goudan&quot;] &#123;&quot;zhang mazi&quot;:17,&quot;zhao si&quot;:20&#125; &#123;&quot;street&quot;:&quot;kai feng&quot;,&quot;city&quot;:&quot;henan&quot;&#125;Time taken: 0.052 seconds, Fetched: 2 row(s) 外部表Hive 并不完全拥有这份数据。当删除表的时候，实际数据不会删除，但描述这个表的元数据会被删除。 测试创建部门、员工两张表123456create external table if not exists default.dept(deptno int,dname string,loc int)row format delimited fields terminated by '\t'; 12345678910create external table if not exists default.emp(empno int,ename string,job string,mgr int,hiredate string,sal double,comm double,deptno int)row format delimited fields terminated by '\t'; 导入数据向两张表中导入 部门数据 和 员工数据 12345hive (default)&gt; load data local inpath &apos;/opt/module/hive/tmp_data/dept.txt&apos; into table dept;Loading data to table default.deptTable default.dept stats: [numFiles=1, totalSize=71]OKTime taken: 0.231 seconds 12345hive (default)&gt; load data local inpath &apos;/opt/module/hive/tmp_data/emp.txt&apos; into table emp;Loading data to table default.empTable default.emp stats: [numFiles=1, totalSize=669]OKTime taken: 0.198 seconds 删除 dept123hive (default)&gt; drop table dept;OKTime taken: 0.42 seconds 可以看到，删除表后，数据还在。 再次创建 dept 表再次使用上面的建表语句，把 dept 表建出来，但是 不导入任何数据 使用查询语句查询 dept 12345678hive (default)&gt; create external table if not exists default.dept( &gt; deptno int, &gt; dname string, &gt; loc int &gt; ) &gt; row format delimited fields terminated by &apos;\t&apos;;OKTime taken: 0.043 seconds 12345678hive (default)&gt; select * from dept;OKdept.deptno dept.dname dept.loc10 ACCOUNTING 170020 RESEARCH 180030 SALES 190040 OPERATIONS 1700Time taken: 0.052 seconds, Fetched: 4 row(s) 可以看到，如果数据存在，那么创建表只要能指定到这个 HDFS 文件夹，那么就能查出来数据。 管理表与外部表的互相转换查询表的类型12345678910111213141516hive (default)&gt; desc formatted test;OKcol_name data_type comment# col_name data_type comment id int # Detailed Table Information # 省略 Location: hdfs://hadoop02:9000/user/hive/warehouse/test Table Type: MANAGED_TABLE # 此处即为表类型，可以看到是管理表 # 省略 # Storage Information SerDe Library: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe # 省略 修改为外部表123hive (default)&gt; alter table test set tblproperties(&apos;EXTERNAL&apos;=&apos;TRUE&apos;);OKTime taken: 0.129 seconds 再次查看表类型1234567891011121314151617hive (default)&gt; desc formatted test;OKcol_name data_type comment# col_name data_type comment id int # Detailed Table Information Database: default # 省略 Location: hdfs://hadoop02:9000/user/hive/warehouse/test Table Type: EXTERNAL_TABLE # 可以看到表类型已经改为了外部表 # 省略 # Storage Information SerDe Library: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe # 省略 再次改为管理表123hive (default)&gt; alter table test set tblproperties(&apos;EXTERNAL&apos;=&apos;FALSE&apos;);OKTime taken: 0.129 seconds 注意点 EXTERNAL 必须为大写设置是否是外部表只能通过 EXTERNAL 为 TRUE 或 FALSE 来控制&#39;EXTERNAL&#39;=&#39;FALSE&#39;、&#39;EXTERNAL&#39;=&#39;TRUE&#39;，固定写法，区分大小写]]></content>
      <categories>
        <category>hive</category>
        <category>ddl</category>
      </categories>
      <tags>
        <tag>hive</tag>
        <tag>ddl</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hive(五) DDL]]></title>
    <url>%2Fhive%2Fddl%2Fhive-5.html</url>
    <content type="text"><![CDATA[DDL 语句：数据库模型定义语言，用于定义数据库、表的结构。DDL 语句不仅可以操作数据库，也可以操作数据表。 DDL 库操作创建数据库注意一定要加上 if not exists，避免报错。 1create database if not exists db_hive ; 创建数据库，并指定 HDFS 的存储路径1create database if not exists db_hive2 location '/db_hive2.db'; 查询数据库1234567hive (default)&gt; show databases;OKdatabase_namedb_hivedb_hive2defaultTime taken: 0.013 seconds, Fetched: 3 row(s) 模糊查询库123456hive (default)&gt; show databases like &apos;db_hive*&apos;;OKdatabase_namedb_hivedb_hive2Time taken: 0.01 seconds, Fetched: 2 row(s) 查看数据库详情12345hive (default)&gt; desc database db_hive;OKdb_name comment location owner_name owner_type parametersdb_hive hdfs://hadoop02:9000/user/hive/warehouse/db_hive.db root USER Time taken: 0.016 seconds, Fetched: 1 row(s 修改数据库可以使用 ALTER DATABASE 没了为某个数据库设置键值对属性(dbpeoperties)，来描述这个数据库的属性信息。数据库的其他元数据信息都是不可更改的，包括数据吗名和数据库所在目录位置。 123hive (default)&gt; alter database db_hive set dbproperties(&apos;createtime&apos;=&apos;20191230&apos;);OKTime taken: 0.019 seconds extended 可以查看附加值12345hive (default)&gt; desc database extended db_hive;OKdb_name comment location owner_name owner_type parametersdb_hive hdfs://hadoop02:9000/user/hive/warehouse/db_hive.db root USER &#123;createtime=20191230&#125;Time taken: 0.013 seconds, Fetched: 1 row(s 删除数据库123hive (default)&gt; drop database is not exists db_hive;OKTime taken: 0.075 seconds 强制删除数据库如果数据库中有数据，可以使用 CASCADE 命令强制删除。 123hive (default)&gt; drop database is not exists db_hive2 cascade;OKTime taken: 0.033 seconds DDL 表操作建表语法123456789CREATE [EXTERNAL] TABLE [IF NOT EXISTS] table_name[(col_name data_type [COMMENT col_comment], ...)][COMMENT table_comment][PARTITIONED BY (col_name data_type [COMMENT col_comment], ...)][CLUSTERED BY (col_name, col_name, ...)[SORTED BY (col_name [ASC|DESC], ...)] INTO num_buckets BUCKETS][ROW FORMAT row_format][STORED AS file_format][LOCATION hdfs_path] 建表语法解释 CREATE TABLE 创建一个指定名字的表，如果表名称已存在，则会出现异常；可以通过 IF NOT EXISTS 来规避。 EXTERNAL 可以让用户创建一个 外部表，在建表的同时指定一个指向实际数据的路径。Hive 创建内部表时，会将数据移动到数据仓库指向的路径；若创建外部表，仅记录数据所在的路径，不对数据的位置做任何更改。在删除表的时候，内部表的元数据和数据会被一起删除，而外部表只删除元数据。 COMMENT 为表和列添加注释 PARTITIONED BY 创建分区表 CLUSTERED BY 创建分桶表，按照列进行分区 SORTED BY 排序规则，不常用，按照列进行分桶 ROW FORMAT 行格式化规则包括：DELIMITED [FIELDS TERMINATED BY char] [COLLECTION ITEMS TERMINATED BY char] [MAP KEYS TERMINATED BY char] [LINES TERMINATED BY char] SERDE serde_name [WITH SERDEPROPERTIES](peoperty_name=property_value, ...) 在建表时可以自定义 serDe（Serialize、Deserialize 的简称，目的是用于序列化、反序列化），或者使用自带的 serDe。如果没有指定 ROW FORMAT 或 ROW FORMAT DELIMITED，将会使用自带的 serDe。在建表时，还需要为表指定列，在指定表的列的同事也会指定自定义的 serDe，Hive 通过 serDe 确定表的具体的列的数据 STORED AS 指定存储文件类型。常用类型为： SEQUENCEFILE（二进制序列文件）、TEXTFILE（文本）、RCFILE（列式存储格式文件）。 如果是纯文本数据，可以使用 STORED AS TEXTFILE。如果数据需要压缩，可以使用 STORED AS SEQUENCEFILE LOCATION 指定表再 HDFS 上的存储位置 LIKE 允许用户复制现有的表结构，但是不复制数据 查看表信息以之前的 peopel 表为例。 12345678910111213141516171819202122232425hive (default)&gt; show create table people;OKcreatetab_stmtCREATE TABLE `people`( `name` string, `friends` array&lt;string&gt;, `children` map&lt;string,int&gt;, `address` struct&lt;street:string,city:string&gt;)ROW FORMAT DELIMITED FIELDS TERMINATED BY &apos;,&apos; COLLECTION ITEMS TERMINATED BY &apos;_&apos; MAP KEYS TERMINATED BY &apos;:&apos; LINES TERMINATED BY &apos;\n&apos; STORED AS INPUTFORMAT &apos;org.apache.hadoop.mapred.TextInputFormat&apos; OUTPUTFORMAT &apos;org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat&apos;LOCATION &apos;hdfs://hadoop02:9000/user/hive/warehouse/people&apos;TBLPROPERTIES ( &apos;COLUMN_STATS_ACCURATE&apos;=&apos;true&apos;, &apos;numFiles&apos;=&apos;1&apos;, &apos;totalSize&apos;=&apos;116&apos;, &apos;transient_lastDdlTime&apos;=&apos;1577674200&apos;)Time taken: 0.132 seconds, Fetched: 21 row(s) 可以看到，除了建表时手动写的一些语句外，还增加了 STORED AS、LOCATIONM、TBLPROPERTIES 等。]]></content>
      <categories>
        <category>hive</category>
        <category>ddl</category>
      </categories>
      <tags>
        <tag>hive</tag>
        <tag>ddl</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hive(四) Hive 数据类型]]></title>
    <url>%2Fhive%2Fhive-4.html</url>
    <content type="text"><![CDATA[Hive 中也有和 Java 类似的基本数据类型、复杂数据类型，也可以进行类型转换。 Hive 的数据类型基本数据类型 Hive 数据类型 Java 数据类型 长度 例子 TINYINT byte 1 byte 有符号整数 20 SMALLINT short 2 byte 有符号整数 20 INT int 4 byte 有符号整数 20 BIGINT long 8 byte 有符号整数 20 BOOLEAN boolean 布尔类型 TRUE、FALSE FLOAT float 单精度浮点数 3.14 DOUBLE double 双精度浮点数 3.14 STRING string 字符类型，可指定字符集，可使用单引号或双引号 &#39;test&#39;、&quot;test&quot; TIMESTAMP 时间类型 BINARY 字节数组 Hive 是 String 类型，相当于数据库的 varchar 类型。该类型是一个可变字符串，理论上可以存储 2GB 的字符数。 集合数据类型 数据类型 描述 语法 STRUCT 结构体，类似于Java Bean，可以通过 a.b 访问 struct() MAP 键值对，使用数组标识符可以访问数据 map() ARRAY 一组具有相同类型和名称的变量的集合 Array() ARRAY 和 Map 与 Java 中的 Array、Map 类型，STRUCT 与 c 语言中的 struct 类型，封装了一个命名字段集合，复杂数据类型允许任意层次嵌套。 示例注意：Hive 每次只能解析一行数据，如果是有结构，且美化过的 JSON，Hive 解析不了。 如下数据，对应 Hive 而言是没有格式的，解析不了。123&#123; "name": "zhangsan"&#125; 使用 测试数据，测试 Hive 的复杂数据类型 测试数据解析：laiyy,liyl_nixy,xiao lai:18_xiao yang:19,zheng zhou_henan对应为：123456789101112&#123; "name": "laiyy", "friends": ["liyl", "nixy"], "children": &#123; "xiao lai":18, "xiao yang":19 &#125;, "address": &#123; "street": "zheng zhou", "city": "henan" &#125;&#125; 在 Hive 上创建一个 people 表 12345678910create table people( name string, friends array&lt;string&gt;, -- 创建一个 friends 字段，类型为 array，存储 string children map&lt;string, int&gt;, -- 创建一个 children 字段，类型为 map，key 为 string 类型， value 为 int 类型 address struct&lt;street:string, city:string&gt; -- 创建一个 address 字段，类型为 struct，其中 street 字段为 string 类型，city 字段为 string 类型) row format delimited fields terminated by ',' -- 列分隔符collection items terminated by '_' -- 数据分隔符，分隔 MAP、STRUCT、ARRAYmap keys terminated by ':' -- MAP 中的 KV 分隔符lines terminated by '\n' -- 以 \n 分隔每一行 HQL 解释为：以 \n 分隔每一行，读取一行数据，以 , 分隔每个字段的值；如果值中有 _，则为数组类型；如果值中有 :，则为 map，: 分隔 map 的 KV 加载数据并查询测试 12345678910111213hive (default)&gt; load data local inpath &apos;/opt/module/hive/tmp_data/people.txt&apos; into table people;Loading data to table default.peopleTable default.people stats: [numFiles=1, totalSize=116]OKTime taken: 0.899 secondshive (default)&gt; select * from people;OKpeople.name people.friends people.children people.addresslaiyy [&quot;liyl&quot;,&quot;nixy&quot;] &#123;&quot;xiao lai&quot;:18,&quot;xiao yang&quot;:19&#125; &#123;&quot;street&quot;:&quot;zheng zhou&quot;,&quot;city&quot;:&quot;henan&quot;&#125;lierg [&quot;cuihua&quot;,&quot;goudan&quot;] &#123;&quot;zhang mazi&quot;:17,&quot;zhao si&quot;:20&#125; &#123;&quot;street&quot;:&quot;kai feng&quot;,&quot;city&quot;:&quot;henan&quot;&#125;Time taken: 0.293 seconds, Fetched: 2 row(s) 由此可见，复杂结构体的测试也通过了。 测试单字段查询 123456hive (default)&gt; select friends from people;OKfriends[&quot;liyl&quot;,&quot;nixy&quot;][&quot;cuihua&quot;,&quot;goudan&quot;]Time taken: 0.078 seconds, Fetched: 2 row(s) 查询数组中的某个下标的数据 123456hive (default)&gt; select friends[1] from people;OK_c0nixygoudanTime taken: 0.07 seconds, Fetched: 2 row(s) 查询 map 中的某个 key 123456hive (default)&gt; select children[&apos;xiao lai&apos;] from people;OK_c018NULLTime taken: 0.073 seconds, Fetched: 2 row(s) 查询结构体的某个字段 123456hive (default)&gt; select address.city from people;OKcityhenanhenanTime taken: 0.054 seconds, Fetched: 2 row(s) 类型转换Hive 的原子数据类型是可以进行 隐式转换 的，类似于 Java 的类型转换。如某表达式用 INT 类型，TINYINT 会自动转换为 INT 联系，但是 Hive 不会反向转化（某表达式用 TINYINT，INT 不会自动转为 TINYINT，会返回错误，除非使用强制类型转换 CAST） 隐式类型转换规则 任何整数类型都可以隐式转换为一个范围更广的类型所有整数类型、FLOAT、STRING(数值) 都行都可以隐式转换为 DOUBLETINYINT、SMALLINT、INT 都可以转换为 FLOATBOOLEAN 不可以转换为其他任何类型 CAST 强制转换如 CAST(‘1’ AS INT)，可以将字符串 1 转换为整数 1；如果强制类型转换失败，如 CAST(‘X’ AS INT)，表达式会返回 NULL。 测试12345hive (default)&gt; select CAST(&apos;1&apos; AS INT);OK_c01Time taken: 0.086 seconds, Fetched: 1 row(s) 12345hive (default)&gt; select CAST(&apos;abc&apos; AS INT);OK_c0NULLTime taken: 0.072 seconds, Fetched: 1 row(s)]]></content>
      <categories>
        <category>hive</category>
      </categories>
      <tags>
        <tag>hive</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hive(三) JDBC 访问、常用命令]]></title>
    <url>%2Fhive%2Fhive-3.html</url>
    <content type="text"><![CDATA[Hive 的元数据可以存储在 MySQL 中，解决了 derby 只能单客户端连接的问题。Hive 也可以开启类似 JDBC 的连接查询方式。 HiveJDBC 访问hiveserver2：可以提供一个类似于 JDBC 的连接方式，连接成功后，可以在程序中使用 SQL 进行操作（不是 HQL）。 修改 hive-site.xml 在 hive-site.xml 中，增加配置 hiveserver2 连接的 用户名、密码。注意：此用户必须拥有 HDFS 中 /tmp/hive 目录的读写权限此用户是系统用户，并不是随意指定的12345678&lt;property&gt; &lt;name&gt;hive.server2.thrift.client.user&lt;/name&gt; &lt;value&gt;root&lt;/value&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;hive.server2.thrift.client.password&lt;/name&gt; &lt;value&gt;123456&lt;/value&gt;&lt;/property&gt; 创建一个 test.txt，将 test.txt 存储在 test 表中（create table test(id int)） 123456789101112131415hive&gt; load data local inpath &apos;/opt/module/hive/tmp_data/test.txt&apos; into table test;Loading data to table default.testTable default.test stats: [numFiles=1, totalSize=11]OKTime taken: 1.355 secondshive&gt; select * from test;OK12345NULLTime taken: 0.233 seconds, Fetched: 6 row(s) 启动 hiveserver2：# bin/hiveserver2，是个阻塞进程启动 beeline123[root@hadoop02 hive]# bin/beeline Beeline version 1.2.1 by Apache Hivebeeline&gt; 连接 hiveserver2 如果没有配置 hiveserver2 的用户名、密码，则在进行下面的连接时，会提示连接被拒绝 如果在 hadoop 的 vore-site.xml 文件中没有如下配置，也会提示连接被拒绝 12345&lt;!-- hadoop 集群的 core-site.xml --&gt;&lt;property&gt; &lt;name&gt;hadoop.http.staticuser.user&lt;/name&gt; &lt;value&gt;root&lt;/value&gt;&lt;/property&gt; 成功连接 语法： !connect jdbc:hive2://host:porthost 为 hive 所在服务器，port 为 10000. 1234567beeline&gt; !connect jdbc:hive2://hadoop02:10000Connecting to jdbc:hive2://hadoop02:10000Enter username for jdbc:hive2://hadoop02:10000: rootEnter password for jdbc:hive2://hadoop02:10000: ******Connected to: Apache Hive (version 1.2.1)Driver: Hive JDBC (version 1.2.1)Transaction isolation: TRANSACTION_REPEATABLE_READ 测试 1234567891011121314151617180: jdbc:hive2://hadoop02:10000&gt; show tables;+-----------+--+| tab_name |+-----------+--+| test |+-----------+--+1 row selected (0.096 seconds)0: jdbc:hive2://hadoop02:10000&gt; select * from test;+----------+--+| test.id |+----------+--+| 1 || 2 || 3 || 4 || 5 |+----------+--+ 常用命令123456789101112131415[root@hadoop02 hive]# bin/hive -helpusage: hive -d,--define &lt;key=value&gt; Variable subsitution to apply to hive commands. e.g. -d A=B or --define A=B --database &lt;databasename&gt; Specify the database to use -e &lt;quoted-query-string&gt; SQL from command line -f &lt;filename&gt; SQL from files -H,--help Print help information --hiveconf &lt;property=value&gt; Use value for given property --hivevar &lt;key=value&gt; Variable subsitution to apply to hive commands. e.g. --hivevar A=B -i &lt;filename&gt; Initialization SQL file -S,--silent Silent mode in interactive shell -v,--verbose Verbose mode (echo executed SQL to the console) 常用命令命令行执行 hql执行完后自动退出 1234567891011[root@hadoop02 hive]# bin/hive -e &quot;select * from test;&quot;Logging initialized using configuration in jar:file:/opt/module/hive/lib/hive-common-1.2.1.jar!/hive-log4j.propertiesOK12345Time taken: 1.208 seconds, Fetched:5 row(s)[root@hadoop02 hive]# 执行文件内的 hql创建一个文件： hql.txt，文件内容为1select * from test; 执行 12345678910[root@hadoop02 hive]# bin/hive -f tmp_data/hql.txt Logging initialized using configuration in jar:file:/opt/module/hive/lib/hive-common-1.2.1.jar!/hive-log4j.propertiesOK12345Time taken: 1.155 seconds, Fetched: 5 row(s) hive 命令查看 hdfs1234hive&gt; dfs -ls /;Found 2 itemsdrwx-wx-wx - root supergroup 0 2019-12-23 15:17 /tmpdrwxr-xr-x - root supergroup 0 2019-12-23 15:18 /user 查看本地文件系统12345hive&gt; ! ls /opt/module;hadoop-2.7.2hivejdk1.8.0_144zookeeper-3.4.10 查看历史命令进入当前用户的根目录，查看 .hivehistory 文件 123456789101112[root@hadoop02 ~]# cat .hivehistory show databaes;show databases;use default;create table stu(id int, name string) row format delimited fields terminated by &apos;\t&apos;;quit;show tables;create table test(id int);show tables;load data local inpath &apos;/opt/module/hive/tmp_data/test.txt&apos; into table test;select * from test;quit; 常用配置Hive 数据仓库位置 默认数据仓库的最原始位置在 HDFS 上，路径为： /user/hive/warehouse/在仓库目录下，没有对默认的数据库 default 创建文件夹。如果某张表属于 default 库，则会直接在数据仓库目录下创建一个文件夹修改 default 数据仓库的原始位置（hive-site.xml） 12345&lt;property&gt; &lt;name&gt;hive.metastore.warehouse.dir&lt;/name&gt; &lt;value&gt;/user/hive/warehouse&lt;/value&gt; &lt;description&gt;默认仓库存储路径&lt;/description&gt;&lt;/property&gt; 查询后信息显示的配置 在 hive-site 中增加配置，显示当前数据库，以及查询表的头信息配置 12345678910&lt;property&gt; &lt;name&gt;hive.cli.print.current.db&lt;/name&gt; &lt;value&gt;false&lt;/value&gt; &lt;description&gt;是否打印当前数据库&lt;/description&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;hive.cli.print.header&lt;/name&gt; &lt;value&gt;false&lt;/value&gt; &lt;description&gt;是否打印头信息&lt;/description&gt;&lt;/property&gt; 测试：12345678hive (default)&gt; select * from test;OKtest.id12345 可以看到库名：hive(default)。头信息：test.id hive 运行日志 Hive 默认的日志存放在 /tmp/[当前用户]/hive.log 下 12345[root@hadoop02 hive]# ll /tmp/root/总用量 3708-rw-r--r-- 1 root root 2292655 12月 27 16:01 hive.log-rw-r--r--. 1 root root 25667 12月 23 15:18 hive.log.2019-12-23-rw-r--r-- 1 root root 1470990 12月 26 15:27 hive.log.2019-12-26 将 hive-log4j.properties.template 复制一份为 hive-log4j.properties，修改 log 存储位置 12#hive.log.dir=$&#123;java.io.tmpdir&#125;/$&#123;user.name&#125;hive.log.dir=/opt/logs/hive 修改后重启 hive 即可。 参数配置方式 查看 mapreduce task 数量 12hive (default)&gt; set mapred.reduce.tasks;mapred.reduce.tasks=-1 设置 mapreduce task 数量 123hive (default)&gt; set mapred.reduce.tasks=10;hive (default)&gt; set mapred.reduce.tasks;mapred.reduce.tasks=10 另外一种设置方式 12345[root@hadoop02 hive]# bin/hive -hiveconf mapred.reduce.tasks=10;Logging initialized using configuration in file:/opt/module/hive/conf/hive-log4j.propertieshive (default)&gt; set mapred.reduce.tasks;mapred.reduce.tasks=10]]></content>
      <categories>
        <category>hive</category>
      </categories>
      <tags>
        <tag>hive</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hive(二) 本地文件导入 Hive、MySQL 存储元数据]]></title>
    <url>%2Fhive%2Fhive-2.html</url>
    <content type="text"><![CDATA[除了使用命令创建表、插入数据外，也可以将本地文件数据导入 Hive。 本地文件导入 Hive准备一个 待导入文件，将文件放在 /opt/module/datas 文件夹下。 需要注意语法： load data local inpath [local path] into table [table name] 12345hive&gt; load data local inpath &apos;/opt/module/datas/student.txt&apos; into table student;Loading data to table default.studentTable default.student stats: [numFiles=3, numRows=0, totalSize=66, rawDataSize=0]OKTime taken: 1.397 seconds 查看 WebUI 查询 123456789hive&gt; select * from student;OK1 laiyy2 laiyy1NULL NULLNULL NULLNULL NULLNULL NULLTime taken: 0.282 seconds, Fetched: 6 row(s) 出现了四条 NULL 记录 解决办法在建表的时候，就指定分隔符，且导入时，需要按照建表时指定的分隔符来分隔数据。 新建一张表，以 \t 分隔 注意语法：create table [table name] fow format delimited fields terminated by [terminated type] 12345678hive&gt; create table stu(id int, name string) row format delimited fields terminated by &apos;\t&apos;;OKTime taken: 0.12 secondshive&gt; show tables;OKstustudentTime taken: 0.02 seconds, Fetched: 2 row(s) 导入数据到 stu 表，查看表数据 1234567891011121314hive&gt; load data local inpath &apos;/opt/module/datas/student.txt&apos; into table stu;Loading data to table default.stuTable default.stu stats: [numFiles=1, totalSize=49]OKTime taken: 0.148 secondshive&gt; select * from stu;OK1001 zhangsan1002 lisi1003 wangwu1004 zhaoliuTime taken: 0.041 seconds, Fetched: 4 row(s) 将本地文件 put 进表再创建一个文件 stu.txt 1hadoop fs -put stu.txt /user/hive/warehouse/stu 调用 select * 查看数据 12345678910hive&gt; select * from stu;OK1005 haha1006 heiheiNULL NULL1001 zhangsan1002 lisi1003 wangwu1004 zhaoliuTime taken: 0.052 seconds, Fetched: 7 row(s) 将 HDFS 上的数据 put 进表将 student.txt 复制为 student2.txt 文件，并上传至 HDFS 根目录下，然后将根目录下的数据 put 到 stu 表中 注意语法：load data inpath [hdfs path] into table [table name] 1234567891011121314151617181920212223[root@hadoop02 datas]# hadoop fs -put student2.txt /hive&gt; load data inpath &apos;/student2.txt&apos; into table stu;Loading data to table default.stuTable default.stu stats: [numFiles=3, totalSize=121]OKTime taken: 0.132 secondshive&gt; select * from stu;OK1005 haha1006 heiheiNULL NULL1001 zhangsan1002 lisi1003 wangwu1004 zhaoliu1001 zhangsan1002 lisi1003 wangwu1004 zhaoliu 此时再查看 WebUI，发现根目录下的 /student2.txt 文件消失了 其实，student2.txt 文件并没有删除，是 hive 修改了 student2.txt 文件的元数据，从原本的 / 目录 修改为 /user/hive/warehouse/stu 目录 元数据存储在 MySQL在 hadoop02 上，连接 Hive 后，使用 XShell 再开一个窗口，还是 hadoop02 ，在另外一个窗口没有关闭的情况下，再连接 Hive，会报如下错误 1234567891011Caused by: javax.jdo.JDOFatalDataStoreException: Unable to open a test connection to the given database. JDBC url = jdbc:derby:;databaseName=metastore_db;create=true, username = APP. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------java.sql.SQLException: Failed to start database &apos;metastore_db&apos; with class loader sun.misc.Launcher$AppClassLoader@214c265e, see the next exception for details. at org.apache.derby.impl.jdbc.SQLExceptionFactory40.getSQLException(Unknown Source) at org.apache.derby.impl.jdbc.Util.newEmbedSQLException(Unknown Source) at org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source) at org.apache.derby.impl.jdbc.EmbedConnection.bootDatabase(Unknown Source) at org.apache.derby.impl.jdbc.EmbedConnection.&lt;init&gt;(Unknown Source) at org.apache.derby.impl.jdbc.EmbedConnection40.&lt;init&gt;(Unknown Source) at org.apache.derby.jdbc.Driver40.getNewEmbedConnection(Unknown Source) at org.apache.derby.jdbc.InternalDriver.connect(Unknown Source) at org.apache.derby.jdbc.Driver20.connect(Unknown Source) 错误原因 Hive 默认数据库是 derby，是单用户的，当有两个连接以上时就会报错。为了防止这个错误，可以把元数据信息从 derby 中改为存储在 mysql 中。 使用 MySQL 存储元数据注意：本例假设 MySQL 已经成功安装，且 MySQL 已经配置了 root+密码，所有主机访问 本例采用MySQL 57 版本，插件包为 5.1.34 版本 将插件包拷贝到 %HIVE_HOME%/lib/ 下。 1[root@hadoop02 mysql-connector-java-5.1.27]# cp mysql-connector-java-5.1.27-bin.jar /opt/module/hive/lib/ 修改 Hive 配置信息 在 /opt/module/hive/conf/ 下创建一个 hive-site.xml 文件，根据 官方文档，在 hive-site.xml 中添加数据库配置 注意：数据库要先创建好，表会在启动时自动创建；文件名称必须为 hive-site.xml，否则无效 1234567891011121314151617181920&lt;?xml version="1.0" encoding="UTF-8" standalone="no"?&gt;&lt;?xml-stylesheet type="text/xsl" href="configuration.xsl"?&gt;&lt;configuration&gt; &lt;property&gt; &lt;name&gt;javax.jdo.option.ConnectionURL&lt;/name&gt; &lt;value&gt;jdbc:mysql://hadoop02:3306/hive_meta&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;javax.jdo.option.ConnectionDriverName&lt;/name&gt; &lt;value&gt;com.mysql.jdbc.Driver&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;javax.jdo.option.ConnectionUserName&lt;/name&gt; &lt;value&gt;root&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;javax.jdo.option.ConnectionPassword&lt;/name&gt; &lt;value&gt;123456&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; 启动 hive 由于版本问题导致的 SSL 日志忽略即可。 1234567891011121314[root@hadoop02 hive]# bin/hiveLogging initialized using configuration in jar:file:/opt/module/hive/lib/hive-common-1.2.1.jar!/hive-log4j.propertiesThu Dec 26 15:18:55 CST 2019 WARN: Establishing SSL connection without server&apos;s identity verification is not recommended. According to MySQL 5.5.45+, 5.6.26+ and 5.7.6+ requirements SSL connection must be established by default if explicit option isn&apos;t set. For compliance with existing applications not using SSL the verifyServerCertificate property is set to &apos;false&apos;. You need either to explicitly disable SSL by setting useSSL=false, or set useSSL=true and provide truststore for server certificate verification.Thu Dec 26 15:18:55 CST 2019 WARN: Establishing SSL connection without server&apos;s identity verification is not recommended. According to MySQL 5.5.45+, 5.6.26+ and 5.7.6+ requirements SSL connection must be established by default if explicit option isn&apos;t set. For compliance with existing applications not using SSL the verifyServerCertificate property is set to &apos;false&apos;. You need either to explicitly disable SSL by setting useSSL=false, or set useSSL=true and provide truststore for server certificate verification.Thu Dec 26 15:18:55 CST 2019 WARN: Establishing SSL connection without server&apos;s identity verification is not recommended. According to MySQL 5.5.45+, 5.6.26+ and 5.7.6+ requirements SSL connection must be established by default if explicit option isn&apos;t set. For compliance with existing applications not using SSL the verifyServerCertificate property is set to &apos;false&apos;. You need either to explicitly disable SSL by setting useSSL=false, or set useSSL=true and provide truststore for server certificate verification.Thu Dec 26 15:18:55 CST 2019 WARN: Establishing SSL connection without server&apos;s identity verification is not recommended. According to MySQL 5.5.45+, 5.6.26+ and 5.7.6+ requirements SSL connection must be established by default if explicit option isn&apos;t set. For compliance with existing applications not using SSL the verifyServerCertificate property is set to &apos;false&apos;. You need either to explicitly disable SSL by setting useSSL=false, or set useSSL=true and provide truststore for server certificate verification.Thu Dec 26 15:18:56 CST 2019 WARN: Establishing SSL connection without server&apos;s identity verification is not recommended. According to MySQL 5.5.45+, 5.6.26+ and 5.7.6+ requirements SSL connection must be established by default if explicit option isn&apos;t set. For compliance with existing applications not using SSL the verifyServerCertificate property is set to &apos;false&apos;. You need either to explicitly disable SSL by setting useSSL=false, or set useSSL=true and provide truststore for server certificate verification.Thu Dec 26 15:18:56 CST 2019 WARN: Establishing SSL connection without server&apos;s identity verification is not recommended. According to MySQL 5.5.45+, 5.6.26+ and 5.7.6+ requirements SSL connection must be established by default if explicit option isn&apos;t set. For compliance with existing applications not using SSL the verifyServerCertificate property is set to &apos;false&apos;. You need either to explicitly disable SSL by setting useSSL=false, or set useSSL=true and provide truststore for server certificate verification.Thu Dec 26 15:18:56 CST 2019 WARN: Establishing SSL connection without server&apos;s identity verification is not recommended. According to MySQL 5.5.45+, 5.6.26+ and 5.7.6+ requirements SSL connection must be established by default if explicit option isn&apos;t set. For compliance with existing applications not using SSL the verifyServerCertificate property is set to &apos;false&apos;. You need either to explicitly disable SSL by setting useSSL=false, or set useSSL=true and provide truststore for server certificate verification.Thu Dec 26 15:18:56 CST 2019 WARN: Establishing SSL connection without server&apos;s identity verification is not recommended. According to MySQL 5.5.45+, 5.6.26+ and 5.7.6+ requirements SSL connection must be established by default if explicit option isn&apos;t set. For compliance with existing applications not using SSL the verifyServerCertificate property is set to &apos;false&apos;. You need either to explicitly disable SSL by setting useSSL=false, or set useSSL=true and provide truststore for server certificate verification.hive&gt; 执行一些测试 查询不到表，是因为 mysql 只是存储 元数据，而现在还没有在 mysql 做元数据存储的基础上创建 hive 表，所以查询不到。 123hive&gt; show tables;OKTime taken: 0.016 second 创建一个表，再查询 1234567hive&gt; create table test(id int);OKTime taken: 0.208 secondshive&gt; show tables;OKtestTime taken: 0.018 seconds, Fetched: 1 row(s)]]></content>
      <categories>
        <category>hive</category>
      </categories>
      <tags>
        <tag>hive</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hive(一) 基础概念、安装、基础命令]]></title>
    <url>%2Fhive%2Fhive-1.html</url>
    <content type="text"><![CDATA[Hive 是 Facebook 开源的用于解决 海量结构化日志 的数据统计。Hive 是基于 Hadoop 的数据仓库地址，可以 将结构化的数据文件映射为一张表，并提供 类似 SQL 的查询功能。Hive 的本质是将 HQL(Hive Query Language) 转化为 MapReduce。 基本概念 数据仓库通过 SQL 进行统计分析 将 SQL 中常用的操作（select、where、group等）用 MapReduce 写成很多模板 将所有的 MapReduce 模板封装到 Hive 中 用户根据业务需求，编写响应的 HQL 语句 HQL 调用 Hive 中的 MapReduce 模板 通过模板运行 MapReduce 程序，生成响应的分析结果 将运行结果返回给客户端 注意点 Hive 的数据存储在 HDFS 中Hive 分析数据底层的默认实现是 MapReduce执行程序运行在 Yarn 上 Hive 的优缺点优点 操作接口采用类 SQL 语法，提供快速开发的能力（简单、容易上手）避免了写 MapReduce，减少学习成本、工作量执行延迟较高，因此常用于数据分析，对实时性要求不高的场合对于处理大数据有优势，处理小数据没有优势支持自定义函数，可以根据自己的需求实现自己的函数 缺点 HQL 表达能力有限 迭代式算法无法表达；数据挖掘方面不擅长； 效率低 Hive 自动生成 MapReduce 作业，通常不够只能Hive 调优困难，粒度较粗 架构 与数据库的比较Hive 采用了类似于 SQL 的查询语言：HQL（Hive Query Language），因此很容易将 Hive 理解为数据库。从结构上看，Hive 和数据库除了拥有类似的查询语言外，再无类似之处。 查询语言由于 SQL 被广泛的应用在数据库中，因此基于 Hive 的特性，设计了类 SQL 的查询语言，熟悉 SQL 的话可以很方便的使用 Hive 做开发 数据存储位置Hive 是建立在 Hadoop 上的，所有 Hive 的数据都是存储在 HDFS 中，而数据库则可以将数据存储在块设备或本地文件系统中 数据更新由于 Hive 是针对数据仓库应用设计的，而数据仓库的内容是 读多写少 的，因此，Hive 不建议修改数据，所有的数据都是加载的时候就确定好的。而数据库中的数据通常是需要进行修改的。 索引Hive 在加载数据的过程中不会对数据进行任何处理，甚至不会对数据进行扫描，因此也没有对数据中的某些 key 建立索引。Hive 要访问数据中满足条件的特性值，需要 暴力扫描整个数据，因此访问的延迟较高。由于 MapReduce 的引入，Hive 可以并行访问数据，因此即使没有索引，对于大量数据的访问，Hive 依然有优势。 数据库中，通常会针对一个或几个列建立索引，因此对于少量的特定条件的数据的访问，数据库可以有很高的效率，较低的延迟。 执行Hive 中大多数查询的执行是通过 Hadoop 的 MapReduce 来实现的，数据库通常有自己的执行引擎 执行延迟Hive 在查询数据的时候，由于没有索引，需要扫描整个表，因此延迟较高。由于 MapReduce 本身具有较高延迟，因此在利用 MapReduce 执行 Hive 查询时，也会有较高的延迟。 数据库的执行延迟较低（在数据规模小的时候） 可扩展性Hive 是建立在 Hadoop 上的，因此 Hive 的可扩展性和 Hadoop 的可扩展性是高度一致的。数据库由于 ACID 雨衣的严格限制，扩展非常有限 数据规模Hive 可以利用 MapReduce 进行并行运算，可以支持很大规模的数据数据库可支持的数据规模要比 Hive 小很多 安装示例使用 Hadoop-2.7.2、Hive 1.2.1、MySQL 5.6.24 版本 省略 Hadoop-2.7.2 安装 安装 hive 将 hive-1.2.1 拷贝到 /opt/software 文件夹，并加压到 /opt/module/hive 下 拷贝 conf/hive-env.sh.template 文件为 hive-env.sh 修改 hive-env.sh 1234HADOOP_HOME=/opt/module/hadoop-2.7.2HIVE_CONF_DIR=/opt/module/hive/confexport HADOOP_HOME HIVE_CONF_DIR 启动 hive 1234[root@hadoop02 hive]# bin/hiveLogging initialized using configuration in jar:file:/opt/module/hive/lib/hive-common-1.2.1.jar!/hive-log4j.propertieshive&gt; 测试 Hive、创建表 查看数据库 1234hive&gt; show databases;OKdefaultTime taken: 0.397 seconds, Fetched: 1 row(s) 进入 default 数据库，创建一张 student 表 12345678910111213141516171819hive&gt; use default;OKTime taken: 0.028 secondshive&gt; create table student(id int, name string);OKTime taken: 0.529 secondshive&gt; show tables;OKstudentTime taken: 0.018 seconds, Fetched: 1 row(s)hive&gt; select * from student;OKTime taken: 0.291 seconds 插入一条数据 1234567891011121314151617181920212223hive&gt; insert into student values(1, &apos;laiyy&apos;);Query ID = root_20191223102633_3f3c7996-6af7-4718-9634-7b0e13adc979Total jobs = 3Launching Job 1 out of 3Number of reduce tasks is set to 0 since there&apos;s no reduce operatorStarting Job = job_1577067217027_0001, Tracking URL = http://hadoop03:8088/proxy/application_1577067217027_0001/Kill Command = /opt/module/hadoop-2.7.2/bin/hadoop job -kill job_1577067217027_0001Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 02019-12-23 10:26:48,722 Stage-1 map = 0%, reduce = 0%2019-12-23 10:26:57,020 Stage-1 map = 100%, reduce = 0%, Cumulative CPU 2.4 secMapReduce Total cumulative CPU time: 2 seconds 400 msecEnded Job = job_1577067217027_0001Stage-4 is selected by condition resolver.Stage-3 is filtered out by condition resolver.Stage-5 is filtered out by condition resolver.Moving data to: hdfs://hadoop02:9000/user/hive/warehouse/student/.hive-staging_hive_2019-12-23_10-26-33_045_4325354072781105943-1/-ext-10000Loading data to table default.studentTable default.student stats: [numFiles=1, numRows=1, totalSize=8, rawDataSize=7]MapReduce Jobs Launched: Stage-Stage-1: Map: 1 Cumulative CPU: 2.4 sec HDFS Read: 3551 HDFS Write: 79 SUCCESSTotal MapReduce CPU Time Spent: 2 seconds 400 msecOKTime taken: 26.301 seconds 插入完成后，查看 HDFS Web UI 再次插入一条数据，查看 WebUI 注意：这个 copy1 并不是真的拷贝的之前 000000_0 的数据！ 可以看到，两个文件的大小是不一样的，出现 copy_1 的原因是因为 HDFS 中同一个文件夹下不能出现两个相同名字的文件，所以新插入的数据生成的文件默认拼接了 copy_1，如果再插入数据，则会生成 copy_2、copy_3 以此类推 查看数据 12345678910111213141516171819202122232425262728293031323334353637hive&gt; select * from student;OK1 laiyy2 laiyy1Time taken: 0.039 seconds, Fetched: 2 row(s)hive&gt; select name from student;OKlaiyylaiyy1Time taken: 0.069 seconds, Fetched: 2 row(s)hive&gt; select count(*) from student;Query ID = root_20191223103741_2b3573f9-5941-49c7-b4b7-dfd6e402e3d6Total jobs = 1Launching Job 1 out of 1Number of reduce tasks determined at compile time: 1In order to change the average load for a reducer (in bytes): set hive.exec.reducers.bytes.per.reducer=&lt;number&gt;In order to limit the maximum number of reducers: set hive.exec.reducers.max=&lt;number&gt;In order to set a constant number of reducers: set mapreduce.job.reduces=&lt;number&gt;Starting Job = job_1577067217027_0003, Tracking URL = http://hadoop03:8088/proxy/application_1577067217027_0003/Kill Command = /opt/module/hadoop-2.7.2/bin/hadoop job -kill job_1577067217027_0003Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 12019-12-23 10:37:53,751 Stage-1 map = 0%, reduce = 0%2019-12-23 10:37:58,136 Stage-1 map = 100%, reduce = 0%, Cumulative CPU 0.99 sec2019-12-23 10:38:02,253 Stage-1 map = 100%, reduce = 100%, Cumulative CPU 2.52 secMapReduce Total cumulative CPU time: 2 seconds 520 msecEnded Job = job_1577067217027_0003MapReduce Jobs Launched: Stage-Stage-1: Map: 1 Reduce: 1 Cumulative CPU: 2.52 sec HDFS Read: 6633 HDFS Write: 2 SUCCESSTotal MapReduce CPU Time Spent: 2 seconds 520 msecOK2Time taken: 22.124 seconds, Fetched: 1 row(s) 退出 Hive 1hive&gt; quit; 此例中，insert、select count(*) 时，会运行 MapReduce 程序，其他不会。因为 count(*) 牵扯到计算；insert 牵扯到创建文件（也可以理解为计算）]]></content>
      <categories>
        <category>hive</category>
      </categories>
      <tags>
        <tag>hive</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Zookeeper（二） 原理、Java API 操作]]></title>
    <url>%2Fzookeeper%2Fzookeeper-2.html</url>
    <content type="text"><![CDATA[&nbsp; Zookeeper 内部原理选举机制 半数机制：集群中半数以上的机器存活，集群可用。所以 Zookeeper 适合安装 奇数台服务器 Zookeeper 虽然在配置文件中没有指定 Master 和 Slave，但是 Zookeeper 工作室，是有一个节点为 Leader，其他为 Follower；Leader 是通过 内部选举机制临时产生 选举过程假设有舞台服务器组成 Zookeeper 集群，它们的 id 为 1~5，同时，它们都是最新启动的，没有历史数据，所有配置一样。假设服务器依次启动，其选举过程为： 服务器 A 启动，此时只有一台服务器启动，它发出的报文没有任何响应，选举状态为 LOOKING 服务器 B 启动，与 A 通信，互相交换自己的选举结果。由于两者都没有历史数据，所以 id 较大的 B 胜出；但是，由于没有超过半数以上的服务器同意（5台服务器，半数以上是3)，所以 A、B 继续保持 LOOKING 服务器 C 启动，与 A、B 通信，根据前面的分析，此时 C 是集群中的 Leader。 服务器 D 启动，与 A、B、C 通信，理论上来说应该是 D 为 Leader，但是 C 已经成为了 Leader， 所以 D 只能成为 Follower 服务器 E 启动，同样与 D 一样，只能当 Follower 节点类型 持久型 客户端和服务器端断开链接后，创建的节点不删除；Zookeeper 给该节点名称进行顺序编号 创建 ZNode 时，设置顺序标识，ZNode 名称后会附加一个值，顺序号是一个单调递增的计数器，由父节点维护 注意：在分布式系统中，顺序号可以被用于为所有的事件进行全局排序，这样客户端可以通过顺序号推断事件的顺序 短暂型 客户端与服务器端断开链接后，创建的节点自己删除；Zookeeper 给该节点名称进行顺序编码 Stat 结构体使用 stat 命令，查看节点状态，返回值如下 123456789101112[zk: localhost:2181(CONNECTED) 0] stat /laiyycZxid = 0x200000002ctime = Fri Dec 20 10:19:03 CST 2019mZxid = 0x200000011mtime = Fri Dec 20 10:36:33 CST 2019pZxid = 0x200000018cversion = 9dataVersion = 1aclVersion = 0ephemeralOwner = 0x0dataLength = 5numChildren = 7 cZxid 每次修改 Zookeeper 状态，都会受到一个 zxid 形式的时间戳，也就是 Zookeeper 的 事务 id；事务 id 是 Zookeeper 中所有修改的总的次序，每个修改都有一个 zxid，如果 zxid1 &lt; zxid2，那么说明 zxid1 在 zxid2 之前发生 ctime ZNode 被创建时的毫秒数（1970开始） mZxid ZNode 最后一次修改的事务 id mtime 最后一次修改的好描述（1970开始） pZxid ZNode 最后更新的子节点事务 id cversion ZNode 子节点变化数，ZNode 子节点修改次数 dataVersion ZNode 数据变化号 aclVersion ZNode 访问控制列表的变化号 ephemeralOwner 如果是临时节点，这个是 ZNode 拥有者的 sessionId；如果不是临时节点，则是 0 dataLength ZNode 数据长度 numChildren ZNode 子节点数 监听器原理 首先，需要一个 main 线程 在 main 线程中创建 Zookeeper 客户端，此时会创建两个线程，一个负责网络通信，一个负责监听 通过 connect 线程，将注册的监听事件发送到 Zookeeper 在 Zookeeper 的注册监听器列表中将注册的监听事件添加到列表中 Zookeeper 坚挺到有数据、路径的变化时，就会将这个消息发送给 监听线程 监听线程内部调用 process 方法 常见的监听：1、监听节点数据变化(get path [watch])；2、监听子节点增减的变化(ls path [watch]) 写数据流程 Client 向 Zookeeper 的 Server1 上写数据，发送一个写请求 如果 Server1 不是 Leader，那么 Server1 会把接收到的请求转发给 Leader。 Zookeeper 的 Server 中有一个是 Leader，Leader 会将写请求广播给各个 Server，各个 Server 写成功后就会通知 Leader 当 Leader 收到大多数 Server 数据写成功，就说明数据写成功 如果有三个节点的话，只要有两个节点写成功，就认为数据写成功。写成功后，Leader 会告诉 Server1 数据写成功了 Server1 通知 Client 数据写成功，流程结束 API 操作创建客户端连接1234567891011121314151617181920212223242526private static final String ZOOKEEPER_HOST_URL = "hadoop02:2181,hadoop03:2181,hadoop04:2181";private static final int SESSION_TIMEOUT = 2000;private ZooKeeper client;@Beforepublic void init() throws IOException &#123; client = new ZooKeeper(ZOOKEEPER_HOST_URL, SESSION_TIMEOUT, new Watcher() &#123; @Override public void process(WatchedEvent watchedEvent) &#123; System.out.println(watchedEvent); &#125; &#125;);&#125;@Afterpublic void close() throws Exception&#123; if (null != client)&#123; client.close(); &#125;&#125;@Testpublic void connect()&#123; System.out.println(client);&#125; 全日制 123452019-12-20 11:37:46,542 INFO [org.apache.zookeeper.ZooKeeper] - Client environment:zookeeper.version=3.4.10-39d3a4f269333c922ed3db283be479f9deacaa0f, built on 03/23/2017 10:13 GMTState:CONNECTING sessionid:0x0 local:null remoteserver:null lastZxid:0 xid:1 sent:0 recv:0 queuedpkts:0 pendingresp:0 queuedevents:0.... 创建子节点12345678910111213141516171819@Testpublic void createNode() throws Exception&#123; // 参数解释 // 参数 1：子节点路径 // 参数 2：创建子节点时绑定的数据 // 参数 3：权限 // ANYONE_ID_UNSAFE：任何人都可访问 // AUTH_IDS：只有创建者才可访问 // OPEN_ACL_UNSAFE：开放的 ACL，不安全（常用） // CREATOR_ALL_ACL：授权用户具备权限 // READ_ACL_UNSAFE：制度权限 // 参数 4：节点类型 // PERSISTENT：持久型 // PERSISTENT_SEQUENTIAL：持久型带节点序号 // EPHEMERAL：临时型 // EPHEMERAL_SEQUENTIAL：临时型带序号） String path = client.create("/laiyy", "test_api".getBytes(StandardCharsets.UTF_8), ZooDefs.Ids.OPEN_ACL_UNSAFE, CreateMode.PERSISTENT); System.out.println(path);&#125; 1232019-12-20 11:47:27,378 INFO [org.apache.zookeeper.ClientCnxn] - Session establishment complete on server hadoop03/192.168.233.132:2181, sessionid = 0x36f2112be2e0003, negotiated timeout = 4000/laiyy2019-12-20 11:47:27,388 INFO [org.apache.zookeeper.ZooKeeper] - Session: 0x36f2112be2e0003 closed 查看服务器 12[zk: localhost:2181(CONNECTED) 8] ls /[laiyy, zookeeper] 获取子节点1234567@Testpublic void getChildren() throws Exception &#123; List&lt;String&gt; children = client.getChildren("/", false); System.out.println("子节点包括：" + children); // 休眠5秒，防止还没有获取到就已经关闭连接 TimeUnit.SECONDS.sleep(5);&#125; 获取子节点，并监听数据变化修改创建连接中的 Watcher，启动成功后查看日志 1234567891011121314151617client = new ZooKeeper(ZOOKEEPER_HOST_URL, SESSION_TIMEOUT, new Watcher() &#123; @Override public void process(WatchedEvent watchedEvent) &#123; List&lt;String&gt; children = null; try &#123; System.out.println("------------------- 监控开始 ---------------------"); children = client.getChildren("/", true); for (String child : children) &#123; System.out.println(child); &#125; System.out.println("------------------- 监控结束 ----------------------"); &#125; catch (KeeperException | InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125;); 1234------------------- 监控开始 ---------------------laiyyzookeeper------------------- 监控结束 ---------------------- 在服务器中进行创建、删除节点操作：123[zk: localhost:2181(CONNECTED) 18] create /test &apos;test&apos;Created /test[zk: localhost:2181(CONNECTED) 19] delete /tes 控制台打印：123456789------------------- 监控开始 ---------------------laiyyzookeepertest------------------- 监控结束 ----------------------------------------- 监控开始 ---------------------laiyyzookeeper------------------- 监控结束 ---------------------- 获取节点状态12345678@Testpublic void exist() throws Exception &#123; Stat stat = client.exists("/laiyy", false); // 如果节点不再存，stat 为 null System.out.println(stat); // 休眠5秒，防止还没有获取到就已经关闭连接 TimeUnit.SECONDS.sleep(5);&#125; 监听服务器节点动态上下线需求：主节点可以有多台，可以动态上下线，任意一台客户端都能实时感知主节点服务器的上下线 服务端12345678910111213141516171819202122232425262728293031323334public class Server &#123; private static final String ZOOKEEPER_HOST_URL = "hadoop02:2181,hadoop03:2181,hadoop04:2181"; private static final int SESSION_TIMEOUT = 2000; private ZooKeeper zooKeeper; public static void main(String[] args) throws IOException, KeeperException, InterruptedException &#123; args = new String[]&#123;"localhost:001"&#125;; Server server = new Server(); // 连接集群 server.connect(); // 注册节点 server.register(args[0]); TimeUnit.MINUTES.sleep(10); &#125; private void register(String hostname) throws KeeperException, InterruptedException &#123; zooKeeper.create("/servers/server", hostname.getBytes(StandardCharsets.UTF_8), ZooDefs.Ids.OPEN_ACL_UNSAFE, CreateMode.EPHEMERAL_SEQUENTIAL); System.out.println(hostname + " 上线了！"); &#125; private void connect() throws IOException &#123; zooKeeper = new ZooKeeper(ZOOKEEPER_HOST_URL, SESSION_TIMEOUT, new Watcher() &#123; @Override public void process(WatchedEvent watchedEvent) &#123; System.out.println(watchedEvent); &#125; &#125;); &#125;&#125; 客户端监听123456789101112131415161718192021222324252627282930313233343536373839404142434445464748public class Client &#123; private static final String ZOOKEEPER_HOST_URL = "hadoop02:2181,hadoop03:2181,hadoop04:2181"; private static final int SESSION_TIMEOUT = 2000; private ZooKeeper zooKeeper; public static void main(String[] args) throws Exception &#123; Client client = new Client(); client.connect(); client.getChildren(); TimeUnit.MINUTES.sleep(5); &#125; private void getChildren() throws Exception &#123; List&lt;String&gt; children = zooKeeper.getChildren("/servers", true); // 存储服务器节点集合名称 List&lt;String&gt; hosts = new ArrayList&lt;&gt;(); for (String child : children) &#123; byte[] data = zooKeeper.getData("/servers/" + child, false, null); hosts.add(new String(data)); &#125; // 打印主机名称 for (String host : hosts) &#123; System.out.println(" 监听到 " + host); &#125; &#125; private void connect() throws Exception &#123; zooKeeper = new ZooKeeper(ZOOKEEPER_HOST_URL, SESSION_TIMEOUT, new Watcher() &#123; @Override public void process(WatchedEvent watchedEvent) &#123; System.out.println(watchedEvent); try &#123; getChildren(); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125; &#125;); &#125;&#125; 测试 先在集群上创建一个 /servers 节点，然后启动 Client123456[zk: localhost:2181(CONNECTED) 20] create /servers &apos;servers&apos;Created /servers# java 控制打印WatchedEvent state:SyncConnected type:None path:null 在服务器上创建 /servers/server 节点，查看 client 控制台 1234567[zk: localhost:2181(CONNECTED) 21] create -e -s /servers/server &apos;server&apos;Created /servers/server0000000000# java 控制台打印WatchedEvent state:SyncConnected type:NodeChildrenChanged path:/servers 监听到 server 运行 java 的 server，查看 server 和 client 控制台 1234567891011# serverWatchedEvent state:SyncConnected type:None path:nulllocalhost:001 上线了！# client WatchedEvent state:SyncConnected type:NodeChildrenChanged path:/servers 监听到 localhost:001 监听到 server2 监听到 server 关掉 java 的 server，查看 client 输出 123WatchedEvent state:SyncConnected type:NodeChildrenChanged path:/servers 监听到 server2 监听到 server 由此可以验证，Client 实现了 server 动态上下线监听]]></content>
      <categories>
        <category>zookeeper</category>
      </categories>
      <tags>
        <tag>zookeeper</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Zookeeper（一） 安装、命令行操作]]></title>
    <url>%2Fzookeeper%2Fzookeeper-1.html</url>
    <content type="text"><![CDATA[Zookeeper 是一个开源的分布式的，为分布式应用提供协调服务器的项目。 ZookeeperZookeeper 从设计模式角度来理解，是一个基于 观察者模式 设计的分布式服务管理框架，它负责存储和管理数据，然后接受 观察者 的注册，一旦数据的状态发生变化，Zookeeper 就会负责 通知以及在 Zookeeper 上注册的观察者，让其作出相应的反应。 Zookeeper 可以解释为 文件系统 + 通知机制 的整合。 特点 Zookeeper 是一个 领导者(Leader)、多个 跟随者(Follower) 组成的集群 集群中只要有半数以上的节点存活，Zookeeper 集群就能正常服务。(半数=以上是指，如果有 5 台服务器，则最少有 3 台正常；如果有 6 台服务器，最少有 4 台正常) 全局数据一致：每个 Server 上保存一份相同的数据备份，Client 无论连接到哪台 Server，数据都是一致的 更新请求顺序进行：来自同一个 Client 的更新请求将按照其发送顺序依次执行 数据更新的原子性：一次数据更新，要么成功，要么失败 实时性：在一定时间范围内，Client 能读取到最新数据 数据结构Zookeeper 的数据模型结构与 Unix 文件系统类似，整体上可以看做是一棵树，每个节点称作是一个 ZNode。每个 ZNode 默认存储 1MB 数据，每个 ZNode 都可以通过其 路径唯一标识。 应用场景Zookeeper 提供的服务包括：统一命名管理、统一配置管理、统一集群管理、服务器节点动态上下线、软负载均衡等 统一命名管理 在分布式环境下，经常需要对 应用/服务 进行统一命名，便于识别。类似于：ip 不容易记，而域名容易记。 统一配置管理 在分布式环境下，配置文件同步非常重要 一般要求一个集群中，所有节点的配置信息是一一致的；对配置文件修改后，往往希望能够快速同步到各个节点上 配置管理可以交给 Zookeeper 实现 可以将配置信息写入 Zookeeper 上的一个 ZNode；各个客户端服务器监听这个 ZNode；一旦 ZNode 中数据被修改，Zookeeper 将通知各个客户端服务器 统一集群管理 分布式环境下下，实时掌握各个节点的状态是非常必要的 可根据节点实时状态做一些调整 Zookeeper 可以实现实时监控节点状态变化 可以将节点信息写入 Zookeeper 上的一个 ZNode；监听这个 ZNode 获取它的实时状态变化 服务器节点动态上下线 客户端能实时洞察到服务器上下线变化 软负载均衡 在 Zookeeper 中记录每台服务器的访问数，让访问数最少的服务器去处理最新的客户端请求 安装以 Zookeeper 3.4.10 为例。 本地模式安装省略 JDK 安装步骤 将 Zookeeper 的压缩包拷贝到服务器上，解压到 /opt/software 1tar -zxf zookeeper-3.4.10.tar.gz -C /opt/module/ 修改配置 将 /opt/module/zookeeper-3.4.10/conf/ 下的 zoo_sample.cfg 复制一份为 zoo.cfg 修改 dataDir 路径 1234567891011[root@hadoop02 conf]# vim zoo.cfg # 心跳，2秒一次tickTime=2000# Leader 和 Follower 之间刚启动时进行通信的最大延迟时间：10 个心跳。如果超过 10 个心跳都没有通信，则认为 Leader 和 Follower 连接失败initLimit=10# 同步频率，5 个心跳；启动成后，5 个心跳没有通信，认为 Leader、Follower 连接失败syncLimit=5# 数据存储位置dataDir=/opt/module/zookeeper-3.4.10/zkData# 客户端的端口号，即 Client 访问 Zookeeper 时使用哪个端口通信clientPort=2181 在 ZOOKEEPER_HOME 中创建 zkData 文件夹 启动 Zookeeper 服务、查看启动结果 12345678910111213141516# 启动服务[root@hadoop02 zookeeper-3.4.10]# bin/zkServer.sh startZooKeeper JMX enabled by defaultUsing config: /opt/module/zookeeper-3.4.10/bin/../conf/zoo.cfgStarting zookeeper ... STARTED# 查看启动结果[root@hadoop02 zookeeper-3.4.10]# bin/zkServer.sh statusZooKeeper JMX enabled by defaultUsing config: /opt/module/zookeeper-3.4.10/bin/../conf/zoo.cfgMode: standalone# 查看进程[root@hadoop02 zookeeper-3.4.10]# jps1425 Jps1369 QuorumPeerMain 启动客户端 12345678910111213141516171819202122232425262728[root@hadoop02 zookeeper-3.4.10]# bin/zkCli.sh Connecting to localhost:21812019-12-19 14:48:02,837 [myid:] - INFO [main:Environment@100] - Client environment:zookeeper.version=3.4.10-39d3a4f269333c922ed3db283be479f9deacaa0f, built on 03/23/2017 10:13 GMT2019-12-19 14:48:02,839 [myid:] - INFO [main:Environment@100] - Client environment:host.name=hadoop022019-12-19 14:48:02,839 [myid:] - INFO [main:Environment@100] - Client environment:java.version=1.8.0_1442019-12-19 14:48:02,841 [myid:] - INFO [main:Environment@100] - Client environment:java.vendor=Oracle Corporation2019-12-19 14:48:02,841 [myid:] - INFO [main:Environment@100] - Client environment:java.home=/opt/module/jdk1.8.0_144/jre2019-12-19 14:48:02,841 [myid:] - INFO [main:Environment@100] - Client environment:java.class.path=/opt/module/zookeeper-3.4.10/bin/../build/classes:/opt/module/zookeeper-3.4.10/bin/../build/lib/*.jar:/opt/module/zookeeper-3.4.10/bin/../lib/slf4j-log4j12-1.6.1.jar:/opt/module/zookeeper-3.4.10/bin/../lib/slf4j-api-1.6.1.jar:/opt/module/zookeeper-3.4.10/bin/../lib/netty-3.10.5.Final.jar:/opt/module/zookeeper-3.4.10/bin/../lib/log4j-1.2.16.jar:/opt/module/zookeeper-3.4.10/bin/../lib/jline-0.9.94.jar:/opt/module/zookeeper-3.4.10/bin/../zookeeper-3.4.10.jar:/opt/module/zookeeper-3.4.10/bin/../src/java/lib/*.jar:/opt/module/zookeeper-3.4.10/bin/../conf:2019-12-19 14:48:02,841 [myid:] - INFO [main:Environment@100] - Client environment:java.library.path=/opt/module/protobuf-2.5.0:/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib2019-12-19 14:48:02,841 [myid:] - INFO [main:Environment@100] - Client environment:java.io.tmpdir=/tmp2019-12-19 14:48:02,841 [myid:] - INFO [main:Environment@100] - Client environment:java.compiler=&lt;NA&gt;2019-12-19 14:48:02,841 [myid:] - INFO [main:Environment@100] - Client environment:os.name=Linux2019-12-19 14:48:02,841 [myid:] - INFO [main:Environment@100] - Client environment:os.arch=amd642019-12-19 14:48:02,842 [myid:] - INFO [main:Environment@100] - Client environment:os.version=3.10.0-693.el7.x86_642019-12-19 14:48:02,842 [myid:] - INFO [main:Environment@100] - Client environment:user.name=root2019-12-19 14:48:02,842 [myid:] - INFO [main:Environment@100] - Client environment:user.home=/root2019-12-19 14:48:02,842 [myid:] - INFO [main:Environment@100] - Client environment:user.dir=/opt/module/zookeeper-3.4.102019-12-19 14:48:02,843 [myid:] - INFO [main:ZooKeeper@438] - Initiating client connection, connectString=localhost:2181 sessionTimeout=30000 watcher=org.apache.zookeeper.ZooKeeperMain$MyWatcher@5c29bfdWelcome to ZooKeeper!2019-12-19 14:48:02,866 [myid:] - INFO [main-SendThread(localhost:2181):ClientCnxn$SendThread@1032] - Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)JLine support is enabled2019-12-19 14:48:02,937 [myid:] - INFO [main-SendThread(localhost:2181):ClientCnxn$SendThread@876] - Socket connection established to localhost/127.0.0.1:2181, initiating session2019-12-19 14:48:02,955 [myid:] - INFO [main-SendThread(localhost:2181):ClientCnxn$SendThread@1299] - Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x16f1ce7c5fd0000, negotiated timeout = 30000WATCHER::WatchedEvent state:SyncConnected type:None path:null[zk: localhost:2181(CONNECTED) 0] 退出客户端 1234[zk: localhost:2181(CONNECTED) 5] quitQuitting...2019-12-19 14:49:22,721 [myid:] - INFO [main:ZooKeeper@684] - Session: 0x16f1ce7c5fd0000 closed2019-12-19 14:49:22,722 [myid:] - INFO [main-EventThread:ClientCnxn$EventThread@519] - EventThread shut down for session: 0x16f1ce7c5fd0000 关闭服务 1234[root@hadoop02 zookeeper-3.4.10]# bin/zkServer.sh stopZooKeeper JMX enabled by defaultUsing config: /opt/module/zookeeper-3.4.10/bin/../conf/zoo.cfgStopping zookeeper ... STOPPED 分布式安装在 hadoop 基础上，在 hadoop02、hadoop03、hadoop04 三个节点上部署 Zookeeper 在 hadoop02 上创建 zkData 文件夹，并在文件夹内创建一个 myid 文件将 zookeeper 文件夹分发到剩余两台机器上 1xsync /opt/module/zookeeper-3.4.10/ 修改三台服务器上的 myid 文件，文件内容分别为 2、3、4修改 hadoop02 上的 zoo.cfg 文件，并分发到其他服务器上 12345678####################cluster##################### 注意，必须以 server. 开头， . 后面的数字是 myid 文件中配置的数字# hadoop02 是服务器的 ip 地址或 hostname# 2888：服务器与集群中的 Leader 交换信息的端口# 3888：如果 Leader 挂了，需要一个端口来重新进行选举 server.2=hadoop02:2888:3888server.3=hadoop03:2888:3888server.4=hadoop04:2888:3888 分别启动 Zookeeper，查看状态 12345678910111213141516171819202122232425262728293031323334# hadoop02[root@hadoop02 zookeeper-3.4.10]# bin/zkServer.sh startZooKeeper JMX enabled by defaultUsing config: /opt/module/zookeeper-3.4.10/bin/../conf/zoo.cfgStarting zookeeper ... STARTED[root@hadoop02 zookeeper-3.4.10]# bin/zkServer.sh statusZooKeeper JMX enabled by defaultUsing config: /opt/module/zookeeper-3.4.10/bin/../conf/zoo.cfgMode: follower# hadoop03[root@hadoop03 zookeeper-3.4.10]# bin/zkServer.sh startZooKeeper JMX enabled by defaultUsing config: /opt/module/zookeeper-3.4.10/bin/../conf/zoo.cfgStarting zookeeper ... STARTED[root@hadoop03 zookeeper-3.4.10]# bin/zkServer.sh statusZooKeeper JMX enabled by defaultUsing config: /opt/module/zookeeper-3.4.10/bin/../conf/zoo.cfgMode: leader# hadoop04[root@hadoop04 zookeeper-3.4.10]# bin/zkServer.sh startZooKeeper JMX enabled by defaultUsing config: /opt/module/zookeeper-3.4.10/bin/../conf/zoo.cfgStarting zookeeper ... STARTED[root@hadoop04 zookeeper-3.4.10]# bin/zkServer.sh statusZooKeeper JMX enabled by defaultUsing config: /opt/module/zookeeper-3.4.10/bin/../conf/zoo.cfgMode: follower 客户端命令行操作help可以显示所有操作命令 1234567891011121314151617181920212223[zk: localhost:2181(CONNECTED) 3] helpZooKeeper -server host:port cmd args stat path [watch] set path data [version] ls path [watch] delquota [-n|-b] path ls2 path [watch] setAcl path acl setquota -n|-b val path history redo cmdno printwatches on|off delete path [version] sync path listquota path rmr path get path [watch] create [-s] [-e] path data acl addauth scheme auth quit getAcl path close connect host:port ls path [watch]查看当前 ZNode 中所包含的内容；除根节点外，都不能以 / 结尾 12[zk: localhost:2181(CONNECTED) 1] ls /[zookeeper] 节点监听 在 hadoop03、hadoop04 上，监听 /laiyy 节点的变化。 12[zk: localhost:2181(CONNECTED) 0] ls /laiyy watch[gender0000000002, name, gender0000000001, gender0000000004, gender0000000003] 在 hadoop02 上修改/创建一个 /laiyy 节点或子节点，查看 hadoop03、hadoop04 的变化 12[zk: localhost:2181(CONNECTED) 16] create /laiyy/email &apos;laiyy0728@gmail.com&apos;Created /laiyy/email 1234[zk: localhost:2181(CONNECTED) 1] WATCHER::WatchedEvent state:SyncConnected type:NodeChildrenChanged path:/laiyy 注意：监听方式只有一次有效，即监听到一次变化后，后续的就不再监听了 ls2 path [watch]获取 ZNode 总所包含的内容，包括更新时间、次数等；除根节点外，都不能以 / 结尾 12345678910111213[zk: localhost:2181(CONNECTED) 2] ls2 /[zookeeper]cZxid = 0x0ctime = Thu Jan 01 08:00:00 CST 1970mZxid = 0x0mtime = Thu Jan 01 08:00:00 CST 1970pZxid = 0x0cversion = -1dataVersion = 0aclVersion = 0ephemeralOwner = 0x0dataLength = 0numChildren = 1 create普通创建。 -s 含有序列， -e 临时（重启或超时即消失） 注意： 创建节点的同时，需要写入数据，否则创建不成功 1234[zk: localhost:2181(CONNECTED) 4] create /laiyy &quot;test_create&quot;Created /laiyy[zk: localhost:2181(CONNECTED) 5] ls /[laiyy, zookeeper] 短暂节点 1234[zk: localhost:2181(CONNECTED) 0] create -e /laiyy/name &quot;laiyy&quot;Created /laiyy/name[zk: localhost:2181(CONNECTED) 1] ls /laiyy[name] 创建成功后，退出客户端重新连接查看 /laiyy 节点 1234567891011[zk: localhost:2181(CONNECTED) 2] quitQuitting...2019-12-20 10:24:15,052 [myid:] - INFO [main:ZooKeeper@684] - Session: 0x26f2112be2b0001 closed2019-12-20 10:24:15,054 [myid:] - INFO [main-EventThread:ClientCnxn$EventThread@519] - EventThread shut down for session: 0x26f2112be2b0001[root@hadoop02 zookeeper-3.4.10]# bin/zkCli.sh Connecting to localhost:2181[zk: localhost:2181(CONNECTED) 0] ls /laiyy[] 带序号的节点（持久型） 123456789101112131415[zk: localhost:2181(CONNECTED) 1] create -s /laiyy/gender &apos;man&apos;Created /laiyy/gender0000000001[zk: localhost:2181(CONNECTED) 4] ls /laiyy[gender0000000001][zk: localhost:2181(CONNECTED) 1] create -s /laiyy/gender &apos;man&apos;Created /laiyy/gender0000000002[zk: localhost:2181(CONNECTED) 1] create -s /laiyy/gender &apos;man&apos;Created /laiyy/gender0000000003[zk: localhost:2181(CONNECTED) 1] create -s /laiyy/gender &apos;man&apos;Created /laiyy/gender0000000004[zk: localhost:2181(CONNECTED) 8] ls /laiyy[gender0000000002, gender0000000001, gender0000000004, gender0000000003] get path [watch]获取节点的值 12345678910111213[zk: localhost:2181(CONNECTED) 6] get /laiyytest_createcZxid = 0x200000002ctime = Fri Dec 20 10:19:03 CST 2019mZxid = 0x200000002mtime = Fri Dec 20 10:19:03 CST 2019pZxid = 0x200000002cversion = 0dataVersion = 0aclVersion = 0ephemeralOwner = 0x0dataLength = 11numChildren = 0 监听值的变化 在 hadoop03、hadoop04 上，监听 /laiyy 节点的变化。 12345678910111213[zk: localhost:2181(CONNECTED) 1] get /laiyy watchtest_createcZxid = 0x200000002ctime = Fri Dec 20 10:19:03 CST 2019mZxid = 0x200000002mtime = Fri Dec 20 10:19:03 CST 2019pZxid = 0x20000000dcversion = 7dataVersion = 0aclVersion = 0ephemeralOwner = 0x0dataLength = 11numChildren = 5 在 hadoop02 上，修改 /laiyy 节点的值，查看 hadoop03、hadoop04 上的输出123456789101112[zk: localhost:2181(CONNECTED) 15] set /laiyy &apos;emmmm&apos;cZxid = 0x200000002ctime = Fri Dec 20 10:19:03 CST 2019mZxid = 0x200000011mtime = Fri Dec 20 10:36:33 CST 2019pZxid = 0x20000000dcversion = 7dataVersion = 1aclVersion = 0ephemeralOwner = 0x0dataLength = 5numChildren = 5 1234[zk: localhost:2181(CONNECTED) 1] WATCHER::WatchedEvent state:SyncConnected type:NodeDataChanged path:/laiyy 注意：监听方式只有一次有效，即监听到一次变化后，后续的就不再监听了 set设置节点的具体值 创建 /laiyy/name 节点，赋值为 laiyy，使用 set 节点重新赋值 12345678910111213[zk: localhost:2181(CONNECTED) 12] get /laiyy/namelaiyycZxid = 0x20000000dctime = Fri Dec 20 10:31:18 CST 2019mZxid = 0x20000000dmtime = Fri Dec 20 10:31:18 CST 2019pZxid = 0x20000000dcversion = 0dataVersion = 0aclVersion = 0ephemeralOwner = 0x0dataLength = 5numChildren = 0 1234567891011121314151617181920212223242526[zk: localhost:2181(CONNECTED) 13] set /laiyy/name &apos;hahaha&apos;cZxid = 0x20000000dctime = Fri Dec 20 10:31:18 CST 2019mZxid = 0x20000000emtime = Fri Dec 20 10:32:50 CST 2019pZxid = 0x20000000dcversion = 0dataVersion = 1aclVersion = 0ephemeralOwner = 0x0dataLength = 6numChildren = 0[zk: localhost:2181(CONNECTED) 14] get /laiyy/name hahahacZxid = 0x20000000dctime = Fri Dec 20 10:31:18 CST 2019mZxid = 0x20000000emtime = Fri Dec 20 10:32:50 CST 2019pZxid = 0x20000000dcversion = 0dataVersion = 1aclVersion = 0ephemeralOwner = 0x0dataLength = 6numChildren = 0 stat查看节点状态 123456789101112[zk: localhost:2181(CONNECTED) 0] stat /laiyycZxid = 0x200000002ctime = Fri Dec 20 10:19:03 CST 2019mZxid = 0x200000011mtime = Fri Dec 20 10:36:33 CST 2019pZxid = 0x200000018cversion = 9dataVersion = 1aclVersion = 0ephemeralOwner = 0x0dataLength = 5numChildren = 7 delete删除节点 1234567[zk: localhost:2181(CONNECTED) 1] ls /laiyy[address, gender0000000002, name, gender0000000001, gender0000000004, email, gender0000000003][zk: localhost:2181(CONNECTED) 2] delete /laiyy/address[zk: localhost:2181(CONNECTED) 3] ls /laiyy[gender0000000002, name, gender0000000001, gender0000000004, email, gender0000000003][zk: localhost:2181(CONNECTED) 4] delete /laiyyNode not empty: /laiyy rmr递归删除节点 123[zk: localhost:2181(CONNECTED) 5] rmr /laiyy[zk: localhost:2181(CONNECTED) 6] ls / [zookeeper]]]></content>
      <categories>
        <category>zookeeper</category>
      </categories>
      <tags>
        <tag>zookeeper</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[hadoop（19）Map Reduce 多 Job 串联、Top N]]></title>
    <url>%2Fhadoop%2Fmap-reduce%2Fhadoop-19.html</url>
    <content type="text"><![CDATA[在之前的示例中，都是单个 Job 执行 MapReduce 程序，如何进行多 Job 串联？ 多 Job 串联在有大量的文本（文档、网页）时，如何建立索引？ 示例现有三个文档作为输入数据：a.txt、b.txt、c.txt，期望输出文件中某个字符串在哪个文件中，分别出现几次。 第一次 MapReduce12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667// Mapperpublic class FirstMapper extends Mapper&lt;LongWritable, Text, Text, IntWritable&gt; &#123; private String fileName; private Text outKey = new Text(); private IntWritable outValue = new IntWritable(1); @Override protected void setup(Context context) throws IOException, InterruptedException &#123; FileSplit fileSplit = (FileSplit) context.getInputSplit(); fileName = fileSplit.getPath().getName(); &#125; @Override protected void map(LongWritable key, Text value, Context context) throws IOException, InterruptedException &#123; String[] fields = value.toString().split(" "); for (String field : fields) &#123; String k = field + "--" + fileName; outKey.set(k); context.write(outKey, outValue); &#125; &#125;&#125;// Reducerpublic class FirstReduce extends Reducer&lt;Text, IntWritable, Text, IntWritable&gt; &#123; private IntWritable outValue = new IntWritable(); @Override protected void reduce(Text key, Iterable&lt;IntWritable&gt; values, Context context) throws IOException, InterruptedException &#123; int sum = 0; for (IntWritable value : values) &#123; sum += value.get(); &#125; outValue.set(sum); context.write(key, outValue); &#125;&#125;// Driverpublic static void main(String[] args) throws InterruptedException, IOException, ClassNotFoundException &#123; Configuration configuration = new Configuration(); Job job = Job.getInstance(configuration); job.setJarByClass(FirstDriver.class); job.setMapperClass(FirstMapper.class); job.setReducerClass(FirstReduce.class); job.setMapOutputKeyClass(Text.class); job.setMapOutputValueClass(IntWritable.class); job.setOutputKeyClass(Text.class); job.setOutputValueClass(IntWritable.class); FileInputFormat.setInputPaths(job, new Path("D:\\dev\\hadoop\\job\\*.txt")); FileOutputFormat.setOutputPath(job, new Path("D:\\dev\\hadoop\\job\\output")); boolean succeed = job.waitForCompletion(true); System.exit(succeed ? 0 : 1);&#125; 运行结果： 第二次 MapReduce12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061// Mapperpublic class SecondMapper extends Mapper&lt;LongWritable, Text, Text, Text&gt; &#123; private Text outKey = new Text(); private Text outValue = new Text(); @Override protected void map(LongWritable key, Text value, Context context) throws IOException, InterruptedException &#123; String line = value.toString(); String[] split = line.split("--"); outKey.set(split[0]); outValue.set(split[1]); context.write(outKey, outValue); &#125;&#125;// Reducerpublic class SecondReducer extends Reducer&lt;Text, Text, Text, Text&gt; &#123; private Text outValue = new Text(); @Override protected void reduce(Text key, Iterable&lt;Text&gt; values, Context context) throws IOException, InterruptedException &#123; StringBuilder builder = new StringBuilder(); for (Text value : values) &#123; builder.append(value.toString().replace("\t", "--&gt;")).append("\t"); &#125; outValue.set(builder.toString()); context.write(key, outValue); &#125;&#125;// Driverpublic static void main(String[] args) throws IOException, ClassNotFoundException, InterruptedException &#123; Configuration configuration = new Configuration(); Job job = Job.getInstance(configuration); job.setJarByClass(SecondDriver.class); job.setMapperClass(SecondMapper.class); job.setReducerClass(SecondReducer.class); job.setMapOutputKeyClass(Text.class); job.setMapOutputValueClass(Text.class); job.setOutputKeyClass(Text.class); job.setOutputValueClass(Text.class); FileInputFormat.setInputPaths(job, new Path("D:\\dev\\hadoop\\job\\output\\part-r-00000")); FileOutputFormat.setOutputPath(job, new Path("D:\\dev\\hadoop\\job\\output1")); boolean succeed = job.waitForCompletion(true); System.exit(succeed ? 0 : 1);&#125; 运行结果 TopN将 排序 Demo 的输出结果进行加工，输出总使用量的前 5 位。 示例FlowBean 保持 排序 Demo 中的实现不变，修改 Mapper、Reducer Mapper 12345678910111213141516171819202122232425262728293031323334353637383940414243444546public class TopnMapper extends Mapper&lt;LongWritable, Text, FlowBean, Text&gt; &#123; /** * 定义一个 TreeMap，作为存储数据的容器 */ private TreeMap&lt;FlowBean, Text&gt; flowMap = new TreeMap&lt;&gt;(); private FlowBean flowBean ; @Override protected void map(LongWritable key, Text value, Context context) throws IOException, InterruptedException &#123; String line = value.toString(); String[] fields = line.split("\t"); String phone = fields[0]; long upFlow = Long.parseLong(fields[1]); long downFlow = Long.parseLong(fields[2]); // 在 map 中创建对象，否则将只会在 flowMap 中存入同一个对象 flowBean = new FlowBean(); flowBean.set(upFlow, downFlow); Text v = new Text(); v.set(phone); flowMap.put(flowBean, v); // 限制 TreeMap 数量 if (flowMap.size() &gt; 5) &#123; flowMap.remove(flowMap.lastKey()); &#125; &#125; @Override protected void cleanup(Context context) throws IOException, InterruptedException &#123; // 遍历 map，输出数据 flowMap.forEach((key, value) -&gt; &#123; try &#123; context.write(key, value); &#125; catch (IOException | InterruptedException e) &#123; e.printStackTrace(); &#125; &#125;); &#125;&#125; Reducer 1234567891011121314151617181920212223242526272829303132333435public class TopnReducer extends Reducer&lt;FlowBean, Text, Text, FlowBean&gt; &#123; /** * 定义一个 TreeMap，作为存储数据的容器 */ private TreeMap&lt;FlowBean, Text&gt; flowMap = new TreeMap&lt;&gt;(); @Override protected void reduce(FlowBean key, Iterable&lt;Text&gt; values, Context context) throws IOException, InterruptedException &#123; for (Text value : values) &#123; FlowBean flowBean = new FlowBean(); flowBean.set(key.getUpFlow(), key.getDownFlow()); flowMap.put(flowBean, new Text(value)); // 如果超过 10 条，去掉流量最小的一条 if (flowMap.size() &gt; 5) &#123; flowMap.remove(flowMap.lastKey()); &#125; &#125; &#125; @Override protected void cleanup(Context context) throws IOException, InterruptedException &#123; // 输出数据 flowMap.forEach((key, value) -&gt; &#123; try &#123; context.write(value, key); &#125; catch (IOException | InterruptedException e) &#123; e.printStackTrace(); &#125; &#125;); &#125;&#125; 省略 Driver，查看结果]]></content>
      <categories>
        <category>hadoop</category>
        <category>map-reduce</category>
      </categories>
      <tags>
        <tag>hadoop</tag>
        <tag>map-reduce</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[hadoop（18） YARN 资源调度器、Hadoop 优化]]></title>
    <url>%2Fhadoop%2Fyarn%2Fhadoop-18.html</url>
    <content type="text"><![CDATA[Yarn 是一个资源调度平台，负责为运算程序提供服务器运算资源，相当于一个分布式的 操作系统，而 MapReduce 等运算程序相当于 操作系统上的应用程序 基础架构Yarn 由 ResourceManager、NodeManager、ApplicationMaster、Container 等组件构成。 ResourceManager 处理客户端请求 监控 NodeManager 启动或监控 ApplicationMaster 资源的分配和调度 NodeManager 管理单个节点上的资源 处理来自 ResourceManager 的命令 处理来自 ApplicationMaster 的命令 ApplicationMaster 负责数据的切分 为应用程序申请资源，并分配给内部的任务 任务的监控、容错 Container 是 YARN 资源的抽象，封装了某个节点上的多维度资源，如：内存、CPU、磁盘、网络等。 工作机制 MapReduce 程序提交任务到客户端所在的节点 申请一个 Application 到 ResourceManager ResourceManager 返回 资源提交路径 和 application_id 将任务所需资源提交到 资源提交路径 上，包括切片信息(Job.Split)，任务信息（Job.xml）、所需 jar 包 资源提交完成后，申请运行 MrAppMaster ResourceManager 将用户的请求初始化为一个 Task，进入任务队列 NodeManager 到 ResourceManager 领取 Task 任务 NodeManager 创建 Container 容器，分配 CPU、内存等资源，启动对应的 MrAppMaster NodeManager 下载 job 资源到本地，MrAppMaster 读取切片信息，决定开启多少个 MapTask Container 向 ResourceManager 申请运行 MapTask 容器 其余 NodeManager 重复 7-10 步骤，等待任务领取完成 任务领取完成后，MrAppMaster 统一发送程序运行脚本，启动 MapTask 所有 MapTask 执行完成后，由 MrAppMaster 向 ResourceManager 申请对应切片数量的 ReduceTask，进行 reduce 工作 ReduceTask 从 MapTask 中获取相应的数据 ReduceTask 执行完成后，MrAppMaster 想 ResourceManager 申请注销自己 资源调度器资源调度器对应上图中的 FIFO调度队列。 Hadoop 资源调度器主要有三种：FIFO(队列)、Capacity Scheduler(容量调度器)、Fair Scheduler(公平调度器)， 默认资源调度器为 Capacity Scheduler FIFO按照到达时间，先到先服务；单项执行 当有新的服务器节点资源时，从队列中获取一个任务，从任务重分配一个 Task 给节点进行服务 Capacity SchedulerHadoop 默认调度器，按照到达时间，先到先服务；并发执行 支持多个队列，每个队列可配置一定的资源量，每个队列采用 FIFO 调度策略为防止同一个用户的作业独占队列中的资源，调度器会对同一个用户提交的作业所占资源量进行限制。如果调度器中有三个队列，可以从三个队列的头部取出三个任务并发执行，相比 FIFO 提高了任务的执行速度。 计算方式：首先，计算每个队列中正在执行的任务数与其应该分得的资源之间的比值，选择一个最小（最闲）的队列；其次，按照作业优先级和提交时间顺序，同时考虑用户资源量限制和内存限制对队列内的任务进项排序 Fair Scheduler按照缺额排序，缺额越大越优先；并发度最高 支持多队列、多用户每个队列中的资源量可以配置同一个队列中的作业公平共享队列的所有资源 分配方式：假设有三个队列：QA、QB、QC，每个队列中的任务按照优先级分配资源，优先级越高分配的资源越多。但是每个任务都会分配到资源，以确保 公平。在资源有限的情况下，每个任务理想情况下获得的资源与实际获得的资源可能存在一定的差距，这个差距就称为 缺额。通一个队列中，任务的资源缺额越大，越先获得资源优先执行。作业是按照缺额的高低来先后执行的，且多个作业同时运行。 任务的推测执行作业完成时间取决于最慢任务的完成时间 一个作业由若干个 Map 任务和 Reduce 任务构成，因硬件老化、软件 bug 等，某些任务可能运行的非常慢（如：99% 的Map 都完成了，少数的 Mpa 进度很慢完不成） 解决方案： 为慢的任务启动一个 备份任务，同时运行，谁先运行完就采用谁的结果。 执行推测任务的前台条件 每个 Task 只能有一个备份任务 当前 Job 已完成的 Task 必须小于 5% 在 mapred-site.xml 中开启推测执行（默认是打开的） 123456789&lt;property&gt; &lt;name&gt;mapreduce.map.speculative&lt;/name&gt; &lt;value&gt;true&lt;/value&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;mapreduce.reduce.speculative&lt;/name&gt; &lt;value&gt;true&lt;/value&gt;&lt;/property&gt; 不能启动推测任务的情况 任务间存在严重的负载倾斜 特殊任务（如向数据库中写数据） 推测方法假设某一时刻，任务 T 的执行进度为 progress，则可通过一定的算法来推测出该任务最终完成的时刻 endTime；另一方面，如果此刻为该任务开启一个备份任务，则可以推断出备份任务可能的完成时刻 endTime1。则： 12345678runTime = (currentTimestamp - taskStartTime) / progress推测运行时间 = (当前时刻 - 任务启动时刻) / 任务运行比例endTime = runTIme + taskStartTime推测结束时刻 = 运行时间 + 任务启动时刻entTime1 = currentTimestamp + avgRunTime备份任务推测完成时刻 = 当前时刻 + 运行完成任务的平均时间 MR 总是选择 entTime - endTime1 差值最大的任务，并为之启动备份任务为防止大量任务同时启动备份任务造成资源浪费，MR 为每个作业设置了同时启动备份任务数目的上限推测执行机制实际上采用了经典的优化方案：以空间换时间。同时启动多个相同的任务处理相同数据，并让这些任务竞争，以缩短数据处理时间。显然这种方法占用更多的计算资源。在集群资源紧缺的情况下，应合理使用，争取在多用少量资源的情况下，减少作业的计算时间 Hadoop 优化MapReduce 速度慢的原因MapReduce 效率的瓶颈在于：计算机性能、IO 操作优化 计算机性能包括： CPU、内存、磁盘监控、网络 IO 操作优化包括： 数据倾斜Map 和 Reduce 数设置不合理Map 运行时间太长，导致 Reduce 等待太久小文件过多大量不可分块的超大文件溢写次数过多归并次数过多 优化方法可以从六个方面考虑优化：数据输入、Map、Reduce、IO、数据倾斜、参数调优 数据输入 合并小文件 在执行 MR 任务之前，将小文件进行合并，大量小文件会产生大量的 Map 任务，增加 Map 任务装载数，而任务的装载比较耗时，从而导致 MR 运行慢。 解决办法：采用 CombinerTextInputFormat 作为输入，解决输入端大量小文件的问题。 Map 减小溢写次数 通过调整 mapred-site.xml 文件中的 mapreduce.task.io.sort.mb 和 mapreduce.map.sort.spill.percent 参数，增大触发溢写的内存上限，减少溢写次数，从而减小磁盘 IO 减少合并次数 通过调整 mapred-site.xml 文件中的 mapreduce.task.io.sort.factor 参数，增大合并的文件数目，减少合并次数，从而缩短 MR 处理时间 在 Map 之后，不影响业务逻辑的前台下，先进行 Combine 处理，减少 IO（适用于汇总） Reduce 合理设置 Map、Reduce 数 影响 Map 个数的是 切片，影响 reduce 个数的是 setNumReduceTasks 方法。这两个数值都不能设置太小，也不能太大。太小会导致 Task 等待，处理时间长；太大会导致 Map、Reduce 任务间竞争资源，造成处理超时等错误 设置 Map、Reduce 共存 调整 mapred-site.xml 文件中的 mapreduce.job.reduce.slowstart.completedmaps 参数，使 Map 运行到一定程度后，Reduce 也开始运行，减少 Reduce 等待时间。 规避使用 Reduce 由于 Reduce 在用于连接数据集的时候会产生大量的网络消耗，如果不需要使用 Reduce，则可以进行规避，减少大量的 shuffle 时间 合理设置 Reduce 的 buffer 默认情况下，数据达到一个阈值的时候，Buffer 中的数据就会写入磁盘，然后 Reduce 会从磁盘中获得所有数据。Buffer 和 Reduce 是没有直接关联的，中间有多次 写磁盘 -&gt; 读磁盘 的过程，可以通过调整参数来规避，使得 Buffer 中的一部分数据可以直接输送到 Reduce，减少 IO 开销。 通过调整 mapred-site.xml 文件中的 mapreduce.reduce.input.buffer.percent 配置，默认为 0.0。 当数值大于 0 时，会保留指定比例的内存读 Buffer 中的数据直接交给 Reduce，这样一来，设置 Buffer 需要内存、读取数据需要内存、Reduce 计算也需要内存，如果调整的不合理可能会撑爆服务器，因此需要根据作业运行情况去进行调整。 IO 数据压缩 安装 Snappy 或 LZO，开启数据压缩 使用 SequenceFile 二进制文件 数据倾斜数据倾斜包含：数据频率倾斜（某一区域内的数据量远远大于其他区域）、数据大小倾斜（部分记录的大小远远大于平均值） 解决方案 抽样和范围分区 通过对原始数据进行抽样得到的结果集来预设分区边界值。 自定义分区 使用自定义分区，将某些 key 发送给固定的 Reduce 实例，将剩余 key 发送给剩余的 Reduce 实例 Combine 使用 Combine 可以大量较小数据倾斜，在可能的情况下，Combine 的目的就是聚合并精简数据 采用 MapJoin，避免 ReduceJoin 参数设置 mapred-default.xml 参数 说明 mapreduce.map.memory.mb 一个 MapTask 可以使用的资源上线，默认 1024M。如果 MapTask 实际使用的资源超过该值，将被强制杀死 mapreduce.reduce.memory.mb 一个 ReduceTask 可以使用的资源上线，默认 1024M。如果 ReduceTask 实际使用的资源超过该值，将被强制杀死 mapreduce.map.cpu.vcores 一个 MapTask 可使用的最大 CPU 数目，默认 1 mapreduce.reduce.cpu.vcores 一个 ReduceTask 可使用的最大 CPU 数目，默认 1 mapreduce.reduce.shuffle.parallelcopies 每个 Reduce 去 Map 中获取数据的并行数，默认 5 mapreduce.reduce.shuffle.merge.percent Buffer 中的数据达到多少比例开始写入磁盘，默认 0.66 mapreduce.reduce.shuffle.input.buffer.percent Buffer 大小占 Reduce 可用内存的比例，默认 0.7 mapreduce.reduce.input.buffer.percent 指定多少比例的内存用来存放 Buffer 中的数据，默认 0.0 mapreduce.task.io.sort.mb Shuffle 的环形缓冲区大小，默认 100M mapreduce.map.sort.spill.percent 环形缓冲区溢写的阈值，默认 0.8 mapreduce.map.maxattempts 每个 MapTask 最大重试次数，超过该值认为 MapTask 失败，默认 4 mapreduce.reduce.maxattempts 每个 ReduceTask 最大重试次数，超过该值认为 ReduceTask 失败，默认 4 mapreduce.task.timeout Task 超时时间，如果 Task 在一定时间内没有读取新数据，也没有输出数据，则认为 Task 处于 Block 状态，为防止因为用户程序永远 Block 不退出，则强制设置一个超时时间，默认为 10 分钟 yarn-default.xml 参数 说明 yarn.scheduler.minimum-allocation-mb 应用程序 Container 分配的最小内存，默认 1024 yarn.scheduler.maximum-allocation-mb 应用程序给 Container 份分配的最大内存，默认 8192 yarn.scheduler.minimum-allocation-vcores 每个 Container 申请最小 CPU 核数，默认 1 yarn.scheduler.maximum-allocation-vcores 每个 Container 申请的最大 CPU 核数，默认 4 yarn.nodemanager.resource.memory-mb 给 Container 分配的最大物理内存，默认 8192 小文件优化 小文件弊端 HDFS 上每个文件都要在 NameNode 上建立一个索引，索引大小约 150 byte，当小文件较多时会产生很多索引文件，一方面会大量占用 NameNode 的内存空间，另一方面就是索引文件过大，使得索引速度变慢。 优化方式 在数据采集时，将小文件或小批数据合并为大文件再上传 HDFS 在业务处理前，在 HDFS 上使用 MapReduce 程序，对小文件进行合并 在 MapReduce 处理时，使用 CombineTextInputFormat 提高效率 解决方案 Hadoop Archive 归档是一个高效的将小文件放入 HDFS 块中的文件存档工具，能工将多个小文件打包为一个 HAR 文件，减少 NameNode 内存使用 Sequence File 由一系列二进制 KV 组成，如果 key 为文件名，value 为文件内存，则可以将大批小文件合并成一个大文件 CombineFileInputFormat 新的 InputFormat，用于将多个文件合并为一个单独的 Split，且它会考虑数据的存储位置 开启 JVM 重用 对于大量小文件的任务，可以开启 JVM 重用，会减少大约一半的运行时间。JVM 重用原理：一个 Map 运行在一个 JVM 中，开启后，该 Map 在 JVM 上运行完毕后，JVM 会继续运行其他的 Map。可以通过修改 mapred-site.xml 中的 mapreduce.job.jvm.numtasks 参数，默认为 1，即运行一个 Task 就销毁 JVM]]></content>
      <categories>
        <category>hadoop</category>
        <category>yarn</category>
      </categories>
      <tags>
        <tag>hadoop</tag>
        <tag>yarn</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[hadoop（17） Map Reduce 计数器、压缩]]></title>
    <url>%2Fhadoop%2Fmap-reduce%2Fhadoop-17.html</url>
    <content type="text"><![CDATA[Hadoop 为每个作业维护若干个内置计数器，以描述多项指标。如：记录已处理的字节数和记录数，使用户可以监控已处理的输入数据量和已产生的输出数据量 计数器计数器 API 枚举方式计数采用计数器组、计数器名称的方式计数计数器结果在程序运行后，在控制台上查看 示例在运行核心业务 MapReduce 之前，往往要先进行数据清洗，清理掉不符合用户要求的数据。清理过程往往只需要运行 Mapper 程序，不需要运行 Reduce 程序 使用一个项目中的日志信息作为输入数据，去除字段长度小于 11 的日志信息 数据信息敏感，不公开 123456789101112131415161718192021222324public class LogMapper extends Mapper&lt;LongWritable, Text, Text, NullWritable&gt; &#123; @Override protected void map(LongWritable key, Text value, Context context) throws IOException, InterruptedException &#123; String line = value.toString(); boolean result = parseLog(line, context); if (result)&#123; return; &#125; context.write(value, NullWritable.get()); &#125; private boolean parseLog(String line, Context context) &#123; String[] fields = line.split(" "); if (fields.length &gt; 11)&#123; context.getCounter("map", "true").increment(1); return true; &#125; context.getCounter("map", "false").increment(1); return false; &#125;&#125; 123456789101112131415161718192021222324252627282930public static void main(String[] args) throws IOException, ClassNotFoundException, InterruptedException &#123; // 获取 job 对象 Configuration configuration = new Configuration(); Job job = Job.getInstance(configuration); // 设置 jar 存放路径 job.setJarByClass(LogDriver.class); // 关联 Mapper、Reducer 业务类 job.setMapperClass(LogMapper.class); // 指定最终输出的数据 KV 类型 job.setOutputKeyClass(Text.class); job.setOutputValueClass(NullWritable.class); // 指定 job 的输入文件所在目录 FileInputFormat.setInputPaths(job, new Path("D:\\dev\\log\\*")); // 指定 job 的输出结果所在目录 FileOutputFormat.setOutputPath(job, new Path("D:\\dev\\log\\output")); job.setNumReduceTasks(0); // 提交 job boolean succeed = job.waitForCompletion(true); System.exit(succeed ? 0 : 1);&#125; 查看结果 数据清洗前： 数据清洗后： 具体更复杂的数据清洗，根据输入数据的不同进行高度定制化，此例只做基础概念思想 压缩压缩技术能够有效减少底层存储系统（HDFS）读写字节数。压缩提高了网络带宽和磁盘空间的效率。在运行 MapReduce 程序时，IO 操作、网络传输、shuffle 和 merge 要花费大量的时间，尤其是数据规模很大、工作负载密集的情况下，因此使用数据压缩非常重要。 磁盘IO 和网络带宽是 hadoop 的宝贵资源，数据压缩对于节省资源、最小化磁盘 IO、网络传输很有帮助；可以在 任意 MapReduce 阶段启用压缩。压缩也是有代价的。 压缩是提高 hadoop 运行效率的一种优化策略，通过对 Mapper、Reduce 程序运行过程的数据进行压缩，以减少磁盘 IO，提高 MapReduce 程序运行速度。 注意：采用压缩技术，减少了磁盘 IO，但同时增加了 CPU 运算负担，所以，压缩特性运用得当，能提高性能，但是运用不得当也可能降低性能 压缩基本原则 运算密集型的任务，少用压缩 IO 密集型的任务，多用压缩 压缩编码 压缩格式 是否 hadoop 自带 算法 文件扩展名 是否可切分 是否需要修改程序 对应编解码器 DEFLATE 是 DEFLATE .deflate 否 否 DefaultCodec GZIP 是 DEFLATE .gz 否 否 GzipCodec bzip2 是 bzip2 .bz2 是 否 BZip2Codec LZO 否 LZO .lzo 是 是，需要建索引、指定输入格式 LzopCodec Snappy 否 Snappy .snappy 否 否 SnappyCodec 性能比较 压缩算法 原始文件大小 压缩文件大小 压缩速度 解压速度 gzip 8.3G 1.8G 17.5M/S 58M/S bzip2 8.3G 1.1G 2.4M/S 9.5M/S LZO 8.3G 2.9G 49.3M/S 74.6M/S Snappy 在单核 i7 64 位处理器上，压缩速度可以达到 250M/S 以上，解压速度可以达到 500M/S 以上；但是压缩完的文件大小还是很大，且不可以切分。 压缩方式对比GZip 压缩 优点： 压缩率较高，压缩、解压速度较快 hadoop 本身支持，在应用中处理 gzip 文件和直接处理文本一样 大部分 linux 系统都自带 gzip 命令，使用方便 缺点： 不支持切分 应用场景 当每个文件压缩后，文件大小在 130M 以内（即一个块大小的 1.1 倍以内），都可以考虑用 gzip 压缩。 BZip2 优点 支持切分 压缩率高 hadoop 自带，使用方便 缺点 压缩、解压速度慢 应用场景 对速度要求不高，但是要求较高压缩率； 输出后的数据比较大，处理后的速度需要压缩存档减少磁盘空间并且以后数据用的比较少 对单个很大的文本文件向压缩以较少存储空间，同时需要支持切分，而且兼容之前的应用程序 LZO 优点 压缩、解压速度快 压缩率合理 支持切分，hadoop 中最流行的压缩格式 可以在 linux 中安装 lzop 命令，使用方便 缺点 压缩率比 gzip 低 hadoop 本身不支持，需要安装 在应用中需要对 lzo 格式的文件做特殊处理（建索引、指定文件格式） 应用场景 一个很大的文本文件，压缩后还大于 200M 以上的可以考虑。单个文件越大，lzo 优点越明显 Snappy 优点 高速压缩、解压 压缩率合理 缺点 不支持切分 压缩率比 gzip 低 hadoop 本身不支持，需要安装 应用场景 当 MapReduce 的 Map 输出数据比较大，作为 Map 到 Reduce 的中间数据压缩格式 作为 MapReduce 作业的输出和另外一个 MapReduce 作业的输入 压缩位置的选择 Map 输入之前 在有大量数据并计划重复处理的情况下，应该考虑对输入进行压缩。此时无需指定使用的压缩方式，hadoop 可以检查文件的扩展名，如果扩展名能够匹配，就会使用恰当的编解码方式对文件进行压缩，否则，hadoop 不会使用压缩 Map 处理之后、Reduce 之前 当 Mapper 任务输出的中间数据量很大时，应考虑再此阶段采用压缩技术，能够显著改善内部数据的 shuffle 过程；而 shuffle 过程在 hadoop 处理过程中是消耗资源最多的环节。如果发现数据量大造成网络传输缓慢，应该考虑使用压缩技术，可以用于 Mapper 输出压缩的格式为：LZO、Snappy。 需要注意：LZO 是提供 hadoop 压缩数据的通用压缩编解码器。设计目的是达到与硬盘读写速度相当的压缩速度，因此速度是优先考虑的因素，而不是压缩率。与 gzip 编解码器相比，它的压缩速度是 gzip 的 5 倍，解压速度是 gzip 的 2 倍。同一个文件用 LZO 压缩后，比用 gzip 压缩后大 50%，但是比压缩前小 25%~50%，这对于改善性能非常有利，Map 阶段完成时间快大概 4 倍。 Reducer 输出 此阶段启用压缩，能够减少要存储的数据量，因此降低所需的磁盘空间。当 MapReduce 作业形成链条时，第二个作业的输入也以压缩，所以启用压缩同样有效。 压缩参数的配置 参数 默认值 阶段 备注 io.compression.codecs（core-site.xml） DefaultCodec、GzipCodec、BZipCodec 输入压缩 hadoop 使用文件扩展名判断是否支持某种编解码器 mapreduce.map.output.compress（mapred-site.xml） false mapper 输出 为 true 时启用压缩 mapreduce.map.output.compress.codec（mapred-site.xml） DefaultCodec mapper 输出 多用 LZO 或 Snappy mapreduce.output.fileoutputformat.compress（mapred-site.xml） false reduce 输出 为 true 时启用压缩 mapreduce.output.fileoutputformat.compress.type（mapred-site.xml） RECORD reduce 输出 SequenceFile 输出使用的压缩类型（BLOCK、NONE、RECORD） mapreduce.output.fileoutputformat.compress.codec（mapred-site.xml） DefaultCodec reduce 输出 具体的压缩编码 示例CompressionCodec 有两个方法可以用于轻松的压缩、解压数据。 想要对正在被写入一个输出流的数据进行压缩，可以使用 createOutputStream 方法创建一个 CompressionOutputStream，将其以压缩格式写入底层的流。想要对输入数据进行嘉业，可以使用 createInputStream 方法床架一个 CompressionInputStream，从而从底层的流读取未压缩的数据 压缩测试输入数据：使用之前 CombinerTextInputFormat 示例 中的 输入数据 d.txt 作为压缩测试的输入数据，测试不同压缩方式下的压缩率、耗时等。 123456789101112131415161718192021222324252627282930313233343536 public static void main(String[] args) throws Exception&#123; String filePath = "d:/dev/wordcount/d.txt";// String type = "org.apache.hadoop.io.compress.BZip2Codec";// String type = "org.apache.hadoop.io.compress.DefaultCodec"; String type = "org.apache.hadoop.io.compress.GzipCodec"; compress(filePath, type);&#125;/** * 测试压缩 * @param path 待压缩文件路径 * @param type 压缩方式 */private static void compress(String path, String type) throws Exception&#123; // 1. 获取输入流 FileInputStream inputStream = new FileInputStream(new File(path)); // 2. 设置压缩方式 Class&lt;?&gt; compressClass = Class.forName(type); // 3. 反射获取编解码实例 CompressionCodec codec = (CompressionCodec) ReflectionUtils.newInstance(compressClass, new Configuration()); // 4. 获取输出流，通过编解码实例获取后缀 FileOutputStream outputStream = new FileOutputStream(new File(path + codec.getDefaultExtension())); // 5.创建压缩输出流 CompressionOutputStream codecOutputStream = codec.createOutputStream(outputStream); // 6. 流的对拷 IOUtils.copyBytes(inputStream, codecOutputStream, 1024, false); // 7. 关闭资源 IOUtils.closeStream(codecOutputStream); IOUtils.closeStream(outputStream); IOUtils.closeStream(inputStream);&#125; 测试结果 可见压缩前后数据大小的区别非常明显 解压测试123456789101112131415161718192021222324252627282930313233public static void main(String[] args) throws Exception&#123;// String path = "d:/dev/wordcount/d.txt.bz2";// String path = "d:/dev/wordcount/d.txt.gz"; String path = "d:/dev/wordcount/d.txt.deflate"; decompress(path);&#125;private static void decompress(String path) throws Exception&#123; // 1. 校验文件是否可以解压 CompressionCodecFactory factory = new CompressionCodecFactory(new Configuration()); CompressionCodec codec = factory.getCodec(new Path(path)); if (null == codec)&#123; System.out.println("不支持压缩"); return; &#125; // 2. 获取输入流 FileInputStream inputStream = new FileInputStream(path); CompressionInputStream codecInputStream = codec.createInputStream(inputStream); // 3. 获取输出流 FileOutputStream fileOutputStream = new FileOutputStream(new File(path + ".txt")); // 4. 流对拷 IOUtils.copyBytes(codecInputStream, fileOutputStream, 1024, false); // 5. 关闭流 IOUtils.closeStream(fileOutputStream); IOUtils.closeStream(codecInputStream); IOUtils.closeStream(inputStream);&#125; 测试结果 Map 输出端采用压缩即是 MapReduce 的输入、输出文件都是未压缩的文件，仍然可以对 Map 任务的中间结果输出做压缩（原因是 Map 结束后要将文件写入磁盘，并通过网络传输到 Reduce 节点，对其压缩可以提高很多性能） Hadoop 源码支持的压缩格式有：BZip2Codec、DefaultCodec 基于 CombinerTextInputFormat 示例 进行操作。 首先执行 wordcount 实例，查看控制台 MapReduce 过程的字节数 1234567891011121314151617181920Map-Reduce Framework Map input records=3792092 Map output records=5056134 Map output bytes=50561388 Map output materialized bytes=60673704 Input split bytes=778 Combine input records=0 Combine output records=0 Reduce input groups=10 Reduce shuffle bytes=60673704 Reduce input records=5056134 Reduce output records=10 Spilled Records=10112268 Shuffled Maps =8 Failed Shuffles=0 Merged Map outputs=8 GC time elapsed (ms)=259 Total committed heap usage (bytes)=8830582784压缩前总耗时：9090 ms 修改 WordCountDriver，增加压缩配置 1234// 开启压缩configuration.set("mapreduce.map.output.compress", "true");// 指定压缩格式configuration.setClass("mapreduce.map.output.compress.codec", BZip2Codec.class, CompressionCodec.class); 再次运行测试，查看控制台 MapReduce 过程字节数（开启压缩后的程序会比开启压缩前要慢很多） 1234567891011121314151617181920Map-Reduce Framework Map input records=3792092 Map output records=5056134 Map output bytes=50561388 Map output materialized bytes=207808 Input split bytes=778 Combine input records=0 Combine output records=0 Reduce input groups=10 Reduce shuffle bytes=207808 Reduce input records=5056134 Reduce output records=10 Spilled Records=10112268 Shuffled Maps =8 Failed Shuffles=0 Merged Map outputs=8 GC time elapsed (ms)=286 Total committed heap usage (bytes)=7362576384压缩总耗时：312134 ms Reduce 输出压缩还是以上例为例，将 map 压缩注释掉（为了快速测试 reduce 压缩，省去 map 压缩的等待时间），增加如下配置，开启 reduce 压缩123456789// 开启 reduce 压缩FileOutputFormat.setCompressOutput(job, true);// 采用 bzip 压缩FileOutputFormat.setOutputCompressorClass(job, BZip2Codec.class);// 采用gzip压缩//FileOutputFormat.setOutputCompressorClass(job, GzipCodec.class);// 采用默认压缩//FileOutputFormat.setOutputCompressorClass(job, DefaultCodec.class); 测试三种压缩方式的执行耗时，由于文件过小，实际总耗时相差无几。 123reduce bz2 总耗时：9132reduce gz 总耗时：9166reduce default 总耗时：9038]]></content>
      <categories>
        <category>hadoop</category>
        <category>map-reduce</category>
      </categories>
      <tags>
        <tag>hadoop</tag>
        <tag>map-reduce</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[hadoop（16） Map Reduce ReduceJoin、MapJoin]]></title>
    <url>%2Fhadoop%2Fmap-reduce%2Fmap-join%2Fhadoop-16.html</url>
    <content type="text"><![CDATA[ReduceJoin 的工作： Map 端的主要工作：为来自不同表或者文件的 KV 对，打标签以区别不同来源的记录，然后用连接字段作为 key，其余部分和新加的标志位作为 value，最后进行输出。Reduce 端的主要工作：在 Reduce 端以连接字段作为 key 的分组已经完成，只需要在每个分组中，将那么来源于不同文件的记录分开，最后完成合并即可。 ReduceJoin示例需求：输入数据为两个表：订单、商品信息，将商品信息中的数据，根据商品的 pid，合并到订单数据中。 TableBean 12345678910111213141516171819202122232425262728293031323334353637383940414243444546public class TableBean implements Writable &#123; /** * 订单 id */ private String id; /** * 产品 id */ private String pid; /** * 数量 */ private int amount; /** * 产品名称 */ private String pname; /** * 标记位 */ private String flag; public void write(DataOutput dataOutput) throws IOException &#123; dataOutput.writeUTF(id); dataOutput.writeUTF(pid); dataOutput.writeInt(amount); dataOutput.writeUTF(pname); dataOutput.writeUTF(flag); &#125; public void readFields(DataInput dataInput) throws IOException &#123; id = dataInput.readUTF(); pid = dataInput.readUTF(); amount = dataInput.readInt(); pname = dataInput.readUTF(); flag = dataInput.readUTF(); &#125; @Override public String toString() &#123; return id + "\t" + pname + "\t" + amount; &#125; // 省略 get、set&#125; Mapper 1234567891011121314151617181920212223242526272829303132333435363738public class TableMapper extends Mapper&lt;LongWritable, Text, Text, TableBean&gt; &#123; private TableBean table = new TableBean(); private String fileName; private Text outKey = new Text(); /** * 在 map 执行前，获取文件名称，来判断当前处理的是哪个文件 */ @Override protected void setup(Context context) throws IOException, InterruptedException &#123; FileSplit inputSplit = ((FileSplit) context.getInputSplit()); fileName = inputSplit.getPath().getName(); &#125; @Override protected void map(LongWritable key, Text value, Context context) throws IOException, InterruptedException &#123; String line = value.toString(); String[] fields = line.split("\t"); if (fileName.contains("order")) &#123; // order.txt table.setId(fields[0]); table.setPid(fields[1]); table.setAmount(Integer.parseInt(fields[2])); table.setFlag("order"); &#125; else &#123; // pd.txt table.setFlag("pd"); table.setPid(fields[0]); table.setPname(fields[1]); &#125; outKey.set(table.getPid()); context.write(outKey, table); &#125;&#125; Reducer 1234567891011121314151617181920212223242526272829303132333435363738public class TableReducer extends Reducer&lt;Text, TableBean, TableBean, NullWritable&gt; &#123; @Override protected void reduce(Text key, Iterable&lt;TableBean&gt; values, Context context) throws IOException, InterruptedException &#123; List&lt;TableBean&gt; tableBeans = Lists.newArrayList(); // 注意！！！！！ // 一定要遍历中重新创建对象，拷贝数据到新创建的对象中，并把新创建的对象放入一个新的 list 中！！ // 否则 tableBeans 里面的对象都是同一个对象！！！ for (TableBean value : values) &#123; TableBean tableBean = new TableBean(); try &#123; // 示例使用的是 commons 包的对象拷贝，阿里规范禁止使用，如果在 spring 项目中使用 hadoop，尽量使用 spring util 的对象拷贝 BeanUtils.copyProperties(tableBean, value); tableBeans.add(tableBean); &#125; catch (IllegalAccessException | InvocationTargetException e) &#123; e.printStackTrace(); &#125; &#125; // 1. 获取 orders List&lt;TableBean&gt; orders = tableBeans.stream().filter(tableBean -&gt; tableBean.getFlag().equals("order")) .collect(Collectors.toList()); // 2. 获取商品，并转换为 map，key 为商品id，value 为商品名称 Map&lt;String, String&gt; pd = tableBeans.stream().filter(tableBean -&gt; tableBean.getFlag().equals("pd")) .collect(Collectors.toMap(TableBean::getPid, TableBean::getPname)); // 3. 遍历 orders，赋值 pname，并输出 for (TableBean order : orders) &#123; order.setPname(pd.get(order.getPid())); context.write(order, NullWritable.get()); &#125; &#125;&#125; 省略 Driver，查看运行结果 缺点合并的操作在 Reduce 阶段完成，Reduce 端的处理压力太大，Map 节点的运算负载很低，资源利用率不高，而且在 Reduce 阶段极易产生数据倾斜。 推荐使用 MapJoin MapJoin适用场景： 一个张表十分小，一个表十分大 优点 在 Map 端缓存多张表，提前处理业务逻辑，增加了 Map 业务，减少 Reduce 数据压力，尽可能减少数据倾斜 方法 1、在 Mapper 的 setup 阶段，将文件读取到缓存集合中2、在驱动函数中加载缓存 实现依然使用上例中的输入数据，输入结果也应该与上例一致。 Driver 由于 MapJoin 不需要 Reduce 端，此时可以将 Driver 中的 MapperKeyClass、MapperValueClass、ReduceClass 去掉 1234567891011121314151617181920212223242526272829303132333435public static void main(String[] args) throws Exception &#123; // 获取 job 对象 Configuration configuration = new Configuration(); Job job = Job.getInstance(configuration); // 设置 jar 存放路径 job.setJarByClass(MapJoinDriver.class); // 关联 Mapper、Reducer 业务类 job.setMapperClass(MapJoinMapper.class); // 指定最终输出的数据 KV 类型 job.setOutputKeyClass(Text.class); job.setOutputValueClass(NullWritable.class); // 指定 job 的输入文件所在目录 // 只读入 order FileInputFormat.setInputPaths(job, new Path("D:\\dev\\join\\order.txt")); // 指定 job 的输出结果所在目录 FileOutputFormat.setOutputPath(job, new Path("D:\\dev\\join\\output1")); // 加载缓存数据 job.addCacheFile(new URI("file:///d:/dev/join/pd.txt")); // MapJoin 的逻辑不需要 Reduce，设置 ReduceTask 为 0 job.setNumReduceTasks(0); // 提交 job boolean succeed = job.waitForCompletion(true); System.exit(succeed ? 0 : 1);&#125; Mapper 1234567891011121314151617181920212223242526272829303132public class MapJoinMapper extends Mapper&lt;LongWritable, Text, Text, NullWritable&gt; &#123; private Map&lt;String, String&gt; fieldMap = new HashMap&lt;&gt;(); private Text outKey = new Text(); @Override protected void setup(Context context) throws IOException, InterruptedException &#123; String path = context.getCacheFiles()[0].getPath(); BufferedReader reader = new BufferedReader(new InputStreamReader(new FileInputStream(path), StandardCharsets.UTF_8)); String line; while (StringUtils.isNotBlank(line = reader.readLine()))&#123; String[] fields = line.split("\t"); fieldMap.put(fields[0], fields[1]); &#125; IOUtils.closeStream(reader); &#125; @Override protected void map(LongWritable key, Text value, Context context) throws IOException, InterruptedException &#123; String line = value.toString(); String[] fields = line.split("\t"); String pid = fields[1]; String pname = fieldMap.get(pid); outKey.set(fields[0] + "\t" + pname + "\t" + fields[2]); context.write(outKey, NullWritable.get()); &#125;&#125; 查看结果]]></content>
      <categories>
        <category>hadoop</category>
        <category>map-reduce</category>
        <category>map-join</category>
      </categories>
      <tags>
        <tag>hadoop</tag>
        <tag>map-reduce</tag>
        <tag>map-join</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[hadoop（15） Map Reduce 工作流程、OutputFormat]]></title>
    <url>%2Fhadoop%2Fmap-reduce%2Fhadoop-15.html</url>
    <content type="text"><![CDATA[MapTask 流程分为：Read 阶段、Map 阶段、Collect 阶段、溢写阶段、Combine 阶段ReduceTask 流程分为：Copy 阶段、Merge 阶段、Sort 阶段、Reduce 阶段 工作流程MapTask 流程 Read 阶段 客户端获取待处理文本，提交之前，获取待处理数据的信息，然后根据参数设置，形成一个任务分配的规划；提交信息（Job.split、jar、Job.xml）；计算出 MapTask 数量、开启 MapTask，TextInputFormat 开始读取数据 Map 阶段 读取后，返回对应的 KV 数据，并把数据写入到 Mapper 中 Collect 阶段 Mapper 将数据写入环形缓冲区，并进行分区、排序 溢写阶段 将分区、排序后的数据，溢写到文件（分区且区内有序） Combine 阶段 将溢写后的数据进行归并排序 ReduceTask 流程 Copy 阶段 将 MapTask 执行结束后，将对应分区的数据，拷贝到 ReduceTask 中 Merge 阶段 将数据进行归并排序 Sort 阶段 合并 ReduceTask 中的文件，进行归并排序 Reduce 阶段 进行数据处理逻辑，通过 TextOutputFormat 输出到指定位置 ReduceTask 数量ReduceTask 的并行度，影响着整个 Job 的并发度和执行效率，但是与 MapTask 的并发度，由切片数决定 不同，ReduceTask 的数量是可以手动设置的。job.setNumReduceTasks(2); ReduceTask 的数量设置，需要根据集群性能去测试调节，并不是一成不变的。 注意事项 ReduceTask=0，表示没有 Reduce 阶段，输出文件的个数和 Map 个数一致。 ReduceTask=1，输出文件个数为 1 个（默认） 如果数据分布不均匀，就有可能在 Reduce 阶段产生数据倾斜 ReduceTask 数量并不是任意设置，还要考虑业务逻辑需求，有些情况下，需要计算全局汇总结果，就只能有一个 ReduceTask 具体需要多少个 ReduceTask，需要根据集群性能而定 如果分数区不是 1，但是 ReduceTask 为 1，不会执行分区过程！理由：在 MapTask 源码中，执行分区的前提，是判断 ReduceNum 格式是否大于 1，不大于 1 不执行分区 Shuffle 流程Shuffle 运行在 Map 方法之后，Reduce 方法之前；部分与 Map、Reduce 重合。 Map 阶段Map 接收之后，数据写入环形缓冲区，对数据进行分区、排序，数据量到达缓冲区 80% 后，开始溢写数据（可选 Combiner 合并）；溢写到磁盘，生成 2 个文件：spill.index、spill.out；对数据进行归并排序（可选 Combiner 合并）、数据压缩；将文件写入磁盘，分区输出 Reduce 阶段从 MapTask 拷贝数据到内存缓冲区（内存不够时溢写到磁盘）；对每个 Map 来的数据进行归并排序；按照相同的 key 进行分组；执行 reduce 方法 OutputFormatOutputFormat 是 MapReduce 输出的基类，所有实现了 MapReduce 输出都实现了 OutputFormat 接口。常见的几个实现类： TextOutputFormat 默认输出格式，把每条记录斜纹文本行。KV 可以是任意类型，toString 方法可以把它们转为字符串 SequenceFileOutputFormat 可以将将 SequenceFileOutputFormat 的输出，作为后续 MapReduce 任务的输入；格式紧凑，容易压缩 自定义 OutputFormat 自定义实现输出，可定制 自定义实现需求，根据 日志文件，将包含 baidu.com 的日志输出到 baidu.log，其他的输出到 other.log Mapper、Reducer 12345678910111213141516public class LogMapper extends Mapper&lt;LongWritable, Text, Text, NullWritable&gt; &#123; @Override protected void map(LongWritable key, Text value, Context context) throws IOException, InterruptedException &#123; context.write(value, NullWritable.get()); &#125;&#125;public class LogReducer extends Reducer&lt;Text, NullWritable, Text, NullWritable&gt; &#123; @Override protected void reduce(Text key, Iterable&lt;NullWritable&gt; values, Context context) throws IOException, InterruptedException &#123; context.write(key, NullWritable.get()); &#125;&#125; RecordeWriter、OutputFormat 1234567891011121314151617181920212223242526272829303132333435363738394041424344public class CustomerOutputFormat extends FileOutputFormat&lt;Text, NullWritable&gt; &#123; @Override public RecordWriter&lt;Text, NullWritable&gt; getRecordWriter(TaskAttemptContext job) throws IOException, InterruptedException &#123; return new LogRecordWriter(job); &#125;&#125;public class LogRecordWriter extends RecordWriter&lt;Text, NullWritable&gt; &#123; private FSDataOutputStream baidu, other; public LogRecordWriter(TaskAttemptContext job) &#123; try &#123; FileSystem fileSystem = FileSystem.get(job.getConfiguration()); baidu = fileSystem.create(new Path("d:/dev/opf/baidu.log")); other = fileSystem.create(new Path("d:/dev/opf/other.log")); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; @Override public void write(Text key, NullWritable value) throws IOException &#123; // 获取域名 String domain = key.toString(); if (domain.contains("baidu.com"))&#123; baidu.write((domain+"\n").getBytes("UTF-8")); &#125; else &#123; other.write((domain+"\n").getBytes("UTF-8")); &#125; &#125; @Override public void close(TaskAttemptContext context) throws IOException, InterruptedException &#123; IOUtils.closeStream(baidu); IOUtils.closeStream(other); &#125;&#125; Driver 1job.setOutputFormatClass(CustomerOutputFormat.class); 测试结果]]></content>
      <categories>
        <category>hadoop</category>
        <category>map-reduce</category>
      </categories>
      <tags>
        <tag>hadoop</tag>
        <tag>map-reduce</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[hadoop（14） Map Reduce 排序、合并]]></title>
    <url>%2Fhadoop%2Fmap-reduce%2Fsort%2Fhadoop-14.html</url>
    <content type="text"><![CDATA[排序，是 MapReduce 中最重要的操作之一。默认的排序方式是 字典排序，且实现此排序的方式是 快速排序。 MapTask 和 MapReduce 均会对数据按照 key 进行排序，该操作属于 Hadoop 的默认操作。任何程序中的数据均会被排序，不论逻辑上是否需要。 排序概述 对于 MapTask 它会将处理的结果暂时放到 环形缓冲区 中，当缓冲区的使用率达到一定的阈值之后，再对缓冲区中的数据进行一次快速排序，并将这些有序数据溢写到磁盘上，而当数据处理完毕后，它会对磁盘上的文件进行 归并排序。 对于 ReduceTask 它从 每个 MapTask 上远程拷贝相应的数据文件，如果文件大小超过一定阈值，则溢写到磁盘上，否则存储到内存。如果磁盘上的文件数据达到一定阈值，则进行一次 归并排序，以生成一个更大的文件。如果内存中文件大小或数目，达到一定阈值，则进行一次 合并，将数据溢写到磁盘上。当所有数据拷贝完成后，ReduceTask 统一对内存和磁盘上的数据进行一次 归并排序。 排序的分类 部分排序 MapReduce 根据输入记录的键，对数据集排序，保证输出的每个文件，内部有序 全排序 最终输出结果只有一个文件，且文件内部有序。实现方式是：只设置一个 ReduceTask。但是该犯法在处理大型文件是，效率极低，完全丧失了 MapReduce 所提供的并行架构。 辅助排序（GroupingComparator 分组） 在 Reduce 端对 key 进行分组。应用于：在接收的 key 为 bean 对象时，想让一个或几个字段相同（并不是全部字段相同）的 key 进入到同一个 Reduce 方法时，可以使用分组排序 二次排序 在自定义排序过程中，如果 compareTo 中的条件为两个，即为二次排序。 自定义排序（全排序）bean 对象作为 key 传输，需要实现 WritableComparable 接口，重写 compareTo 方法。 需求：使用之前 序列化实例 的结果作为 输入数据，期望输出：按照总流量倒序排序。 实现 Bean 序列化实例 中的 FlowBean 类，实现 WritableComparable 接口，重写 compareTo 方法123456789public int compareTo(FlowBean flowBean) &#123; // 比较 if (sumFlow &gt; flowBean.getSumFlow())&#123; return -1; &#125; else if (sumFlow &lt; flowBean.getSumFlow())&#123; return 1; &#125; return 0;&#125; Mapper 123456789101112131415161718private FlowBean flowBean = new FlowBean();@Overrideprotected void map(LongWritable key, Text value, Context context) throws IOException, InterruptedException &#123; String line = value.toString(); String[] fields = line.split("\t"); String phone = fields[0]; long upFlow = Long.parseLong(fields[1]); long downFlow = Long.parseLong(fields[2]); flowBean.set(upFlow, downFlow); Text text = new Text(); text.set(phone); context.write(flowBean, text);&#125; Reducer 12345678@Overrideprotected void reduce(FlowBean key, Iterable&lt;Text&gt; values, Context context) throws IOException, InterruptedException &#123; for (Text value : values) &#123; context.write(value, key); &#125;&#125; Driver 省略，测试结果 区内排序需求：使用 输入数据，期望输出：根据手机号的前三位不同，分成不同的文件，并在每个文件中，按照总流量倒序输出。 在上一例全排序的基础上，增加一个分区操作。 1234567891011121314151617public class FlowBeanPartitioner extends Partitioner&lt;FlowBean, Text&gt; &#123; @Override public int getPartition(FlowBean flowBean, Text text, int numPartitions) &#123; int partitioner = 4; String phonePrefix = text.toString().substring(0, 3); if ("134".equals(phonePrefix))&#123; partitioner = 0; &#125; else if ("135".equals(phonePrefix))&#123; partitioner = 1; &#125; else if ("136".equals(phonePrefix))&#123; partitioner = 2; &#125;else if ("137".equals(phonePrefix))&#123; partitioner = 3; &#125; return partitioner; &#125;&#125; 查看结果 合并 Combiner 是 MapReduce 程序中 Maper 和 Reducer 之外的一种组件Combiner 是父类是 ReducerCombiner 与 Reducer 的区别在于运行的位置：Combiner 是在每个 MapTask 所在的节点运行；Reducer 是接收全局所有 Mapper 的输出结果Combiner 的意义是对每个 MapTask 的数据进行局部汇总，以减小网络的传输量应用前提：不能影响最终的业务逻辑（Combiner 输出的 KV，应该与 Reducer 的输入 KV 类型对应） 自定义 Combiner需求： 使用 输入数据，进行 局部汇总，以减小网络传输量。 期望输出：分隔单词，局部汇总每个单词的数量 以 WordCount 实例为例 原始的 WordCount 的控制台输出为：123456789101112131415161718Map-Reduce Framework Map input records=8 Map output records=18 Map output bytes=168 Map output materialized bytes=210 Input split bytes=100 Combine input records=0 Combine output records=0 Reduce input groups=7 Reduce shuffle bytes=210 Reduce input records=18 Reduce output records=7 Spilled Records=36 Shuffled Maps =1 Failed Shuffles=0 Merged Map outputs=1 GC time elapsed (ms)=7 Total committed heap usage (bytes)=514850816 方案 1 自实现一个 Combiner，并在 Driver 中注册。 123456789101112131415public class WordCountCombiner extends Reducer&lt;Text, IntWritable, Text, IntWritable&gt; &#123; private IntWritable outValue = new IntWritable(); @Override protected void reduce(Text key, Iterable&lt;IntWritable&gt; values, Context context) throws IOException, InterruptedException &#123; int sum = 0; // 1. 累加求和 for (IntWritable value : values) &#123; sum += value.get(); &#125; outValue.set(sum); context.write(key, outValue); &#125;&#125; 1job.setCombinerClass(WordCountCombiner.class); 测试运行：123456789101112131415161718Map-Reduce Framework Map input records=8 Map output records=18 Map output bytes=168 Map output materialized bytes=85 //缩小了 Input split bytes=100 Combine input records=18 // 相比之前 Combine 有变化 Combine output records=7 Reduce input groups=7 Reduce shuffle bytes=85 // 缩小了 Reduce input records=7 // 缩小了 Reduce output records=7 Spilled Records=14 // 缩小了 Shuffled Maps =1 Failed Shuffles=0 Merged Map outputs=1 GC time elapsed (ms)=11 // 缩小了 Total committed heap usage (bytes)=514850816 方案 2 直接将之前的 Reducer 作为 Combiner 即可。job.setCombinerClass(WordCountReducer.class); 辅助排序GroupingComparator，对 Reducer 阶段的数据根据某一个或几个字段进行分组。 分组排序步骤： 自定义排序类，继承 WritableComparator从学 compare 方法创建一个构造，将比较对象传给父类 Demo根据订单 输入数据，进行分组，并找出每笔订单中最贵的商品 实现步骤： 利用 “订单 id、成交金额” 作为 key，可以将 Map 阶段读取到的订单数据按照 id 进行排序。如果 id 相同，再根据金额降序，然后发送到 Reducer 在 Reducer 利用 GroupingComparator 将订单相同的 KV 聚合成组，然后取第一个即可。 创建一个 Bean，用于存储订单信息 12345678910111213141516171819202122232425262728public class OrderBean implements WritableComparable&lt;OrderBean&gt; &#123; private int orderId; private double price; public int compareTo(OrderBean order) &#123; // 先按照 id 升序，id 相同的按照价格降序 if (orderId &gt; order.getOrderId())&#123; return 1; &#125; else if (orderId &lt; order.getOrderId())&#123; return -1; &#125; else &#123; return Double.compare(order.getPrice(), price); &#125; &#125; public void write(DataOutput dataOutput) throws IOException &#123; dataOutput.writeInt(orderId); dataOutput.writeDouble(price); &#125; public void readFields(DataInput dataInput) throws IOException &#123; orderId = dataInput.readInt(); price = dataInput.readDouble(); &#125; // 省略&#125; Mapper 12345678910111213141516public class OrderMapper extends Mapper&lt;LongWritable, Text, OrderBean, NullWritable&gt; &#123; private OrderBean order = new OrderBean(); @Override protected void map(LongWritable key, Text value, Context context) throws IOException, InterruptedException &#123; String[] fields = value.toString().split("\t"); int orderId = Integer.parseInt(fields[0]); double price = Double.parseDouble(fields[2]); order.setOrderId(orderId); order.setPrice(price); context.write(order, NullWritable.get()); &#125;&#125; Reducer 1234567public class OrderReducer extends Reducer&lt;OrderBean, NullWritable, OrderBean, NullWritable&gt; &#123; @Override protected void reduce(OrderBean key, Iterable&lt;NullWritable&gt; values, Context context) throws IOException, InterruptedException &#123; context.write(key, NullWritable.get()); &#125;&#125; Driver 省略 结果 开始分组排序在得到了结果后，可以看到，现在的结果确实是不同订单的，在一起显示，且是按照倒序排列的。只不过，没有进行分组，没有完成只输出第一条。在此基础上，开始进行辅助分组排序。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647public class OrderGroupingComparator extends WritableComparator &#123; // 创建一个构造，调用父方法的构造，第二个参数必须传为 true public OrderGroupingComparator() &#123; super(OrderBean.class, true); &#125; /** * 注意，一定要重写两个参数均为 WritableComparable 的比较方法 */ @Override public int compare(WritableComparable a, WritableComparable b) &#123; OrderBean order1 = ((OrderBean) a); OrderBean order2 = ((OrderBean) b); int result; if (order1.getOrderId() &gt; order2.getOrderId())&#123; result = 1; &#125; else if (order1.getOrderId() &lt; order2.getOrderId())&#123; result = -1; &#125; else &#123; result = 0; &#125; return result; &#125;&#125;// WritableComparator 源码protected WritableComparator(Class&lt;? extends WritableComparable&gt; keyClass, boolean createInstances) &#123; this(keyClass, (Configuration)null, createInstances);&#125;protected WritableComparator(Class&lt;? extends WritableComparable&gt; keyClass, Configuration conf, boolean createInstances) &#123; this.keyClass = keyClass; this.conf = conf != null ? conf : new Configuration(); // 由此可见，如果 OrderGroupingComparator 的构造参数，在调用父类的构造时， // 如果传入的是 false，或者不传入第二个参数，则 key1、buffer 均为 null，此时可能出现空指针异常。 if (createInstances) &#123; this.key1 = this.newKey(); this.key2 = this.newKey(); this.buffer = new DataInputBuffer(); &#125; else &#123; this.key1 = this.key2 = null; this.buffer = null; &#125;&#125; Driver 1job.setGroupingComparatorClass(OrderGroupingComparator.class); 运行测试]]></content>
      <categories>
        <category>hadoop</category>
        <category>map-reduce</category>
        <category>sort</category>
      </categories>
      <tags>
        <tag>hadoop</tag>
        <tag>map-reduce</tag>
        <tag>sort</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[hadoop（13） Map Reduce 工作流程、Shuffle]]></title>
    <url>%2Fhadoop%2Fmap-reduce%2Fshuffle%2Fhadoop-13.html</url>
    <content type="text"><![CDATA[在了解了常见的 InputFormat，及其处理分片的方式后，通过集成 FileInputFormat 自实现了一个自定义的 InputFormat，并通过自实现的 InputFormat，完成了一个对小文件的汇总合并工作。 那么此时，就需要深入了解一下 MapReduce 的具体工作流程 MapReduce 工作流程 准备待处理文件 客户端进行 submit 之前，获取待处理数据的信息，根据参数配置，形成一份任务分配的规划（即 切片信息） 提交切片信息(job.split) 和 jar(集群模式下提交)、Job.xml 计算 MapTask 的数量（Yarn 中会先创建一个 MrAppMaster，根据 job.split 决定分配 MapTask 的数量） 执行 InputFormat 的 initialize 方法，获取文件、分片信息 执行 Mapper 操作 向环形缓冲区(默认 100M)中写入 KV 数据（日志中会打印 0%、50% 等信息）；缓冲区右侧是数据，左侧是数据的元数据（索引、位置、k-v 的起始位置等）。当缓冲区达到 80% 时，数据溢写到磁盘，且左右两侧数据清空，并反向写入数据。 进行分区、排序 溢出到文件（分区、且区内有序） 归并排序并合并文件（Reducer） 所有的 MapTask 任务完成后，启动 ReduceTask（数量由 MapTask 分区数量决定），并告知 ReduceTask 处理数据的范围（数据分区） 将 MapTask 处理后的数据下载到 ReduceTask 本地磁盘 将 ReduceTask 的文件进行归并排序，合并为一个文件后，进行 Reduce 操作 通过 OutputFormat 写出文件 ShuffleMap 方法之后，Reduce 方法之前的数据处理，称之为 Shuffle。此操作涉及：分区、排序、归并排序、数据压缩等。 Partition 分区分区：将统计的结果，按照不同的条件，输出到不同的文件中。默认分区实现：HashPartitioner。 1234567public class HashPartitioner&lt;K, V&gt; extends Partitioner&lt;K, V&gt; &#123; public int getPartition(K key, V value, int numReduceTasks) &#123; return (key.hashCode() &amp; Integer.MAX_VALUE) % numReduceTasks; &#125;&#125; 由源码可知，默认的分区是根据 key 的HashCode 对 ReduceTasks 个数取模得到的。用户没有办法控制哪个 key 存储到哪个分区。 修改 WordCount 实例，增加配置： job.setNumReduceTasks(2);，再次运行。当 Mapper 进入 context.write(key, value); 时，将进行分区操作。 1234567// MapTask.javapublic void write(K key, V value) throws IOException, InterruptedException &#123; // collector 收集器；此处调用的是 MapOutputBuffer 的 collect 方法 collector.collect(key, value, // 此处调用的 Partitioner 即为 HashPartitioner partitioner.getPartition(key, value, partitions));&#125; 运行后查看输出目录，发现有 2 个文件，证明分区成功。 自定义分区实现步骤： 自定义类，继承 Partitioner，重写 getPartition 方法 在 Job 驱动中，设置自定义的 Partitioner 根据自定义的 Partitioner 逻辑，设置相应数量的 ReduceTask 需求：使用之前 序列化实例 的输入数据，实现 按照手机号归属地不同，输出的不同的文件中。 期望输出：如果手机号以 偶数 结尾，输入的一个文件，否则输出到不同文件。 根据文件内容，手机号以 0、3、5、7、8 结尾，则 0、8 输出到一个文件，其余的每个手机号一个文件。 注意：在使用自定义的 Partitioner 时，必须要指定 ReduceTask 的数量（setNumReduceTasks），否则只会输出一个文件，且所有数据都在这一个文件中！如果指定的 ReduceTask 数量，小于 Partitioner 中的数量，则会出现 IO 异常，原因：无法确定输出结果用哪个 ReduceTask 输出。如果指定的 ReduceTask 数量，大于 Partitioner 中的数量，不会报错，但是会出现几个空文件分区号必须从0开始，逐一累加 在之前序列化实例的基础上，进行修改 自定义 Partitioner 1234567891011121314151617181920public class FlowBanPartitioner extends Partitioner&lt;Text, FlowBean&gt; &#123; // 注意：getPartition 只能从 0 开始。 @Override public int getPartition(Text text, FlowBean flowBean, int numPartitions) &#123; // 如果手机号以 `偶数` 结尾，输入的一个文件，否则输出到不同文件 String phone = text.toString(); String key = phone.substring(9, 12); if (key.equals("885"))&#123; return 0; &#125; else if (key.equals("889"))&#123; return 1; &#125; else if (key.equals("883"))&#123; return 2; &#125; else if (key.equals("887"))&#123; return 3; &#125; else &#123; return 4; &#125; &#125;&#125; 修改 Driver 1234// 修改 Partitionerjob.setPartitionerClass(FlowBeanPartitioner.class);// 根据 Partitioner，设置 ReduceTaskjob.setNumReduceTasks(5); 测试运行]]></content>
      <categories>
        <category>hadoop</category>
        <category>map-reduce</category>
        <category>shuffle</category>
      </categories>
      <tags>
        <tag>hadoop</tag>
        <tag>map-reduce</tag>
        <tag>shuffle</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[hadoop（12） Map Reduce MapReduce 框架原理：InputFormat（二）]]></title>
    <url>%2Fhadoop%2Fmap-reduce%2Finput-format%2Fhadoop-12.html</url>
    <content type="text"><![CDATA[此前了解了 InputFormat 运行时，需要参考的 MapTask 并行度决定机制，以及任务提交的流程，那么接下来就需要深入分析 InputFormat 机制。 FileInputFormat 切片机制切片机制 简单的按照文件的内容长度进行切片 切片大小默认为 Block 大小 切片时不考虑数据集整体，而是针对每一个文件单独切片 源码中计算切片大小Math.max(minSize, Math.min(maxSize, blockSize)); mapreduce.input.fileinputformat.split.minsize=1mapreduce.input.fileinputformat.split.maxsize=Long.MAX_VALUE 基于此，默认情况下，切片大小 等于 blockSize 切片大小的设置maxsize：切片最大值，参数如果调得比 blockSize 小，则会让切片变小，而且就等于配置的这个参数的值。minsize：切片最小值，如果调的比 blockSize 大，则可以让切片变得比 blockSize 还大 获取切片信息的 APIinputSplit.gePath.getName()：获取切片的文件名称(FileSplit)content.getInputSplit(); 根据文件类型获取切片信息 CombineTextInputFormat 切片机制Hadoop 默认的 TextInputFormat 切片机制是对任务按文件规划切片，不管文件多小，都会是一个单独的切片，都会交给一个 MapTask，这样如果有大量小文件，就会产生大量的 MapTask，处理效率极其低下。 CombineTextInputFormat 用于小文件过多的场景，它可以将多个小文件从逻辑上规划到一个切片中，这样多个小文件就可以交给一个 MapTask 处理。 最大值设置CombineTextInputFormat.setMaxInputSplitSize(job, 4194304); // 4 M 这个最大值的设置最好按照实际的小文件大小情况来设置。 切片机制生成切片的过程包括：虚拟存储过程、切片过程 两步。 如：虚拟切片最大值为 4 M，现在有 4 个文件，分别为：a.txt(1.7M)、b.txt(5.1M)、c.txt(3.4M)、d.txt(6.8M)。 虚拟存储过程： a：1.7 &lt; 4，划分为 1 块（1.7M）b：4 &lt; 5.1 &lt; 24；则划分为 2 块（2.55M，2.55M）c：3.4 &lt; 4：划分为 1块（3.4M）d：4 &lt; 6.8 &lt; 24：划分为 2块（3.4M，3.4M） 切片过程： 如果虚拟存储的文件大小大于设置好的最大值，则单独形成一个切片否则跟下一个虚拟存储文件进行合并，共同形成一个切片 所以最终会形成 3 个切片：(1.7 + 2.55)M、(2.55 + 3.4)M、(3.4 + 3.4)M 案例实操准备 4 个测试文件：a.txt(1.7M)、b.txt(5.1M)、c.txt(3.4M)、d.txt(6.8M)。 期望：一个切片，处理4个文件。 默认处理利用这个 4 个文件，运行 WordCount 实例，查看切片个数。 设置虚拟存储 设置虚拟存储切片最大值为 4M 在任务提交之前，增加配置：1234567// 设置任务使用虚拟存储切片job.setInputFormatClass(CombineTextInputFormat.class);// 设置虚拟存储切片最大值为 4 MCombineTextInputFormat.setMaxInputSplitSize(job, 4194304);// 提交 jobboolean succeed = job.waitForCompletion(true); 设置虚拟存储切片最大值为 20M 在任务提交之前，增加配置：1234567// 设置任务使用虚拟存储切片job.setInputFormatClass(CombineTextInputFormat.class);// 设置虚拟存储切片最大值为 20 MCombineTextInputFormat.setMaxInputSplitSize(job, 20971520);// 提交 jobboolean succeed = job.waitForCompletion(true); FileInputFormat 实现类在运行 MapReduce 程序时，输入的文件包括：基于行的日志文件、二进制格式文件、数据库表等 。针对不同的数据类型，MapReduce 如何读取数据？ FileInputFormat 常见实现：TextInputFormat(文本文件)，KeyValueTextInputFormat（基于 KV 的文本文件），NLineInputFormat（按行处理）、CombineTextInputFormat（小文件处理）、自定义 InputFormat。 TextInputFormatTextInputFormat 是默认的 FileInputFormat 实现类。按行读取每条记录。key 是该行在整个文件中的字节偏移量（LongWritable 类型）；value 是读取到的该行内容（不包括任何终止符，Text 类型）。 KeyValueTextInputFormat每一行为一条记录，被分隔符分隔为 key、value。可以通过 configuration.set(KeyValueLineRecordReader.KEY_VALUE_SEPERATOR, &quot;\t&quot;); 来设定分隔符，默认分隔符是 \t。此时的 key 是每行排在分隔符之前的 Text 序列。 demo需求：统计输入文件中，每一行的第一个单词相同的行数。参考文件：key-value.txt 如：输入数据格式为12345laiyy#dahe.cn likeliyl#dahe.cn likelaiyy#sina.com.cn hatelaiyy#study hadoopliyl#study hadoop 期望输出为：12laiyy 3liyl 2 Mapper 1234567private IntWritable outValue = new IntWritable(1);@Overrideprotected void map(Text key, Text value, Context context) throws IOException, InterruptedException &#123; System.out.println("当前行的 key ：" + key + " ---&gt; 当前行的 value：" + value); context.write(key, outValue);&#125; Reducer 1234567891011private IntWritable outValue = new IntWritable();@Overrideprotected void reduce(Text key, Iterable&lt;IntWritable&gt; values, Context context) throws IOException, InterruptedException &#123; int sum = 0; for (IntWritable value : values) &#123; sum += value.get(); &#125; outValue.set(sum); context.write(key, outValue);&#125; Driver 12345678910111213141516public static void main(String[] args) throws IOException, ClassNotFoundException, InterruptedException &#123; // 获取 job 对象 Configuration configuration = new Configuration(); // 设置分隔符 configuration.set(KeyValueLineRecordReader.KEY_VALUE_SEPERATOR, "#"); Job job = Job.getInstance(configuration); // 省略 // 设置使用 KeyValue 形式的 InputFormat job.setInputFormatClass(KeyValueTextInputFormat.class); // 省略&#125; 检查输出结果 NLineInputFormat如果使用 NLineInputFormat，代表每个 map 进程处理的 InputSplit 不再按照 Block 去划分，而是按照 NLineInputFormat 指定的行数来划分。即：输入文件的总行数/N=切片数。如果不能整除，切片数为 商+1。 如：使用 hadoop 的 README.txt 文件作为输入，如果 N 为 5，则每个输入分片包括 5 行；文件总共 32 行，则应该有 7 个分片。 Demo使用 WordCount 实例作为测试代码，对每个单词进行个数统计。根据输入文件的行数来规定输出几个切片。此案例要求每 5 行放入一个切片。 只需要在 WordCount 的 Driver 中，Job 提交之前，加入下列代码即可。Mapper、Reducer 都不需要变动。1234// 设置为 NLineInputFormatjob.setInputFormatClass(NLineInputFormat.class);// 5 行一个切片NLineInputFormat.setNumLinesPerSplit(job, 5); 自定义 InputFormat步骤： 自定义一个类，集成 FileInputFormat改写 RecordReader，实现一次读取一个完整文件，封装为 KV在输出的时候，使用 SequenceFileOutputFormat 输出合并文件 无论是 HDFS 还是 MapReduce，在处理小文件时，效率都非常低，但是又难免面临大量小文件的场景。此时，可以使用自定义 InputFormat 实现小文件的合并。 需求 将多个小文件，合并为一个 SequenceFile 文件（Hadoop 用来存储二进制形式的 k-v 对的文件格式），SequenceFile 中存储着多着文件，存储形式为 文件路径 + 名称 为 key，内容为 value 准备三个小文件：sf_1.txt，sf_2.txt，sf_3.txt 自定义 InputFormat123456789101112131415/** * Text：key，存储的是文件路径+名称 * BytesWritable：value，存储的是整个文件的字节流 */public class CustomerInputFormat extends FileInputFormat&lt;Text, BytesWritable&gt; &#123; @Override public RecordReader&lt;Text, BytesWritable&gt; createRecordReader(InputSplit split, TaskAttemptContext context) throws IOException, InterruptedException &#123; CustomerRecordReader recordReader = new CustomerRecordReader(); // 初始化 recordReader.initialize(split, context); return recordReader; &#125;&#125; 实现 RecordReader 自定义实现 RecordReader，实现一次读取一个完整文件，封装为 KV 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899public class CustomerRecordReader extends RecordReader&lt;Text, BytesWritable&gt; &#123; /** * 切片 */ private FileSplit fileSplit; /** * 配置信息 */ private Configuration configuration; /** * 输出的 key（路径 + 名称） */ private Text key = new Text(); /** * 输出的 value（整个文件内容） */ private BytesWritable value = new BytesWritable(); // 标识是否正在读取 private boolean progressing = true; /** * 初始化 * @param split 切片 * @param context 上下文 */ @Override public void initialize(InputSplit split, TaskAttemptContext context) throws IOException, InterruptedException &#123; this.fileSplit = (FileSplit) split; configuration = context.getConfiguration(); &#125; /** * 核心业务逻辑 */ @Override public boolean nextKeyValue() throws IOException, InterruptedException &#123; if (progressing) &#123; // 获取 fs 对象 Path path = fileSplit.getPath(); FileSystem fileSystem = path.getFileSystem(configuration); // 获取输入流 FSDataInputStream inputStream = fileSystem.open(path); // 封装 key key.set(path.toString()); // 拷贝，将文件内容拷贝到 buffer 中 byte[] buffer = new byte[(int) fileSplit.getLength()]; IOUtils.readFully(inputStream, buffer, 0, buffer.length); // 封装 value value.set(buffer, 0, buffer.length); // 关闭资源 IOUtils.closeStream(inputStream); progressing = false; return true; &#125; return false; &#125; /** * 获取当前的 key */ @Override public Text getCurrentKey() throws IOException, InterruptedException &#123; return key; &#125; @Override public BytesWritable getCurrentValue() throws IOException, InterruptedException &#123; return value; &#125; /** * 获取处理进度 */ @Override public float getProgress() throws IOException, InterruptedException &#123; return 0; &#125; /** * 关闭资源 */ @Override public void close() throws IOException &#123; &#125;&#125; MapReduce Mapper 1234567public class CustomerMapper extends Mapper&lt;Text, BytesWritable, Text, BytesWritable&gt; &#123; @Override protected void map(Text key, BytesWritable value, Context context) throws IOException, InterruptedException &#123; context.write(key, value); &#125;&#125; Reducer 12345678910public class CustomerReducer extends Reducer&lt;Text, BytesWritable, Text, BytesWritable&gt; &#123; @Override protected void reduce(Text key, Iterable&lt;BytesWritable&gt; values, Context context) throws IOException, InterruptedException &#123; // 循环写出 for (BytesWritable value : values) &#123; context.write(key, value); &#125; &#125;&#125; Driver 123456789public static void main(String[] args) throws IOException, ClassNotFoundException, InterruptedException &#123; // 省略 // 设置 InputFormat、OutputFormat job.setInputFormatClass(CustomerInputFormat.class); job.setOutputFormatClass(SequenceFileOutputFormat.class); // 省略&#125; 执行结果]]></content>
      <categories>
        <category>hadoop</category>
        <category>map-reduce</category>
        <category>input-format</category>
      </categories>
      <tags>
        <tag>hadoop</tag>
        <tag>map-reduce</tag>
        <tag>input-format</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[hadoop（11） Map Reduce MapReduce 框架原理：InputFormat（一） MapTask 并行度决定机制]]></title>
    <url>%2Fhadoop%2Fmap-reduce%2Finput-format%2Fhadoop-11.html</url>
    <content type="text"><![CDATA[在了解了 Hadoop 的序列化操作，实现了基本的 Bean 序列化的一个 demo，接下来分析一下 MapReduce 的框架原理。 切片与MapTask 并行度决定机制MapTask 的并行度决定 Map 阶段的任务处理并发度，进而影响整个 Job 的处理速度。 问题： 一个 1G 的数据，启动 8 个MapTask，可以提高集群的并发处理能力。但是如果是一个 1K 的数据，也启动 8 个MapTask，会提高性能吗？MapTask 是否越多越好？什么因素会影响到 MapTask 的并行度？ MapTask并行度决定机制前置概念： 数据块：Block 在 HDFS 物理上把数据分成一块一块的。数据切片：在逻辑上对输入进行分片，并不会在磁盘上将其分片存储。 现在，假设有一个 300M 的数据，分别存放在 DataNode 1、2、3 上，DataNode1 上存储 0~128M 数据，DataNode2 上存储 128~256M 数据，DataNode3 上存储 256~300M 数据。如果数据切片大小为 100M，则读取第一个切片没有问题，当读取第2、3个切片时，需要将DataNode1 上的剩余的数据拷贝到 MapTask2 上，将 DataNode2 上剩余的数据拷贝到 MapTask3 上，这样会存在大量的数据 IO，严重影响性能。 如果数据切片大小为 128M（即与 Block 大小一致），此时，每个 MapTask 都读取 128M 数据，则可以分别运行在三台 DataNode 上，没有数据拷贝，此时性能最高。 MapTask 并行度决定机制 一个 Job 的 Map 阶段并行度由客户端在提交 Job 时的切片数决定 每个切片分配一个 MapTask 并行实例处理 默认情况下，切片大小等于 BlockSize 切片时不考虑数据集整体，而是逐个针对每个文件单独切片 Job 提交流程、切片源码在 Job 调用 job.waitForCompletion 时，进行任务提交。此方法会调用 submit() 方法进行真正的提交。 任务提交流程123456789101112131415public boolean waitForCompletion(boolean verbose ) throws IOException, InterruptedException, ClassNotFoundException &#123; if (state == JobState.DEFINE) &#123; // 调用真正的提交 submit(); &#125; if (verbose) &#123; // 打印日志 monitorAndPrintJob(); &#125; else &#123; // 忽略 &#125; return isSuccessful();&#125; 1234567891011121314151617181920public void submit() throws IOException, InterruptedException, ClassNotFoundException &#123; // 判断任务状态 ensureState(JobState.DEFINE); // 将老旧的 API 转换为新的 API，为兼容性考虑 setUseNewAPI(); // 连接 connect(); final JobSubmitter submitter = getJobSubmitter(cluster.getFileSystem(), cluster.getClient()); status = ugi.doAs(new PrivilegedExceptionAction&lt;JobStatus&gt;() &#123; public JobStatus run() throws IOException, InterruptedException, ClassNotFoundException &#123; // 提交任务的详细信息 return submitter.submitJobInternal(Job.this, cluster); &#125; &#125;); state = JobState.RUNNING; LOG.info("The url to track the job: " + getTrackingURL());&#125; connect 连接流程1234567891011121314private synchronized void connect() throws IOException, InterruptedException, ClassNotFoundException &#123; if (cluster == null) &#123; cluster = ugi.doAs(new PrivilegedExceptionAction&lt;Cluster&gt;() &#123; public Cluster run() throws IOException, InterruptedException, ClassNotFoundException &#123; // 创建一个新的 Cluster return new Cluster(getConfiguration()); &#125; &#125;); &#125; &#125; 1234567891011public Cluster(Configuration conf) throws IOException &#123; this(null, conf);&#125;public Cluster(InetSocketAddress jobTrackAddr, Configuration conf) throws IOException &#123; this.conf = conf; this.ugi = UserGroupInformation.getCurrentUser(); // Cluster 初始化 initialize(jobTrackAddr, conf);&#125; 1234567891011121314151617181920private void initialize(InetSocketAddress jobTrackAddr, Configuration conf) throws IOException &#123; synchronized (frameworkLoader) &#123; for (ClientProtocolProvider provider : frameworkLoader) &#123; ClientProtocol clientProtocol = null; try &#123; if (jobTrackAddr == null) &#123; // 创建一个 LocalJobRunner（在本地运行时） clientProtocol = provider.create(conf); &#125; else &#123; // 创建一个 YARNRunner（在集群运行时） clientProtocol = provider.create(jobTrackAddr, conf); &#125; // 省略 &#125; &#125; // 省略&#125; 实际提交流程123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051JobStatus submitJobInternal(Job job, Cluster cluster) throws ClassNotFoundException, InterruptedException, IOException &#123; // 校验输出路径 checkSpecs(job); Configuration conf = job.getConfiguration(); // 缓存处理 addMRFrameworkToDistributedCache(conf); // 任务临时目录， tmp/hadoop-Administrator\mapred\staging，每次运行任务都会在这个目录下创建一个文件夹，将所需数据都保存在内 // 当任务执行结束后，会删除文件夹内的所有数据 Path jobStagingArea = JobSubmissionFiles.getStagingDir(cluster, conf); // 获取网络 ip InetAddress ip = InetAddress.getLocalHost(); // 省略 // 生成一个唯一的 jobId JobID jobId = submitClient.getNewJobID(); job.setJobID(jobId); Path submitJobDir = new Path(jobStagingArea, jobId.toString()); JobStatus status = null; try &#123; // 省略 // 提交文件的信息到之前创建的文件夹下（本机下不会提交） copyAndConfigureFiles(job, submitJobDir); Path submitJobFile = JobSubmissionFiles.getJobConfPath(submitJobDir); // 写入切片信息到文件夹 int maps = writeSplits(job, submitJobDir); conf.setInt(MRJobConfig.NUM_MAPS, maps); // 省略 // 写入任务信息到文件夹 writeConf(conf, submitJobFile); printTokens(jobId, job.getCredentials()); // 提交完成后，删除文件夹内信息 status = submitClient.submitJob( jobId, submitJobDir.toString(), job.getCredentials()); // 省略 &#125; finally &#123; // 省略 &#125;&#125; 切片流程12345678910111213private int writeSplits(org.apache.hadoop.mapreduce.JobContext job, Path jobSubmitDir) throws IOException, InterruptedException, ClassNotFoundException &#123; JobConf jConf = (JobConf)job.getConfiguration(); int maps; if (jConf.getUseNewMapper()) &#123; // 使用新的切片规则 maps = writeNewSplits(job, jobSubmitDir); &#125; else &#123; // 使用旧切片规则 maps = writeOldSplits(jConf, jobSubmitDir); &#125; return maps;&#125; 12345678910111213141516private &lt;T extends InputSplit&gt; int writeNewSplits(JobContext job, Path jobSubmitDir) throws IOException, InterruptedException, ClassNotFoundException &#123; // 获取配置信息 Configuration conf = job.getConfiguration(); InputFormat&lt;?, ?&gt; input = ReflectionUtils.newInstance(job.getInputFormatClass(), conf); // 获取切片信息 List&lt;InputSplit&gt; splits = input.getSplits(job); T[] array = (T[]) splits.toArray(new InputSplit[splits.size()]); Arrays.sort(array, new SplitComparator()); JobSplitWriter.createSplitFiles(jobSubmitDir, conf, jobSubmitDir.getFileSystem(conf), array); return array.length;&#125; 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465// 此处调用的是 FileInputFormat 中的 getSplitspublic List&lt;InputSplit&gt; getSplits(JobContext job) throws IOException &#123; StopWatch sw = new StopWatch().start(); long minSize = Math.max(getFormatMinSplitSize(), getMinSplitSize(job)); long maxSize = getMaxSplitSize(job); List&lt;InputSplit&gt; splits = new ArrayList&lt;InputSplit&gt;(); // 文件信息 List&lt;FileStatus&gt; files = listStatus(job); // 按照文件，一个一个切片 for (FileStatus file: files) &#123; Path path = file.getPath(); long length = file.getLen(); if (length != 0) &#123; BlockLocation[] blkLocations; if (file instanceof LocatedFileStatus) &#123; blkLocations = ((LocatedFileStatus) file).getBlockLocations(); &#125; else &#123; FileSystem fs = path.getFileSystem(job.getConfiguration()); blkLocations = fs.getFileBlockLocations(file, 0, length); &#125; // 判断是否可切割 if (isSplitable(job, path)) &#123; // 获取块大小（如果是 local 运行：2.x 32 M，1.x 64 M，yarn 集群：128M，） long blockSize = file.getBlockSize(); // 获取切片大小 long splitSize = computeSplitSize(blockSize, minSize, maxSize); long bytesRemaining = length; // 如果当前文件大小 / 切片大小 &gt; 1.1，进入此方法进行切片 while (((double) bytesRemaining)/splitSize &gt; SPLIT_SLOP) &#123; // 重新计算切片开始位置 int blkIndex = getBlockIndex(blkLocations, length-bytesRemaining); // 添加切片 splits.add(makeSplit(path, length-bytesRemaining, splitSize, blkLocations[blkIndex].getHosts(), blkLocations[blkIndex].getCachedHosts())); bytesRemaining -= splitSize; &#125; if (bytesRemaining != 0) &#123; int blkIndex = getBlockIndex(blkLocations, length-bytesRemaining); // 添加切片 splits.add(makeSplit(path, length-bytesRemaining, bytesRemaining, blkLocations[blkIndex].getHosts(), blkLocations[blkIndex].getCachedHosts())); &#125; &#125; else &#123; // not splitable splits.add(makeSplit(path, 0, length, blkLocations[0].getHosts(), blkLocations[0].getCachedHosts())); &#125; &#125; else &#123; //Create empty hosts array for zero length files splits.add(makeSplit(path, 0, length, new String[0])); &#125; &#125; // Save the number of input files for metrics/loadgen job.getConfiguration().setLong(NUM_INPUT_FILES, files.size()); sw.stop(); if (LOG.isDebugEnabled()) &#123; LOG.debug("Total # of splits generated by getSplits: " + splits.size() + ", TimeTaken: " + sw.now(TimeUnit.MILLISECONDS)); &#125; return splits;&#125; 总结 先创建一个数据存储的临时目录 开始规划切片，遍历处理目录下的每个文件 遍历文件： 获取文件大小计算切片大小，公式： Math.max(minSize, Math.min(maxSize, blockSize))默认情况下，切片大小 = blockSize开始切片：local 运行（第一个切片 0~32M，第二个切片 32~64M …）；Yarn 运行（第一个切片 0~128M，第二个切片 128~256M …）；注意：每次切片时，都需要判断切片完成后剩余部分是否是块大小的 1.1 倍，大于就切片，否则不切将切片信息写入切片规划文件InputSplit 只记录切片的元数据信息（起始位置、长度、所在节点列表等） 提交切片规划文件（local 运行时为临时目录，集群运行时为 yarn）；Yarn 上的 MrAppMaster 根据切片规划文件计算开启 MapTask 个数。]]></content>
      <categories>
        <category>hadoop</category>
        <category>map-reduce</category>
        <category>input-format</category>
      </categories>
      <tags>
        <tag>hadoop</tag>
        <tag>map-reduce</tag>
        <tag>input-format</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[hadoop（10） Map Reduce 序列化]]></title>
    <url>%2Fhadoop%2Fmap-reduce%2Fhadoop-10.html</url>
    <content type="text"><![CDATA[在 MapReduce 的 数据序列化类型 中，介绍了几种常见的 Hadoop 序列化类，实现了一个基础的 WordCount Demo，使用到了 Long、String、Integer 对应的序列化类，那么接下来就需要了解一下 Hadoop 具体的怎么序列化的。 Hadoop 序列化序列化概述 什么是序列化、反序列化 序列化：就是把内存中的对象，转换为字节序列 或其他数据传输协议，以便存储到磁盘或网络传输。反序列化：就是将收到的字节序列或其他数据传输协议或磁盘的持久化数据，转换成内存中的对象。 为什么要序列化？ 一般来说，对象 只能生存在内存中，断电即消失。而且，对象 只能由本地进程使用，不能被发送到网络上的另外一台计算机中。然而，序列化 可以存储 对象，且可以将对象 发送到远程计算机。 为什么不用 Java 自身的序列化？ Java 的序列化是一个重量级的框架(Serializable)，一个对象被序列化后，别额外附带很多信息，如：校验信息、Header、继承体系等，不便于在网络中高效传输。基于此，Hadoop 开发了一套属于自己的序列化机制：Writable。 Hadoop 序列化的特点 紧凑：高效使用存储空间 快速：读写数据的额外开销小 可扩展：随着通信协议的升级而升级 互操作：支持多语言交互 自定义实现序列化实现步骤： 实现 Writable 接口 反序列化时，需要反射调用空参构造函数 重写序列化方法 重写反序列化 方法 反序列化的顺序和序列化的顺序保持一致 重写 toString 实现 Comparable 接口（MapReduce 的 Shuffle 过程要求对 key 必须能排序；当需要排序的时候才做） 序列化 Demo需求：根据 测试文件，统计每个手机号的上行流量、下行流量、总流量。文件中，倒数第三列为上行流量，倒数第二列为下行流量，最后一列为网络请求状态码。 创建统计流量的 Bean 对象创建一个统计流量的 Bean 对象，并实现序列化操作 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960public class FlowBean implements Writable &#123; /** * 上行流量 */ private long upFlow; /** * 下行流量 */ private long downFlow; /** * 总流量 */ private long sumFlow; /** * 空参构造，反射用 */ public FlowBean() &#123; &#125; public void set(long upFlow, long downFlow)&#123; this.upFlow = upFlow; this.downFlow = downFlow; this.sumFlow = upFlow + downFlow; &#125; @Override public String toString() &#123; return upFlow + "\t" + downFlow + "\t" + sumFlow; &#125; // 省略 get、set /** * 序列化 * @param dataOutput 输入输出 * @throws IOException 可能异常 */ public void write(DataOutput dataOutput) throws IOException &#123; dataOutput.writeLong(upFlow); dataOutput.writeLong(downFlow); dataOutput.writeLong(sumFlow); &#125; /** * 反序列化 * @param dataInput 输入数据 * @throws IOException 可能异常 */ public void readFields(DataInput dataInput) throws IOException &#123; // 必须和序列化方法顺序一致 upFlow = dataInput.readLong(); downFlow = dataInput.readLong(); sumFlow = dataInput.readLong(); &#125;&#125; MapReduce 程序Mapper123456789101112131415161718192021222324252627public class FlowCountMapper extends Mapper&lt;LongWritable, Text, Text, FlowBean&gt; &#123; private FlowBean flowBean = new FlowBean(); private Text outKey = new Text(); @Override protected void map(LongWritable key, Text value, Context context) throws IOException, InterruptedException &#123; // 1 17319758889 192.168.100.1 www.baidu.com 2481 24685 200 // 1. 获取一行 String line = value.toString(); // 2. 切割 String[] fields = line.split("\t"); // 3. 封装对象 outKey.set(fields[1]); int length = fields.length; long upFlow = Long.parseLong(fields[length - 3]); long downFlow = Long.parseLong(fields[length - 2]); flowBean.setUpFlow(upFlow); flowBean.setDownFlow(downFlow); // 4. 写出 context.write(outKey, flowBean); &#125;&#125; Reducer12345678910111213141516171819202122public class FlowCountReducer extends Reducer&lt;Text, FlowBean, Text, FlowBean&gt; &#123; private FlowBean flowBean = new FlowBean(); @Override protected void reduce(Text key, Iterable&lt;FlowBean&gt; values, Context context) throws IOException, InterruptedException &#123; // 两个相同的手机号的访问记录 // 11 17319788888 192.168.100.11 www.java1234.com 231 28 200 // 12 17319788888 192.168.100.12 211 7852 200 long sumUpFlow = 0; long sumDownFlow = 0; for (FlowBean value : values) &#123; sumUpFlow += value.getUpFlow(); sumDownFlow += value.getDownFlow(); &#125; flowBean.set(sumUpFlow, sumDownFlow); context.write(key, flowBean); &#125;&#125; Deiver1234567891011121314151617181920212223242526272829303132public static void main(String[] args) throws IOException, ClassNotFoundException, InterruptedException &#123; // 获取 job 对象 Configuration configuration = new Configuration(); Job job = Job.getInstance(configuration); // 设置 jar 存放路径 job.setJarByClass(FlowCountDriver.class); // 关联 Mapper、Reducer 业务类 job.setMapperClass(FlowCountMapper.class); job.setReducerClass(FlowCountReducer.class); // 指定 Mapper 输出的 KV 类型 job.setMapOutputKeyClass(Text.class); job.setMapOutputValueClass(FlowBean.class); // 指定最终输出的数据 KV 类型 job.setOutputKeyClass(Text.class); job.setOutputValueClass(FlowBean.class); // 指定 job 的输入文件所在目录 FileInputFormat.setInputPaths(job, new Path(args[0])); // 指定 job 的输出结果所在目录 FileOutputFormat.setOutputPath(job, new Path(args[1])); // 提交 job// job.submit(); boolean succeed = job.waitForCompletion(true); System.exit(succeed ? 0 : 1);&#125; 运行测试设置输入输出路径： 查看输出结果：]]></content>
      <categories>
        <category>hadoop</category>
        <category>map-reduce</category>
      </categories>
      <tags>
        <tag>hadoop</tag>
        <tag>map-reduce</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[hadoop（9） Map Reduce 基础概念，WordCount Demo 实现]]></title>
    <url>%2Fhadoop%2Fmap-reduce%2Fhadoop-9.html</url>
    <content type="text"><![CDATA[HDFS、MapReduce、Yarn 是 Hadoop 的三大模块，其中，HDFS 负责存储，MapReduce 负责计算，Yarn 负责资源调度 MapReduceMapReduce 是一个 分布式运算程序的编程框架，是用户开发 基于Hadoop的数据分析应用的核心框架。 MapReduce 的核心功能，是将 用户编写的业务逻辑代码，和自带的默认组件，整合成一个完整的分布式运算程序，并发的运行在一个 Hadoop 集群上。 优缺点优点 易于编程 简单地实现一些接口，就可以完成一个分布式程序。这个分布式程序可以分布到大量的廉价 pc 机器上运行。也就是说，写一个分布式程序和写一个串行程序一模一样。 就是因为这个特点，使得MapReduce编程变得非常流行。 良好的扩展性 当计算资源不能得到满足时，可以通过简单的扩展机器来扩展计算能力。 高容错性 MapReduce 设计初衷，就是使程序能够部署在廉价的 pc 机器上，这就要求它具有很高的容错性。如：一台机器挂掉了，它可以把上面的计算任务转移到另外一个节点上，不至于这个任务运行失败，而且这个过程不需要人工参与，完全由 Hadoop 内部完成。 适合 PB 级以上海量数据离线处理 可以实现上千台服务器集群并发工作，提供数据处理能力。 缺点 不擅长实时计算 无法像 MySQL 一样，在毫秒级或秒级内返回结果 不擅长流式计算 流式计算的输入数据是动态的，而 MapReduce 的输入数据集的静态的，不能动态变化。这是由 MapReduce 自身的设计特点决定的。 不擅长 DAG(有向图) 计算 有向图：多个应用程序存在依赖关系，后一个程序的输入是前一个程序的输出。MapReduce 可以做 DAG 计算，但是不推荐。原因的每个 MapReduce 的输出结果都会写入磁盘，会造成大量的磁盘 IO，导致性能低下。 核心思想MapReduce 运算程序一般分为两个阶段：Map 阶段(分),Reduce 阶段(合)。Map 阶段的兵法 MapTask，完全并发运行，互不相干。Reduce 阶段的并发 ReduceTask，完全并发运行，互补相干。但是它们的数据依赖于上一阶段的所有 MapTask 并发实例的输出。MapReduce 编程模型只能包含一个 Map 阶段和一个 Reduce 阶段，如果业务逻辑复杂，只能多个 MapReduce 程序串行运行。 例如： MapReduce 进程一个完整的 MapReduce 程序在分布式运行时有三类实例进程： MrAppMaster：负责整个程序的过程调度以及正太协调MapTask：负责 Map 阶段的整个数据处理流程ReduceTask：负责 Reduce 阶段的整个数据处理流程 Hadoop 数据序列化类型 Java 类型 Hadoop Writable 类型 boolean BooleanWritable byte ByteWritable int IntWritable float FloatWritable long LongWritable double DoubleWritable String Text Map MapWritable array ArrayWritable MapReduce 编程规范MapReduce 编程分为三个部分： Mapper、Reducer、Driver Mapper 阶段 用户自定义的 Mapper 要继承自己的父类 Mapper 的数据数据是 KV 对形式，KV 类型自定义 Mapper 的业务逻辑写在 map() 方法中 Mapper 的输出数据是 KV 对形式，KV 类型自定义 map() 方法对每个 KV 只调用一次 Reducer 阶段 用户自定义的 Reducer 要继承自己的父类 Reducer 的输入类型对应 Mapper 的输出数据类型，也是 KV Reducer 的业务逻辑写在对应的 reduce() 方法中 reduce() 方法对每个 KV 只调用一次 Driver 阶段相当于 YARN 集群的客户端，用于提交整个程序到 YARN 集群，提交的是封装了 MapReduce 程序相关运行参数的 Job 对象 WordCount(Demo)需求：给定一个文本文件 README.txt，统计文本中每个单词出现的总次数 流程分析： Mapper 阶段 将 MapTask 传给我们的文本内容转换为 String 根据空格将单词分为单词 将单词输出为 &lt;单词, 1&gt; (如果有相同的单词，输出的也是 &lt;单词, 1&gt;， 因为 map 阶段只做拆分，不做合并) Reducer 阶段 汇总各个 key 的个数 输出该 key 的总次数 Driver 获取配置信息，获取 job 对象实例 指定本程序的 jar 包所在的本地路径 关联 Mapper、Reducer 业务类 指定 Mapper 输出的 KV 类型 指定最终输出的数据 KV 类型 指定 job 的原始文件所在目录 指定 job 的输出结果所在目录 提交 job Mapper 实现12345678910111213141516171819202122232425262728/** * @author laiyy * @date 2019/12/3 16:36 * * LongWritable：输入数据的 key（此处为偏移量） 类型 * Text：输入数据的 value（每一行数据） 类型 * Text：输出数据的 key 类型 * IntWritable：输出数据的 value 类型 */public class WordCountMapper extends Mapper&lt;LongWritable, Text, Text, IntWritable&gt; &#123; private Text outKey = new Text(); private IntWritable writable = new IntWritable(1); @Override protected void map(LongWritable key, Text value, Context context) throws IOException, InterruptedException &#123; // 1. 将当前读入的行数据转换为 String 类型 String line = value.toString(); // 2. 切割单词 String[] words = line.split(" "); // 3. 循环写出 for (String word : words) &#123; outKey.set(word);; writable.set(1); context.write(outKey, writable); &#125; &#125;&#125; Reducer 实现1234567891011121314151617181920212223242526272829303132/** * @author laiyy * @date 2019/12/3 16:49 * * Text：Map 阶段输出的 key 类型 * IntWritable：Map 阶段输出的 value 的类型 * Text：最终结果的 key 的类型 * IntWritable：最终结果的 value 类型 */public class WordCountReducer extends Reducer&lt;Text, IntWritable, Text, IntWritable&gt; &#123; private IntWritable outValue = new IntWritable(); @Override protected void reduce(Text key, Iterable&lt;IntWritable&gt; values, Context context) throws IOException, InterruptedException &#123; /* 在 Map 阶段输出的数据格式为： &#123;key1,1&#125;, &#123;key2,1&#125; ,如： &#123;china,1&#125;, &#123;japan,1&#125;, &#123;china, 1&#125; 在 Reducer 阶段作为输入时， 相同的将合并，即 key：china， values：[1,1] */ int sum = 0; // 1. 累加求和 for (IntWritable value : values) &#123; sum += value.get(); &#125; outValue.set(sum); context.write(key, outValue); &#125;&#125; Driver 实现123456789101112131415161718192021222324252627282930313233343536public class WordCountDriver &#123; public static void main(String[] args) throws IOException, ClassNotFoundException, InterruptedException &#123; // 获取 job 对象 Configuration configuration = new Configuration(); Job job = Job.getInstance(configuration); // 设置 jar 存放路径 job.setJarByClass(WordCountDriver.class); // 关联 Mapper、Reducer 业务类 job.setMapperClass(WordCountMapper.class); job.setReducerClass(WordCountReducer.class); // 指定 Mapper 输出的 KV 类型 job.setMapOutputKeyClass(Text.class); job.setMapOutputValueClass(IntWritable.class); // 指定最终输出的数据 KV 类型 job.setOutputKeyClass(Text.class); job.setOutputValueClass(IntWritable.class); // 指定 job 的输入文件所在目录 FileInputFormat.setInputPaths(job, new Path("d:/dev/README.txt")); // 指定 job 的输出结果所在目录 FileOutputFormat.setOutputPath(job, new Path("d:/dev/mr-demo1")); // 提交 job，为 true 时打印执行信息// job.submit(); boolean succeed = job.waitForCompletion(true); System.exit(succeed ? 0 : 1); &#125;&#125; 执行测试运行时可以看到打印信息如下： 打开执行后的 part-r-00000 文件如下： 在集群中运行将 Driver 的输入、输出路径改为参数获取方式：12345// 指定 job 的输入文件所在目录FileInputFormat.setInputPaths(job, new Path(args[0]));// 指定 job 的输出结果所在目录FileOutputFormat.setOutputPath(job, new Path(args[1])); 在 pom.xml 文件中增加如下配置：12345678910111213141516171819202122232425262728293031323334&lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt; &lt;version&gt;2.3.2&lt;/version&gt; &lt;configuration&gt; &lt;source&gt;1.8&lt;/source&gt; &lt;target&gt;1.8&lt;/target&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;plugin&gt; &lt;artifactId&gt;maven-assembly-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;descriptorRefs&gt; &lt;descriptorRef&gt;jar-with-dependencies&lt;/descriptorRef&gt; &lt;/descriptorRefs&gt; &lt;archive&gt; &lt;!-- 打包主类 --&gt; &lt;mainClass&gt;com.laiyy.study.mapreduce.wordcount.WordCountDriver&lt;/mainClass&gt; &lt;/archive&gt; &lt;/configuration&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;make-assembly&lt;/id&gt; &lt;phase&gt;package&lt;/phase&gt; &lt;goals&gt; &lt;goal&gt;single&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; &lt;/plugins&gt;&lt;/build&gt; 然后使用 mvn package 打包后，会生成两个文件： 12hadoop-1.0-SNAPSHOT.jarhadoop-1.0-SNAPSHOT-jar-with-dependencies.jar 第一个 jar 是没有 hadoop 依赖的，第二个 jar 是有 hadoop 依赖的。 由于在 hadoop 集群上运行，所以可以使用第一个 jar。如果服务器上没有 hadoop 依赖，则使用第二个 jar 即可。 将第一个 jar 上传至 hadoop，由于使用的是 hadoop 集群，所以输入、输出路径均为 HDFS 路径。 运行测试：123456789101112[root@hadoop02 hadoop-2.7.2]# hadoop jar hadoop-1.0-SNAPSHOT.jar com.laiyy.study.mapreduce.wordcount.WordCountDriver /laiyy /laiyy/output19/12/04 14:11:07 INFO client.RMProxy: Connecting to ResourceManager at hadoop03/192.168.233.132:803219/12/04 14:11:09 WARN mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.19/12/04 14:11:10 INFO input.FileInputFormat: Total input paths to process : 319/12/04 14:11:10 INFO mapreduce.JobSubmitter: number of splits:319/12/04 14:11:10 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1575438331337_000119/12/04 14:11:11 INFO impl.YarnClientImpl: Submitted application application_1575438331337_000119/12/04 14:11:11 INFO mapreduce.Job: The url to track the job: http://hadoop03:8088/proxy/application_1575438331337_0001/19/12/04 14:11:11 INFO mapreduce.Job: Running job: job_1575438331337_000119/12/04 14:11:24 INFO mapreduce.Job: Job job_1575438331337_0001 running in uber mode : false19/12/04 14:11:24 INFO mapreduce.Job: map 0% reduce 0%... 执行结束后，查看 HDFS 中 /laiyy/output 文件夹内容，并下载 part-r-0000 文件，查看文件输出.]]></content>
      <categories>
        <category>hadoop</category>
        <category>map-reduce</category>
      </categories>
      <tags>
        <tag>hadoop</tag>
        <tag>map-reduce</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hadoop（8） DataNode、小文件存档]]></title>
    <url>%2Fhadoop%2Fhdfs%2Fhadoop-8.html</url>
    <content type="text"><![CDATA[在了解了 NameNode、SecondaryNameNode 的工作机制、FsImage 与 Edits 数据备份、NameNode 安全机制与多目录后，对 NameNode 有了一些基础了解。在此基础之上，接下来了解一下 DataNode 的工作机制。 DataNode 工作机制DataNode 中存储的每个数据块，以文件形式存储在磁盘上。包括 2 个文件：数据本身、元数据(包括数据块的长度、校验和、时间戳) DataNode 启动后，向 NameNode 注册 NameNode 注册成功后，会同步在 NameNode 元数据中 DataNode 每个一个固定的周期向 NameNode 再注册（默认1小时） DataNode 与 NameNode 以 3 秒一次 的心跳机制判断是否断开。心跳返回结果带有 NameNode 给 DataNode 的命令 NameNode 超过 10 分钟没有收到心跳，则认为该节点不可用 DataNode 数据完整性 当 DataNode 读取 Block 时，它会计算 CheckSum(校验和) 如果计算后的 CheckSum 与 Block 创建时的值不一样，说明 Block 已经损坏 Client 读取其他 DataNode 上的 Block DataNode 在其文件创建后，周期性的验证 CheckSum 掉线时限DataNode 进程死亡或者网路故障，造成 DataNode 与 NameNode 无法通信，NameNode 不会立即把该节点判定为 死亡，要经过一段时间后才会判定为死亡，这段时间称为 超时时长。HDFS 默认的超时时长为 10min + 30s 超时时长计算公示： 2 * dfs.namenode.heartbeat.recheck-interval + 10 * dfs.heartbeat.interval 具体可参考 官方文档，默认值为： dfs.namenode.heartbeat.recheck-interval 5 分钟(300000)、dfs.heartbeat.interval 3秒（3s） 如果需要修改掉线时限，可以修改 hdfs-site.xml 文件。 服役新数据节点现在已经有 3 台服务器构成了一个 hadoop 集群，如果现在需要在此基础上，再增加一个新的数据节点，就称为 新数据节点服役。 环境准备 以 hadoop04 为主，克隆一台 hadoop05 修改 hadoop05 的 ip、主机名称 删除原来 HDFS 中的 data/ 和 log/ 应用 /etc/profile 配置文件 服役新节点 启动原始集群 02、03、04 删除 05 的 data/ 和 log/ 启动 05 的 DataNode(sbin/hadoop-daemon.sh start datanode) 启动 05 的 NodeManager(sbin/yarn-daemon.sh start nodemanager) 在 05 上上传文件进行测试 查看 WebUI 的 datanodes 退役旧数据节点主机白名单添加到白名单里的主机节点，都允许访问 NameNode，否则不允许访问。 配置步骤： 在 NameNode 的 %HADOOP_HOME%/etc/hadoop 目录下创建 dfs.hosts 文件，添加白名单（此次不添加 05）1234# dfs.hostshadoop02hadoop03hadoop04 在 NameNode 的 hdfs-site.xml 文件中增加 dfs.hosts 配置 12345&lt;!-- 配置白名单 --&gt;&lt;property&gt; &lt;name&gt;dfs.hosts&lt;/name&gt; &lt;value&gt;/opt/module/hadoop-2.7.2/etc/hadoop/dfs.hosts&lt;/value&gt;&lt;/property&gt; 分发到 03、04，并刷新 NameNode 123[root@hadoop02 hadoop]# xsync hdfs-site.xml[root@hadoop02 hadoop]# hdfs dfsadmin -refreshNodesRefresh nodes successful 更新 ResourceManager 12[root@hadoop03 ~]# yarn rmadmin -refreshNodes19/12/02 14:26:29 INFO client.RMProxy: Connecting to ResourceManager at hadoop03/192.168.233.132:8033 查看 WebUI 在执行上述操作的时候，02、03、04、05 都未关闭，也就是说，在执行上述操作之前，在 WebUI 的 DataNodes 中是可以看到 02、03、04、05 四台机器的。在执行完上述操作后，再次查看 WebUI 如果数据不均衡，可以使用命令来实现集群的再平衡 123[root@hadoop02 hadoop-2.7.2]# sbin/start-balancer.sh starting balancer, logging to /opt/module/hadoop-2.7.2/logs/hadoop-root-balancer-hadoop02.outTime Stamp Iteration# Bytes Already Moved Bytes Left To Move Bytes Being Moved 此时再查看 README.TXT 文件的块信息，由 05 变更到 02 上了。 黑名单退役在黑名单上的主机会被强制退出。 在测试实现这种情况之前，需要将现场恢复，即将 hdfs-site.xml 中添加的白名单配置先注释掉，并刷新 NameNode 和 ResourceManager，启动 05 上的 DataNode 在 NameNode 的 %HADOOP_HOME%/etc/hadoop 目录下，创建 dfs.hosts.exclude 文件，并添加 05 修改 NameNode 上的 hdfs-site.xml 文件，增加 dfs.hosts.exclude 配置 12345&lt;!-- 黑名单 --&gt;&lt;property&gt; &lt;name&gt;dfs.hosts.exclude&lt;/name&gt; &lt;value&gt;/opt/module/hadoop-2.7.2/etc/hadoop/dfs.hosts.exclude&lt;/value&gt;&lt;/property&gt; 刷新 NameNode、ResourceManager12345[root@hadoop02 hadoop]# hdfs dfsadmin -refreshNodesRefresh nodes successful[root@hadoop03 ~]# yarn rmadmin -refreshNodes19/12/02 14:26:29 INFO client.RMProxy: Connecting to ResourceManager at hadoop03/192.168.233.132:8033 查看 WebUI，提示正在退役中(Decommission In Progress)，此时正在退役的节点会将数据块复制到其他节点上，保证数据的完整性。 稍等一会后再刷新页面，提示 05 节点已退役完成：Decommissioned。 如果数据不平衡，可以和白名单一样，使用 balance 命令平衡数据。 需要注意的点： 等待退役节点状态为 Decommissioned，此时所有的块都已经复制完成，停止该节点及节点资源管理器。注意：如果副本数是 3，服役的节点小于等于 3，是不能退役的！需要修改副本数后才能退役！ 不允许白名单和黑名单中存在同一个主机 DataNode 多目录修改配置与 NameNode 多目录差不多，也是修改 hdfs-site.xml，增加如下配置1234&lt;property&gt; &lt;name&gt;dfs.datanode.data.dir&lt;/name&gt; &lt;value&gt;file:///$&#123;hadoop.tmp.dir&#125;/dfs/data1,file:///$&#123;hadoop.tmp.dir&#125;/dfs/data2&lt;/value&gt;&lt;/property&gt; 分发到不同主机上后，重启 hadoop 集群即可。 注意： DataNode 与 NameNode 不同，DataNode 每个目录中存放的数据不一样。数据不是副本！ 小文件存档小文件存档的弊端鉴于每个文件在 DataNode 中分块存储，每个块的元数据村存在 NameNode 中，因此 HDFS 存储小文件会非常低效。因为大量的小文件会耗尽 NameNode 中的大部分内存。但是，需要注意的是，存储小文件所需要的磁盘容量和数据块的大小无关。 如：一个 1MB 的文件，设置为 128M 的块存储，实际使用的磁盘空间是 1MB，而不是 128MB。 解决办法之一HDFS 存档文件或 HAR 文件，是一个更搞笑的文件存档工具，它将文件存在 HDFS 块，在减少 NameNode 内存使用的同时，允许对文件进行透明访问。具体来说，HDFS 存档文件对内还是一个一个的独立文件，对外（NameNode）而言却是一个整体，减少了 NameNode 的内存。 测试 在 HDFS 中，存放几个测试文件： 文件压缩：12345# 参数解释# archive：开始文件压缩# -archiveName：指定压缩的名称# -p： 从那个目录，压缩到那个目录[root@hadoop03 hadoop-2.7.2]# hadoop archive -archiveName outout.har -p / /output 执行完成后，查看 WebUI 可以看到，文件成功输出了，但是我们看不到文件的内容是否和压缩前一致，解决办法：使用 hadoop fs -ls -R har:///output/output.har 命令查看 1234[root@hadoop02 hadoop-2.7.2]# hadoop fs -ls -R har:///output/outout.har-rw-r--r-- 3 root supergroup 15429 2019-12-02 16:23 har:///output/outout.har/LICENSE.txt-rw-r--r-- 3 root supergroup 101 2019-12-02 16:22 har:///output/outout.har/NOTICE.txt-rw-r--r-- 3 root supergroup 1366 2019-12-02 16:22 har:///output/outout.har/README.txt 文档解压：1[root@hadoop02 hadoop-2.7.2]# hadoop fs -cp har:///output/outout.har /har 回收站开启回收站功能，可以将删除的文件，在不超时的情况下，恢复原数据，起到防止误删、备份等作用。 回收站参数设置及工作机制 开启回收站功能参数 fs.trash.interval：默认值为 0，表示 禁用回收站，其他值表示该文件的存活时间，单位 分钟 fs.trash.checkpoint.interval：默认值为 0，表示 检查回收站的时间间隔，如果为 0，则该值与 fs.trash.interval 的时间间隔相同。单位 分钟 要求：fs.trash.checkpoint.interval &lt;= fs.trash.interval 修改 core-site.xml 文件1234&lt;property&gt; &lt;name&gt;fs.trash.interval&lt;/name&gt; &lt;value&gt;1&lt;/value&gt;&lt;/property&gt; 删除一条数据测试 123[root@hadoop03 hadoop-2.7.2]# hadoop fs -rm /README.txt19/12/02 17:31:15 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 1 minutes, Emptier interval = 0 minutes.Moved: &apos;hdfs://hadoop02:9000/README.txt&apos; to trash at: hdfs://hadoop02:9000/user/root/.Trash/Current 在 WebUI 中查看回收站 错误原因：进入垃圾回收站的默认用户名为 dr.who， 需要修改回收站用户名 修改 core-site.xml，并分发的 03、04 上，重启集群1234&lt;property&gt; &lt;name&gt;hadoop.http.staticuser.user&lt;/name&gt; &lt;value&gt;root&lt;/value&gt;&lt;/property&gt; 再次查看 WebUI： 快照管理快照，相当于对目录做了一次备份。此操作并 不会立即赋值所有文件 ，而是 指向同一个文件。当写入发生时，才会产生新文件。 常见命令 开启指定目录的快照功能： hdfs dfsadmin -allowSnapshot &lt;path&gt; 12[root@hadoop02 hadoop-2.7.2]# hdfs dfsadmin -allowSnapshot /laiyyAllowing snaphot on /laiyy succeeded 禁用指定目录的快照功能(默认)：hdfs dfsadmin -disallowSnapshot &lt;path&gt;对指定目录创建快照：hdfs dfs -createSnapshot &lt;path&gt; 12[root@hadoop02 hadoop-2.7.2]# hdfs dfs -createSnapshot /laiyyCreated snapshot /laiyy/.snapshot/s20191203-135428.244 此时在 WebUI 中是看不到快照文件的，因为这个快照文件是隐藏文件，输入 /laiyy/.snapshot 即可查看 创建目录快照并指定名称：hdfs dfs -createSnapshot &lt;path&gt; &lt;name&gt;快照重命名：hdfs dfs -renameSnapshot &lt;path&gt; &lt;oldName&gt; &lt;newName&gt; 1[root@hadoop02 hadoop-2.7.2]# hdfs dfs -renameSnapshot /laiyy s20191203-135428.244 laiyy_snapshot 查看 WebUI，可以看到快照名称已经修改了。 列出当前用户可以快照的目录：hdfs lsSnapshottableDir比较两个快照目录的不同：hdfs snapshotDiff &lt;path&gt; &lt;from&gt; &lt;to&gt; 12345# path 哪个路径的快照# from、to：比较 form 和 to 两个快照的区别# 此时的 from 用 "." 指代 /laiyy 文件夹，此时比较是没有任何区别的[root@hadoop02 hadoop-2.7.2]# hdfs snapshotDiff /laiyy . .snapshot/laiyy_snapshotDifference between current directory and snapshot laiyy_snapshot under directory /laiyy: 在已经创建快照之后，再往 /laiyy 下上传一个文件，比较结果 1234[root@hadoop02 hadoop-2.7.2]# hdfs snapshotDiff /laiyy . .snapshot/laiyy_snapshotDifference between current directory and snapshot laiyy_snapshot under directory /laiyy:M .- ./LICENSE.txt 再创建一个新的快照，比较两个快照之间的区别 1234[root@hadoop02 hadoop-2.7.2]# hdfs snapshotDiff /laiyy .snapshot/laiyy_snapshot .snapshot/laiyy_snapshot1Difference between snapshot laiyy_snapshot and snapshot laiyy_snapshot1 under directory /laiyy:M .+ ./LICENSE.txt 删除快照：hdfs dfs -deleteSnapshot &lt;path&gt; &lt;name&gt; 1hdfs dfs -deleteSnapshot /laiyy laiyy_snapshot 查看 WebUI]]></content>
      <categories>
        <category>hadoop</category>
        <category>hdfs</category>
      </categories>
      <tags>
        <tag>hadoop</tag>
        <tag>hdfs</tag>
        <tag>DataNode</tag>
        <tag>trash</tag>
        <tag>snapshot</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hadoop（7） NameNode 和 SecondaryNameNode、集群安全模式]]></title>
    <url>%2Fhadoop%2Fhdfs%2Fhadoop-7.html</url>
    <content type="text"><![CDATA[此前通过代码了解了 HDFS API 和 I/O 操作，并了解了 HDFS 读写数据的过程，对 HDFS 整体运行过程有了初步了解。接下来就需要了解一下 NN（NameNode）、2NN（SecondaryNameNode） 的区别 NN 和 2NN 的工作机制如果 NameNode 中的元数据存储在 NameNode 节点的磁盘中，由于要经常进行随机访问，还要响应客户端请求，效率会很低。因此，元数据必须要放在内存中。但是，如果只存储在内存中，一旦断点、服务重启，元数据就会丢失。因此，基于这种情况，产生了在磁盘中备份元数据的 FsImage。 在此基础上，当在内存中更新元数据，如果同时更新 FsImage，会导致效率降低；如果不更新，会产生一致性问题，一旦 NameNode 断电，数据就会丢失。基于这种情况，Hadoop 引入了 Edits 文件(只进行追加操作，效率高)。每当元数据有更新或者添加时，就会修改内存中的元数据并追加到 Edits 中。这样，一旦 NameNode 断电，可以通过 FsImage 和 Edits 合并成一个元数据。 但是这样还有一个问题没有解决，那就是如果长时间添加数据到 Edits 中，会导致该文件数据过大，效率很低，而且，一旦断电，恢复元数据需要的时间很长。因此，需要定时进行 FsImage 和 Edits 的合并。 如果这个操作由 NameNode 完成，效率又会降低。因此引入了一个新的节点 SecondaryNameNode，专门用于 FsImage 和 Edits 的合并。 流程： NameNode 启动时，加载 Edits 和 FsImage 到内存（每个 block 占元数据 150byte） 客户端进行增删改操作时，NameNode 要先记录操作日志，更新Edits，再去进行其他后续请求 SecondaryNameNode 请求 NameNode，检查是否触发检查点（触发条件：检查时间到，或 Edits 中的数据满：达到 100W 条） 2NN 请求执行检查点（CheckPoint） NameNode 滚动正在写的 Edits（即从 edits_001 文件，滚动到 edits_002 文件，后续的操作日志将写入 edit_002 中） 将 edits_001 和 FsImage 拷贝到 2NN 2NN 将 FsImage 和 edits_001 加载到内存并合并 2NN 生成新的 FsImage（如：fsimage.checkpoint） 将新生成的 FsImage 拷贝到 NameNonde，并重命名为 fsimage，加载到内存 镜像文件和编辑日志 (FsImage、Edits)在 NameNode 所在的服务器中，查看 fsimage 和 edits 文件(/opt/module/hadoop-2.7.2/data/tmp/dfs/name/current)1234567891011121314151617181920212223-rw-r--r--. 1 root root 1383 11月 26 11:13 edits_0000000000000000001-0000000000000000019-rw-r--r--. 1 root root 1816 11月 26 12:13 edits_0000000000000000020-0000000000000000043-rw-r--r--. 1 root root 42 11月 26 13:13 edits_0000000000000000044-0000000000000000045-rw-r--r--. 1 root root 1048576 11月 26 13:13 edits_0000000000000000046-0000000000000000046-rw-r--r--. 1 root root 42 11月 26 14:53 edits_0000000000000000047-0000000000000000048-rw-r--r--. 1 root root 1048576 11月 26 14:53 edits_0000000000000000049-0000000000000000049-rw-r--r--. 1 root root 260 11月 26 17:39 edits_0000000000000000050-0000000000000000054-rw-r--r--. 1 root root 1048576 11月 26 17:39 edits_0000000000000000055-0000000000000000055-rw-r--r--. 1 root root 1081 11月 27 10:11 edits_0000000000000000056-0000000000000000072-rw-r--r--. 1 root root 42 11月 27 11:11 edits_0000000000000000073-0000000000000000074-rw-r--r--. 1 root root 1048576 11月 27 11:48 edits_0000000000000000075-0000000000000000080-rw-r--r--. 1 root root 1339 11月 28 15:32 edits_0000000000000000081-0000000000000000098-rw-r--r--. 1 root root 42 11月 28 16:32 edits_0000000000000000099-0000000000000000100-rw-r--r--. 1 root root 1048576 11月 28 16:32 edits_0000000000000000101-0000000000000000101-rw-r--r--. 1 root root 42 11月 29 11:21 edits_0000000000000000102-0000000000000000103-rw-r--r--. 1 root root 1048576 11月 29 11:21 edits_0000000000000000104-0000000000000000104-rw-r--r--. 1 root root 1048576 11月 29 14:19 edits_inprogress_0000000000000000105-rw-r--r--. 1 root root 765 11月 29 11:21 fsimage_0000000000000000103-rw-r--r--. 1 root root 62 11月 29 11:21 fsimage_0000000000000000103.md5-rw-r--r--. 1 root root 765 11月 29 14:19 fsimage_0000000000000000104-rw-r--r--. 1 root root 62 11月 29 14:19 fsimage_0000000000000000104.md5-rw-r--r--. 1 root root 4 11月 29 14:19 seen_txid-rw-r--r--. 1 root root 207 11月 29 14:19 VERSION 查看 FsImage 文件此时，查看 fsimage_0000000000000000103 文件，可以看到一些简略信息，详细信息都被二进制编码了。 我们可以通过 hdfs 的命令，将文件转储为可以看懂的 XML 文件：123456# 参数解释：# oiv：转储 fsimage 文件# -p：以何种格式转储# -i：转储哪个文件# -o：转储到什么位置hdfs oiv -p XML -i fsimage_0000000000000000103 -o ~/fsimage.xml 执行命令，查看对应文件夹下的 fsimage.xml 文件(cat ~/fsimage.xml)12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061&lt;?xml version="1.0"?&gt;&lt;fsimage&gt; &lt;NameSection&gt; &lt;genstampV1&gt;1000&lt;/genstampV1&gt; &lt;genstampV2&gt;1011&lt;/genstampV2&gt; &lt;genstampV1Limit&gt;0&lt;/genstampV1Limit&gt; &lt;lastAllocatedBlockId&gt;1073741834&lt;/lastAllocatedBlockId&gt; &lt;txid&gt;103&lt;/txid&gt; &lt;/NameSection&gt; &lt;INodeSection&gt; &lt;lastInodeId&gt;16402&lt;/lastInodeId&gt; &lt;inode&gt; &lt;id&gt;16385&lt;/id&gt; &lt;type&gt;DIRECTORY&lt;/type&gt; &lt;name&gt;&lt;/name&gt; &lt;mtime&gt;1574923975056&lt;/mtime&gt; &lt;permission&gt;root:supergroup:rwxr-xr-x&lt;/permission&gt; &lt;nsquota&gt;9223372036854775807&lt;/nsquota&gt; &lt;dsquota&gt;-1&lt;/dsquota&gt; &lt;/inode&gt; &lt;inode&gt; &lt;id&gt;16398&lt;/id&gt; &lt;type&gt;FILE&lt;/type&gt; &lt;name&gt;log.out&lt;/name&gt; &lt;replication&gt;2&lt;/replication&gt; &lt;mtime&gt;1574818660432&lt;/mtime&gt; &lt;atime&gt;1574923642491&lt;/atime&gt; &lt;perferredBlockSize&gt;134217728&lt;/perferredBlockSize&gt; &lt;permission&gt;root:supergroup:rw-r--r--&lt;/permission&gt; &lt;blocks&gt; &lt;block&gt; &lt;id&gt;1073741829&lt;/id&gt; &lt;genstamp&gt;1006&lt;/genstamp&gt; &lt;numBytes&gt;1349614&lt;/numBytes&gt; &lt;/block&gt; &lt;/blocks&gt; &lt;/inode&gt; &lt;/INodeSection&gt; &lt;INodeReferenceSection&gt;&lt;/INodeReferenceSection&gt; &lt;SnapshotSection&gt; &lt;snapshotCounter&gt;0&lt;/snapshotCounter&gt; &lt;/SnapshotSection&gt; &lt;INodeDirectorySection&gt; &lt;directory&gt; &lt;parent&gt;16385&lt;/parent&gt; &lt;/directory&gt; &lt;/INodeDirectorySection&gt; &lt;FileUnderConstructionSection&gt;&lt;/FileUnderConstructionSection&gt; &lt;SnapshotDiffSection&gt; &lt;diff&gt; &lt;inodeid&gt;16385&lt;/inodeid&gt; &lt;/diff&gt; &lt;/SnapshotDiffSection&gt; &lt;SecretManagerSection&gt; &lt;currentId&gt;0&lt;/currentId&gt; &lt;tokenSequenceNumber&gt;0&lt;/tokenSequenceNumber&gt; &lt;/SecretManagerSection&gt; &lt;CacheManagerSection&gt; &lt;nextDirectiveId&gt;1&lt;/nextDirectiveId&gt; &lt;/CacheManagerSection&gt;&lt;/fsimage&gt; 查看 Edits 文件使用命令将 edits 文件转储为 xml：hdfs oev -p XML -i edits_0000000000000000102-0000000000000000103 -o ~/edits.xmloev：转储 edits 文件 12345678910111213141516&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;EDITS&gt; &lt;EDITS_VERSION&gt;-63&lt;/EDITS_VERSION&gt; &lt;RECORD&gt; &lt;OPCODE&gt;OP_START_LOG_SEGMENT&lt;/OPCODE&gt; &lt;DATA&gt; &lt;TXID&gt;102&lt;/TXID&gt; &lt;/DATA&gt; &lt;/RECORD&gt; &lt;RECORD&gt; &lt;OPCODE&gt;OP_END_LOG_SEGMENT&lt;/OPCODE&gt; &lt;DATA&gt; &lt;TXID&gt;103&lt;/TXID&gt; &lt;/DATA&gt; &lt;/RECORD&gt;&lt;/EDITS&gt; 注意NameNode 通过 %HADOOP_HOME%/data/tmp/name/current/seen_txid 文件，来确定下次开机启动的时候，合并哪些 Edits。 CheckPoint 设置2NN CheckPoint 检查点时间设置，通常情况下，每隔一小时执行一次。 此配置可以参考 Hadoop 官方文档 中的 dfs.namenode.checkpoint.period 设置项，单位为 秒。 1234&lt;property&gt; &lt;name&gt;dfs.namenode.checkpoint.period&lt;/name&gt; &lt;value&gt;3600&lt;/value&gt;&lt;/property&gt; CheckPoint 每分钟检查一次操作次数，当操作次数达到 100万 时，SecondaryNameNode 执行一次。12345678910&lt;!-- 设置 CheckPoint 操作此时达到多少时执行 2NN --&gt;&lt;property&gt; &lt;name&gt;dfs.namenode.checkpoint.txns&lt;/name&gt; &lt;value&gt;1000000&lt;/value&gt;&lt;/property&gt;&lt;!-- 设置多长时间检查一次操作数 --&gt;&lt;property&gt; &lt;name&gt;dfs.namenode.checkpoint.check.period&lt;/name&gt; &lt;value&gt;60&lt;/value&gt;&lt;/property&gt; NameNode 故障处理NameNode 故障后，可以采用如下两种方式进行数据恢复。 将 2NN 中的数据拷贝到 NN 存储数据的目录注意：此操作依赖于 2NN 的数据完整性 步骤： kill -9 NameNode删除 NameNode 存储的数据(%HADOOP_HOME%/data/tmp/name/*)拷贝 2NN 中的数据到 NN 存储数据目录( 2NN 下的 %HADOOP_HOME%/data/tmp/namesecondary/*)重启 NameNode 拷贝方法：1scp -r root@hadoop04:/opt/module/hadoop-2.7.2/data/tmp/dfs/namesecondary/* /opt/module/hadoop-2.7.2/data/tmp/dfs/name/ 单独其中 NameNode： sbin/hadoop-daemon.sh start namenode 导入检查点使用 -importCheckpoint 选项，启动 NameNode 守护进程，进而将 2NN 中的数据拷贝到 NameNode 中。 步骤： 修改 NameNode 的 hdfs-site.xml 文件： 12345678&lt;property&gt; &lt;name&gt;dfs.namenode.checkpoint.period&lt;/name&gt; &lt;value&gt;120&lt;/value&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;dfs.namenode.name.dir&lt;/name&gt; &lt;value&gt;your hadoop namenode dir&lt;/value&gt;&lt;/property&gt; kill -9 NameNode 删除 NameNode 中存储的数据(%HADOOP_HOME%/data/tmp/name/*) 如果 2NN 和 NameNode 不在同一个主机节点上，需要将 2NN 存储数据的目录，拷贝到 NN 存储数据的平级目录，并删除 in_use.lock 文件。 123scp -r root@hadoop04:/opt/module/hadoop-2.7.2/data/tmp/dfs/namesecondary/* /opt/module/hadoop-2.7.2/data/tmp/dfs/cd /opt/module/hadoop-2.7.2/data/tmp/dfs/namesecondaryrm -rf in_use.lock 导入检查点数据 1bin/hdfs namenode -importCheckpoint 启动 NameNodesbin/hadoop-daemon.sh start namenode 集群安全模式安全模式的条件 NameNode 启动 NameNode 启动时，首先将镜像文件（FsImage）加载到内存中，并执行编辑日志（Edits）中的各项操作。一旦在内存中成功简历文件系统元数据的映像，则创建一个新的 FsImage 文件和一个空白的编辑日志，此时，NameNode 开始监听 DataNode 的请求。这个过程中，NameNode 一直处于安全模式，即：NameNode 的文件系统对客户端来说是只读的。 DataNode 启动 系统中的数据块的位置并不是由 NameNode 维护的，而是以块列表的形式存储在 DataNode 中 。在系统的正常操作期间，NameNode 会在内存中保留所有块位置的映射信息。在安全模式下，DataNode 会向 NameNode 发送最新的块列表信息，NameNode 了解到足够多的块位置信息后，即可搞笑运行文件系统。 安全模式退出判断 如果满足 最小副本条件，NameNode 将会在 30s 后退出安全模式。所谓 最小副本条件：是指在整个文件系统中 99.9% 的块满足最小副本级别（默认值：dfs.replication.min=1）。在启动一个刚刚格式化的 HDFS 集群时，因为系统中还没有任何块，所以 NameNode 不会进入安全模式。 安全模式的命令、语法等当集群处于安全模式，不能执行任何写操作。集群启动完成后，自动退出安全模式。 常用命令： bin/hdfs dfsadmin -safemode get：查看安全模式状态 12[root@hadoop02 hadoop-2.7.2]# bin/hdfs dfsadmin -safemode getSafe mode is OFF bin/hdfs dfsadmin -safemode enter：进入安全模式 12[root@hadoop02 hadoop-2.7.2]# bin/hdfs dfsadmin -safemode enterSafe mode is ON 此时的 HDFS 文件系统状态为： 上传一个文件测试一下：12[root@hadoop02 hadoop-2.7.2]# bin/hdfs dfs -put README.txt /put: Cannot create file/README.txt._COPYING_. Name node is in safe mode. 可以发现，上传时已经报错：不能上传文件，因为 NameNode 处于 SafeMode。所以在 HDFS 中没有新上传的文件。 bin/hdfs dfsadmin -safemode leave：离开安全模式 12[root@hadoop02 hadoop-2.7.2]# bin/hdfs dfsadmin -safemode leaveSafe mode is OFF 此时再次执行上传文件，查看文件系统状态 bin/hdfs dfsadmin -safemode wait：等待安全模式 等待安全模式测试等待安全模式的步骤： 先使集群进入到安全模式 12[root@hadoop02 hadoop-2.7.2]# bin/hdfs dfsadmin -safemode enterSafe 在 %HADOOP_HOME% 路径下创建一个脚本 safemode.sh 12345#!/bin/bashhdfs dfsadmin -safemode waithdfs dfs -put /opt/module/hadoop-2.7.2/NOTICE.txt / 修改权限：1chmod 777 safemode.sh 执行脚本，可以看到当前进程阻塞住了，并没有上传 NOTICE.txt 文件。1./safemode.sh 在 xshell 中再打开一个窗口，执行命令：12[root@hadoop02 hadoop-2.7.2]# bin/hdfs dfsadmin -safemode leaveSafe mode is OFF 再查看之前阻塞的进程，发现已经正常通行，且 NOTICE.txt 文件上传到了 HDFS 中 NameNode 多目录配置NameNode 的本地目录可以配置为多个，且每个目录存在的内容相同，增加了可靠性注意：此方法只是保证了数据的可靠性，并不是保证 NameNode 可靠性，它们对应的依然是一个 NameNode 实例 第 0 步：关闭集群 第一步：修改 ddfs-site.xml 文件，增加如下内容，并分发到三台机器上 1234&lt;property&gt; &lt;name&gt;dfs.namenode.name.dir&lt;/name&gt; &lt;value&gt;file:///$&#123;hadoop.tmp.dir&#125;/dfs/name1,file:///$&#123;hadoop.tmp.dir&#125;/dfs/name2&lt;/value&gt;&lt;/property&gt; 1xsync etc/hadoop/hdfs-site.xml 第二步：删除 data 和 logs 中的所有数据 123[root@hadoop02 hadoop-2.7.2]# rm -rf data/ logs/[root@hadoop03 hadoop-2.7.2]# rm -rf data/ logs/[root@hadoop04 hadoop-2.7.2]# rm -rf data/ logs/ 格式化集群并启动 123[root@hadoop02 hadoop-2.7.2]# hdfs namenode -format[root@hadoop03 hadoop-2.7.2]# hdfs namenode -format[root@hadoop04 hadoop-2.7.2]# hdfs namenode -format 查看 %HADOOP_HOME%/data/dfs 文件夹：1234[root@hadoop04 ~]# ll /opt/module/hadoop-2.7.2/data/tmp/dfs/总用量 0drwxr-xr-x. 3 root root 21 11月 29 16:52 name1drwxr-xr-x. 3 root root 21 11月 29 16:52 name2 可见两个文件夹都创建成功了。 启动集群：12[root@hadoop02 hadoop-2.7.2]# sbin/start-dfs.sh[root@hadoop03 hadoop-2.7.2]# sbin/start-yarn.sh 上传文件并测试，可以看到在 name1、name2 中都有对应的文件，且信息完全相同 1[root@hadoop02 hadoop-2.7.2]# hadoop fs -put NOTICE.txt /]]></content>
      <categories>
        <category>hadoop</category>
        <category>hdfs</category>
      </categories>
      <tags>
        <tag>hadoop</tag>
        <tag>hdfs</tag>
        <tag>NameNode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hadoop（6） HDFS API 操作]]></title>
    <url>%2Fhadoop%2Fhdfs%2Fhadoop-6.html</url>
    <content type="text"><![CDATA[此前，完成了一个基础的完全分布式集群，并且使用 Java 程序代码实现测试连通了 Hadoop 集群，且在 HDFS 中创建了一个文件夹。由此开始学习 Hadoop 的一些 Java API 操作。 API 操作通用方法 123456789101112131415@Beforepublic void initFileSystem() throws URISyntaxException, IOException, InterruptedException &#123; Configuration configuration = new Configuration(); // 两个副本 configuration.set("dfs.replication", "2"); fileSystem = FileSystem.get(new URI("hdfs://hadoop02:9000"), configuration, "root");&#125;@Afterpublic void closeFileSystem() throws IOException &#123; if (null != fileSystem) &#123; fileSystem.close(); &#125;&#125; HDFS API 操作文件上传123456@Testpublic void testCopyFromLocalFile() throws IOException &#123; // 上传文件，参数1：待上传文件位置，参数2：HDFS 路径 fileSystem.copyFromLocalFile(new Path("d:\\log\\error.log"), new Path("/error.log")); System.out.println("上传完成");&#125; 将 $HADOOP_HOME$/etc/hadoop/hdfs-site.xml 文件，拷贝到 Java 程序的 /resources 文件夹下，并修改为：1234567&lt;configuration&gt; &lt;!-- 副本数量改为 1 --&gt; &lt;property&gt; &lt;name&gt;dfs.replication&lt;/name&gt; &lt;value&gt;1&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; 注释掉程序中设置副本数的代码，再次上传文件，查看上传后文件副本数 结论：1、如果程序中未设置副本数，且不存在 hdfs-site.xml 文件，则以 Hadoop 中设置的 hdfs-site.xml 中的副本数优先2、如果程序中未设置副本数，存在 hdfs-site.xml 文件，以程序中的 hdfs-site.xml 中的副本数优先3、如果程序中设置了副本数，且存在 hdfs-site.xml，以程序中设置的副本数优先4、如果程序中设置了副本数，且不存在 hdfs-site.xml，以程序中设置的副本数优先 即：Java 程序 &gt; resources 中的 hdfs-site.xml &gt; hadoop 中的 hdfs-site.xml &gt; hadoop 默认的副本数 文件下载123456789@Testpublic void testCopyToLocalFile() throws IOException &#123; // 从 HDFS 拷贝的本机 fileSystem.copyToLocalFile(new Path("/error.log"), new Path("d:\\log\\copy-to-local.log")); // 参数1：是否删除源数据，参数2：HDFS，参数3：本地路径，参数4：是否开启本地模式校验 // 参数4： 为true 时，下载成功后不会生成 .crc 文件，为 false 时会生成 .crc 文件 // .crc 文件：校验数据可靠性的文件 fileSystem.copyToLocalFile(false, new Path("/error.log"), new Path("d:\\log\\copy-to-local-1.log"), true);&#125; 文件删除123456@Testpublic void testDelete() throws IOException &#123; // 参数1：HDFS // 参数2：是否递归删除，当参数1是文件夹时，需要设置为 true，否则报错 fileSystem.delete(new Path("/error1.log"), false);&#125; 文件改名123456@Testpublic void testRename() throws IOException &#123; // 参数1：要修改的 HDFS // 参数2：修改为 HDFS fileSystem.rename(new Path("/error.log"), new Path("/log.out"));&#125; 查看文件详情可以查看文件名称、权限、长度、块信息等 123456789101112131415public void testListFiles() throws IOException &#123; // 参数1：HDFS // 参数2：是否遍历 // 返回值：获取到的文件信息迭代器 RemoteIterator&lt;LocatedFileStatus&gt; files = fileSystem.listFiles(new Path("/"), false); while (files.hasNext()) &#123; // 文件信息 LocatedFileStatus next = files.next(); System.out.println(next); for (BlockLocation blockLocation : next.getBlockLocations()) &#123; // 块信息 System.out.println(blockLocation); &#125; &#125;&#125; 返回值：123456789101112131415161718// 文件信息&#123; "path": "hdfs://hadoop02:9000/error1.log", // 文件路径 "isDirectory": false, // 是否是文件夹 "length":1349614, // 文件长度 "replication": 2, // 副本数 "blocksize": 134217728, // 块大小 "modification_time": 1574819199782, // 修改时间 "access_time": 1574819199617, "owner": "root", // 所有者 "group": "supergroup", // 所有组 "permission": "rw-r--r--", // 权限 "isSymlink": false&#125;// 块信息// 分别代表：起始位置，结束位置，块所在的hadoop服务器0,1349614,hadoop03,hadoop02 判断是否是文件夹1234567@Testpublic void testIsDir() throws IOException &#123; RemoteIterator&lt;LocatedFileStatus&gt; files = fileSystem.listFiles(new Path("/"), true); while (files.hasNext()) &#123; System.out.println(files.next().getPath().getName() + " 是否是文件夹？" + !files.next().isFile()); &#125;&#125; HDFS I/O 流操作文件上传123456789101112131415161718@Testpublic void testPutFileToHdfs() throws IOException &#123; // 2、获取输入流 FileInputStream inputStream = new FileInputStream(new File("d:/log/error.log")); // 3、获取输出流 FSDataOutputStream fsDataOutputStream = fileSystem.create(new Path("/test-io.log")); // 4、流的对拷 IOUtils.copyBytes(inputStream, fsDataOutputStream, configuration); // 5、关闭资源 IOUtils.closeStream(inputStream); IOUtils.closeStream(fsDataOutputStream);&#125; 文件下载123456789101112131415@Testpublic void testGetFileFromHdfs() throws IOException &#123; // 获取输入流 FSDataInputStream inputStream = fileSystem.open(new Path("/log.out")); // 获取输出流 FileOutputStream outputStream = new FileOutputStream(new File("d:/log/log1.out")); // 流的对拷 IOUtils.copyBytes(inputStream, outputStream, configuration); // 关闭资源 IOUtils.closeStream(outputStream); IOUtils.closeStream(inputStream);&#125; HDFS 文件定位读取先往 HDFS 中上传一个大于 128M 的文件，在管理器中查看一下文件的分块大于1。 可见当前文件分为了两块存储。如果此时进行下载，会将两块数据合并起来下载。但如果只想要下载其中的一部分，现在的下载方法无法实现。 12345678910111213141516171819202122232425262728293031323334353637383940// 只读取第一块的数据public void testReadFileSeek1() throws IOException &#123; // 获取输入流 FSDataInputStream inputStream = fileSystem.open(new Path("/hadoop-2.7.2.tar.gz")); FileOutputStream outputStream = new FileOutputStream("d:/log/hadoop.part1"); // 只拷贝 128 M byte[] buffer = new byte[1024]; for (int i = 0; i &lt; 1024 * 128; i++) &#123; inputStream.read(buffer); outputStream.write(buffer); &#125; IOUtils.closeStream(outputStream); IOUtils.closeStream(inputStream);&#125;// 再读取第二块public void testReadFileSeek2() throws IOException&#123; // 获取输入流 FSDataInputStream inputStream = fileSystem.open(new Path("/hadoop-2.7.2.tar.gz")); // 指定读取开始点 inputStream.seek(1024 * 1024 * 128); // 获取输出流 FileOutputStream outputStream = new FileOutputStream("d:/log/hadoop.part2"); // 对拷 IOUtils.copyBytes(inputStream, outputStream, configuration); // 关闭资源 IOUtils.closeStream(outputStream); IOUtils.closeStream(inputStream);&#125;// 拼接两块数据// 由于当前是 windows 环境，使用 cmd 窗口拼接。// cmd 进入两块所在目录// 命令：type hadoop.part2 &gt;&gt; hadoop.part1// 再把 part1 的后缀改为 tar.gz 即可查看 HDFS 读写数据流程HDFS 写数据流程 使用 FileSystem.get 创建一个分布式文件系统客户端，向 NameNode 请求上传文件 NameNode 检查 HDFS 中是否有待上传的文件（根据路径、文件名判断），如果存在该文件，则报错文件已存在 如果 NameNode 检查后，HDFS 没有待上传的文件，则开始响应上传文件 请求上传第一个 block（根据配置不同，block 大小也不同），此时会向 DataNode 请求，由 DataNode 决定可以上传到哪几个节点上 DataNode 返回可以上传的节点（判断条件：节点距离，负载） FileSystem 创建输出流（FsDataOutputStream），与 DataNode 建立通道（串行） DataNode 应答，所有可上传节点应答成功后，开始传输数据 所有数据传输完成后，通知 NameNode 节点距离计算节点距离：两个节点到最近的共同祖先的距离总和 HDFS 写数据过程中，NameNode 会选择距离上传数据最近距离的 DataNode 接收数据，此时需要计算节点距离。 (d1-r1-n0, d1-r1-n0)，由于这两个节点在同一个服务器上，此时距离为 0。即：同一节点上的进程距离为 0。(d1-r1-n1, d1-r1-n2)，由于这两个节点都在同一个机架上，所以 n1、n2 的共同祖先都为 r1，此时距离为 1+1=2(d1-r2-n0, d1-r3-n2)，这两个节点在同一个集群的不同机架上，即这两个节点的共同祖先为 d1，节点到集群还需要经过机架，所以这两个节点到共同祖先的距离都为 2，则节点距离为 2+2=4(d1-r2-n1, d2-r4-n1)，这两个节点也不在同一个集群，则共同祖先为最外围的“网段”，此时每个节点到“网段”的距离都为 3，所以节点距离为 3+3=6 机架感知（副本存储节点选择）默认情况下，当副本数为 3 时，HDFS 的副本策略是在 本地机架 上的一个节点放置一个副本，在 本地机架的另外一个节点 上放置一个副本，最后再 另外一个机架 的不同节点上防止最后一个副本。 老版本的 hadoop 正好相反，是在 本地机架 上放置一个副本，在 另外一个机架 上放置 2 个副本。 HDFS 读数据流程 客户端请求下载文件（向 NameNode 发送请求） NameNode 返回目标文件元数据 客户端创建输入流 客户端请求读取数据（根据距离决定从那个 DataNode 获取数据） DataNode 传输数据]]></content>
      <categories>
        <category>hadoop</category>
        <category>hdfs</category>
      </categories>
      <tags>
        <tag>hadoop</tag>
        <tag>hdfs</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hadoop（5） HDFS]]></title>
    <url>%2Fhadoop%2Fhdfs%2Fhadoop-5.html</url>
    <content type="text"><![CDATA[在此前，已经成功启动、测试了 hadoop 集群的功能，了解了部分 hadoop 知识，下面就需要开始针对 hadoop 进行继续深入学习 HDFS、MapReduce 的知识。 HDFS 概述 HDFS 是一种分布式文件管理系统，用于文件存储，通过目录树来定位文件；其次，由于是分布式的，由多台服务器联合起来实现功能。HDFS 使用场景：适合一次写入、多次独处的场景，且不支持文件的修改，适合用于做数据分析，不适合做网盘应用。 HDFS 的优缺点优点 高容错性 数据自动保存多个副本。通过增加副本的形式，提供了容错性。默认 3 个副本，当有其中一个副本挂掉了，会在其他服务器上再增加一个副本，保证最多有三个副本存在。且三个副本不能在同一个机器上 适合处理大数据 数据规模：能够处理 GB、TB、PB 级别数据文件规模：能够处理百万以上的文件数量 可以构建在廉价机器上，通过多副本机制，提高可靠性 缺点 不适合低延迟数据访问：如毫秒级数据存储 无法高效的对大量小文件进行存储 存储大量小文件的话，会占用 NameNode 大量内存来存储文件目录和块信息，这样是不可取的。NameNode 的内存总是有限的小文件存储的寻址时间会超过读取时间，违反了 HDFS 的设计目标 不支持并发写入、文件随机修改 一个文件只能有一个写，不允许多个线程同时写仅支持数据的追加(append)，不支持文件随机修改 HDFS 组成架构 NameNode(nn)：就是 Master，是一个管理者 管理HDFS 的命名空间；配置副本策略；管理数据块映射信息；处理客户端读写请求 DataNode：就是 Slave。NameNode 下达命令，DataNode 执行实际操作。 存储实际的数据块；执行数据块的读/写操作 Client：客户端 文件切分。文件上传到 HDFS 的时候，Client 将文件切分成一个一个的 Block（默认 128M）然后进行上传 与 NameNode 交互，获取文件位置信息 与 DataNode 交互，读取、写入数据 提供一些命令管理 HDFS，如 NameNode 格式化 通过一些命令访问 HDFS，如对 HDFS 的增删改查 Secondary NameNode：非 NameNode 热备，当 NameNode 挂掉后，并不会马上替换 NameNode 提供服务 辅助 NameNode，分担其工作，如：定期合并 Fsimage(镜像文件)、Edits(编辑日志)，并推送到 NameNode 紧急情况下辅助恢复 NameNode，但是可能会丢失数据 HDFS 文件块大小HDFS 中的文件上是分块存储（Block），大小可通过参数配置 (dfs.blocksize)，默认在 2.X 中为 128M，1.X 为 64M HDFS 块大小设置主要取决于磁盘传输速度。 自带 Shell 操作基本语法bin/hadoop fs 具体命令bin/hdfs dfs 具体命令 常用命令 启动集群 12sbin/start-dfs.shsbin/start-yarn.sh 获取帮助文档 1hadoop fs -help [command] 查看 HDFS 目录信息 12hadoop fs -lshadoop fs -l -R [dir path] # 递归查询 在 HDFS 上创建目录 1hadoop fs -mkdir -p [your dir path]# 创建多级目录 将本地文件剪切到 HDFS 1hadoop fs -moveFromLocal [local file] [hdfs] 追加一个文件到已经存在的文件末尾 1hadoop fs -appendToFile [local file] [hdfs] 可能的报错信息 1：1appendToFile: Failed to APPEND_FILE /user/laiyy/haha.txt for DFSClient_NONMAPREDUCE_-1628325628_1 on 192.168.233.131 because lease recovery is in progress. Try again later. 可能的报错信息 2：1ava.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[192.168.233.131:50010,DS-f6860e33-55fb-44b1-9b95-4a61b0264267,DISK], DatanodeInfoWithStorage[192.168.233.133:50010,DS-8191d13c-f9c0-4d3c-8e3d-fa29d8a76ee5,DISK]], original=[DatanodeInfoWithStorage[192.168.233.131:50010,DS-f6860e33-55fb-44b1-9b95-4a61b0264267,DISK], DatanodeInfoWithStorage[192.168.233.133:50010,DS-8191d13c-f9c0-4d3c-8e3d-fa29d8a76ee5,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via &apos;dfs.client.block.write.replace-datanode-on-failure.policy&apos; in its configuration. 错误原因：1、使用 jps 查看三台机器上的 DataNode 是否都存在，如果缺少了某个 DataNode，则会出现这种错误。2、如果三台 DataNode 都存在，则查看三台机器上的 %HADOOP_HOME%/data/dfs/data/current/VERSION 和 %HADOOP_HOME%/data/dfs/name/current/VERSION 文件，对比三台机器上的文件，查看 namenode 的 namespaceID、clusterID 是否一致，查看 datanode 的 storageID、clusterID 是否一致。如果不一致，则会出现这种错误。 解决办法： 第一步：停止集群 sbin/stop-dfs.sh、sbin/stop-yarn.sh第二步：删除 %HADOOP_HOME%/data 下的数据第三步：格式化 NameNode bin/hdfs namenode -format第四步：重启集群 sbin/start-dfs.sh、sbin/start-yarn.sh 将本地文件复制到 HDFS 12hadoop fs -copyFromLocal [local file] [hdfs]hadoop fs -put [local file] [hdfs] 从 HDFS 拷贝到本地 12hadoop fs -copyToLocal [hdfs] [local path]hadoop fs -get [hdfs] [local path] 从 HDFS 的一个路径，拷贝到另外一个路径 1hadoop fs -cp [hdfs] [hdfs] 从 HDFS 的一个路径，剪切到另外一个路径 1hadoop fs -mv [hdfs] [hdfs] 合并下载多个文件 12hadoop fs -getmerge [hadfs] [local path]# like：[hadoop fs -getmerge /user/laiyy/* merge.txt] 查看文件 1hadoop fs -tail [hdfs txt file] 删除文件 1hadoop fs -rm [hdfs] 删除空目录 1hadoop fs -rmdir [hdfs empty dir] 统计文件夹大小信息 1hadoop fs -du -s -h [hdfs] 设置 HDFS 文件副本数量 1hadoop fs -setrep [num] [hdfs] HDFS 客户端环境测试pom12345678910111213141516171819202122232425262728293031&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;version&gt;4.12&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.logging.log4j&lt;/groupId&gt; &lt;artifactId&gt;log4j-core&lt;/artifactId&gt; &lt;version&gt;2.12.1&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.hadoop&lt;/groupId&gt; &lt;artifactId&gt;hadoop-client&lt;/artifactId&gt; &lt;version&gt;2.7.2&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.hadoop&lt;/groupId&gt; &lt;artifactId&gt;hadoop-common&lt;/artifactId&gt; &lt;version&gt;2.7.2&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.hadoop&lt;/groupId&gt; &lt;artifactId&gt;hadoop-hdfs&lt;/artifactId&gt; &lt;version&gt;2.7.2&lt;/version&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 测试使用客户端创建目录123456789Configuration configuration = new Configuration();// 指定 NameNode（从 core-site.xml 中获取）configuration.set("fs.defaultFS","hdfs://hadoop02:9000");// 获取 hdfs 客户端FileSystem fileSystem = FileSystem.get(configuration);// 在 hdfs 上创建路径fileSystem.mkdirs(new Path("/laiyy"));// 关闭资源fileSystem.close(); 运行结果：123456org.apache.hadoop.security.AccessControlException: Permission denied: user=Administrator, access=WRITE, inode=&quot;/laiyy&quot;:root:supergroup:drwxr-xr-x at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:319) at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:292) at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:213) at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:190) at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1720) 错误原因： 使用 win10 调用 hadoop，用户为 Administrator，而 HDFS 的用户为 root，用户权限不足 解决方法： 在运行 main 方法时，动态的给定一hadoop用户值。 再次运行： 另一种方式1234567Configuration configuration = new Configuration();// 获取 hdfs 客户端；参数1：NameNode地址，参数2：配置信息，参数3：hadoop 用户FileSystem fileSystem = FileSystem.get(new URI("hdfs://hadoop02:9000"), configuration, "root");// 在 hdfs 上创建路径fileSystem.mkdirs(new Path("/laiyy"));// 关闭资源fileSystem.close();]]></content>
      <categories>
        <category>hadoop</category>
        <category>hdfs</category>
      </categories>
      <tags>
        <tag>hadoop</tag>
        <tag>hdfs</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hadoop（4） 完全分布式]]></title>
    <url>%2Fhadoop%2Fhadoop-4.html</url>
    <content type="text"><![CDATA[在之前的例子中，完成了一个单机版的 Hadoop + HDFS + YARN 的搭建过程，并成功执行测试成功。本例中将尝试搭建一个完全分布式的 Hadoop 集群，并验证测试。 Hadoop 集群准备Hadoop 集群需要准备至少三台 Linux 主机（hadoop02、hadoop03、hadoop04），本例使用 VM 模拟三台 CentOS 7 主机。三台主机环境需要一致，都需要关闭防火墙、设置静态 ip、设置主机名称、JDK、Hadoop 等安装 虚拟机准备以 hadoop01 为源，克隆三台虚拟机 hadoop02、hadoop03、hadoop04 编写一个集群分发脚本需要 linux 中事先安装有 rsync 脚本。如果执行命令 rsync 提示没有此命令，在 CentOS 下，执行 yum install -y rsync 安装即可。 需求：循环复制文件到所有节点的相同目录下 在 hadoop01 的 root 用户家目录中，创建一个 bin 目录用于存放脚本，并创建 xsync 脚本文件 12345678910111213141516171819202122232425262728#!/bin/bash# 获取输入参数的个数，如果没有参数，直接退出params=$#if((params==0)); thenecho 'please input param'exit;fi# 获取文件名称param_1=$1file_name=`basename $param_1`echo 'file_name is $file_name'# 获取上级目录的绝对路径dir=`cd -P $(dirname $param_1); pwd`echo 'dir is $dir'# 获取当前用户名称user=`whoami`# 循环 hadoop02-04，同步文件for((host=2;host&lt;=4;host++)); do echo 'rsync file to hadoop0$host' rsync -rvl $dir/$file_name $user@hadoop0$host:$dirdoneecho 'rsync file done' 需要注意： 执行当前脚本的 user 必须有权限操作当前主机待分发的文件或文件夹；也必须在对应的需要分发的主机上拥有此用户，且有操作对应文件夹的权限。 待分发的文件、文件夹必须使用绝对路径，以保证同步到对应主机的位置也是正确的 测试分发脚本 执行 xsync /root/bin，在 hadoop02-04 上查看 /root 目录下是否同步了 xsync 脚本 注意：如果 xsync 命令识别不了，可以把 xsync 文件放置在 /usr/local/bin 目录下 集群部署集群部署规划 hadoop02 hadoop03 hadoop04 HDFS NamdeNode、DataNode DataNode SecondaryNameNode YARN NodeManager ResourceManager、NodeManager NodeManager 需要保证： NameNode 和 SecondaryNameNode 不在一台机器上ResourceManager 上没有 NameNode 和 SecondaryNameNode，防止内存消耗过大 核心配置文件 core-site.xml 在 hadoop02 上，修改 core-site.xml 文件 123456789101112&lt;configuration&gt; &lt;!-- 修改 hdfs 地址 --&gt; &lt;property&gt; &lt;name&gt;fs.defaultFS&lt;/name&gt; &lt;value&gt;hdfs://hadoop02:9000&lt;/value&gt; &lt;/property&gt; &lt;!-- 修改 hadoop 运行时的数据存储位置，可以不存在，启动时会自动创建 --&gt; &lt;property&gt; &lt;name&gt;hadoop.tmp.dir&lt;/name&gt; &lt;value&gt;/opt/module/hadoop-2.7.2/data/tmp&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; HDFS 修改 hadoop-env.sh 中的 JAVA_HOME export JAVA_HOME=/opt/module/jdk1.8.0_144 修改 hdfs-site.xml 文件123456789101112&lt;configuration&gt; &lt;!-- 副本数量改为3 --&gt; &lt;property&gt; &lt;name&gt;dfs.replication&lt;/name&gt; &lt;value&gt;3&lt;/value&gt; &lt;/property&gt; &lt;!-- 指定 hadoop 辅助名称节点主机配置（SecondaryNameNode，2nn） --&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.secondary.http-address&lt;/name&gt; &lt;value&gt;hadoop04:50090&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; YARN 修改 yarn-env.sh、mapred-env.sh 中的 JAVA_HOME export JAVA_HOME=/opt/module/jdk1.8.0_144 修改 yarn-site.xml 123456789101112131415161718192021222324&lt;configuration&gt; &lt;!-- 修改 reduce 获取数据的方式（洗牌） --&gt; &lt;property&gt; &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt; &lt;value&gt;mapreduce_shuffle&lt;/value&gt; &lt;/property&gt; &lt;!-- 修改 resourcemanager 的 地址 --&gt; &lt;property&gt; &lt;name&gt;yarn.resourcemanager.hostname&lt;/name&gt; &lt;value&gt;hadoop03&lt;/value&gt; &lt;/property&gt; &lt;!-- 开启日志聚集 &lt;property&gt; &lt;name&gt;yarn.log-aggregation-enable&lt;/name&gt; &lt;value&gt;true&lt;/value&gt; &lt;/property&gt; --&gt; &lt;!-- 日志保留时间 7 天，单位：秒 &lt;property&gt; &lt;name&gt;yarn.log-aggregation.retain-seconds&lt;/name&gt; &lt;value&gt;604800&lt;/value&gt; &lt;/property&gt; --&gt;&lt;/configuration&gt; 修改 mapred-site.xml1234567891011121314151617181920&lt;configuration&gt; &lt;!-- 指定 MR 运行在 YARN 上 --&gt; &lt;property&gt; &lt;name&gt;mapreduce.framework.name&lt;/name&gt; &lt;value&gt;yarn&lt;/value&gt; &lt;/property&gt; &lt;!-- 修改历史服务器地址 &lt;property&gt; &lt;name&gt;mapreduce.jobhistory.address&lt;/name&gt; &lt;value&gt;hadoop01:10020&lt;/value&gt; &lt;/property&gt; --&gt; &lt;!-- 修改历史服务器 WebUI 地址 &lt;property&gt; &lt;name&gt;mapreduce.jobhistory.webapp.address&lt;/name&gt; &lt;value&gt;hadoop01:19888&lt;/value&gt; &lt;/property&gt; --&gt;&lt;/configuration&gt; 将修改后的配置文件同步到 03、04 上 xsync /opt/module/hadoop-2.7.2/etc/hadoop/ 即可 集群启动集群单点启动 第一次启动需要格式化 NameNode bin/hdfs namenode -format 启动 在 hadoop02 上执行 sbin/hadoop-daemon.sh start namenode 及 sbin/hadoop-daemon.sh start datanode 在 hadoop03 上执行 sbin/hadoop-daemon.sh start datanode 在 hadoop04 上执行 sbin/hadoop-daemon.sh start datanode 集群群起ssh 免密登陆在 hadoop02 上使用 ssh-keygen 生成秘钥，将生成后的 id_rsa.pub 文件中的内容，拷贝到 hadoop03、hadoop04 中 在 hadoop02 中使用 ssh-copy-id hadoop02、ssh-copy-id hadoop03、ssh-copy-id hadoop04 命令拷贝公钥。 如果不将公钥拷贝到本机，使用 ssh hadoop02 登陆本机时也需要输入密码。 此时即完成 hadoop02 对 03、04 的免密登陆，以同样的方式，在 03、04 上实现免密登陆 群起集群 HDFS 配置 slaves 在 hadoop02 中配置修改 etc/hadoop/slaves 文件，注意：文件内容不允许有空格，不允许有空行 12345vim etc/hadoop/slaves hadoop02hadoop03hadoop04 分发到 03、04 上： xsync etc/hadoop/slaves 停止现有的服务，群起服务 在 hadoop02 中，使用命令 sbin/start-dfs.sh 群起服务12345678[root@hadoop02 hadoop-2.7.2]# sbin/start-dfs.shStarting namenodes on [hadoop02]hadoop02: starting namenode, logging to /opt/module/hadoop-2.7.2/logs/hadoop-root-namenode-hadoop02.outhadoop02: starting datanode, logging to /opt/module/hadoop-2.7.2/logs/hadoop-root-datanode-hadoop02.outhadoop04: starting datanode, logging to /opt/module/hadoop-2.7.2/logs/hadoop-root-datanode-hadoop04.outhadoop03: starting datanode, logging to /opt/module/hadoop-2.7.2/logs/hadoop-root-datanode-hadoop03.outStarting secondary namenodes [hadoop04]hadoop04: starting secondarynamenode, logging to /opt/module/hadoop-2.7.2/logs/hadoop-root-secondarynamenode-hadoop04.out 使用 jps 在三台服务器上查看启动情况 群起集群 YARN注意： 由于在 yarn-site.xml 中存在配置 yarn.resourcemanager.hostname 的值为 hadoop03，所以在群起 yarn 时，必须在 hadoop03 上启动，否则会报错 使用命令 sbin/start-yarn.sh 群起 YARN123456[root@hadoop03 hadoop-2.7.2]# sbin/start-yarn.sh starting yarn daemonsstarting resourcemanager, logging to /opt/module/hadoop-2.7.2/logs/yarn-root-resourcemanager-hadoop03.outhadoop02: starting nodemanager, logging to /opt/module/hadoop-2.7.2/logs/yarn-root-nodemanager-hadoop02.outhadoop04: starting nodemanager, logging to /opt/module/hadoop-2.7.2/logs/yarn-root-nodemanager-hadoop04.outhadoop03: starting nodemanager, logging to /opt/module/hadoop-2.7.2/logs/yarn-root-nodemanager-hadoop03.out 查看启动结果 hadoop02 12345[root@hadoop02 hadoop-2.7.2]# jps2353 DataNode2837 NodeManager2985 Jps2221 NameNode hadoop03 12345[root@hadoop03 hadoop-2.7.2]# jps2544 ResourceManager1932 DataNode2829 NodeManager2991 Jps hadoop04 12345[root@hadoop04 hadoop-2.7.2]# jps1745 DataNode2329 Jps1804 SecondaryNameNode2175 NodeManager 集群时间同步使用 crontab 定时同步时间 crontab 定时任务 基本语法： crontab [command] command 功能 -e 编辑 crontab 定时任务 -l 查询 crontab 任务 -r 删除当前用户所有的 crontab 任务 crontab 语法参数 含义 范围 第一个 * 一小时当中的第几分钟 0~59 第二个 * 一天当中的第几个小时 0~23 第三个 * 一个月当中的第几天 1~31 第四个 * 一年当中的第几个月 1~12 第五个 * 一周当中的星期几 0~7(0 和 7 都代表星期日) crontab 特殊符号 特殊符号 含义 * 代表任何时间 , 代表不连续的时间。如：“0 8,12,16 *”，代表每天 8点0分，12点0分，16点0分 执行 - 代表连续时间范围。如：“0 5 1-6”，代表 周一到周六的凌晨5点0分 执行 */n 代表每隔多久执行一次。如：“10 *”，代表每隔 10 分钟执行一次 时间同步时间服务器(hadoop02) 查看 ntp 是否安装 在 hadoop02 中，执行 rpm -qa | grep ntp，如果没有任何输出，则代表 ntp 没有安装。没有安装的情况下，执行 yum install -y ntp 进行安装。123[root@hadoop02 ~]# rpm -qa | grep ntpntpdate-4.2.6p5-29.el7.centos.x86_64ntp-4.2.6p5-29.el7.centos.x86_64 修改 ntp 配置文件 修改 /etc/ntp.conf 文件 授权网段 192.168.x.0-192.168.x.255 上的机器都可以从 hadoop02 上查询和同步时间 打开第 17 行的注释，修改网段即可。 将 #restrict 192.168.1.0 mask 255.255.255.0 nomodify notrap 修改为 restrict 192.168.233.0 mask 255.255.255.0 nomodify notrap 修改集群在局域网中不使用其他互联网时间 将 第21~24行 注释即可。 当该节点(hadoop02) 丢失网络连接，依然可用采用本地时间作为时间服务器为集群中的其他节点提供时间同步 在上一步的位置增加如下配置12server 127.127.1.0fudge 127.127.1.0 stratum 10 注意：127.0.0.1 是本地地址 127.127.1.0 是回环地址 修改 /etc/sysconfig/ntpd 文件 在文件中增加 SYNC_HWCLOCK=yes，代表 保证硬件时间与系统时间一起同步 启动/重启ntpd 12345678910111213141516[root@hadoop02 ~]# systemctl status ntpd.service● ntpd.service - Network Time Service Loaded: loaded (/usr/lib/systemd/system/ntpd.service; disabled; vendor preset: disabled) Active: inactive (dead) # 可以看到此时未启动[root@hadoop02 ~]# systemctl start ntpd.service[root@hadoop02 ~]# systemctl status ntpd.service● ntpd.service - Network Time Service Loaded: loaded (/usr/lib/systemd/system/ntpd.service; disabled; vendor preset: disabled) Active: active (running) since 一 2019-09-23 17:04:23 CST; 3s ago # 可以看到此时是运行状态 Process: 1437 ExecStart=/usr/sbin/ntpd -u ntp:ntp $OPTIONS (code=exited, status=0/SUCCESS) Main PID: 1438 (ntpd) CGroup: /system.slice/ntpd.service └─1438 /usr/sbin/ntpd -u ntp:ntp -g... 设置开机启动：systemctl enable ntpd.service 其他机器(03、04)在 03、04 上，使用 crontab 同步 02 的时间。 先随便修改一个时间 date -s &#39;2018-11-11 11:11:11&#39;，然后编写 crontab 脚本，每分钟从 hadoop02 上同步时间。等待一分钟后再次查看时间。 hadoop 源码编译在 apache 的 hadoop 官方网站上，hadoop 源码是 32 位的，当需要 64 位的 hadoop 时，就需要重新编译源码 需要准备： 能联网的 CentOS、hadoop 源码包、jdk 64 位，apache-ant、maven、protobuf 序列化框架 本例使用版本： hadoop：1.7.2apache-ant：1.9.9maven：3.0.5protobuf：2.5.0jdk：1.8.0_144 64 bit 另外需要安装插件：yum install -y glibc-headers gcc-c++ make cmake openssl ncurses-devel 注意：所有操作必须在 root 用户下完成 安装 protobuf解压 protobuf-2.5.0 到 /opt/module/，进入 /opt/module/protobuf-2.5.0/ 文件夹，依次执行下列命令：12345./configuremakemake checkmake installldconfig 修改环境变量，设置 protobuf 的环境到 PATH 中。12export LD_LIBRARY_PATH=/opt/module/protobuf-2.5.0export PATH=$PATH:$LD_LIBRARY_PATH 验证 protobuf 安装是否成功 protoc --version 编译源码执行 tar -zxf hadoop-2.7.2-src.tar.gz 解压，然后执行 mvn package -Pdist,native -DskipTests -Dtar，成功后，编译好的 64 位安装包就在 hadoop-2.7.2-src/hadoop-dist/target 下。编译期间报错的话继续在此执行此命令就行。]]></content>
      <categories>
        <category>hadoop</category>
      </categories>
      <tags>
        <tag>hadoop</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hadoop（3） yarn、history server、logs server]]></title>
    <url>%2Fhadoop%2Fhadoop-3.html</url>
    <content type="text"><![CDATA[在上例中，测试了 HDFS 以及在 HDFS 下执行 MapReduce 示例。本例中，测试启动 YARN，并在 YARN 中执行 MapReduce 程序、并查看历史执行信息和执行日志信息 配置 YARN配置 yarn-env.sh修改 yarn-env.sh 中的 JAVA_HOME 1vim etc/hadoop/yarn-env.sh 将第 23 行的注释去掉，修改 JAVA_HOME 为 export JAVA_HOME=/opt/module/jdk1.8.0_144 12345622 # some Java parameters23 # export JAVA_HOME=/home/y/libexec/jdk1.6.0/24 if [ &quot;$JAVA_HOME&quot; != &quot;&quot; ]; then25 #echo &quot;run java in $JAVA_HOME&quot;26 JAVA_HOME=$JAVA_HOME27 fi 配置 yarn-site.xml123456789101112131415vim etc/hadoop/yarn-site.xml&lt;configuration&gt; &lt;!-- 修改 reduce 获取数据的方式（洗牌） --&gt; &lt;property&gt; &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt; &lt;value&gt;mapreduce_shuffle&lt;/value&gt; &lt;/property&gt; &lt;!-- 修改 resourcemanager 的 地址 --&gt; &lt;property&gt; &lt;name&gt;yarn.resourcemanager.hostname&lt;/name&gt; &lt;value&gt;hadoop01&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; 配置 mapred-env.sh修改 mapred-env.sh 的 JAVA_HOME：第 16 行去掉注释，修改 JAVA_HOME 为 export JAVA_HOME=/opt/module/jdk1.8.0_144 创建并修改 mapred-site.xml 文件拷贝 etc/hadoop/mapred-site.xml.template 文件为 mapred-site.xml 文件，指定 MR 运行在 YARN 上1234567891011cp mapred-site.xml.template mapred-site.xmlvim mapred-site.xml&lt;configuration&gt; &lt;!-- 指定 MR 运行在 YARN 上 --&gt; &lt;property&gt; &lt;name&gt;mapreduce.framework.name&lt;/name&gt; &lt;value&gt;yarn&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; 启动 YARN在保证 NameNode 和 DataNode 启动的情况下，启动 ResourceManager 和 NodeManager。 进入 /opt/module/hadoop-2.7.2，利用 yarn-daemon.sh 启动。 注意启动顺序：ResourceManager 先启动 123sbin/yarn-daemon.sh start resourcemanagersbin/yarn-daemon.sh start nodemanager 查看是否启动成功 12345[root@hadoop01 hadoop-2.7.2]# jps1345 NameNode1505 DataNode2068 ResourceManager2327 NodeManager 查看 Web UI访问 hadoop01:50070，hdfs 正常使用，继续访问 hadoop01:8088，查看 MapReduce 程序运行进程 50070：HDFS8088：MapReduce 测试 8088 的 MapReduce删除 hdfs 中的 /user/laiyy/output： bin/hdfs dfs -rm -r /user/laiyy/output 执行 MapReduce word count 1hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.2.jar wordcount /user/laiyy/input /user/laiyy/output 控制台打印日志如下：12345678910...19/09/20 17:35:36 INFO mapreduce.Job: The url to track the job: http://hadoop01:8088/proxy/application_1568971486858_0001/19/09/20 17:35:36 INFO mapreduce.Job: Running job: job_1568971486858_000119/09/20 17:35:46 INFO mapreduce.Job: Job job_1568971486858_0001 running in uber mode : false19/09/20 17:35:46 INFO mapreduce.Job: map 0% reduce 0%19/09/20 17:35:52 INFO mapreduce.Job: map 100% reduce 0%19/09/20 17:35:58 INFO mapreduce.Job: map 100% reduce 100%19/09/20 17:35:59 INFO mapreduce.Job: Job job_1568971486858_0001 completed successfully 在什么地方执行的任务：The url to track the job: http://hadoop01:8088/proxy/application_1568971486858_0001/map、reduce 执行流程：map x% reduce x%执行结果：Job job_1568971486858_0001 completed successfully 在 8088 上查看执行信息 配置 Yarn 历史运行服务器在 8088 上，某任务执行结束后，可以在进度条后看到有一个 history 选项卡，此选项卡可以查看历史运行记录。但是在没有配置历史运行服务器的时候，此选项卡打开后是 404，要想看到历史执行记录，需要配置 历史运行服务器 配置方式： 修改 mapred-site.xml 文件 启动历史服务器 查看 JobHistory 修改 mapred-site.xml 文件 打开 mapred-site.xml 文件，增加如下配置123456789101112131415161718&lt;configuration&gt; &lt;!-- 指定 MR 运行在 YARN 上 --&gt; &lt;property&gt; &lt;name&gt;mapreduce.framework.name&lt;/name&gt; &lt;value&gt;yarn&lt;/value&gt; &lt;/property&gt; &lt;!-- 修改历史服务器地址 --&gt; &lt;property&gt; &lt;name&gt;mapreduce.jobhistory.address&lt;/name&gt; &lt;value&gt;hadoop01:10020&lt;/value&gt; &lt;/property&gt; &lt;!-- 修改历史服务器 WebUI 地址 --&gt; &lt;property&gt; &lt;name&gt;mapreduce.jobhistory.webapp.address&lt;/name&gt; &lt;value&gt;hadoop01:19888&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; 启动历史服务器 执行命令 sbin/mr-jobhistory-daemon.sh start historyserver 查看启动是否成功 123456[root@hadoop01 hadoop-2.7.2]# jps1505 ResourceManager2373 JobHistoryServer1753 NodeManager1370 DataNode1292 NameNode 访问 8088 中的 history 选项卡，查看历史执行记录 如果出现下面的情况，是因为在本机没有在 hosts 配置 hadoop01 的地址，修改本机 hosts 文件，增加上 hadoop01 的映射即可 配置好 hosts 后，刷新页面，即可看到该任务的执行流程 日志服务器Logs 选项卡可以查看整个执行过程的相关日志，此时点击 Logs 选项卡，会提示如下信息 按照提示信息，我们需要配置 日志服务器 日志聚集的概念：应用运行完成后，将程序运行日志的信息上传到 HDFS 系统上日志聚集的好处：可以方便的查看到程序运行详情，方便开发调试 注意：开启日志聚集功能，需要重启 NodeManager、ResourceManager、HistoryManager 开启日志聚集的步骤： 停止服务 修改配置 yarn-site.xml 重新启动 执行测试 停止服务 1234567891011[root@hadoop01 hadoop-2.7.2]# sbin/mr-jobhistory-daemon.sh stop historyserverstopping historyserver[root@hadoop01 hadoop-2.7.2]# sbin/yarn-daemon.sh stop nodemanagerstopping nodemanagernodemanager did not stop gracefully after 5 seconds: killing with kill -9[root@hadoop01 hadoop-2.7.2]# sbin/yarn-daemon.sh stop resourcemanagerstopping resourcemanager[root@hadoop01 hadoop-2.7.2]# jps3332 Jps1370 DataNode1292 NameNode 配置 yarn-site.xml 1234567891011121314151617181920212223&lt;configuration&gt; &lt;!-- 修改 reduce 获取数据的方式（洗牌） --&gt; &lt;property&gt; &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt; &lt;value&gt;mapreduce_shuffle&lt;/value&gt; &lt;/property&gt; &lt;!-- 修改 resourcemanager 的 地址 --&gt; &lt;property&gt; &lt;name&gt;yarn.resourcemanager.hostname&lt;/name&gt; &lt;value&gt;hadoop01&lt;/value&gt; &lt;/property&gt; &lt;!-- 开启日志聚集 --&gt; &lt;property&gt; &lt;name&gt;yarn.log-aggregation-enable&lt;/name&gt; &lt;value&gt;true&lt;/value&gt; &lt;/property&gt; &lt;!-- 日志保留时间 7 天，单位：秒 --&gt; &lt;property&gt; &lt;name&gt;yarn.log-aggregation.retain-seconds&lt;/name&gt; &lt;value&gt;604800&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; 重新启动 12345678910111213[root@hadoop01 hadoop-2.7.2]# sbin/yarn-daemon.sh start resourcemanagerstarting resourcemanager, logging to /opt/module/hadoop-2.7.2/logs/yarn-root-resourcemanager-hadoop01.out[root@hadoop01 hadoop-2.7.2]# sbin/yarn-daemon.sh start nodemanagerstarting nodemanager, logging to /opt/module/hadoop-2.7.2/logs/yarn-root-nodemanager-hadoop01.out[root@hadoop01 hadoop-2.7.2]# sbin/mr-jobhistory-daemon.sh start historyserverstarting historyserver, logging to /opt/module/hadoop-2.7.2/logs/mapred-root-historyserver-hadoop01.out[root@hadoop01 hadoop-2.7.2]# jps3825 Jps3622 NodeManager3784 JobHistoryServer1370 DataNode1292 NameNode3373 ResourceManager 执行测试 删除 hdfs 上的 output 文件夹，重新执行 word count 示例 123bin/hdfs dfs -rm -r /user/laiyy/outputhadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.2.jar wordcount /user/laiyy/input /user/laiyy/output 在 8088 上选择最后一个执行的任务，进入 history 选项卡，再进入 Logs 选项卡查看结果 配置文件的说明Hadoop 配置文件分为量类：默认配置文件、自定义配置文件。自定义配置文件的优先级更高 默认配置文件 默认配置文件 存放位置 core-default.xml hadoop-common-xxx.jar/core-default.xml hdfs-default.xml hadoop-hdfs-xxx.jar/hdfs-default.xml yarn-default.xml hadoop-yarn-common-xxx.jar/yarn-default.xml mapred-defaultt.xml hadoop-mapreduce-client-core-xxx.jar/mapred-default.xml 自定义配置文件core-site.xml、hdfs-site.xml、yarn-site.xml、mapred-site.xml 存放在 $HADOOP_HOME/etc/hadoop 文件夹下，可根据需求修改配置]]></content>
      <categories>
        <category>hadoop</category>
      </categories>
      <tags>
        <tag>hadoop</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hadoop（2） 伪分布式]]></title>
    <url>%2Fhadoop%2Fhadoop-2.html</url>
    <content type="text"><![CDATA[配置伪分布式集群，需要注意修改对应的 hdfs 配置文件、JAVA_HOME、副本备份个数等信息。另外在启动集群之前，需要格式化 NameNode（只有第一次启动需要格式化） 常用端口号 HDFS NameNode（web UI）： dfs.namenode.http-address（50070）SecondaryNameNode 辅助节点：50090HDFS 数据节点：dfs.datanode.address（50010）fs.defaultFS:8020/9000YARN ResourceManager web UI： yarn.resourcemanager.webapp.address（8088） 修改配置文件修改 core-site.xml 文件修改 core-site.xml 中关于 hdfs、数据存储等配置 12cd /opt/module/hadoop-2.7.2/etc/hadoopvim core-site.xml 将 configutation 标签内容修改为：123456789101112&lt;configuration&gt; &lt;!-- 修改 hdfs 地址 --&gt; &lt;property&gt; &lt;name&gt;fs.defaultFS&lt;/name&gt; &lt;value&gt;hdfs://hadoop01:9000&lt;/value&gt; &lt;/property&gt; &lt;!-- 修改 hadoop 运行时的数据存储位置，可以不存在，启动时会自动创建 --&gt; &lt;property&gt; &lt;name&gt;hadoop.tmp.dir&lt;/name&gt; &lt;value&gt;/opt/module/hadoop-2.7.2/etc/hadoop/data/tmp&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; 修改 hadoop-env.sh修改 hadoop 的默认 JDK 路径，如果不修改配置，则可能在分布式集群环境下导致 JAVA_HOME 失效 1vim hadoop-env.sh 将 JAVA_HOME 从原来的 export JAVA_HOME=${JAVA_HOME}，修改为 /opt/module/jdk1.8.0_144/ 修改 hdfs-site.xml指定 hdfs 副本的数量为 1 个，默认为 3 个123456&lt;configuration&gt; &lt;property&gt; &lt;name&gt;dfs.replication&lt;/name&gt; &lt;value&gt;1&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; 启动集群格式化 NameNode第一次启动集群时，需要格式化 NameNode，后面如果再启动时不需要格式化 NameNode 123cd /opt/module/hadoop-2.7.2bin/hdfs namenode -format 控制台输出：12345678910111213141516...19/09/20 15:23:31 INFO namenode.FSNamesystem: Retry cache on namenode is enabled19/09/20 15:23:31 INFO namenode.FSNamesystem: Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis19/09/20 15:23:31 INFO util.GSet: Computing capacity for map NameNodeRetryCache19/09/20 15:23:31 INFO util.GSet: VM type = 64-bit19/09/20 15:23:31 INFO util.GSet: 0.029999999329447746% max memory 966.7 MB = 297.0 KB19/09/20 15:23:31 INFO util.GSet: capacity = 2^15 = 32768 entries19/09/20 15:23:31 INFO namenode.FSImage: Allocated new BlockPoolId: BP-1194915434-192.168.233.130-156896421185419/09/20 15:23:31 INFO common.Storage: Storage directory /opt/module/hadoop-2.7.2/etc/hadoop/data/tmp/dfs/name has been successfully formatted.19/09/20 15:23:31 INFO namenode.NNStorageRetentionManager: Going to retain 1 images with txid &gt;= 019/09/20 15:23:31 INFO util.ExitUtil: Exiting with status 019/09/20 15:23:31 INFO namenode.NameNode: SHUTDOWN_MSG: /************************************************************SHUTDOWN_MSG: Shutting down NameNode at hadoop01/192.168.233.130************************************************************/ 当看到控制台输出 SHUTDOWN_MSG: Shutting down NameNode at hadoop01/192.168.233.130 时，即为格式化完成。 启动 NameNode、DataNode启动 NameNode 12[root@hadoop01 hadoop-2.7.2]# sbin/hadoop-daemon.sh start namenodestarting namenode, logging to /opt/module/hadoop-2.7.2/logs/hadoop-root-namenode-hadoop01.out 启动 DataNode1sbin/hadoop-daemon.sh start datanode 验证是否启动成功 JPS 验证 1234[root@hadoop01 hadoop-2.7.2]# jps1345 NameNode1505 DataNode1583 Jps Web UI 验证 浏览器访问 hadoop01 的 ip:50070，查看 WebUI 是否可以访问 集群的基础信息： 集群的详细信息： DataNode 信息： HDFS 文件管理系统： HDFS 管理创建一个文件夹在 hdfs 根目录下再创建其他文件夹以保存文件 1bin/hdfs dfs -mkdir -p /user/laiyy/input 然后在 WebUI 中查看 将 wcinput 文件夹里的东西上传到 hdfs 中123cd /opt/module/demo../hadoop-2.7.2/bin/hdfs dfs -put wcinput/wc.input /user/laiyy/input -put :上传文件 整体命令：将 wcinput 下的 wc.input 文件，上传到 hdfs 中的 /user/laiyy/input 下 验证上传结果：12[root@hadoop01 demo]# ../hadoop-2.7.2/bin/hdfs dfs -ls -R /user/laiyy/input-rw-r--r-- 1 root supergroup 57 2019-09-20 16:20 /user/laiyy/input/wc.input 使用 hdfs 的文件路径运行 word count 示例1hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.2.jar wordcount /user/laiyy/input /user/laiyy/output 此时的 input、output 的路径都是 hdfs 的路径，不是linux的路径。 查看执行结果123456[root@hadoop01 hadoop-2.7.2]# bin/hdfs dfs -ls -R /user/laiyydrwxr-xr-x - root supergroup 0 2019-09-20 16:20 /user/laiyy/input-rw-r--r-- 1 root supergroup 57 2019-09-20 16:20 /user/laiyy/input/wc.inputdrwxr-xr-x - root supergroup 0 2019-09-20 16:28 /user/laiyy/output-rw-r--r-- 1 root supergroup 0 2019-09-20 16:28 /user/laiyy/output/_SUCCESS-rw-r--r-- 1 root supergroup 55 2019-09-20 16:28 /user/laiyy/output/part-r-00000 直接查看 hdfs 中 output 中的执行结果：1234567[root@hadoop01 hadoop-2.7.2]# bin/hdfs dfs -cat /user/laiyy/output/part-r-00000hadoop 3hdfs 1laiyy 1laiyy0728 1mapreduce 1yarn 1 关于 NameNode 格式化一定不能经常格式化 NameNode。当需要格式化 NameNode 时，需要先用 jps 命令，查看一下 NameNode 和 DataNode 是否都已经关闭，如果没有关闭，需要关闭 NameNode 和 DataNode。 在关闭 NameNode 和 DataNode 的情况下，删除 HADOOP_HOME 下的 data 和 log 文件夹，然后执行 NameNode 格式化命令。 其中 data 文件夹可能不在 HADOOP_HOME 下，此时该文件夹在 HADOOP_HOME/etc/hadoop 下。 为何在 DataNode 存在时不能格式化 NameNode？ 在 data 文件夹或 data/tmp/dfs 文件夹下，有两个文件夹，分别为 data、name，分别对应 DataNode 和 NameNode。 在 data/current/ 和 name/current/ 下，都有一个 VERSION 文件，在 VERSION 文件中，可以看到对应的信息： NameNode 123456namespaceID=1748201392clusterID=CID-7c41ca27-aaa9-4b85-9966-36af0e361a58cTime=0storageType=NAME_NODEblockpoolID=BP-1270008624-192.168.233.130-1568966288591layoutVersion=-63 DataNode 123456storageID=DS-9be19535-bada-4b25-9076-f7260386a990clusterID=CID-7c41ca27-aaa9-4b85-9966-36af0e361a58cTime=0datanodeUuid=a4e2c662-26b0-4f7f-8bd4-f6012b54c3e7storageType=DATA_NODElayoutVersion=-56 对比两个文件，可以看到 DataNode 和 NameNode 中的 clusterID 完全一致。 此时，如果由于 DataNode 没有停止，或 data 文件夹没有清空，就格式化 NameNode 的话，会导致 NameNode 的 clusterID 重新生成， 此时，NameNode 和 DataNode 的 clusterID 不一致，导致崩溃。 DataNode 和 NameNode 在 clusterID 不一致，导致只能同时只能有一个工作的问题]]></content>
      <categories>
        <category>hadoop</category>
      </categories>
      <tags>
        <tag>hadoop</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hadoop 学习（1） 基础概念、基础环境搭建安装、官方示例]]></title>
    <url>%2Fhadoop%2Fhadoop-1.html</url>
    <content type="text"><![CDATA[HadoopHadoop 是 Apache 基金会所开发的分布式系统基础架构，主要解决海量数据的存储、分析计算问题。Hadoop 通常是指一个更广泛的概念：Hadoop 生态圈（包括 HBase、Spark 等） Hadoop 的三大发型版本 Apache 最原始版本，对于入门学习最好 Cloudera 收费，在大型互联网公司用的比较多 Hortonworks 文档比较好 Hadoop 的优势 高可靠性 Hadoop 底层维护多个数据副本（默认3个），所以即使 Hadoop 某个计算元素或存储出现故障，也不会导致数据的丢失 高扩展性 在集群中分配任务数据，可方便的扩展数以千计的节点 高效性 在 MapReduce 思想下，Hadoop 是并行工作的，以加快任务处理速度 高容错性 自动将失败的任务重新分配执行 1.x 与 2.x 的区别Hadoop 包含的模块，以及 1.X、2.X 的区别： Hadoop 三大组件HDFSHDFS 架构： NameNode(nn)：相当于一本书的目录；存储文件的元数据，如：文件名、目录结构、文件属性（生成时间、副本数、文件权限），以及每个文件的快列表和快所在的 DataNode DateNode(dn)：相当于目录对应的具体内容；在本地文件系统存储文件块数据，以及块数据的校验和 Secondary NameNode(2nn)：用来监控 HDFS 状态的辅助后台程序，每个一段时间获取 HDFS 元数据快照。 YarnResourceManager（相当于老板） &gt; NodeManager（相当于技术总监）/ApplicationMaster（相当于项目经理） 其中 NodeManager 负责某一个节点，ApplicationMaster 负责节点中的某个任务 ResourceManager 处理客户端请求：管理整个服务器集群资源（磁盘、cpu等）监控 NodeManager启动、监控 ApplicationMaster（在集群上运行的任务）资源的分配、调度 NodeManager 管理单个节点上的资源处理来自 ResourceManager 的命令处理 ApplicationMaster 的命令 ApplicationMaster 负责数据切分为应用程序申请资源并分配给内部任务任务的监控和容错 Container：为 ApplicationMaster 服务 YARN 中资源的抽象，封装了节点上多维度资源，如：内存、CPU、磁盘、网络等，服务 ApplicationMaster MapReduceMapReduce 将计算过程分为两个阶段：Map 阶段、Reduce 阶段 Map 阶段：并行处理输入数据 Reduce 阶段：对 Map 结果进行汇总 大数据生态体系 Hadoop 环境搭建环境准备 CentOS 7JDK 1.8Hadoop 2.9.2 CentOS 设置修改网卡使用 ROOT 用户，设置 NAT 模式网络连接、设置静态 IP （防止 dhcp 导致 ip 变化）1vim /etc/sysconfig/network-scripts/ifcfg-ens33 禁用掉 ipv6，将获取 ip 的方式从 dhcp 改为 static，设置静态 ip 地址 IPADDR、网关 GATEWAY、dns DNS1 123456789101112131415161718192021TYPE=EthernetPROXY_METHOD=noneBROWSER_ONLY=noBOOTPROTO=staticDEFROUTE=yesIPV4_FAILURE_FATAL=noIPV6INIT=noIPV6_AUTOCONF=noIPV6_DEFROUTE=noIPV6_FAILURE_FATAL=noIPV6_ADDR_GEN_MODE=stable-privacyNAME=ens33UUID=672a42a7-bbbb-453e-8ebe-ca0ae27eef49DEVICE=ens33ONBOOT=yesIPADDR=192.168.52.100GATEWAY=192.168.52.2DNS1=192.168.52.2 注意：网关需要与虚拟机中的 NAT 网卡设置一致！ 另外，也需要将 VM8 网卡设置一个静态ip，且这个静态 ip 不能与虚拟机的静态 ip一致，必须在一个网段 修改 hostname、hosts1234vim /etc/sysconfig/networkNETWORKING=yesHOSTNAME=hadoop01 123456vim /etc/hosts192.168.52.100 hadoop01192.168.52.101 hadoop02192.168.52.102 hadoop03192.168.52.103 hadoop04 其中，hosts 文件中的 hadoop02、hadoop03、hadoop04 暂时还没有，先配置上，为后面集群做准备。 安装 JDK、Hadoop寻找一个文件夹或创建一个空文件夹，作为 jdk、hadoop 的安装目录。本例以 /opt 文件夹为例。 在 /opt 文件夹下创建 module 文件夹，存放 jdk、hadoop 安装文件，创建 software 文件夹，存在 jdk、hadoop 安装包 12cd /optmkdir module software 利用 xftp 将下载好的 jdk1.8、hadoop 2.9.2 存入 software 文件夹下，解压安装到 module 文件夹下 1234cd softwaretar -zxf jdk-8u144-linux-x64.tar.gz -C ../module/tar -zxf hadoop-2.9.2.tar.gz -C ../module/ 设置 jdk、hadoop 环境变量 1vim /etc/profile 在文件最后添加：123export JAVA_HOME=/opt/module/jdk1.8.0_144export HADOOP_HOME=/opt/module/hadoop-2.9.2export PATH=$PATH:$JAVA_HOME/bin:$HADOOP_HOME/bin:$HADOOP_HOME/sbin 应用环境变量：1source /etc/profile 使用 java、javac、hadoop 命令，测试环境变量设置是否成功 官方案例[grep]创建一个用于输入的文件夹任意找一个地方，创建一个 input 文件夹，本例使用与 hadoop 统计目录。1mkdir -p demo/input 拷贝 hadoop/etc/hadoop/*.xml，到 input 文件夹，用于 grep 案例的输入源 执行官方 demo在 demo 文件夹下，执行 hadoop 官方 demo1hadoop jar ../hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.2.jar grep input/ output &apos;dfs[a-z.]+&apos; 解释： hadoop：以 hadoop 命令执行jar：执行的是 jar 包xx.jar：具体 jar 包，本例是 2.7.2 版本的官方 hadoop MapReduce 示例grep：由于有多个示例，选择执行哪个示例，此处是执行 grep 案例input：指明输入示例的文件夹output：指明输出结果的文件夹，且这个文件夹必须不存在，否则会报文件夹已存在的错误dfs[a-z.]+：正则过滤 查看控制台输出12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505119/09/20 14:29:11 INFO Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id19/09/20 14:29:11 INFO jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=19/09/20 14:29:11 INFO input.FileInputFormat: Total input paths to process : 819/09/20 14:29:11 INFO mapreduce.JobSubmitter: number of splits:819/09/20 14:29:11 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_local1540340101_0001...19/09/20 14:29:13 INFO mapred.LocalJobRunner: reduce &gt; reduce19/09/20 14:29:13 INFO mapred.Task: Task &apos;attempt_local801724989_0002_r_000000_0&apos; done.19/09/20 14:29:13 INFO mapred.LocalJobRunner: Finishing task: attempt_local801724989_0002_r_000000_019/09/20 14:29:13 INFO mapred.LocalJobRunner: reduce task executor complete.19/09/20 14:29:14 INFO mapreduce.Job: Job job_local801724989_0002 running in uber mode : false19/09/20 14:29:14 INFO mapreduce.Job: map 100% reduce 100%19/09/20 14:29:14 INFO mapreduce.Job: Job job_local801724989_0002 completed successfully19/09/20 14:29:14 INFO mapreduce.Job: Counters: 30 File System Counters FILE: Number of bytes read=1158544 FILE: Number of bytes written=2216290 FILE: Number of read operations=0 FILE: Number of large read operations=0 FILE: Number of write operations=0 Map-Reduce Framework Map input records=1 Map output records=1 Map output bytes=17 Map output materialized bytes=25 Input split bytes=120 Combine input records=0 Combine output records=0 Reduce input groups=1 Reduce shuffle bytes=25 Reduce input records=1 Reduce output records=1 Spilled Records=2 Shuffled Maps =1 Failed Shuffles=0 Merged Map outputs=1 GC time elapsed (ms)=18 Total committed heap usage (bytes)=273203200 Shuffle Errors BAD_ID=0 CONNECTION=0 IO_ERROR=0 WRONG_LENGTH=0 WRONG_MAP=0 WRONG_REDUCE=0 File Input Format Counters Bytes Read=123 File Output Format Counters Bytes Written=23 检查执行结果1234[root@hadoop01 demo]# ll output/总用量 4-rw-r--r--. 1 root root 11 9月 20 14:29 part-r-00000-rw-r--r--. 1 root root 0 9月 20 14:29 _SUCCESS 看到生成了两个文件：part-r-00000、_SUCCESS。 其中，_SUCCESS 文件大小为 0，没有任何内容，只是标记当前执行成功了。 查看 part-r-00000 文件的内容12[root@hadoop01 demo]# cat output/part-r-00000 1 dfsadmin 可以看到统计到的符合正则过滤的条件的单词，只有一个，为 dfsadmin。此时如果再次执行刚才的 hadoop 任务，控制台将报错如下：1234519/09/20 14:42:58 INFO jvm.JvmMetrics: Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initializedorg.apache.hadoop.mapred.FileAlreadyExistsException: Output directory file:/opt/module/demo/output already exists at org.apache.hadoop.mapreduce.lib.output.FileOutputFormat.checkOutputSpecs(FileOutputFormat.java:146) at org.apache.hadoop.mapreduce.JobSubmitter.checkSpecs(JobSubmitter.java:266) at org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:139) 官方案例[word count]创建输入源创建一个 wcinput 用于 word count 案例的输入源，并创建一个 wc.input 文件，输入一些字符串12345678[root@hadoop01 demo]# mkdir wcinput[root@hadoop01 demo]# cd wcinput/[root@hadoop01 wcinput]# vim wc.inputhadoop yarnhadoop mapreducehadoop hdfslaiyylaiyy0728 执行 word count 示例1hadoop jar ../hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.2.jar wordcount wcinput/ wcoutput 与上例的区别仅仅是将 grep 换为 wordcount，调整了输入、输出目录，去掉了正则过滤。 查看输出结果：1234567[root@hadoop01 demo]# cat wcoutput/part-r-00000 hadoop 3hdfs 1laiyy 1laiyy0728 1mapreduce 1yarn 1 可以看到每个单词出现的频率]]></content>
      <categories>
        <category>hadoop</category>
      </categories>
      <tags>
        <tag>hadoop</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[RocketMQ（3） Rocket 集群]]></title>
    <url>%2Frocketmq%2Frocketmq-3.html</url>
    <content type="text"><![CDATA[RocketMQ 集群模式分为四种：单 master、多 master、多 master 多 slave 异步复制、多 master 多 slave 同步双写 四种集群模式单 master风险较大，一旦 broker 宕机或者重启，将导致整个服务部可用。不建议线上环境使用 多 master一个集群全部都是 master，没有 slave 优点配置简单，单个 master 宕机，或者重启未付，对应用没有影响，在磁盘配置为 RAID10 时，即是机器宕机不可恢复的情况，消息也不会丢失（异步刷盘会丢失少量消息，同步刷盘不会丢失消息），性能最高 缺点单个 broker 宕机期间，这台机器上未被消费的消息在机器恢复之前不可订阅，消息的实时性会受到影响。 多 master 多 slave 异步复制每个 master 配置一个 slave，有多对 master slave，HA 采用的是异步复制方式，主备有短暂的消息延迟（毫秒级），master 收到消息后立即向应用返回成功标志，同时向 slave 写入消息。 优点即是磁盘损坏，消息丢失的非常少，且消息的实时性不会受到影响。因为 master 宕机后，消费者仍然可以从 slave 消费，此过程对应用透明，不需要人工干预，性能同多个 master 模式一样 缺点master 宕机，磁盘损坏下，会丢失少量消息 多 master 多 slave 同步双写每个 master 配置一个 slave，有多对 master slave，HA 采用同步双写模式，主备都成功才会返回成功 优点数据与服务都无单点，master 宕机情况下，消息无延迟，服务可用性与数据可用性最高 缺点性能比异步复制低 10% 左右，发送单个 master 的 RT 会略高，主机宕机后，slave 不能自动切换为主机（后续版本会支持） 一主一从修改 master 配置进入 conf/2m-2s-async，修改文件：broker-a-s.properties:12rm -rf broker-a-s.properties cp broker-a.properties broker-a-s.properties 然后打开 broker-a-s.properties，修改：12brokerId=1brokerRole=SLAVE 修改两个配置文件的 nameserver 为两个服务器对应的 nameserver 地址，多个地址用英文分号分割 修改 slave 配置将 master 的 broker-a.properties、broker-a-s.properties 同步过来，在 master 上执行12scp broker-a.properties 192.168.52.201:/usr/local/include/mq/rocketmq/conf/2m-2s-async/scp broker-a-s.properties 192.168.52.201:/usr/local/include/mq/rocketmq/conf/2m-2s-async/ 启动集群依次启动 master、slave 的 nameserver1nohup ./bin/mqnamesrv &amp; 在 master 上使用 broker-a.properties 启动 broker1nohup sh ./bin/mqbroker -c /usr/local/include/mq/rocketmq/conf/2m-2s-async/broker-a.properties &gt; /dev/null 2&gt;&amp;1 &amp; 在 slave 上使用 broker-a-s.properties 启动 broker1nohup sh ./bin/mqbroker -c /usr/local/include/mq/rocketmq/conf/2m-2s-async/broker-a-s.properties &gt; /dev/null 2&gt;&amp;1 &amp; 验证集群在 rocketmq-console 中，修改 nameserver 配置：1rocketmq.config.namesrvAddr=192.168.52.200:9876;192.168.52.201:9876 启动 console，并查看集群属性 缺陷当主节点挂掉后，消息将无法写入 双主双从双主双从，异步刷盘，同步复制（生产环境建议采用此方式） 集群搭建准备4份 RocketMQ 环境，修改配置文件 conf/2m-2s-sync/broker-a.properties，将 brokerRole 改为：SYNC_MASTER,flushDiskType 改为 ASYNC_FLUSH，nameserver 为四台服务器的 nameserver 地址其他与之前 async 的配置一样 修改 conf/2m-2s-sync/broker-a-s.0properties 的 brokerId 为大于 0 的值，brokerRole 为 SLAVE，nameserver 为四台服务器的 nameserver 地址。 修改 conf/2m-2s-sync/broker-b.0properties、conf/2m-2s-sync/broker-b-2.0properties，与 a 的区别在与 brokerName 都为 broker-b 启动集群每台机器都启动 nameserveernohup ./bin/mqnamesrv &amp; 在第一台机器上启动 broker-a1nohup sh ./bin/mqbroker -c /usr/local/include/mq/rocketmq/conf/2m-2s-sync/broker-a.properties &gt; /dev/null 2&gt;&amp;1 &amp; 在第二台机器上启动 broker-b1nohup sh ./bin/mqbroker -c /usr/local/include/mq/rocketmq/conf/2m-2s-sync/broker-b.properties &gt; /dev/null 2&gt;&amp;1 &amp; 在第三台机器上启动 broker-a-s1nohup sh ./bin/mqbroker -c /usr/local/include/mq/rocketmq/conf/2m-2s-sync/broker-a-s.properties &gt; /dev/null 2&gt;&amp;1 &amp; 在第四台机器上启动 broker-b-s1nohup sh ./bin/mqbroker -c /usr/local/include/mq/rocketmq/conf/2m-2s-sync/broker-b-s.properties &gt; /dev/null 2&gt;&amp;1 &amp; 验证集群修改 rocket-console 的配置：rocketmq.config.namesrvAddr=192.168.52.200:9876;192.168.52.201:9876;192.168.52.202:9876;192.168.52.203:9876，启动 console，打开 集群选项卡：]]></content>
      <categories>
        <category>rocketmq</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[RocketMQ（2） 顺序消息、事务消息]]></title>
    <url>%2Frocketmq%2Frocketmq-2.html</url>
    <content type="text"><![CDATA[RocketMQ 顺序消息：消息有序是指可以按照消息发送顺序来消费。RocketMQ 可以严格的保证消息有序，但是这个顺序逼格不是全局顺序，只是分区(queue)顺序。要保证群居顺序，只能有一个分区。 顺序消息在 MQ 模型中，顺序要由三个阶段保证： 消息被发送时，保持顺序 消息被存储时的顺序和发送的顺序一致 消息被消费时的顺序和存储的顺序一致 发送时保持顺序，意味着对于有顺序要求的消息，用户应该在同一个线程中采用同步的方式发送。存储保持和发送的顺序一致，则要求在同一线程中被发送出来的消息 A/B，存储时 A 要在 B 之前。而消费保持和存储一致，则要求消息 A/B 到达 Consumer 之后必须按照先后顺序被处理。 生产者12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758package com.laiyy.study.rocketmqprovider.order;import org.apache.rocketmq.client.exception.MQBrokerException;import org.apache.rocketmq.client.exception.MQClientException;import org.apache.rocketmq.client.producer.DefaultMQProducer;import org.apache.rocketmq.client.producer.MessageQueueSelector;import org.apache.rocketmq.client.producer.SendResult;import org.apache.rocketmq.common.message.Message;import org.apache.rocketmq.common.message.MessageQueue;import org.apache.rocketmq.remoting.common.RemotingHelper;import org.apache.rocketmq.remoting.exception.RemotingException;import java.io.UnsupportedEncodingException;import java.util.List;/** * @author laiyy * @date 2019/4/21 16:18 * @description */public class OrderProducer &#123; public static void main(String[] args) throws MQClientException, UnsupportedEncodingException, RemotingException, InterruptedException, MQBrokerException &#123; // 1、创建 DefaultMQProducer DefaultMQProducer producer = new DefaultMQProducer("demo-producer"); // 2、设置 name server producer.setNamesrvAddr("192.168.52.200:9876"); // 3、开启 producer producer.start(); // 连续发送 5 条信息 for (int index = 1; index &lt;= 5; index++) &#123; // 创建消息 Message message = new Message("TOPIC_DEMO", "TAG_A", "KEYS_!", ("HELLO！" + index).getBytes(RemotingHelper.DEFAULT_CHARSET)); // 指定 MessageQueue，顺序发送消息 // 第一个参数：消息体 // 第二个参数：选中指定的消息队列对象（会将所有的消息队列传进来，需要自己选择） // 第三个参数：选择对应的队列下标 SendResult result = producer.send(message, new MessageQueueSelector() &#123; // 第一个参数：所有的消息队列对象 // 第二个参数：消息体 // 第三个参数：传入的消息队列下标 @Override public MessageQueue select(List&lt;MessageQueue&gt; list, Message message, Object o) &#123; // 获取队列下标 int index = (int) o; return list.get(index); &#125; &#125;, 0); System.out.println("发送第：" + index + " 条信息成功：" + result); &#125; // 关闭 producer producer.shutdown(); &#125;&#125; 控制台输出结果：12345678910发送第：1 条信息成功：SendResult [sendStatus=SEND_OK, msgId=C0A800677E4C18B4AAC26ACE66560000, offsetMsgId=C0A834C800002A9F00000000000000B8, messageQueue=MessageQueue [topic=TOPIC_DEMO, brokerName=broker-a, queueId=0], queueOffset=1]发送第：2 条信息成功：SendResult [sendStatus=SEND_OK, msgId=C0A800677E4C18B4AAC26ACE66630001, offsetMsgId=C0A834C800002A9F0000000000000171, messageQueue=MessageQueue [topic=TOPIC_DEMO, brokerName=broker-a, queueId=0], queueOffset=2]发送第：3 条信息成功：SendResult [sendStatus=SEND_OK, msgId=C0A800677E4C18B4AAC26ACE66660002, offsetMsgId=C0A834C800002A9F000000000000022A, messageQueue=MessageQueue [topic=TOPIC_DEMO, brokerName=broker-a, queueId=0], queueOffset=3]发送第：4 条信息成功：SendResult [sendStatus=SEND_OK, msgId=C0A800677E4C18B4AAC26ACE66690003, offsetMsgId=C0A834C800002A9F00000000000002E3, messageQueue=MessageQueue [topic=TOPIC_DEMO, brokerName=broker-a, queueId=0], queueOffset=4]发送第：5 条信息成功：SendResult [sendStatus=SEND_OK, msgId=C0A800677E4C18B4AAC26ACE666C0004, offsetMsgId=C0A834C800002A9F000000000000039C, messageQueue=MessageQueue [topic=TOPIC_DEMO, brokerName=broker-a, queueId=0], queueOffset=5]17:45:11.545 [NettyClientSelector_1] INFO RocketmqRemoting - closeChannel: close the connection to remote address[192.168.52.200:10909] result: true17:45:11.548 [NettyClientSelector_1] INFO RocketmqRemoting - closeChannel: close the connection to remote address[192.168.52.200:9876] result: true17:45:11.549 [NettyClientSelector_1] INFO RocketmqRemoting - closeChannel: close the connection to remote address[192.168.52.200:10911] result: trueProcess finished with exit code 0 可以看到，所有消息的 queueId 都为 0，顺序消息生产成功。 消费者1234567891011121314151617181920212223242526272829303132333435363738394041424344public class OrderConsumer &#123; public static void main(String[] args) throws MQClientException &#123; // 1、创建 DefaultMQPushConsumer DefaultMQPushConsumer consumer = new DefaultMQPushConsumer("demo-consumer"); // 2、设置 name server consumer.setNamesrvAddr("192.168.52.200:9876"); // 设置消息拉取最大数 consumer.setConsumeMessageBatchMaxSize(2); // 3、设置 subscribe consumer.subscribe("TOPIC_DEMO", // 要消费的主题 "*" // 过滤规则 ); // 4、创建消息监听 consumer.registerMessageListener(new MessageListenerOrderly() &#123; @Override public ConsumeOrderlyStatus consumeMessage(List&lt;MessageExt&gt; list, ConsumeOrderlyContext consumeOrderlyContext) &#123; // 5、获取消息信息 for (MessageExt msg : list) &#123; // 获取主题 String topic = msg.getTopic(); // 获取标签 String tags = msg.getTags(); // 获取信息 try &#123; String result = new String(msg.getBody(), RemotingHelper.DEFAULT_CHARSET); System.out.println("Consumer 消费信息：topic：" + topic+ "，tags：" + tags + "，消息体：" + result); &#125; catch (UnsupportedEncodingException e) &#123; e.printStackTrace(); return ConsumeOrderlyStatus.SUSPEND_CURRENT_QUEUE_A_MOMENT; &#125; &#125; // 6、返回消息读取状态 return ConsumeOrderlyStatus.SUCCESS; &#125; &#125;); // 启动消费者 consumer.start(); &#125;&#125; 顺序消费者与之前的 demo 最大的不同，在于 message listener 从 MessageListenerConcurrently 变为 MessageListenerOrderly，消费标识从 ConsumeConcurrentlyStatus 变为 ConsumeOrderlyStatus。 查看控制台输出：12345Consumer 消费信息：topic：TOPIC_DEMO，tags：TAG_A，消息体：HELLO！1Consumer 消费信息：topic：TOPIC_DEMO，tags：TAG_A，消息体：HELLO！2Consumer 消费信息：topic：TOPIC_DEMO，tags：TAG_A，消息体：HELLO！3Consumer 消费信息：topic：TOPIC_DEMO，tags：TAG_A，消息体：HELLO！4Consumer 消费信息：topic：TOPIC_DEMO，tags：TAG_A，消息体：HELLO！5 事务消息在 RocketMQ 4.3 版本后，开放了事务消息。 RocketMQ 事务消息流程RocketMQ 的事务消息，只要是通过消息的异步处理，可以保证本地事务和消息发送同事成功执行或失败，从而保证数据的最终一致性。 MQ 事务消息解决分布式事务问题，但是第三方 MQ 支持事务消息的中间件不多，如 RockctMQ，它们支持事务的方式也是类似于采用二阶段提交，但是市面上一些主流的 MQ 都是不支持事务消息的，如：Kafka、RabbitMQ 以 RocketMQ 为例，事务消息实现思路大致为： 第一阶段的 Prepared 消息，会拿到消息的地址 第二阶段执行本地事务 第三阶段通过第一阶段拿到的地址去访问消息，并修改状态 也就是说，在业务方法内想要消息队列提交两次消息，一次发送消息和一次确认消息。如果确认消息发送失败，RocketMQ 会定期扫描消息集群中的事务消息。这时候发现了 prepared 消息，它会向消息发送者确认，所以生产方需要实现一个 check 接口。RocketMQ 会根据发送端设置的策略来决定是回滚还是继续发送确认消息。这样就保证了消息发送与本地事务同时成功或同时失败。 事务消息的成功投递需要三个 Topic，分别是 Half Topic：用于记录所有的 prepare 消息 Op Half Topic：记录以及提交了状态的 prepare 消息 Real Topic：事务消息真正的 topic，在 commit 后才会将消息写入该 topic，从而进行消息投递。 事务消息实现1234567891011121314151617181920212223242526272829303132333435363738394041public class TransactionProducer &#123; public static void main(String[] args) throws MQClientException, UnsupportedEncodingException, RemotingException, InterruptedException, MQBrokerException &#123; // 1、创建 TransactionMQProducer TransactionMQProducer producer = new TransactionMQProducer("transaction-producer"); // 2、设置 name server producer.setNamesrvAddr("192.168.52.200:9876"); // 3、指定消息监听对象，用于执行本地事务和消息回查 TransactionListenerImpl transactionListener = new TransactionListenerImpl(); producer.setTransactionListener(transactionListener); // 4、线程池 ThreadPoolExecutor executor = new ThreadPoolExecutor(2, 5, 100, TimeUnit.SECONDS, new ArrayBlockingQueue&lt;Runnable&gt;(2000), new ThreadFactory() &#123; @Override public Thread newThread(Runnable r) &#123; Thread thread = new Thread(r); thread.setName("client-transaction-msg-thread"); return thread; &#125; &#125;); producer.setExecutorService(executor); // 5、开启 producer producer.start(); // 6、创建消息 Message message = new Message("TRANSACTION_TOPIC", "TAG_A", "KEYS_!", "HELLO！TRANSACTION!".getBytes(RemotingHelper.DEFAULT_CHARSET)); // 7、发送消息 TransactionSendResult result = producer.sendMessageInTransaction(message, "hello-transaction"); System.out.println(result); // 关闭 producer producer.shutdown(); &#125;&#125; 事务消息监听器：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768public class TransactionListenerImpl implements TransactionListener &#123; /** * 存储对应书屋的状态信息， key：事务id，value：事务执行的状态 */ private ConcurrentMap&lt;String, Integer&gt; maps = new ConcurrentHashMap&lt;&gt;(); /** * 执行本地事务 * * @param message * @param o * @return */ @Override public LocalTransactionState executeLocalTransaction(Message message, Object o) &#123; // 事务id String transactionId = message.getTransactionId(); // 0：执行中，状态未知 // 1：本地事务执行成功 // 2：本地事务执行失败 maps.put(transactionId, 0); try &#123; System.out.println("正在执行本地事务。。。。"); // 模拟本地事务 TimeUnit.SECONDS.sleep(65); System.out.println("本地事务执行成功。。。。"); maps.put(transactionId, 1); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); maps.put(transactionId, 2); return LocalTransactionState.ROLLBACK_MESSAGE; &#125; return LocalTransactionState.COMMIT_MESSAGE; &#125; /** * 消息回查 * * @param messageExt * @return */ @Override public LocalTransactionState checkLocalTransaction(MessageExt messageExt) &#123; String transactionId = messageExt.getTransactionId(); System.out.println("正在执行消息回查，事务id：" + transactionId); // 获取事务id的执行状态 if (maps.containsKey(transactionId)) &#123; int status = maps.get(transactionId); System.out.println("消息回查状态：" + status); switch (status) &#123; case 0: return LocalTransactionState.UNKNOW; case 1: return LocalTransactionState.COMMIT_MESSAGE; default: return LocalTransactionState.ROLLBACK_MESSAGE; &#125; &#125; return LocalTransactionState.UNKNOW; &#125;&#125; 运行生产者，查看控制台输出：1234正在执行本地事务。。。。正在执行消息回查，事务id：C0A800678F0818B4AAC26AEDDEB10000消息回查状态：0本地事务执行成功。。。。 需要注意：消息回查会隔一段时间执行一次，如果执行本地事务的时间太短，则控制台不会输出事务回查日志。 广播消息生产者1234567891011121314151617181920212223public class Producer &#123; public static void main(String[] args) throws MQClientException, UnsupportedEncodingException, RemotingException, InterruptedException, MQBrokerException &#123; // 1、创建 DefaultMQProducer DefaultMQProducer producer = new DefaultMQProducer("boardcast-producer"); // 2、设置 name server producer.setNamesrvAddr("192.168.52.200:9876"); // 3、开启 producer producer.start(); for (int index = 1; index &lt;= 10; index++) &#123; Message message = new Message("BOARD_CAST_TOPIC", "TAG_A", "KEYS_" + index, ("HELLO！" + index).getBytes(RemotingHelper.DEFAULT_CHARSET)); SendResult result = producer.send(message); System.out.println(result); &#125; // 关闭 producer producer.shutdown(); &#125;&#125; 消费者消费者需要将消费模式修改为 广播消费： consumer.setMessageModel(MessageModel.BROADCASTING); 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647public class Consumer &#123; public static void main(String[] args) throws MQClientException &#123; // 1、创建 DefaultMQPushConsumer DefaultMQPushConsumer consumer = new DefaultMQPushConsumer("boardcast-consumer"); // 2、设置 name server consumer.setNamesrvAddr("192.168.52.200:9876"); // 设置消息拉取最大数 consumer.setConsumeMessageBatchMaxSize(2); // 修改消费模式，默认是集群消费模式，修改为广播消费模式 consumer.setMessageModel(MessageModel.BROADCASTING); // 3、设置 subscribe consumer.subscribe("BOARD_CAST_TOPIC", // 要消费的主题 "*" // 过滤规则 ); // 4、创建消息监听 consumer.registerMessageListener(new MessageListenerConcurrently() &#123; @Override public ConsumeConcurrentlyStatus consumeMessage(List&lt;MessageExt&gt; list, ConsumeConcurrentlyContext consumeConcurrentlyContext) &#123; // 5、获取消息信息 for (MessageExt msg : list) &#123; // 获取主题 String topic = msg.getTopic(); // 获取标签 String tags = msg.getTags(); // 获取信息 try &#123; String result = new String(msg.getBody(), RemotingHelper.DEFAULT_CHARSET); System.out.println("A Consumer 消费信息：topic：" + topic+ "，tags：" + tags + "，消息体：" + result); &#125; catch (UnsupportedEncodingException e) &#123; e.printStackTrace(); return ConsumeConcurrentlyStatus.RECONSUME_LATER; &#125; &#125; // 6、返回消息读取状态 return ConsumeConcurrentlyStatus.CONSUME_SUCCESS; &#125; &#125;); consumer.start(); &#125;&#125; 验证生产者控制台输出12345678910111213SendResult [sendStatus=SEND_OK, msgId=C0A80067971418B4AAC26B2965570000, offsetMsgId=C0A834C800002A9F00000000000026D0, messageQueue=MessageQueue [topic=BOARD_CAST_TOPIC, brokerName=broker-a, queueId=1], queueOffset=0]SendResult [sendStatus=SEND_OK, msgId=C0A80067971418B4AAC26B2965660001, offsetMsgId=C0A834C800002A9F000000000000278F, messageQueue=MessageQueue [topic=BOARD_CAST_TOPIC, brokerName=broker-a, queueId=2], queueOffset=10]SendResult [sendStatus=SEND_OK, msgId=C0A80067971418B4AAC26B29656C0002, offsetMsgId=C0A834C800002A9F000000000000284E, messageQueue=MessageQueue [topic=BOARD_CAST_TOPIC, brokerName=broker-a, queueId=3], queueOffset=0]SendResult [sendStatus=SEND_OK, msgId=C0A80067971418B4AAC26B2965700003, offsetMsgId=C0A834C800002A9F000000000000290D, messageQueue=MessageQueue [topic=BOARD_CAST_TOPIC, brokerName=broker-a, queueId=0], queueOffset=0]SendResult [sendStatus=SEND_OK, msgId=C0A80067971418B4AAC26B29657B0004, offsetMsgId=C0A834C800002A9F00000000000029CC, messageQueue=MessageQueue [topic=BOARD_CAST_TOPIC, brokerName=broker-a, queueId=1], queueOffset=1]SendResult [sendStatus=SEND_OK, msgId=C0A80067971418B4AAC26B2965880005, offsetMsgId=C0A834C800002A9F0000000000002A8B, messageQueue=MessageQueue [topic=BOARD_CAST_TOPIC, brokerName=broker-a, queueId=2], queueOffset=11]SendResult [sendStatus=SEND_OK, msgId=C0A80067971418B4AAC26B29658E0006, offsetMsgId=C0A834C800002A9F0000000000002B4A, messageQueue=MessageQueue [topic=BOARD_CAST_TOPIC, brokerName=broker-a, queueId=3], queueOffset=1]SendResult [sendStatus=SEND_OK, msgId=C0A80067971418B4AAC26B2965960007, offsetMsgId=C0A834C800002A9F0000000000002C09, messageQueue=MessageQueue [topic=BOARD_CAST_TOPIC, brokerName=broker-a, queueId=0], queueOffset=1]SendResult [sendStatus=SEND_OK, msgId=C0A80067971418B4AAC26B29659D0008, offsetMsgId=C0A834C800002A9F0000000000002CC8, messageQueue=MessageQueue [topic=BOARD_CAST_TOPIC, brokerName=broker-a, queueId=1], queueOffset=2]SendResult [sendStatus=SEND_OK, msgId=C0A80067971418B4AAC26B2965AB0009, offsetMsgId=C0A834C800002A9F0000000000002D87, messageQueue=MessageQueue [topic=BOARD_CAST_TOPIC, brokerName=broker-a, queueId=2], queueOffset=12]19:24:35.135 [NettyClientSelector_1] INFO RocketmqRemoting - closeChannel: close the connection to remote address[192.168.52.200:10911] result: true19:24:35.140 [NettyClientSelector_1] INFO RocketmqRemoting - closeChannel: close the connection to remote address[192.168.52.200:9876] result: true19:24:35.140 [NettyClientSelector_1] INFO RocketmqRemoting - closeChannel: close the connection to remote address[192.168.52.200:10909] result: true 消费者控制台输出12345678910A Consumer 消费信息：topic：BOARD_CAST_TOPIC，tags：TAG_A，消息体：HELLO！1A Consumer 消费信息：topic：BOARD_CAST_TOPIC，tags：TAG_A，消息体：HELLO！2A Consumer 消费信息：topic：BOARD_CAST_TOPIC，tags：TAG_A，消息体：HELLO！5A Consumer 消费信息：topic：BOARD_CAST_TOPIC，tags：TAG_A，消息体：HELLO！4A Consumer 消费信息：topic：BOARD_CAST_TOPIC，tags：TAG_A，消息体：HELLO！3A Consumer 消费信息：topic：BOARD_CAST_TOPIC，tags：TAG_A，消息体：HELLO！7A Consumer 消费信息：topic：BOARD_CAST_TOPIC，tags：TAG_A，消息体：HELLO！6A Consumer 消费信息：topic：BOARD_CAST_TOPIC，tags：TAG_A，消息体：HELLO！8A Consumer 消费信息：topic：BOARD_CAST_TOPIC，tags：TAG_A，消息体：HELLO！9A Consumer 消费信息：topic：BOARD_CAST_TOPIC，tags：TAG_A，消息体：HELLO！10 12345678910B Consumer 消费信息：topic：BOARD_CAST_TOPIC，tags：TAG_A，消息体：HELLO！1B Consumer 消费信息：topic：BOARD_CAST_TOPIC，tags：TAG_A，消息体：HELLO！2B Consumer 消费信息：topic：BOARD_CAST_TOPIC，tags：TAG_A，消息体：HELLO！3B Consumer 消费信息：topic：BOARD_CAST_TOPIC，tags：TAG_A，消息体：HELLO！5B Consumer 消费信息：topic：BOARD_CAST_TOPIC，tags：TAG_A，消息体：HELLO！4B Consumer 消费信息：topic：BOARD_CAST_TOPIC，tags：TAG_A，消息体：HELLO！6B Consumer 消费信息：topic：BOARD_CAST_TOPIC，tags：TAG_A，消息体：HELLO！7B Consumer 消费信息：topic：BOARD_CAST_TOPIC，tags：TAG_A，消息体：HELLO！8B Consumer 消费信息：topic：BOARD_CAST_TOPIC，tags：TAG_A，消息体：HELLO！9B Consumer 消费信息：topic：BOARD_CAST_TOPIC，tags：TAG_A，消息体：HELLO！10]]></content>
      <categories>
        <category>rocketmq</category>
      </categories>
      <tags>
        <tag>MQ</tag>
        <tag>RocketMQ</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[RocketMQ（1） 环境搭建、基础运行]]></title>
    <url>%2Frocketmq%2Frocketmq-1.html</url>
    <content type="text"><![CDATA[MQ 全称为 Message Queue，是一种应用程序程序对应用程序的通信方式，应用程序通过读写出入队列的消息来通信，而无需专用连接来连接它们。消息传递指的是程序之间通过在消息中发送数据来进行通信，而不是通过直接调用来通信，直接调用通常用于诸如远程过程调用的技术。 主流 MQ 对比主流 MQ 有 Kafka、RocketMQ、RabbitMQ 等 KafkaKafka 是 Apache 的一个子项目，使用 Scala 实现的一个高性能分布式 publish/subscribe 消息队列系统，主要特点： 快速持久化：通过磁盘顺序读写与零拷贝机制，可以在 O(1) 的系统开销下进行消息持久化 高吞吐：在一台普通的服务器上可以达到 10W/S 的吞吐量 高堆积：支持 Topic 下消费者长时间离线，消息堆积量大 完全的分布式系统，Broker、Producer、Consumer 都原生支持分布式，依赖 ZK 实现负载均衡 支持 Hadoop 数据并行加载；对于像 Hadoop 一样的日志数据和离线分析系统，但又要求实时处理的限制，是一个可行的解决方案 RocketMQ前身是 Metaq，3.0 版本更名为 RocketMQ，alibaba 出品，现交 Apache 孵化。RocketMQ 是一款分布式、队列模型的消息中间件，特点： 能够保证严格的消息顺序 提供丰富的消息拉取模式 高效的订阅者水平扩展能力 实时的消息订阅机制 支持事务消息 亿级消息堆积能力 RabbitMQ使用 Erlang 编写的一个开源的消息队列，本身支持：AMQP、XMPP、SMTP、STOMP 等协议，是一个重量级消息队列，更适合企业级开发。同时也实现的 broker 架构，生产者不会讲消息直接发送给队列，消息在发送给客户端时，现在中心队列排队。对路由、负载均衡、数据持久化有很好的支持。 RocketMQ 单机环境搭建版本 JDK 版本：1.8+ RocketMQ：4.4.0 Maven：3.x os：CentOS 6.5 x64 单机版环境搭建 解压 RocketMQ 4.4.0 到指定文件夹，并修改解压后的文件夹名称 123unzip rocketmq-all-4.4.0-bin-release.zip -d /usr/local/include/mq/cd /usr/local/include/mq/mv rocketmq-all-4.4.0-bin-release/ rocketmq 创建日志、数据文件夹 12mkdir logs store &amp;&amp; cd storemkdir commitlog consumequeue index 修改 conf/2m-2s-async/broker-a.properties 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657# 所属集群名称brokerClusterName=rocketmq-cluster# brijer 名称，不同的配置文件，名称不一样brokerName=broker-a# 0 表示 master，大于0表示 salvebrokerId=0# nameServer 地址，分号分割namesrvAddr=192.168.52.200:9876# 在发送消息时，自动创建服务器不存在的 Topic，默认创建的队列数defaultTopicQueueNums=4# 是否允许 Broker 自动创建 Topic，生产环境需关闭autoCreateTopicEnable=true# 是否允许 Broker 自动创建订阅组，生产环境需关闭autoCreateSubscriptionGroup=true# Broker 对外服务的监听端口listenPort=10911# 删除文件的时间点，默认是凌晨4点deleteWhen=04# 文件保留时间，默认 48 小时fileReservedTime=48# commitLog 每个文件的大小，默认 1GmapedFileSizeCommitLog=1073741824# consumeQueue 每个文件默认存 30W 条，根据需求调整mapedFileSizeConsumeQueue=300000# 检测屋里文件磁盘空间diskMaxUsedSpaceRatio=88# 存储路径storePathRootDir=/usr/local/include/mq/rocketmq/store# commitLog 存储路径storePathCommitLog=/usr/local/include/mq/rocketmq/store/commitlog# 消息队列存储路径storePathConsumeQueue=/usr/local/include/mq/rocketmq/store/consumequeue# 消息索引存储路径storePathIndex=/usr/local/include/mq/rocketmq/store/index# checkpoint 文件存储路径storeCheckPoint=/usr/local/include/mq/rocketmq/store/checkpoint# abort 文件存储路径abortFile=/usr/local/include/mq/rocketmq/store/abort# 限制消息大小maxMessageSize=65535# broker 角色# 1、ASYNC_MASTER：异步复制的 Master# 2、SYNC_MASTER：同步双鞋 Master# 3、SLAVE：从brokerRole=ASYNC_MASTER# 刷盘方式# 1、ASYNC_FLUSH：异步刷盘# 2、SYNC_FLUSH：同步刷盘flushDiskType=ASYNC_FLUSH#checkTransactionMessageEnable=false# 发送消息的线程数量# sendMessageThreadPoolNums=128# 拉取消息线程池数量# pullMessageThreadPoolNums=128 修改 conf 下所有的 xml 文件，将 xml 中的 ${user.home} 修改为 rocketmq 目录 1sed -i &apos;s#$&#123;user.home&#125;#/usr/local/include/mq/rocketmq#g&apos; *.xml 修改 bin/runbroker.sh、bin/runserver.sh 中的 JVM 参数 启动 broker 1nohup sh ./bin/mqnamesrv &amp; 使用 conf/2m-2s-async/broker-a.properties 配置文件，启动 broker 1nohup sh ./bin/mqbroker -c /usr/local/include/mq/rocketmq/conf/2m-2s-async/broker-a.properties &gt; /dev/null 2&gt;&amp;1 &amp; 使用 jps 查看启动结果 RocketMQ 控制台搭建下载地址：https://github.com/apache/rocketmq-externals.git master 分支，拉取到本地，使用 IDE 打开，修改：rocketmq-externals-master\rocketmq-console\src\main\resources\application.properties 配置文件，指定 RocketMQ nameserver 地址(默认端口为 9876)：1rocketmq.config.namesrvAddr=192.168.52.200:9876 访问 http://localhost:8080 消息的生产、消费一个简单的消息生产者使用 SpringBoot 搭建一个简单的消息生产者：12345678910111213141516171819&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.rocketmq&lt;/groupId&gt; &lt;artifactId&gt;rocketmq-client&lt;/artifactId&gt; &lt;version&gt;$&#123;rocketmq.version&#125;&lt;/version&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 12345678910111213141516171819202122public class Producer &#123; public static void main(String[] args) throws MQClientException, UnsupportedEncodingException, RemotingException, InterruptedException, MQBrokerException &#123; // 1、创建 DefaultMQProducer DefaultMQProducer producer = new DefaultMQProducer("demo-producer"); // 2、设置 name server producer.setNamesrvAddr("192.168.52.200:9876"); // 3、开启 producer producer.start(); // 4、创建消息 Message message = new Message("TOPIC_DEMO", "TAG_A", "KEYS_!", "HELLO！".getBytes(RemotingHelper.DEFAULT_CHARSET)); // 5、发送消息 SendResult result = producer.send(message); System.out.println(result); // 6、关闭 producer producer.shutdown(); &#125;&#125; 运行验证控制台打印信息：1234SendResult [sendStatus=SEND_OK, msgId=C0A80067617C18B4AAC26A932C790000, offsetMsgId=C0A834C800002A9F0000000000000000, messageQueue=MessageQueue [topic=TOPIC_DEMO, brokerName=broker-a, queueId=0], queueOffset=0]16:40:30.148 [NettyClientSelector_1] INFO RocketmqRemoting - closeChannel: close the connection to remote address[192.168.52.200:10909] result: true16:40:30.152 [NettyClientSelector_1] INFO RocketmqRemoting - closeChannel: close the connection to remote address[192.168.52.200:9876] result: true16:40:30.152 [NettyClientSelector_1] INFO RocketmqRemoting - closeChannel: close the connection to remote address[192.168.52.200:10911] result: true 查看 rocketmq-console 中 消息 选项卡，并选择主题为 TOPIC_DEMO： 点击 MESSAGE DETAIL 查看消息具体内容： 一个简单的消息消费者依赖与生产者一致 123456789101112131415161718192021222324252627282930313233343536373839404142434445public class Consumer &#123; public static void main(String[] args) throws MQClientException &#123; // 1、创建 DefaultMQPushConsumer DefaultMQPushConsumer consumer = new DefaultMQPushConsumer("demo-consumer"); // 2、设置 name server consumer.setNamesrvAddr("192.168.52.200:9876"); // 设置消息拉取最大数 consumer.setConsumeMessageBatchMaxSize(2); // 3、设置 subscribe consumer.subscribe("TOPIC_DEMO", // 要消费的主题 "*" // 过滤规则 ); // 4、创建消息监听 consumer.registerMessageListener(new MessageListenerConcurrently() &#123; @Override public ConsumeConcurrentlyStatus consumeMessage(List&lt;MessageExt&gt; list, ConsumeConcurrentlyContext consumeConcurrentlyContext) &#123; // 5、获取消息信息 for (MessageExt msg : list) &#123; // 获取主题 String topic = msg.getTopic(); // 获取标签 String tags = msg.getTags(); // 获取信息 try &#123; String result = new String(msg.getBody(), RemotingHelper.DEFAULT_CHARSET); System.out.println("Consumer 消费信息：topic：" + topic+ "，tags：" + tags + "，消息体：" + result); &#125; catch (UnsupportedEncodingException e) &#123; e.printStackTrace(); return ConsumeConcurrentlyStatus.RECONSUME_LATER; &#125; &#125; // 6、返回消息读取状态 return ConsumeConcurrentlyStatus.CONSUME_SUCCESS; &#125; &#125;); // 7、启动消费者（启动后会阻塞） consumer.start(); &#125;&#125; 运行消费者，查看控制台打印信息：1Consumer 消费信息：topic：TOPIC_DEMO，tags：TAG_A，消息体：HELLO！]]></content>
      <categories>
        <category>rocketmq</category>
      </categories>
      <tags>
        <tag>MQ</tag>
        <tag>RocketMQ</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring Cloud 微服务（34） --- APM(三) Pinpoint]]></title>
    <url>%2Fspring-cloud%2Fspring-cloud-34.html</url>
    <content type="text"><![CDATA[Pinpoint 是韩国人编写的 APM 系统，是一个分析大规模分布式系统的平台，并提供处理大量跟踪数据的解决方案。 Pinpoint特点 分布式事务追踪，跟踪跨分布式应用的消息 自动检测应用拓展 水平扩展，以便支持大规模服务器集群 提供代码级了践行，便于定位失败点和瓶颈 提供字节码增强技术，添加新功能无需修改代码 优势 非侵入式：使用字节码增强技术，添加新功能无需修改代码 资源消耗小：对性能影响最小（资源使用量增加约3%） 架构模块 HBase：主要用于存储数据 Pinpoint Collector：部署在 Web 容器上 Pinpoint Web：部署在 Web 容器上 Pinpoint Agent：附加到用于分析的 Java 应用程序 流程：首先通过 agent 收集调用应用的数据，将数据发送到 collector，collector 通过处理和分析数据，最后存储到 HBase 中，可以通过 Pinpoint Web UI 查看已经分析好的调用分析数据 数据结构 Span：RPC 跟踪的基本单位，表示 RPC 到达时处理的工作，包含跟踪数据。Span 将子项标记未 SpanEvent，作为数据结构，每个 Span 包含一个 TraceId Trace：一系列跨度，由相关的 RPC(Span) 组成。同一跟踪中的跨距共享相同的 TransactionId。Trace 通过 SpanIds 和 ParentSpanIds 排序为分层树结构 TraceId：由 TransactionId、SpanId、ParentSpanId 组成的秘钥集合。TransactionId 代表消息id，SpanId 和 ParentSpanId 表示 RPC 父子关系 TransactionId：来自单个事务的分布式系统发送、接收的消息id，必须在整个服务器组是全局唯一的SpanId：接收 RPC 消息时处理的作业 ID，是在 RPC 到达节点时生成的ParentSpanId：生成 RPC 的父 span 的 spanId，如果节点是事务的起始点，不会有父跨度。 兼容性JDK 兼容性 Pinpoint 版本 Agent 需要的 JDK 版本 Collector 需要的 JDK 版本 Web 需要的 JDK 版本 1.0.x 6-8 6+ 6+ 1.1.x 6-8 7+ 7+ 1.5.x 6-8 7+ 7+ 1.6.x 6-8 7+ 7+ 1.7.x 6-8 8+ 8+ 1.8.x 6-8,9+ 8+ 8+ Base 兼容性 Pinpoint 版本 HBase 0.94.x HBase 0.98.x HBase 1.0.x HBase 1.1.x HBase 1.2.x 1.0.x √ × × × × 1.1.x × not tested √ not tested not tested 1.5.x × not tested √ not tested not tested 1.6.x × not tested not tested not tested √ 1.7.x × not tested not tested not tested √ 1.8.x × not tested not tested not tested √ Agent-Collector 兼容性 Agent 版本 Collector 1.0.x Collector 1.1.x Collector 1.5.x Collector 1.6.x Collector 1.7.x Collector 1.8.x 1.0.x √ √ √ √ √ √ 1.1.x not tested √ √ √ √ √ 1.5.x × × √ √ √ √ 1.6.x × × not tested √ √ √ 1.7.x × × × × √ √ 1.8.x × × × × × √ Flink 兼容性 Pinpoint 版本 flink 1.3.x flink 1.4.x 1.7.x √ × 实例HBase 版本为 1.2.11，下载地址：http://mirrors.hust.edu.cn/apache/hbase/hbase-1.2.11/Pinpoint 版本为 1.7.3，下载地址：https://github.com/naver/pinpoint/releases/tag/1.7.Tomcat 版本为：8.x 其中，Pinpoint 需要下载 agent、collector、web 三个文件。 HBase启动 HBase解压 HBase，修改 config/hbase-env.sh 中 JAVA 目录 修改后启动 HBase： ./bin/start-hbase.sh123starting master, logging to /opt/hbase/bin/../logs/hbase-root-master-localhost.localdomain.outJava HotSpot(TM) 64-Bit Server VM warning: ignoring option PermSize=128m; support was removed in 8.0Java HotSpot(TM) 64-Bit Server VM warning: ignoring option MaxPermSize=128m; support was removed in 8.0 稍等片刻后，jps 查看是否启动完成，若出现 HMaster，则启动完成： 加载 Pinpoint HBase 脚本在 https://github.com/naver/pinpoint/tree/master/hbase/scripts 中，获取 hbase-create.hbase、hbase-drop.hbase 文件，新建目录 hbase-script，执行脚本：1./bin/hbase shell /root/hbase-script/hbase-create.hbase Pinpoint启动 Collector、Web将 tomcat 解压为2个包，分别为 collector、web，删除 tomcat 目录下 webapps 下除 ROOT 的文件夹，并删除 ROOT 下所有文件。将 collector、web 分别解压至对应 tomcat 的 ROOT 目录下，解压命令：1jar -xvf pinpoint-collector-1.7.3.war 分别修改两个 tomcat 的 config/server.xml 文件，修改端口 8005、8080、8443、8009 端口，然后分别启动两个 tomcat。启动成功后访问 zipkin：http://192.168.67.136:28080/#/main 配置 Agent创建四个文件夹：eureka、provider、consumer、zuul，并将四个服务移入对应文件夹，解压 agent.tar.gz，将解压后的文件放入四个文件夹： 配置 agent 中的 pinpoint.config 文件，修改 profiler.collector.ip 设置为 pinpoint-collector 的地址，如果在同一个服务器上，不用修改。 可以看到在 pinpoint.config 中监听了 9994、9995、9996 端口，这三个端口在 collector 启动后就开启了，默认即可。如果 collector 需要修改端口，需要修改 $COLLECTOR_TOMCAT_HOME/webapps/ROOT/WEB-INF/classes/pinpoint-collector.properties 文件。 启动服务参数解释：-Dpinpoint.agentId：表示 agent 的唯一标识-Dpinpoint.applicationName：表示用用名称 eurekajava -javaagent:/usr/local/src/pinpoint/soft/eureka/pinpoint-agent-1.7.3/pinpoint-bootstrap-1.7.3.jar -Dpinpoint.agentId=eureka-server -Dpinpoint.applicationName=eureka-server -jar spring-cloud-eureka-server-simple-0.0.1-SNAPSHOT.jar providerjava -javaagent:/usr/local/src/pinpoint/soft/eureka/pinpoint-agent-1.7.3/pinpoint-bootstrap-1.7.3.jar -Dpinpoint.agentId=provider -Dpinpoint.applicationName=provider -jar spring-cloud-apm-skywalking-provider-0.0.1-SNAPSHOT.jar consumerjava -javaagent:/usr/local/src/pinpoint/soft/eureka/pinpoint-agent-1.7.3/pinpoint-bootstrap-1.7.3.jar -Dpinpoint.agentId=consumer -Dpinpoint.applicationName=consumer -jar spring-cloud-apm-skywlaking-consumer-0.0.1-SNAPSHOT.jar zuuljava -javaagent:/usr/local/src/pinpoint/soft/eureka/pinpoint-agent-1.7.3/pinpoint-bootstrap-1.7.3.jar -Dpinpoint.agentId=zuul -Dpinpoint.applicationName=zuul -jar spring-cloud-apm-skywalking-zuul-0.0.1-SNAPSHOT.jar -Xms256m -Xmx256m 成功启动后，访问 pinpoint：http://192.168.67.136:28080/#/main 通过 zuul 获取数据：http://192.168.67.136:9020/client/get-info 再次查看 pinpoint，切换到 zuul 选项卡：红色代表调用失败（第一次调用时需要从 eureka 获取数据，默认超时一秒）。数字代表调用次数 Inspector：检查器，可以查看服务的调用信息。点击查看： 在 Inspector 中，Timeline 选项卡显示请求时间段，information 选项卡显示当前节点启动的信息，包括：应用名、agentId、启动时间等，Heap Usage 显示堆使用情况，JVM/System Cpu Usage 显示 CPU 使用情况，Active Thread 显示线程使用情况。Response Time 显示响应时间，Data Source 显示数据库使用情况]]></content>
      <categories>
        <category>spring-cloud</category>
      </categories>
      <tags>
        <tag>SpringCloud</tag>
        <tag>APM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring Cloud 微服务（33） --- APM(二) SkyWalking]]></title>
    <url>%2Fspring-cloud%2Fspring-cloud-33.html</url>
    <content type="text"><![CDATA[SkyWalking 是有个完整的 APM 系统，被用于追踪、监控、诊断分布式系统。 SkyWalking 整体由 4 个部分组成：collector、agent、web、storage。应用级别的接入，可以使用 SDK 形式接入，也可以使用非侵入式的 Agent 形式接入。agent 将数据转化为 SkyWalking Trace 数据协议，通过 HTTP、gRPC 发送到 collector，collector 对收集到的数据进行分析、整合，最后存储到 es 或 H2 中，一般情况下，H2 用于测试。 SkyWalking 特性SkyWalking 主要功能 分布式只追踪、上下文传输 应用、实例、服务性能指标分析 根源分析 应用拓扑分析 应用于服务依赖分析 慢服务检测 性能优化 SkyWalking 主要特性 多语言探针、类库 Java 自动探针，追踪、监控程序时，无需修改源码 社区提供多语言探针：.NET、Node.js 多种后端存储：Elasticsearch、H2 等 支持 OpenTrancing：Java 自动探针和 OpenTracing API 协同工作 轻量级、完善的后台聚合和分析功能 现代化 Web UI 日志集成 应用、实例、服务的告警 支持接受其他跟踪器数据格式 Zipkin JSON、Thrift、Protobuf v1 和 v2 格式，由 OpenZipkin 库提供支持 Jaeger 采用 Zipkin Thrift 或 JSON v1/v2 格式 SkyWalking 测试用例代码Zuul 1234567891011&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-zuul&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 1234567891011121314151617181920212223242526272829303132333435363738 spring: application: name: spring-cloud-apm-skywalking-zuulserver: port: 9020eureka: client: service-url: defaultZone: http://localhost:8761/eureka/zuul: routes: spring-cloud-apm-skywlaking-consumer: path: /client/** serviceId: spring-cloud-apm-skywlaking-consumerribbon: eureka: enabled: true ReadTimeout: 30000 ConnectionTimeout: 30000 MaxAutoRetries: 0 MaxAutoRetriesNextServer: 1 OkToRetryOnAllOperations: falsehystrix: threadpool: default: coreSize: 1000 maxQueueSize: 1000 queueSizeRejectionThreshold: 500 command: default: execution: isolation: thread: timeoutInMilliseconds: 120001 12345678910@SpringBootApplication@EnableDiscoveryClient@EnableZuulProxypublic class SpringCloudApmSkywalkingZuulApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(SpringCloudApmSkywalkingZuulApplication.class, args); &#125;&#125; Consumer123456&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 123456789server: port: 9021spring: application: name: spring-cloud-apm-skywlaking-consumereureka: client: service-url: defaultZone: http://localhost:8761/eureka/ 1234567891011121314151617181920212223242526272829303132333435363738@SpringBootApplication@EnableFeignClients@EnableDiscoveryClientpublic class SpringCloudApmSkywlakingConsumerApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(SpringCloudApmSkywlakingConsumerApplication.class, args); &#125;&#125;@FeignClient("spring-cloud-apm-skywalking-provider")public interface SkyWalkingFeignService &#123; @RequestMapping(value = "/get-send-info", method = RequestMethod.GET) String getSendInfo(@RequestParam("serviceName") String serviceName);&#125;@RestControllerpublic class SkyWalkingController &#123; private final SkyWalkingFeignService feignService; @Autowired public SkyWalkingController(SkyWalkingFeignService feignService) &#123; this.feignService = feignService; &#125; @GetMapping(value = "/get-info") public String getInfo()&#123; return feignService.getSendInfo("service"); &#125;&#125; Provider123456&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 123456789server: port: 9022spring: application: name: spring-cloud-apm-skywalking-providereureka: client: service-url: defaultZone: http://localhost:8761/eureka/ 123456789101112131415@SpringBootApplication@EnableDiscoveryClient@RestControllerpublic class SpringCloudApmSkywalkingProviderApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(SpringCloudApmSkywalkingProviderApplication.class, args); &#125; @GetMapping(value = "/get-send-info") public String getSendInfo(@RequestParam("serviceName") String serviceName)&#123; return serviceName + " --&gt; " + "spring-cloud-apm-skywalking-provider"; &#125;&#125; SkyWalking 安装SkyWalking 依赖环境： 被监控的应用运行在 JDK6+ SkyWalking collector 和 WebUI 运行在 JDK8+ elasticsearch 5.x（集群可能不能使用） 下载 elasticsearch_5.6.10 版本注意：一定要用 5.x 的 elasticsearch，否则会出现版本问题！ 解压安装后，进入 config/elasticsearch.yml 文件，修改 network.host 为 0.0.0.0。elasticsearch 不允许 root 用户启动，建立新用户并赋权：12useradd eschown -R es:es /path/to/es 切换到 es 用户，启用 es1./bin/elasticsearch 控制台报错：12[1]: max file descriptors [4096] for elasticsearch process is too low, increase to at least [65536][2]: max virtual memory areas vm.max_map_count [65530] is too low, increase to at least [262144] 修改 /etc/security/limits.conf，增加如下配置：12* soft nofile 819200* hard nofile 819200 修改 /etc/sysctl.conf，增加配置：1vm.max_map_count=655360 重新加载配置：1sysctl -p 后台启动 es： ./bin/elasticsearch -d 查看 es 日志：tail -f logs/elasticsearch.log，正常启动。 浏览器访问 elasticsearch，可见，默认的 cluster name 为 elasticsearch： SkyWalking 目录结构 agent：探针相关 bin：collectorService、webappService 启动脚本，其中 startup.* 是同事启动两个脚本的合并命令 config：Collector 的相关配置信息 log：collector、web 的日志文件 webapp：存放 SkyWalking 展示 UI 的 jar 和配置文件 SkyWalking 的默认端口为：8080、10800、11800、12800 等，如果要修改端口，需要修改 config 目录下的 application.yml、webapp 下的 webapp.yml。 修改 config/application.yml 文件，clusterName 与 elasticsearch 的 cluster name 一致，其余采用默认设置。 启动 SkyWalking启动 SkyWalking：1./bin/startup.sh 访问 SkyWalking： 默认 用户名/密码 为：admin/admin 监控项目创建目录创建四个目录，分别对应：consumer、provider、zuul、eureka-server 四个应用，每个应用使用一个对应的 agent 进行启动，其中 agent 是 SkyWalking 的 agent 目录。 修改 agent.config 文件中 agent.application_code，这项配置代表应用。对应修改为 consumer、provider、zuul、eureka。将 eureka、zuul、consumer、provider 打包为 jar，上传到对应目录中。 修改 es 内存配置elasticsearch 默认 JVM 内存为 2g，如果虚拟机内存过小，无法启动。如果略大于 JVM 内存，启动后无法启动其他组件。所以需要修稿 elasticsearch 的默认 JVM 内存。修改 $ES_HOME/config/jvm.options: 修改后重启 es、SkyWalking 使用 top 命令查看使用内存最高的应用，使用 free 命令，查看内存总用量、剩余内存。 依次启动四个应用启动时需要指定 JVM 内存，防止出现内存不够的情况。-Xms 指定最小内存，-Xmx 指定最大内存 eurekajava -javaagent:/usr/local/src/soft/eureka/agent/skywalking-agent.jar -jar /usr/local/src/soft/eureka/spring-cloud-eureka-server-simple-0.0.1-SNAPSHOT.jar -Xms256m -Xmx256m providerjava -javaagent:/usr/local/src/soft/provider/agent/skywalking-agent.jar -jar /usr/local/src/soft/provider/spring-cloud-apm-skywalking-provider-0.0.1-SNAPSHOT.jar -Xms256m -Xmx256m consumerjava -javaagent:/usr/local/src/soft/consumer/agent/skywalking-agent.jar -jar /usr/local/src/soft/consumer/spring-cloud-apm-skywalking-consumer-0.0.1-SNAPSHOT.jar -Xms256m -Xmx256m zuuljava -javaagent:/usr/local/src/soft/zuul/agent/skywalking-agent.jar -jar /usr/local/src/soft/zuul/spring-cloud-apm-skywalking-zuul-0.0.1-SNAPSHOT.jar -Xms256m -Xmx256m 确认启动成功使用 jps 命令查看启动进程： 查看剩余内存是否满足正常运行： 验证 SkyWalking启动成功后访问eureka： http://192.168.67.135:8761/ 访问 SkyWalking： 可见 4 个 app 都启动成功了。使用 zuul 访问 consumer，调用 provider： 再次查看 SkyWalking： 在 service 选项卡中可以看到每个 service 的具体调用情况]]></content>
      <categories>
        <category>spring-cloud</category>
      </categories>
      <tags>
        <tag>SpringCloud</tag>
        <tag>APM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring Cloud 微服务（32） --- APM(一) Sleuth]]></title>
    <url>%2Fspring-cloud%2Fspring-cloud-32.html</url>
    <content type="text"><![CDATA[在微服务架构下，服务按照不同的纬度进行拆分，一次请求可能会涉及到多个服务，并且有可能是由不同的团队开发，可能使用不同的编程语言实现，有可能部署在几百台、几千台服务器上，横跨多个不同的数据中心。因此，需要一些可以帮助理解系统行为、分析性能问题的工具，以便在发生故障时，快速定位、解决问题。此类工具称为 APM APM最出名的 APM 是谷歌公开的论文中提到的 Dapper。Dapper 对分布式跟踪系统提出了如下需求： 性能低损耗：分布式跟踪系统对服务的性能损耗应尽可能做到可以忽略不计，尤其是对性能敏感的应用不能产生损耗。 对应用透明：尽可能使用非侵入的方式实现跟踪，尽可能做到业务代码的低侵入，对业务开发人员做到透明化。 可伸缩性：是指不能随着微服务和集群规模的扩大而使用分布式跟踪系统瘫痪。 跟踪数据可视化、迅速反馈：要有可视化的监控界面，从跟踪数据收集、处理、到结果的展现，尽量做到快速，这样可以对系统的异常状况作出快速反应。 持续监控：要求分布式跟踪系统必须是 7X24 小时工作，否则很难定位到系统偶尔抖动的行为。 在 APM 中的一些术语 Span：基本工作单元。如：发送一次 RPC 请求，就是一个新的 Span。Span 通过一个 64 位的 ID 标识，还包含有描述、事件时间戳、标签、调用它的 Span 的 ID、处理器 ID（一般为 ip 地址）。注意：第一个 Span 是 root Span，它的 ID 和 Trace 的 ID 一样 Trace：一系列 Span 组成的树状结构，简单的说就是一次调用请求 Annotation：标注，用来描述事件的实时状态。有如下状态 cs：Client Sent。客户端发起请求，表示一个 Span 开始sr：Server Received。服务方接收到请求，并开始处理，其值减去 cs 时间，就是网络延迟时间ss：Server Sent。表示请求处理完成，将响应数据返回给客户端。其值减去 sr 时间，就是服务方处理时间cr：Client Received。客户端接收到服务方的返回值，是当前 Span 结束的信号。其值减去 cs，就是一次请求的完整处理时间。 SleuthSleuth 是 SpringCloud 的分布式跟踪系统，通过 Trace 定义一次业务调用链，根据它的信息，我们能知道有多少系统参与了该业务处理。而系统间的调用顺序、时间戳信息，通过 Span 记录。Trace 和 Span 整合，就能知道该业务的完整调用链。 一个简单的 Sleuth源码：https://gitee.com/laiyy0728/spring-cloud/tree/master/spring-cloud-apm/spring-cloud-apm-sleuth 通用 pom1234567891011&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-sleuth&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-openfeign&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; Provider12345server: port: 8082spring: application: name: spring-cloud-apm-sleuth-provider 12345678910111213141516171819@SpringBootApplication@RestControllerpublic class SpringCloudApmSleuthProviderApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(SpringCloudApmSleuthProviderApplication.class, args); &#125; private static final Logger LOGGER = LoggerFactory.getLogger(SpringCloudApmSleuthProviderApplication.class); @GetMapping(value = "/say") public String hello(String name)&#123; LOGGER.info("&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; 接收到参数：&#123;&#125;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;", name); String result = "你好啊~" + name; LOGGER.info("&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; 返回值：&#123;&#125; &lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;", result); return result; &#125;&#125; Consumer12345server: port: 8081spring: application: name: spring-cloud-apm-aleuth-consumer Feign1234567@FeignClient(name = "spring-cloud-apm-sleuth-provider", url = "localhost:8082")public interface HelloService &#123; @RequestMapping(value = "/say") String sayHello(@RequestParam("name") String name);&#125; configuration12345678910111213141516171819202122@Configurationpublic class ConsumerConfiguration &#123; private final BeanFactory beanFactory; @Autowired public ConsumerConfiguration(BeanFactory beanFactory) &#123; this.beanFactory = beanFactory; &#125; @Bean public RestTemplate restTemplate()&#123; return new RestTemplate(); &#125; @Bean public ExecutorService executorService()&#123; ExecutorService executorService = Executors.newFixedThreadPool(2); return new TraceableExecutorService(this.beanFactory, executorService); &#125;&#125; Controller1234567891011121314151617181920212223242526272829303132333435363738394041424344454647@RestControllerpublic class ConsumerController &#123; private static final Logger LOGGER = LoggerFactory.getLogger(ConsumerController.class); private final HelloService helloService; private final RestTemplate restTemplate; private final ExecutorService executorService; @Autowired public ConsumerController(HelloService helloService, RestTemplate restTemplate, ExecutorService executorService) &#123; this.helloService = helloService; this.restTemplate = restTemplate; this.executorService = executorService; &#125; @GetMapping(value = "/hello-feign") public String helloByFeign(String name)&#123; LOGGER.info("&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; feign 调用，参数：&#123;&#125; &lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;", name); String result = helloService.sayHello(name); LOGGER.info("&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; feign 调用，结果：&#123;&#125; &lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;", result); return result; &#125; @GetMapping(value = "/hello-rest") public String helloByRest(String name)&#123; LOGGER.info("&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; rest 调用，参数：&#123;&#125; &lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;", name); String url = "http://localhost:8082/say?name=" + name; String result = restTemplate.getForObject(url, String.class); LOGGER.info("&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; rest 调用，结果：&#123;&#125; &lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;", result); return result; &#125; @GetMapping(value = "/hello-thread") public String helloByThread(String name) throws ExecutionException, InterruptedException &#123; LOGGER.info("&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; 线程 调用，参数：&#123;&#125; &lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;", name); String url = "http://localhost:8082/say?name=" + name; Future&lt;String&gt; future = executorService.submit(() -&gt; &#123; LOGGER.info("&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; 进入线程，参数：&#123;&#125; &lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;", name); return restTemplate.getForObject(url, String.class); &#125;); String result = future.get(); LOGGER.info("&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; 线程 调用，结果：&#123;&#125; &lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;", result); return result; &#125;&#125; 启动类123456789@SpringBootApplication@EnableFeignClientspublic class SpringCloudApmSleuthConsumerApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(SpringCloudApmSleuthConsumerApplication.class, args); &#125;&#125; 验证Fegin 访问验证请求 http://localhost:8081/hello-feign?name=张三 ，Consumer 控制台打印信息如下： Privider 打印信息如下： RestTemplate 验证请求 http://localhost:8081/hello-rest?name=张三 ，Consumer 控制台打印信息如下： Privider 打印信息如下： 线程验证请求 http://localhost:8081/hello-thread?name=张三 ，Consumer 控制台打印信息如下： Privider 打印信息如下： Sleuth 拦截器、链路TraceFilterSleuth 通过 TraceFilter 获取 Span 信息。需要注意：如果需要对 Span 信息做自定义修改，需要实现自己的 Filter。实现的 Filter 优先级需要比 TraceFilter 优先级低，否则无法拿到 TraceFilter 处理后的信息。 Consumer12345678910111213141516171819202122@Component@Order(TraceWebServletAutoConfiguration.TRACING_FILTER_ORDER + 1) // 优先级低public class SessionFilter extends GenericFilterBean &#123; private Pattern pattern = Pattern.compile(SleuthWebProperties.DEFAULT_SKIP_PATTERN); @Override public void doFilter(ServletRequest request, ServletResponse response, FilterChain filterChain) throws IOException, ServletException &#123; if (!(request instanceof HttpServletRequest) || !(response instanceof HttpServletResponse)) &#123; throw new ServletException("只支持 Http 请求"); &#125; HttpServletRequest httpServletRequest = (HttpServletRequest) request; boolean matches = pattern.matcher(httpServletRequest.getRequestURI()).matches(); if (!matches)&#123; // 向链路传入 SessionId，在 Provider 中获取 ExtraFieldPropagation.set("SessionId", httpServletRequest.getSession().getId()); &#125; filterChain.doFilter(request, response); &#125;&#125; Provider1234@GetMapping(value = "/say") public String hello(String name)&#123; return "你好啊！" + name + ", 你的 session id 是：" + ExtraFieldPropagation.get("SessionId"); &#125; BaggageBaggage 是存储在 Span 上下文中的一组 K/V 键值对，和 traceId、spanId 不同，baggage 不是必选项。通过 Baggage 可以把一些信息像行李一样，挂在 sleuth 中，由 Sleuth 帮助沿着调用一直向下传递。Baggage 相当于 Sleuth 暴露的一个功能接口，通过它，可以让数据跟着 Sleuth 一直往后接连传递，典型场景是登录信息的传递。 123456server: port: 8081spring: sleuth: baggage-keys: - SessionId # 配置 Baggage 需要传递的参数名称，需要在传递端，接收端都配置。传递端不配置，不能向后传递；接收端不配置，获取不到数据。]]></content>
      <categories>
        <category>spring-cloud</category>
      </categories>
      <tags>
        <tag>SpringCloud</tag>
        <tag>APM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring Cloud 微服务（31） --- Spring Cloud Config(五) 高可用]]></title>
    <url>%2Fspring-cloud%2Fspring-cloud-31.html</url>
    <content type="text"><![CDATA[对于线上的生产环境，通常对其都是有很高的要求，其中，高可用是不可或缺的一部分。必须保证服务是可用的，才能保证系统更好的运行，这是业务稳定的保证。高可用一般分为两种：客户端高可用、服务端高可用 客户端高可用源码：https://gitee.com/laiyy0728/spring-cloud/tree/master/spring-cloud-config/spring-cloud-config-ha/spring-cloud-config-ha-client 客户端高可用 主要解决当前服务端不可用哪个的情况下，客户端依然可用正常启动。从客户端触发，不是增加配置中心的高可用性，而是降低客户端对配置中心的依赖程度，从而提高整个分布式架构的健壮性。 实现配置的自动装配pom.xml123456&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-config-client&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 配置文件解析123456789101112131415161718192021222324252627282930313233343536373839404142434445@Component@ConfigurationProperties(prefix = ConfigSupportProperties.CONFIG_PREFIX)public class ConfigSupportProperties &#123; /** * 加载的配置文件前缀 */ public static final String CONFIG_PREFIX = "spring.cloud.config.backup"; /** * 默认文件名 */ private final String DEFAULT_FILE_NAME = "fallback.properties"; /** * 是否启用 */ private boolean enabled = false; /** * 本地文件地址 */ private String fallbackLocation; public String getFallbackLocation() &#123; return fallbackLocation; &#125; public void setFallbackLocation(String fallbackLocation) &#123; if (!fallbackLocation.contains(".")) &#123; // 如果只指定了文件路径，自动拼接文件名 fallbackLocation = fallbackLocation.endsWith(File.separator) ? fallbackLocation : fallbackLocation + File.separator; fallbackLocation += DEFAULT_FILE_NAME; &#125; this.fallbackLocation = fallbackLocation; &#125; public boolean isEnabled() &#123; return enabled; &#125; public void setEnabled(boolean enabled) &#123; this.enabled = enabled; &#125;&#125; 自动装配实现类123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186@Configuration@EnableConfigurationProperties(ConfigSupportProperties.class)public class ConfigSupportConfiguration implements ApplicationContextInitializer&lt;ConfigurableApplicationContext&gt;, Ordered &#123; private final Logger logger = LoggerFactory.getLogger(getClass()); /** * 重中之重！！！！ * 一定要注意加载顺序！！！ * * bootstrap.yml 加载类：org.springframework.cloud.bootstrap.config.PropertySourceBootstrapConfiguration 的加载顺序是 * HIGHEST_PRECEDENCE+10， * 如果当前配置类再其之前加载，无法找到 bootstrap 配置文件中的信息，继而无法加载到本地 * 所以当前配置类的装配顺序一定要在 PropertySourceBootstrapConfiguration 之后！ */ private final Integer orderNumber = Ordered.HIGHEST_PRECEDENCE + 11; @Autowired(required = false) private List&lt;PropertySourceLocator&gt; propertySourceLocators = Collections.EMPTY_LIST; @Autowired private ConfigSupportProperties configSupportProperties; /** * 初始化操作 */ @Override public void initialize(ConfigurableApplicationContext configurableApplicationContext) &#123; // 判断是否开启 config server 管理配置 if (!isHasCloudConfigLocator(this.propertySourceLocators)) &#123; logger.info("Config server 管理配置未启用"); return; &#125; logger.info("&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; 检查 config Server 配置资源 &lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;"); ConfigurableEnvironment environment = configurableApplicationContext.getEnvironment(); MutablePropertySources propertySources = environment.getPropertySources(); logger.info("&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; 加载 PropertySources 源：" + propertySources.size() + " 个"); // 判断配置备份功能是否启用 if (!configSupportProperties.isEnabled()) &#123; logger.info("&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; 配置备份未启用，使用：&#123;&#125;.enabled 打开 &lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;", ConfigSupportProperties.CONFIG_PREFIX); return; &#125; if (isCloudConfigLoaded(propertySources)) &#123; // 可以从 spring cloud 中获取配置信息 PropertySource cloudConfigSource = getLoadedCloudPropertySource(propertySources); logger.info("&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; 获取 config service 配置资源 &lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;"); Map&lt;String, Object&gt; backupPropertyMap = makeBackupPropertySource(cloudConfigSource); doBackup(backupPropertyMap, configSupportProperties.getFallbackLocation()); &#125; else &#123; logger.info("&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; 获取 config Server 资源配置失败 &lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;"); // 不能获取配置信息，从本地读取 Properties backupProperty = loadBackupProperty(configSupportProperties.getFallbackLocation()); if (backupProperty != null) &#123; Map backupSourceMap = new HashMap&lt;&gt;(backupProperty); PropertySource backupSource = new MapPropertySource("backupSource", backupSourceMap); propertySources.addFirst(backupSource); &#125; &#125; &#125; @Override public int getOrder() &#123; return orderNumber; &#125; /** * 从本地加载配置 */ private Properties loadBackupProperty(String fallbackLocation) &#123; logger.info("&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; 正在从本地加载！&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;"); PropertiesFactoryBean propertiesFactoryBean = new PropertiesFactoryBean(); Properties properties = new Properties(); try &#123; FileSystemResource fileSystemResource = new FileSystemResource(fallbackLocation); propertiesFactoryBean.setLocation(fileSystemResource); propertiesFactoryBean.afterPropertiesSet(); properties = propertiesFactoryBean.getObject(); if (properties != null)&#123; logger.info("&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; 读取成功！&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;"); &#125; &#125;catch (Exception e)&#123; e.printStackTrace(); return null; &#125; return properties; &#125; /** * 备份配置信息 */ private void doBackup(Map&lt;String, Object&gt; backupPropertyMap, String fallbackLocation) &#123; FileSystemResource fileSystemResource = new FileSystemResource(fallbackLocation); File file = fileSystemResource.getFile(); try &#123; if (!file.exists())&#123; file.createNewFile(); &#125; if (!file.canWrite())&#123; logger.info("&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; 文件无法写入：&#123;&#125; &lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;", fileSystemResource.getPath()); return; &#125; Properties properties = new Properties(); Iterator&lt;String&gt; iterator = backupPropertyMap.keySet().iterator(); while (iterator.hasNext()) &#123; String key = iterator.next(); properties.setProperty(key, String.valueOf(backupPropertyMap.get(key))); &#125; FileOutputStream fileOutputStream = new FileOutputStream(fileSystemResource.getFile()); properties.store(fileOutputStream, "backup cloud config"); &#125;catch (Exception e)&#123; logger.info("&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; 文件操作失败！ &lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;"); e.printStackTrace(); &#125; &#125; /** * 将配置信息转换为 map */ private Map&lt;String, Object&gt; makeBackupPropertySource(PropertySource cloudConfigSource) &#123; Map&lt;String, Object&gt; backupSourceMap = new HashMap&lt;&gt;(); if (cloudConfigSource instanceof CompositePropertySource) &#123; CompositePropertySource propertySource = (CompositePropertySource) cloudConfigSource; for (PropertySource&lt;?&gt; source : propertySource.getPropertySources()) &#123; if (source instanceof MapPropertySource)&#123; MapPropertySource mapPropertySource = (MapPropertySource) source; String[] propertyNames = mapPropertySource.getPropertyNames(); for (String propertyName : propertyNames) &#123; if (!backupSourceMap.containsKey(propertyName)) &#123; backupSourceMap.put(propertyName, mapPropertySource.getProperty(propertyName)); &#125; &#125; &#125; &#125; &#125; return backupSourceMap; &#125; /** * config server 管理配置是否开启 */ private boolean isHasCloudConfigLocator(List&lt;PropertySourceLocator&gt; propertySourceLocators) &#123; for (PropertySourceLocator propertySourceLocator : propertySourceLocators) &#123; if (propertySourceLocator instanceof ConfigServicePropertySourceLocator) &#123; return true; &#125; &#125; return false; &#125; /** * 获取 config service 配置资源 */ private PropertySource getLoadedCloudPropertySource(MutablePropertySources propertySources) &#123; if (!propertySources.contains(PropertySourceBootstrapConfiguration.BOOTSTRAP_PROPERTY_SOURCE_NAME))&#123; return null; &#125; PropertySource&lt;?&gt; propertySource = propertySources.get(PropertySourceBootstrapConfiguration.BOOTSTRAP_PROPERTY_SOURCE_NAME); if (propertySource instanceof CompositePropertySource) &#123; for (PropertySource&lt;?&gt; source : ((CompositePropertySource) propertySource).getPropertySources()) &#123; // 如果配置源是 config service，使用此配置源获取配置信息 // configService 是 bootstrapProperties 加载 spring cloud 的实现：ConfigServiceBootstrapConfiguration if ("configService".equals(source.getName()))&#123; return source; &#125; &#125; &#125; return null; &#125; /** * 判断是否可以从 spring cloud 中获取配置信息 */ private boolean isCloudConfigLoaded(MutablePropertySources propertySources) &#123; return getLoadedCloudPropertySource(propertySources) != null; &#125;&#125; META-INF/spring.factories12org.springframework.cloud.bootstrap.BootstrapConfiguration=\ com.laiyy.gitee.confog.springcloudconfighaclientautoconfig.ConfigSupportConfiguration 客户端实现1234567891011&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-config-client&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.laiyy.gitee.confog&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-config-ha-client-autoconfig&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;/dependency&gt;&lt;/dependencies&gt; bootstrap.yml12345678910spring: cloud: config: label: master uri: http://localhost:9090 name: config-simple profile: dev backup: enabled: true # 自定义配置 -- 是否启用客户端高可用配置 fallbackLocation: D:/cloud # 自动备份的配置文档存放位置 application.yml123456server: port: 9015spring: application: name: spring-cloud-config-ha-client-config 启动类1234567891011121314151617@SpringBootApplication@RestControllerpublic class SpringCloudConfigHaClientConfigApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(SpringCloudConfigHaClientConfigApplication.class, args); &#125; @Value("$&#123;com.laiyy.gitee.config&#125;") private String config; @GetMapping(value = "/config") public String getConfig()&#123; return config; &#125;&#125; config server123456&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-config-server&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 123456789server: port: 9090spring: cloud: config: server: git: uri: https://gitee.com/laiyy0728/config-repo.git search-paths: config-simple 123456789@EnableConfigServer@SpringBootApplicationpublic class SpringCloudConfigHaClientConfigServerApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(SpringCloudConfigHaClientConfigServerApplication.class, args); &#125;&#125; 验证先后启动 config-server、config-client，查看config-client控制台输出：1234567Fetching config from server at : http://localhost:9090Located environment: name=config-simple, profiles=[dev], label=master, version=ee39bf20c492b27c2d1b1d0ff378ad721e79a758, state=nullLocated property source: CompositePropertySource &#123;name=&apos;configService&apos;, propertySources=[MapPropertySource &#123;name=&apos;configClient&apos;&#125;, MapPropertySource &#123;name=&apos;https://gitee.com/laiyy0728/config-repo.git/config-simple/config-simple-dev.yml&apos;&#125;]&#125;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; 检查 config Server 配置资源 &lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; 加载 PropertySources 源：11 个&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; 获取 config service 配置资源 &lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;No active profile set, falling back to default profiles: default 查看 d:/cloud，可见存在 fallback.properties 文件，打开文件，可见配置信息如下：1234#backup cloud config#Wed Apr 10 14:49:36 CST 2019config.client.version=ee39bf20c492b27c2d1b1d0ff378ad721e79a758com.laiyy.gitee.config=dev \u73AF\u5883\uFF0Cgit \u7248 spring cloud config-----\! 访问 http://localhost:9015/config ，可见打印信息如下： 停止 server、client，删除 d:/cloud/fallback.properties，将 ConfigSupportConfiguration 的 orderNumber 改为 Ordered.HIGHEST_PRECEDENCE + 9，再次先后启动 config-server、config-client，查看控制 client 控制台输出如下：1234&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; 检查 config Server 配置资源 &lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; 加载 PropertySources 源：10 个&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; 获取 config Server 资源配置失败 &lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;Fetching config from server at : http://localhost:9090 可见，PropertySources 源从原来的 11 个，变为 10 个。原因是 bootstrap.yml 的加载顺序问题。在源码：org.springframework.cloud.bootstrap.config.PropertySourceBootstrapConfiguration 中，其加载顺序为：Ordered.HIGHEST_PRECEDENCE + 10，而 ConfigSupportConfiguration 的加载顺序为 Ordered.HIGHEST_PRECEDENCE + 9，先于 bootstrap.yml 配置文件加载执行，所以无法获取到远程配置信息，继而无法备份配置信息。 重新进行第一步验证，然后将 config-server、config-client 停掉后，只启动 config-client，可见其控制台打印信息如下：12345&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; 检查 config Server 配置资源 &lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; 加载 PropertySources 源：10 个&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; 获取 config Server 资源配置失败 &lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; 正在从本地加载！&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; 读取成功！&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt; 访问 http://localhost:9015/config 正常返回信息。 由此验证客户端高可用成功 服务端高可用服务端高可用，一般情况下是通过与注册中心结合实现。通过 Ribbon 的负载均衡选择 Config Server 进行连接，来获取配置信息。 源码：https://gitee.com/laiyy0728/spring-cloud/tree/master/spring-cloud-config/spring-cloud-config-ha/spring-cloud-config-ha-server eureka 选择使用 spring-cloud-eureka-server-simple config server1234567891011&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-config-server&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 123456789101112131415spring: cloud: config: server: git: uri: https://gitee.com/laiyy0728/config-repo.git search-paths: config-simple application: name: spring-cloud-config-ha-server-appserver: port: 9090eureka: client: service-url: defaultZone: http://localhost:8761/eureka/ 12345678910@SpringBootApplication@EnableConfigServer@EnableDiscoveryClientpublic class SpringCloudConfigHaServerConfigApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(SpringCloudConfigHaServerConfigApplication.class, args); &#125;&#125; config client1234567891011&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-config-client&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; application.yml123456server: port: 9016spring: application: name: spring-cloud-config-ha-server-client bootstrap.yml12345678910111213spring: cloud: config: label: master name: config-simple profile: dev discovery: enabled: true # 是否从注册中心获取 config server service-id: spring-cloud-config-ha-server-app # 注册中心 config server 的 serviceIdeureka: client: service-url: defauleZone: http://localhost:8761/eureka/ 1234567891011121314151617@SpringBootApplication@RestControllerpublic class SpringCloudConfigHaServerClientApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(SpringCloudConfigHaServerClientApplication.class, args); &#125; @Value("$&#123;com.laiyy.gitee.config&#125;") private String config; @GetMapping(value = "/config") public String getConfig()&#123; return config; &#125;&#125; 启用验证：访问 http://localhost:9016/config ,返回值如下：]]></content>
      <categories>
        <category>spring-cloud</category>
      </categories>
      <tags>
        <tag>SpringCloud</tag>
        <tag>CloudConfig</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring Cloud 微服务（30） --- Spring Cloud Config(四) Spring Cloud 配置、高可用]]></title>
    <url>%2Fspring-cloud%2Fspring-cloud-30.html</url>
    <content type="text"><![CDATA[本地参数覆盖远程参数123456spring: cloud: config: allow-override: true override-none: true override-system-properties: false allow-override：标识 override-system-properties 是否启用，默认为 true，设置为 false 时，意味着禁用用户的设置 override-none：当此项为 true，override-override 为 true，外部的配置优先级更低，而且不能覆盖任何存在的属性源。默认为 false override-system-properties：用来标识外部配置是否能够覆盖系统配置，默认为 true 1234567891011@ConfigurationProperties("spring.cloud.config")public class PropertySourceBootstrapProperties &#123; private boolean overrideSystemProperties = true; private boolean allowOverride = true; private boolean overrideNone = false; public PropertySourceBootstrapProperties() &#123; &#125; // 省略 getter、setter&#125; 客户端功能扩展客户端自动刷新源码：https://gitee.com/laiyy0728/spring-cloud/tree/master/spring-cloud-config/spring-cloud-autoconfig 在有些应用上，不需要再服务端批量推送的时候，客户端本身需要获取变化参数的情况下，使用客户端的自动刷新能完成此功能。 config server 依然采用 spring-cloud-config-simple-server，基础配置不变，配置文件 repo 依然是 https://gitee.com/laiyy0728/config-repo 配置拉取、刷新二方库新建一个二方库（spring-cloud-autoconfig-refresh），用于其他项目引入，以自动刷新配置（用于多个子项目使用同一个配置中心，自动刷新） 1234567891011&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-config-client&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-autoconfigure&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 整个二方库只有这一个类，作用是获取定时刷新时间，并刷新配置1234567891011121314151617181920212223242526272829303132333435@Configuration@ConditionalOnClass(RefreshEndpoint.class)@ConditionalOnProperty("spring.cloud.config.refreshInterval")@AutoConfigureAfter(RefreshAutoConfiguration.class)@EnableSchedulingpublic class SpringCloudAutoconfigRefreshApplication implements SchedulingConfigurer &#123; private static final Logger LOGGER = LoggerFactory.getLogger(SpringCloudAutoconfigRefreshApplication.class); @Autowired public SpringCloudAutoconfigRefreshApplication(RefreshEndpoint refreshEndpoint) &#123; this.refreshEndpoint = refreshEndpoint; &#125; @Value("$&#123;spring.cloud.config.refreshInterval&#125;") private long refreshInterval; private final RefreshEndpoint refreshEndpoint; @Override public void configureTasks(ScheduledTaskRegistrar scheduledTaskRegistrar) &#123; final long interval = getRefreshIntervalilliseconds(); LOGGER.info("&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; 定时刷新延迟 &#123;&#125; 秒启动，每 &#123;&#125; 毫秒刷新一次配置 &lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;", refreshInterval, interval); scheduledTaskRegistrar.addFixedDelayTask(new IntervalTask(refreshEndpoint::refresh, interval, interval)); &#125; /** * 返回毫秒级时间间隔 */ private long getRefreshIntervalilliseconds() &#123; return refreshInterval * 1000; &#125;&#125; /resources/META-INF/spring.factories12org.springframework.boot.autoconfigure.EnableAutoConfiguration=\ com.laiyy.gitee.config.springcloudautoconfigrefresh.SpringCloudAutoconfigRefreshApplication 客户端引入二方库创建客户端项目(spring-cloud-autoconfig-client) 12345678910111213&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-config-client&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- 将配置好的自刷刷新作为二方库引入 --&gt; &lt;dependency&gt; &lt;groupId&gt;com.laiyy.gitee.config&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-autoconfig-refresh&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;/dependency&gt;&lt;/dependencies&gt; bootstrap.yml1234567spring: cloud: config: uri: http://localhost:9090 label: master name: config-simple profile: dev application.yml12345678server: port: 9091spring: application: name: spring-cloud-autoconfig-client cloud: config: refreshInterval: 10 # 延迟时间、定时刷新时间 其余配置与 spring-cloud-config-simple-client 一致 验证启动项目，访问 http://localhost:9090/get-config-info ，正常返回信息。修改 config repo 配置文件，等待 10 秒后，再次访问，可见返回信息已经变为修改后信息。查看 client 控制台，可见定时刷新日志12345678910111213141516Exposing 2 endpoint(s) beneath base path &apos;/actuator&apos;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; 定时刷新延迟 10 秒启动No TaskScheduler/ScheduledExecutorService bean found for scheduled processingTomcat started on port(s): 9091 (http) with context path &apos;&apos;Started SpringCloudAutoconfigClientApplication in 4.361 seconds (JVM running for 5.089)Initializing Spring DispatcherServlet &apos;dispatcherServlet&apos;Initializing Servlet &apos;dispatcherServlet&apos;Fetching config from server at : http://localhost:9090 ------------------ 第一次请求Completed initialization in 7 msLocated environment: name=config-simple, profiles=[dev], label=master, version=00324826262afd5178a648a469247f4fffea945e, state=nullBean &apos;org.springframework.cloud.autoconfigure.ConfigurationPropertiesRebinderAutoConfiguration&apos; of type [org.springframework.cloud.autoconfigure.ConfigurationPropertiesRebinderAutoConfiguration$$EnhancerBySpringCGLIB$$f67277ed] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)Fetching config from server at : http://localhost:9090 ------------------ 定时刷新配置Located environment: name=config-simple, profiles=[dev], label=master, version=00324826262afd5178a648a469247f4fffea945e, state=nullLocated property source: CompositePropertySource &#123;name=&apos;configService&apos;, propertySources=[MapPropertySource &#123;name=&apos;configClient&apos;&#125;, MapPropertySource &#123;name=&apos;https://gitee.com/laiyy0728/config-repo/config-simple/config-simple-dev.yml&apos;&#125;]&#125;... 省略其他多次刷新 客户端回退客户端回退机制，可以在出现网络中断时、或者配置服务因维护而关闭时，使得客户端可以正常使用。当启动回退时，客户端适配器将配置“缓存”到计算机中。要启用回退功能，只需要指定缓存存储的位置即可。 源码：https://gitee.com/laiyy0728/spring-cloud/tree/master/spring-cloud-config/spring-cloud-config-fallback config server 依然采用 spring-cloud-config-simple-server，基础配置不变，配置文件 repo 依然是 https://gitee.com/laiyy0728/config-repo 二方库123456789101112&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-config&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.security&lt;/groupId&gt; &lt;artifactId&gt;spring-security-rsa&lt;/artifactId&gt; &lt;version&gt;1.0.7.RELEASE&lt;/version&gt; &lt;/dependency&gt;&lt;/dependencies&gt; config-client.properties：用于设置是否开启配置1spring.cloud.config.enabled=false /resources/META-INF/spring.factories12org.springframework.cloud.bootstrap.BootstrapConfiguration=\ com.laiyy.gitee.config.springcloudconfigfallbackautorefresh.ConfigServerBootStrap 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192// 用于拉取远程配置文件，并保存到本地@Order(0)public class FallbackableConfigServerPropertySourceLocator extends ConfigServicePropertySourceLocator &#123; private static final Logger LOGGER = LoggerFactory.getLogger(FallbackableConfigServerPropertySourceLocator.class); private boolean fallbackEnabled; private String fallbackLocation; @Autowired(required = false) private TextEncryptor textEncryptor; public FallbackableConfigServerPropertySourceLocator(ConfigClientProperties defaultProperties, String fallbackLocation) &#123; super(defaultProperties); this.fallbackLocation = fallbackLocation; this.fallbackEnabled = !StringUtils.isEmpty(fallbackLocation); &#125; @Override public PropertySource&lt;?&gt; locate(Environment environment)&#123; PropertySource&lt;?&gt; propertySource = super.locate(environment); if (fallbackEnabled &amp;&amp; propertySource != null)&#123; storeLocally(propertySource); &#125; return propertySource; &#125; /** * 转换配置文件 */ private void storeLocally(PropertySource propertySource)&#123; StringBuilder builder = new StringBuilder(); CompositePropertySource source = (CompositePropertySource) propertySource; for (String propertyName : source.getPropertyNames()) &#123; Object property = source.getProperty(propertyName); if (textEncryptor != null)&#123; property = "&#123;cipher&#125;" + textEncryptor.encrypt(String.valueOf(property)); &#125; builder.append(propertyName).append("=").append(property).append("\n"); &#125; LOGGER.info("&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; file content: &#123;&#125; &lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;", builder); saveFile(builder.toString()); &#125; /** * 保存配置到本地 * @param content 配置内容 */ private void saveFile(String content)&#123; File file = new File(fallbackLocation + File.separator + ConfigServerBootStrap.FALLBACK_NAME); try &#123; FileCopyUtils.copy(content.getBytes(), file); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125;&#125;// 用于判断从远程拉取配置文件，还是从本地拉取（spring boot 2.0，spring cloud F版）@Configuration@EnableConfigurationProperties@PropertySource(value = &#123;"config-client.properties","file:&#123;spring.cloud.config.fallback-location:&#125;/fallback.properties"&#125;, ignoreResourceNotFound = true)public class ConfigServerBootStrap &#123; public static final String FALLBACK_NAME = "fallback.properties"; private final ConfigurableEnvironment configurableEnvironment; @Autowired public ConfigServerBootStrap(ConfigurableEnvironment configurableEnvironment) &#123; this.configurableEnvironment = configurableEnvironment; &#125; @Value("$&#123;spring.cloud.config.fallback-location:&#125;") private String fallbackLocation; @Bean public ConfigClientProperties configClientProperties()&#123; ConfigClientProperties configClientProperties = new ConfigClientProperties(this.configurableEnvironment); configClientProperties.setEnabled(false); return configClientProperties; &#125; @Bean public FallbackableConfigServerPropertySourceLocator fallbackableConfigServerPropertySourceLocator()&#123; ConfigClientProperties client = configClientProperties(); return new FallbackableConfigServerPropertySourceLocator(client, fallbackLocation); &#125;&#125; 在 SpringBoot 1.0、Spring Cloud G 版中，会启动报错：123456789101112131415161718***************************APPLICATION FAILED TO START***************************Description:The bean &apos;configClientProperties&apos;, defined in class path resource [com/laiyy/gitee/config/springcloudconfigfallbackautorefresh/ConfigServerBootStrap.class], could not be registered. A bean with that name has already been defined in class path resource [org/springframework/cloud/config/client/ConfigServiceBootstrapConfiguration.class] and overriding is disabled.Action:Consider renaming one of the beans or enabling overriding by setting spring.main.allow-bean-definition-overriding=true2019-03-07 10:10:11.230 ERROR 13828 --- [ main] o.s.boot.SpringApplication : Application run failedorg.springframework.beans.factory.support.BeanDefinitionOverrideException: Invalid bean definition with name &apos;configClientProperties&apos; defined in class path resource [com/laiyy/gitee/config/springcloudconfigfallbackautorefresh/ConfigServerBootStrap.class]: Cannot register bean definition [Root bean: class [null]; scope=; abstract=false; lazyInit=false; autowireMode=3; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=com.laiyy.gitee.config.springcloudconfigfallbackautorefresh.ConfigServerBootStrap; factoryMethodName=configClientProperties; initMethodName=null; destroyMethodName=(inferred); defined in class path resource [com/laiyy/gitee/config/springcloudconfigfallbackautorefresh/ConfigServerBootStrap.class]] for bean &apos;configClientProperties&apos;: There is already [Root bean: class [null]; scope=; abstract=false; lazyInit=false; autowireMode=3; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=org.springframework.cloud.config.client.ConfigServiceBootstrapConfiguration; factoryMethodName=configClientProperties; initMethodName=null; destroyMethodName=(inferred); defined in class path resource [org/springframework/cloud/config/client/ConfigServiceBootstrapConfiguration.class]] bound. at org.springframework.beans.factory.support.DefaultListableBeanFactory.registerBeanDefinition(DefaultListableBeanFactory.java:894) ~[spring-beans-5.1.2.RELEASE.jar:5.1.2.RELEASE] at org.springframework.context.annotation.ConfigurationClassBeanDefinitionReader.loadBeanDefinitionsForBeanMethod(ConfigurationClassBeanDefinitionReader.java:274) ~[spring-context-5.1.2.RELEASE.jar:5.1.2.RELEASE] .... 如果按照报错提示，增加了 spring.main.allow-bean-definition-overriding=true 的配置，没有任何作用；如果修改了 bean 名称123456@Bean(name="clientProperties")public ConfigClientProperties configClientProperties()&#123; ConfigClientProperties configClientProperties = new ConfigClientProperties(this.configurableEnvironment); configClientProperties.setEnabled(false); return configClientProperties;&#125; 会有如下报错：1234567891011121314***************************APPLICATION FAILED TO START***************************Description:Method configClientProperties in org.springframework.cloud.config.client.ConfigClientAutoConfiguration required a single bean, but 2 were found: - configClientProperties: defined by method 'configClientProperties' in class path resource [org/springframework/cloud/config/client/ConfigClientAutoConfiguration.class] - clientProperties: defined by method 'configClientProperties' in class path resource [com/laiyy/gitee/config/springcloudconfigfallbackautorefresh/ConfigServerBootStrap.class]Action:Consider marking one of the beans as @Primary, updating the consumer to accept multiple beans, or using @Qualifier to identify the bean that should be consumed 原因：ConfigClientProperties 在初始化时已经默认单例加载。即：这个 bean 不能被重新注册到 spring 容器中。解决办法：将 spring 容器已经加载的单例的 ConfigClientProperties 注入进来，并在构造中设置为 false 即可123456789101112131415161718192021222324252627@Configuration@EnableConfigurationProperties@PropertySource(value = &#123;"configClient.properties", "file:$&#123;spring.cloud.config.fallbackLocation:&#125;/fallback.properties"&#125;, ignoreResourceNotFound = true)public class ConfigServerBootStrap &#123; public static final String FALLBACK_NAME = "fallback.properties"; private final ConfigurableEnvironment configurableEnvironment; private final ConfigClientProperties configClientProperties; @Autowired public ConfigServerBootStrap(ConfigurableEnvironment configurableEnvironment, ConfigClientProperties configClientProperties) &#123; this.configurableEnvironment = configurableEnvironment; this.configClientProperties = configClientProperties; this.configClientProperties.setEnabled(false); &#125; @Value("$&#123;spring.cloud.config.fallbackLocation:&#125;") private String fallbackLocation; @Bean public FallbackableConfigServerPropertySourceLocator fallbackableConfigServerPropertySourceLocator() &#123; return new FallbackableConfigServerPropertySourceLocator(configClientProperties, fallbackLocation); &#125;&#125; config clientbootstrap.yml12345678spring: cloud: config: uri: http://localhost:9090 label: master name: config-simple profile: dev fallbackLocation: E:\\springcloud application.yml123456789101112131415server: port: 9091spring: application: name: spring-cloud-autoconfig-client main: allow-bean-definition-overriding: truemanagement: endpoints: web: exposure: include: '*' endpoint: health: show-details: always 其余配置、JAVA 类不变 验证启动 config client，查看控制台，可见打印了 2 次远程拉取同步本地文件的信息：123&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; file content: config.client.version=ee39bf20c492b27c2d1b1d0ff378ad721e79a758com.laiyy.gitee.config=dev 环境，git 版 spring cloud config-----! &lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt; 查看本地 E:\springcloud 文件夹，可见多了一个 fallback.properties 文件 文件内容： 更新 config repo 的对应配置文件后，POST 访问 config client 刷新端口：http://localhost:9091/actuator/refresh 可见控制台再次打印同步本地文件信息。此时停止 config server 访问，再次访问 http://localhost:9091/get-config-info ，返回的信息是同步后的更新结果，由此验证客户端回退成功。]]></content>
      <categories>
        <category>spring-cloud</category>
      </categories>
      <tags>
        <tag>SpringCloud</tag>
        <tag>CloudConfig</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring Cloud 微服务（29） --- Spring Cloud Config(三) git 版 coofnig 配置、使用数据库实现配置中心]]></title>
    <url>%2Fspring-cloud%2Fspring-cloud-29.html</url>
    <content type="text"><![CDATA[除了使用 git 作为配置文件的管理中心外，也可以使用关系型数据库、非关系型数据库实现配置中心，以及配置中心的扩展。包括：客户端自动刷新、客户端回退、安全认证、客户端高可用、服务端高可用等。 服务端 git 配置详解git 的版 config 有多种配置： uri 占位符 模式匹配 多残酷 路径搜索占位符 源码：https://gitee.com/laiyy0728/spring-cloud/tree/master/spring-cloud-config/spring-cloud-placeholder 公共依赖123456&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; git 中 uri 占位符Spring Cloud Config Server 支持占位符的使用，支持 {application}、{profile}、{label}，这样的话就可以在配置 uri 的时候，通过占位符使用应用名称来区分应用对应的仓库进行使用。 config server 1234567891011spring: cloud: config: server: git: uri: https://gitee.com/laiyy0728/&#123;application&#125; # &#123;application&#125; 是匹配符，匹配项目名称 search-paths: config-simple application: name: spring-cloud-placeholder-serverserver: port: 9090 config client bootstrap.yml1234567spring: cloud: config: label: master uri: http://localhost:9090 name: config-repo profile: dev 使用 {application} 时，需要注意，在 config client 中配置的 name，既是 config 管理中心的 git 名称，又是需要匹配的配置文件名称。即：远程的 config git 管理中心地址为：https://gitee.com/laiyy0728/config-repo ，在仓库中 config-simple 文件夹下，必须有一个 config-simple.yml 配置文件。否则 config client 会找不到配置文件。 模式匹配、多存储库config server1234567891011121314151617181920spring: profiles: active: native # 本地配置仓库，在测试本地配置仓库之前，需要注释掉这一行 cloud: config: server: git: uri: https://gitee.com/laiyy0728/config-repo search-paths: config-simple repos: simple: https://gitee.com/laiyy0728/simple special: pattern: special*/dev*,*special*/dev* uri: https://gitee.com/laiyy0728/special native: search-locations: C:/Users/laiyy/AppData/Local/Temp/config-simple # 本地配置仓库路径 application: name: spring-cloud-placeholder-serverserver: port: 9090 路径搜索占位符1234567891011spring: cloud: config: server: git: uri: https://gitee.com/laiyy0728/config-repo search-paths: config-* # 匹配以 config 开头的文件夹 application: name: spring-cloud-placeholder-serverserver: port: 9090 关系型数据库实现配置中心架构图： 公共依赖123456&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; mysql config server12345678910111213141516&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-config-server&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-jdbc&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 12345678910111213141516171819202122server: port: 9090spring: application: name: spring-cloud-customer-repo-mysql cloud: config: server: jdbc: sql: SELECT `KEY`, `VALUE` FROM PROPERTIES WHERE application = ? NAD profile = ? AND label = ? label: master profiles: active: jdbc datasource: url: jdbc:mysql:///springcloud?useUnicode=true&amp;charsetEncoding=UTF-8 username: root password: 123456 driver-class-name: com.mysql.cj.jdbc.Driverlogging: level: org.springframework.jdbc.core: debug org.springframework.jdbc.core.StatementCreatorUtils: Trace 其余配置、config client 与之前一致即可。 验证启动 config server、config client，可以看到，config server 打印日志如下：123456789101112131415161718192021222324...Executing prepared SQL queryExecuting prepared SQL statement [SELECT `KEY`, `VALUE` FROM PROPERTIES WHERE application = ? AND profile = ? AND lable = ?]Setting SQL statement parameter value: column index 1, parameter value [config-simple], value class [java.lang.String], SQL type unknownSetting SQL statement parameter value: column index 2, parameter value [dev], value class [java.lang.String], SQL type unknownSetting SQL statement parameter value: column index 3, parameter value [master], value class [java.lang.String], SQL type unknownExecuting prepared SQL queryExecuting prepared SQL statement [SELECT `KEY`, `VALUE` FROM PROPERTIES WHERE application = ? AND profile = ? AND lable = ?]Setting SQL statement parameter value: column index 1, parameter value [config-simple], value class [java.lang.String], SQL type unknownSetting SQL statement parameter value: column index 2, parameter value [default], value class [java.lang.String], SQL type unknownSetting SQL statement parameter value: column index 3, parameter value [master], value class [java.lang.String], SQL type unknownExecuting prepared SQL queryExecuting prepared SQL statement [SELECT `KEY`, `VALUE` FROM PROPERTIES WHERE application = ? AND profile = ? AND lable = ?]Setting SQL statement parameter value: column index 1, parameter value [application], value class [java.lang.String], SQL type unknownSetting SQL statement parameter value: column index 2, parameter value [dev], value class [java.lang.String], SQL type unknownSetting SQL statement parameter value: column index 3, parameter value [master], value class [java.lang.String], SQL type unknownExecuting prepared SQL queryExecuting prepared SQL statement [SELECT `KEY`, `VALUE` FROM PROPERTIES WHERE application = ? AND profile = ? AND lable = ?]Setting SQL statement parameter value: column index 1, parameter value [application], value class [java.lang.String], SQL type unknownSetting SQL statement parameter value: column index 2, parameter value [default], value class [java.lang.String], SQL type unknownSetting SQL statement parameter value: column index 3, parameter value [master], value class [java.lang.String], SQL type unknown... 访问 http://localhost:9091/get-config-info ，返回数据如下： 非关系数据库实现配置中心以 mongodb 为例，需要 spring cloud config server mongodb 依赖，github 地址：https://github.com/spring-cloud-incubator/spring-cloud-config-server-mongodb config server monngodb12345678910111213&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-config-server&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- mongogdb 在 spring cloud config server 的依赖，这个依赖是快照依赖，需要指定 spring 的仓库 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-config-server-mongodb&lt;/artifactId&gt; &lt;version&gt;0.0.3.BUILD-SNAPSHOT&lt;/version&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 12345678server: port: 9090spring: application: name: spring-cloud-customer-repo-mongodb data: mongodb: uri: mongodb://192.168.67.133/springcloud # mongo 数据库地址 123456789@SpringBootApplication@EnableMongoConfigServer // 一定注意，不能写为 EnableConfigServer，一定要是 MongooConfigServerpublic class SpringCloudCustomerRepoMongodbApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(SpringCloudCustomerRepoMongodbApplication.class, args); &#125;&#125; mongo 测试数据collection 名称：springcloud 数据：12345678910111213&#123; "label": "master", "profile": "prod", "source": &#123; "com": &#123; "laiyy": &#123; "gitee": &#123; "config": "I am the mongdb configuration file from dev environment. I will edit." &#125; &#125; &#125; &#125;&#125; config client1234567spring: cloud: config: label: master uri: http://localhost:9090 name: springcloud # 这里指定的是 collection name profile: prod 验证config client 与之前的一致 访问 http://localhost:9091/get-config-info ，返回值为：]]></content>
      <categories>
        <category>spring-cloud</category>
      </categories>
      <tags>
        <tag>SpringCloud</tag>
        <tag>CloudConfig</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring Cloud 微服务（28） --- Spring Cloud Config(二) 刷新配置]]></title>
    <url>%2Fspring-cloud%2Fspring-cloud-28.html</url>
    <content type="text"><![CDATA[刷新配置信息的方式有三种：手动刷新、半自动刷新、自动刷新，其中，半自动刷新利用的是 spring cloud bus，自动刷新利用的是 github、gitee、gitlab 等代码托管网站的 webhooks 手动刷新源码：https://gitee.com/laiyy0728/spring-cloud/tree/master/spring-cloud-config/spring-cloud-config-refresh 手动刷新的 config server 依然选用示例中的 spring-cloud-config-simple-server config client1234567891011&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-config-client&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-security&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; bootstrap.yml1234567spring: cloud: config: label: master uri: http://localhost:9090 name: config-simple profile: dev application.yml12345678910111213spring: application: name: spring-cloud-config-refresh-clientserver: port: 9091management: endpoints: web: exposure: include: '*' # 暴露端点，用于手动刷新 endpoint: health: show-details: always 改造 config properties、config controller123456789101112131415161718192021222324252627282930313233@Component@RefreshScope // 标注为配置刷新域public class ConfigInfoProperties &#123; @Value("$&#123;com.laiyy.gitee.config&#125;") private String config; public String getConfig() &#123; return config; &#125; public void setConfig(String config) &#123; this.config = config; &#125;&#125;@RestController@RefreshScope // 标注为配置刷新域public class ConfigController &#123; private final ConfigInfoProperties configInfoProperties; @Autowired public ConfigController(ConfigInfoProperties configInfoProperties) &#123; this.configInfoProperties = configInfoProperties; &#125; @GetMapping(value = "/get-config-info") public String getConfigInfo()&#123; return configInfoProperties.getConfig(); &#125;&#125; 验证访问 http://localhost:9091/get-config-info ，观察返回值为：1dev 环境，git 版 spring cloud config 修改 https://gitee.com/laiyy0728/config-repo/blob/master/config-simple/config-simple-dev.yml 的内容为：1234com: laiyy: gitee: config: dev 环境，git 版 spring cloud config，使用手动刷新。。。 再次访问 http://localhost:9091/get-config-info ，观察返回值仍为：1dev 环境，git 版 spring cloud config 这是因为没有进行手动刷新，POST 访问：http://localhost:9091/actuator/refresh ，返回信息如下：1234[ "config.client.version", "com.laiyy.gitee.config"] 控制台输出如下：123Fetching config from server at : http://localhost:9090Located environment: name=config-simple, profiles=[dev], label=master, version=a04663a171b0d8f552c3d549ad38401bd6873b95, state=nullLocated property source: CompositePropertySource &#123;name=&apos;configService&apos;, propertySources=[MapPropertySource &#123;name=&apos;configClient&apos;&#125;, MapPropertySource &#123;name=&apos;https://gitee.com/laiyy0728/config-repo/config-simple/config-simple-dev.yml&apos;&#125;]&#125; 此时，再次访问 http://localhost:9091/get-config-info ，观察返回值变为：1dev 环境，git 版 spring cloud config，使用手动刷新。。。 由此证明，手动刷新成功 半自动刷新源码：https://gitee.com/laiyy0728/spring-cloud/tree/master/spring-cloud-config/spring-cloud-config-bus 半自动刷新依赖于 Spring Cloud Bus 总线，而 Bus 总线依赖于 RabbitMQ。 Spring Cloud Bus 刷新配置的流程图： Rabbit MQ 请自行安装启动，在此不做描述 config server bus1234567891011121314151617181920212223242526&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-config-server&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-config-monitor&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-security&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-bus-amqp&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 123456789101112131415161718192021222324252627spring: cloud: config: server: git: uri: https://gitee.com/laiyy0728/config-repo.git search-paths: config-simple bus: trace: enabled: true # 是否启用bus追踪 application: name: spring-cloud-config-bus-server rabbitmq: # rabbit mq 配置 host: 192.168.67.133 port: 5672 username: guest password: guestserver: port: 9090management: endpoints: web: exposure: include: '*' endpoint: health: show-details: always 12345678910111213141516171819@Configurationpublic class SecurityConfig extends WebSecurityConfigurerAdapter &#123; @Override protected void configure(HttpSecurity http) throws Exception &#123; http.csrf().disable(); &#125;&#125;@SpringBootApplication@EnableConfigServerpublic class SpringCloudConfigBusServerApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(SpringCloudConfigBusServerApplication.class, args); &#125;&#125; config client bus123456789101112131415161718192021&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-bus-amqp&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-config-client&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-security&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; bootstrap.yml1234567spring: cloud: config: label: master uri: http://localhost:9090 name: config-simple profile: test application.yml123456789101112131415161718192021222324252627spring: cloud: config: server: git: uri: https://gitee.com/laiyy0728/config-repo.git search-paths: config-simple bus: trace: enabled: true # \u662F\u5426\u542F\u7528bus\u8FFD\u8E2A application: name: spring-cloud-config-bus-server rabbitmq: # rabbit mq \u914D\u7F6E host: 192.168.67.133 port: 5672 username: guest password: guestserver: port: 9090management: endpoints: web: exposure: include: '*' endpoint: health: show-details: always 其余 Java 类与手动刷新一致。 验证访问 http://localhost:9095/get-config-info 将 config-simple/config-simple-test.yml 内容修改为1234com: laiyy: gitee: config: test 环境，git 版 spring cloud config，bus 半自动刷新配置 再次访问 http://localhost:9095/get-config-info ，返回值仍为：1test 环境，git 版 spring cloud config 使用 bus 刷新配置，POST 请求 http://localhost:9095/actuator/bus-refresh ，查看控制台输出：1234567Bean &apos;org.springframework.cloud.autoconfigure.ConfigurationPropertiesRebinderAutoConfiguration&apos; of type [org.springframework.cloud.autoconfigure.ConfigurationPropertiesRebinderAutoConfiguration$$EnhancerBySpringCGLIB$$7c355e31] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)Fetching config from server at : http://localhost:9090Located environment: name=config-simple, profiles=[test], label=master, version=45c17b3b2a7918ed7093251f2085641df446e961, state=nullLocated property source: CompositePropertySource &#123;name=&apos;configService&apos;, propertySources=[MapPropertySource &#123;name=&apos;configClient&apos;&#125;, MapPropertySource &#123;name=&apos;https://gitee.com/laiyy0728/config-repo.git/config-simple/config-simple-test.yml&apos;&#125;]&#125;No active profile set, falling back to default profiles: defaultStarted application in 1.108 seconds (JVM running for 264.482)Received remote refresh request. Keys refreshed [] 再次访问 http://localhost:9095/get-config-info ，返回值变为：1test 环境，git 版 spring cloud config，bus 半自动刷新配置 refresh、bus-refresh 比较 refresh：只能刷新单节点，即：只能刷新指定 ip 的配置信息 bus-refresh：批量刷新，可以刷新订阅了 rabbit queue 的所有节点配置 自动刷新自动刷新实际上很简单，只需要暴露一个 bus-refresh 节点，并在 config-server 的 git 中，配置 webhook 指向暴露出来的 bus-refresh 节点即可，多个 bus-refresh 节点用英文逗号分隔]]></content>
      <categories>
        <category>spring-cloud</category>
      </categories>
      <tags>
        <tag>SpringCloud</tag>
        <tag>CloudConfig</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring Cloud 微服务（27） --- Spring Cloud Config(一) 配置中心、实例]]></title>
    <url>%2Fspring-cloud%2Fspring-cloud-27.html</url>
    <content type="text"><![CDATA[Spring Cloud Config 是 Spring Cloud 微服务体系中的配置中心，是微服务中不可或缺的一部分，其能够很好的将程序中配置日益增多的各种功能的开关、参数的配置、服务器的地址等配置修改后实时生效、灰度发布，分环境、分集群管理配置等进行全面的集中化管理，有利于系统的配置管理、维护。 Spring Cloud Config 配置中心配置中心对比 对比方面 重要性 SpringCloud Config Netflix archaius 携程 Apollo disconf 静态配置管理 高 基于 file 无 支持 支持 动态配置管理 高 支持 支持 支持 支持 统一管理 高 无，需要 git、数据库等 无 支持 支持 多维度管理 中 无，需要 git、数据库等 无 支持 支持 变更管理 高 无，需要 git、数据库等 无 无 无 本地配置缓存 高 无 无 支持 支持 配置更新策略 中 无 无 无 无 配置锁 中 支持 不支持 不支持 不支持 配置校验 中 无 无 无 无 配置生效时间 高 重启生效、手动刷新 手动刷新失效 实时 实时 配置更新推送 高 需要手动触发 需要手动触发 支持 支持 配置定时拉取 高 无 无 支持 配置更新目前依赖事件驱动，client 重启或者 server 推送操作 用户权限管理 中 无，需要 git、数据库等 无 支持 支持 授权、审核、审计 中 无，需要 git、数据库等 无 界面直接提供发布历史、回滚按钮 操作记录存在数据库中，但是无查询接口 配置版本管理 高 git 无 支持 操作记录存在数据库中，但是无查询接口 配置合规检测 高 不支持 不支持 支持（不完整） 实例配置监控 高 需要结合 spring admin 不支持 支持 支持，可以查看每个配置再哪台机器上加载 灰度发布 中 不支持 不支持 支持 不支持部分更新 告警通知 中 不支持 不支持 支持邮件方式告警 支持邮件方式告警 统计报表 中 不支持 不支持 不支持 不支持 依赖关系 高 不支持 不支持 不支持 不支持 支持 SpringBoot 高 原生支持 低 支持 与 SpringBoot 无关 支持 Spring Config 高 原生支持 低 支持 与 SpringBoot 无关 客户端支持 低 java java java、.net java 业务系统入侵 高 入侵性弱 入侵性弱 入侵性弱 入侵性弱、支持注解和 xml 单点故障 高 支持 HA 部署 支持 HA 部署 支持 HA 部署 支持 HA 部署、高可用由 zk 提供 多数据中心部署 高 支持 支持 支持 支持 配置界面 中 无，需要 git、数据库等 无 统一界面 统一界面 配置中心具备的功能 Open API 业务无关性 配置生效监控 一致性 K-V 存储 统一配置实时推送 配合灰度与更新 配置全局恢复、备份、历史 高可用集群 配置中心流转配置中心各流程流转如图： 配置中心支撑体系配置中心的支撑体系大致有两类 开发管理体系 运维管理体系 Spring Cloud ConfigSpring Cloud Config 概述Spring Cloud Config 是一个集中化、外部配置的分布式系统，由服务端、客户端组成，它不依赖于注册中心，是一个独立的配置中心。Spring Cloud Config 支持多种存储配置信息的形式，目前主要有 jdbc、vault、Navicat、svn、git 等形式，默认为 git。 git 版工作原理配置客户端启动时，会向服务端发起请求，服务端接收到客户端的请求后，根据配置的仓库地址，将 git 上的文件克隆到本地的一个临时目录中，这个目录是一个 git 的本地仓库，然后服务端再读取本地文件，返回给客户端。这样做的好处是：当 git 服务故障或网络请求异常时，保证服务端依然能正常工作。 入门案例config repo使用 git 做配置中心的配置文件存储，需要一个 git 仓库，用于保存配置文件。 本例仓库地址： https://gitee.com/laiyy0728/config-repo 在仓库中，新建一个文件夹：config-simple，在文件夹内新建 3 个文件：config-simple-dev.yml、config-simple-test.yml、config-simple-prod.yml 源码：https://gitee.com/laiyy0728/spring-cloud/tree/master/spring-cloud-config/spring-cloud-config-simple config server12345678910&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-config-server&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 1234567891011spring: cloud: config: server: git: uri: https://gitee.com/laiyy0728/config-repo # git 仓库地址 search-paths: config-simple # 从哪个文件夹下拉取配置 application: name: spring-cloud-config-simple-serverserver: port: 9090 1234567@SpringBootApplication@EnableConfigServerpublic class SpringCloudConfigSimpleServerApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(SpringCloudConfigSimpleServerApplication.class, args); &#125;&#125; 验证 config server启动 config server，查看 endpoints mappings label：代表请求的是哪个分支，默认是 master 分支 name：代表请求哪个名称的远程文件 profile：代表哪个版本的文件，如：dev、test、prod 等 从 mappings 中，可以看出，访问获取一个配置的信息，有多种方式，尝试获取 /config-simple/config-simple.dev.yml 配置信息： 由接口获取配置详细信息http://localhost:9090/config-simple/dev/master 、http://localhost:9090/config-simple/dev123456789101112131415&#123; "name": "config-simple", "profiles": [ "dev" ], "label": "master", "version": "520b379e9c7f2e39bb56e599f914b6c08fe13c06", "state": null, "propertySources": [&#123; "name": "https://gitee.com/laiyy0728/config-repo/config-simple/config-simple-dev.yml", "source": &#123; "com.laiyy.gitee.config": "dev 环境，git 版 spring cloud config" &#125; &#125;]&#125; 由绝对文件路径获取配置文件内容http://localhost:9090/master/config-simple-dev.yml 、http://localhost:9090/config-simple-dev.yml1234com: laiyy: gitee: config: dev 环境，git 版 spring cloud config config client在 config server 中获取配置文件以及成功，接下来需要在 config client 中，通过 config server 获取对应的配置文件 123456&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-config-client&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; application.yml1234567891011spring: cloud: config: label: master uri: http://localhost:9090 name: config-simple profile: dev application: name: spring-cloud-config-simple-clientserver: port: 9091 1234567891011121314151617181920212223242526272829303132333435363738394041424344// 用于从远程 config server 获取配置文件内容@Component@ConfigurationProperties(prefix = "com.laiyy.gitee")public class ConfigInfoProperties &#123; private String config; public String getConfig() &#123; return config; &#125; public void setConfig(String config) &#123; this.config = config; &#125;&#125;// 用于打印获取到的配置文件内容@RestControllerpublic class ConfigController &#123; private final ConfigInfoProperties configInfoProperties; @Autowired public ConfigController(ConfigInfoProperties configInfoProperties) &#123; this.configInfoProperties = configInfoProperties; &#125; @GetMapping(value = "/get-config-info") public String getConfigInfo()&#123; return configInfoProperties.getConfig(); &#125;&#125;// 启动类@SpringBootApplicationpublic class SpringCloudConfigSimpleClientApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(SpringCloudConfigSimpleClientApplication.class, args); &#125;&#125; 验证 config client启动 config client，观察控制台，发现 config client 拉取配置的路径是：http://localhost:8888 ，而不是在 yml 中配置的 localhost:9090。这是因为 boot 启动时加载配置文件的顺序导致的。boot 默认先加载 bootstrap.yml 配置，再加载 application.yml 配置。所以需要将 config server 配置移到 bootstrap.yml 中 bootstrap.yml1234567spring: cloud: config: label: master # 代表请求 git 哪个分支，默认 master uri: http://localhost:9090 # config server 地址 name: config-simple # 获取哪个名称的远程文件，可以有多个，英文逗号隔开 profile: dev # 代表哪个分支 application.yml12345spring: application: name: spring-cloud-config-simple-clientserver: port: 9091 访问 http://localhost:9091/get-config-info]]></content>
      <categories>
        <category>spring-cloud</category>
      </categories>
      <tags>
        <tag>SpringCloud</tag>
        <tag>CloudConfig</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring Cloud 微服务（26） --- Zuul(七) Zuul 优化、Zuul 工作原理]]></title>
    <url>%2Fspring-cloud%2Fspring-cloud-26.html</url>
    <content type="text"><![CDATA[Zuul 作为一个网关中间件，需要应付各种复杂场景，整合的组件非常繁杂。在受益于其丰富的功能时，也需要面对很多问题。如：与上层负载均衡器(Nginx等)、性能、调优等。 Zuul 应用优化Zuul 是建立在 Servlet 上的同步阻塞架构，所有在处理逻辑上面是和线程密不可分，每一次请求都需要在线程池获取一个线程来维护 I/O 操作，路由转发的时候又需要从 http 客户端获取线程来维持连接，这样会导致一个组件占用两个线程资源的情况。所以在 Zuul 的使用中，对这部分的优化很有必要。 Zuul 的优化分为以下几个类型： 容器优化：内置容器 tomcat 与 undertow 的比较与参数设置 组件优化：内部集成的组件优化，如 Hystrix 线程隔离、Ribbon、HttpClient、OkHttp 选择等 JVM 参数优化：适用于网关应用的 JVM 参数建议 内部优化：内部原生参数，内部源码，重写等 容器优化把 tomcat 替换为 undertow。undertow 翻译为“暗流”，是一个轻量级、高性能容器。undertow 提供阻塞或基于 XNIO 的非阻塞机制，包大小不足 1M，内嵌模式运行时的堆内存占用只有 4M。 123456789101112131415&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-tomcat&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-undertow&lt;/artifactId&gt;&lt;/dependency&gt; 123456server: undertow: io-threads: 10 worker-threads: 10 direct-buffers: true buffer-size: 1024 # 字节数 配置项 默认值 说明 server.undertow.io-threads Math.max(Runtime.getRuntime().availableProcessors(), 2) 设置 IO 线程数，它主要执行非阻塞的任务，它们负责多个连接，默认设置每个 CPU 核心有一个线程。不要设置太大，否则启动项目会报错：打开文件数过多 server.undertow.worker-threads io-threads * 8 阻塞任务线程数，当执行类型 Servlet 请求阻塞 IO 操作，undertow 会从这个线程池中取得线程。值设置取决于系统线程执行任务的阻塞系统，默认是 IO 线程数 * 8 server.undertow.direct-buffers 取决于 JVM 最大可用内存大小Runtime.getRuntime().maxMemory()，小于 64MB 默认为 false，其余默认为 true 是否分配直接内存（NIO 直接分配的堆外内存 server.undertow.buffer-size 最大可用内存 &lt;64MB：512 字节；64MB&lt; 最大可用内存 &lt;128MB：1024 字节；128MB &lt; 最大可用内存：1024*16 - 20 字节 每块 buffer 的空间大小，空间越小利用越充分，设置太大会影响其他应用 server.undertow.buffers-per-region 最大可用内存 &lt;128MB：10；128MB &lt; 最大可用内存：20 每个区域分配的 buffer 数量，pool 大小是 buffer-size * buffer-per-region 组件优化Hystrix在 Zuul 中默认集成了 Hystrix 熔断器，使得网关应用具有弹性、容错的能力。但是如果使用默认配置，可能会遇到问题。如：第一次请求失败。这是因为第一次请求的时候，zuul 内部需要初始化很多信息，十分耗时。而 hystrix 默认超时时间是一秒，可能会不够。 解决方式： 加大超时时间 1234567hystrix: command: default: execution: isolation: thread: timeoutInMilliseconds: 5000 禁用 hystrix 超时 123456hystrix: command: default: execution: timeout: enabled: false Zuul 中关于 Hystrix 的配置还有一个很重要的点：Hystrix 线程隔离策略。 线程池模式(THREAD) 信号量模式(SEMAPHORE) 官方推荐 是 否 线程 与请求线程分离 与请求线程公用 开销 上下文切换频繁，较大 较小 异步 支持 不支持 应对并发量 大 小 适用场景 外网交互 内网交互 如果应用需要与外网交互，由于网络开销比较大、请求比较耗时，选用线程隔离，可以保证有剩余容器（tomcat 等）线程可用，不会由于外部原因使线程一直在阻塞或等待状态，可以快速返回失败如果应用不需要与外网交互，并且体量较大，使用信号量隔离，这类应用响应通常非常快，不会占用容器线程太长时间，使用信号量线程上下文就会成为一个瓶颈，可以减少线程切换的开销，提高应用运转的效率，也可以气到对请求进行全局限流的作用。 Ribbon123456ribbon: ConnectTimeout: 3000 ReadTimeout: 60000 MaxAutoRetries: 1 # 对第一次请求的发我的重试次数 MaxAutoRetriesNextServer: 1 # 要重试的下一个服务的最大数量（不包括第一个服务） OkToRetryOnAllOperations: true ConnectTimeout、ReadTimeout 是当前 HTTP 客户端使用 HttpClient 的时候生效的，这个超时时间最终会被设置到 HttpClient 中。在设置的时候要结合 Hystrix 超时时间综合考虑。设置太小会导致请求失败，设置太大会导致 Hystrix 熔断控制变差。 JVM 参数优化根据实际情况，调整 JVM 参数 内有优化在官方文档中，zuul 部分将 zuul.max.host.coonnections 属性拆分成了 zuul.host.maxTotalConnections、zuul.host.maxPerRouteConnections，默认值分别为 200、20。需要注意：这个配置只在使用 HttpClient 时有效，使用 OkHttp 无效。 zuul 中还有一个超时时间，使用 serviceId 映射与 url 映射的设置是不一样的，如果使用 serviceId 映射，ribbon.ReadTimeout 与 ribbon.SocketTimeout 生效；如果使用 url 映射，zuul.host.connect-timeout-millis 与 zuul.host.socket-timeout-millis 生效 Zuul 原理、核心zuul 官方提供了一张架构图，很好的描述了 Zuul 工作原理 Zuul Servlet 通过 RequestContext 通关着由许多 Filter 组成的核心组件，所有操作都与 Filter 息息相关。请求、ZuulServlet、Filter 共同构建器 Zuul 的运行时声明周期 Zuul 的请求来自于 DispatcherServlet，然后交给 ZuulHandlerMapping 处理初始化得来的路由定位器RouteLocator，为后续的请求分发做好准备，同时整合了基于事件从服务中心拉取服务列表的机制；进入 ZuulController，主要职责是初始化 ZuulServlet 以及集成 ServletWrappingController，通过重写 handleRequest 方法来将 ZuulServlet 引入声明周期，之后所有的请求都会经过 ZuulServlet；当请求进入 ZuulServlet 之后，第一次调用会初始化 ZuulRunner，非第一次调用就按照 Filter 链的 order 顺序执行；ZuulRunner 中将请求和响应初始化为 RequestContext，包装成 FilterProcessor 转换为为调用 preRoute、route、postRoute、error 方法；最后再 Filter 链中经过种种变换，得到预期结果。 EnableZuulProxy、EnableZuulServer对比 EnableZuulProxy、EnableZuulServer123456@EnableCircuitBreaker@Target(ElementType.TYPE)@Retention(RetentionPolicy.RUNTIME)@Import(ZuulProxyMarkerConfiguration.class)public @interface EnableZuulProxy &#123;&#125; 123456@Target(&#123;ElementType.TYPE&#125;)@Retention(RetentionPolicy.RUNTIME)@Documented@Import(&#123;ZuulServerMarkerConfiguration.class&#125;)public @interface EnableZuulServer &#123;&#125; 这两个注解的区别在于 @Import 中的配置类不一样。查看两个配置类的源码：1234567891011121314151617/** * Responsible for adding in a marker bean to trigger activation of * &#123;@link ZuulProxyAutoConfiguration&#125; * * @author Biju Kunjummen */@Configurationpublic class ZuulProxyMarkerConfiguration &#123; @Bean public Marker zuulProxyMarkerBean() &#123; return new Marker(); &#125; class Marker &#123; &#125;&#125; 1234567891011121314151617/** * Responsible for adding in a marker bean to trigger activation of * &#123;@link ZuulServerAutoConfiguration&#125; * * @author Biju Kunjummen */@Configurationpublic class ZuulServerMarkerConfiguration &#123; @Bean public Marker zuulServerMarkerBean() &#123; return new Marker(); &#125; class Marker &#123; &#125;&#125; 可以看到，这两个配置类的源码一致，区别在于类的注释上 @link 指向的自动装配类不一样，ZuulProxyMarkerConfiguration 对应的是 ZuulProxyAutoConfiguration；ZuulServerMarkerConfiguration 对应的是 ZuulServerAutoConfiguration 查看 ZuulProxyAutoConfiguration 和 ZuulServerAutoConfiguration 的类注解 12345678@Configuration@Import(&#123; RibbonCommandFactoryConfiguration.RestClientRibbonConfiguration.class, RibbonCommandFactoryConfiguration.OkHttpRibbonConfiguration.class, RibbonCommandFactoryConfiguration.HttpClientRibbonConfiguration.class, HttpClientConfiguration.class &#125;)@ConditionalOnBean(ZuulProxyMarkerConfiguration.Marker.class)public class ZuulProxyAutoConfiguration extends ZuulServerAutoConfiguratio&#125; 123456@Configuration@EnableConfigurationProperties(&#123; ZuulProperties.class &#125;)@ConditionalOnClass(&#123;ZuulServlet.class, ZuulServletFilter.class&#125;)@ConditionalOnBean(ZuulServerMarkerConfiguration.Marker.class)public class ZuulServerAutoConfiguration &#123;&#125; 可以发现，这两个类是通过 ZuulServerMarkerConfiguration、ZuulProxyMarkerConfiguration 中 Marker 类是否存在，当做是否进行自动装配的开关。对比两个 AutoCOnfiguration 的具体源码实现，经过对比，可以分析出：ZuulServerAutoConfiguration 的功能是： 初始化配置加载器 初始化路由定位器 初始化路由映射器 初始化配置刷新监听器 初始化 ZuulServlet 加载器 初始化 ZuulController 初始化 Filter 执行解析器 初始化部分 Filter 初始化 Metrix 监控 ZuulProxyAutoConfiguration 的功能是： 初始化服务注册、发现监听器 初始化服务列表监听器 初始化 zuul 自定义的 endpoint 初始化一些 ZuulServerAutoConfiguration 中没有的 filter’ 引入 http 客户端的两种方式：HttpClient、OkHttp Filter 链filter 装载zuul 中的 Filter 必须经过初始化装载，才能在请求中发挥作用，其过程如下 zuul filter 连初始化过程1234567891011121314151617public class ZuulServerAutoConfiguration &#123; // 省略其他代码 @Configuration protected static class ZuulFilterConfiguration &#123; @Autowired private Map&lt;String, ZuulFilter&gt; filters; @Bean public ZuulFilterInitializer zuulFilterInitializer( CounterFactory counterFactory, TracerFactory tracerFactory) &#123; FilterLoader filterLoader = FilterLoader.getInstance(); FilterRegistry filterRegistry = FilterRegistry.instance(); return new ZuulFilterInitializer(this.filters, counterFactory, tracerFactory, filterLoader, filterRegistry); &#125; &#125;&#125; 1234567891011121314151617181920212223242526272829303132333435363738public class ZuulFilterInitializer &#123; // 省略其他代码 // @PostConstruct：表明在 Bean 初始化之前，就把 Filter 的信息保存到 FilterRegistry @PostConstruct public void contextInitialized() &#123; log.info("Starting filter initializer"); TracerFactory.initialize(tracerFactory); CounterFactory.initialize(counterFactory); for (Map.Entry&lt;String, ZuulFilter&gt; entry : this.filters.entrySet()) &#123; filterRegistry.put(entry.getKey(), entry.getValue()); &#125; &#125; // @PreDestroy：表明在 bean 销毁之前清空 filterRegistry 与 FilterLoader。filterloader 可以通过 filter 名、filter class、filter 类型来查询得到相应的 filter @PreDestroy public void contextDestroyed() &#123; log.info("Stopping filter initializer"); for (Map.Entry&lt;String, ZuulFilter&gt; entry : this.filters.entrySet()) &#123; filterRegistry.remove(entry.getKey()); &#125; clearLoaderCache(); TracerFactory.initialize(null); CounterFactory.initialize(null); &#125; private void clearLoaderCache() &#123; Field field = ReflectionUtils.findField(FilterLoader.class, "hashFiltersByType"); ReflectionUtils.makeAccessible(field); @SuppressWarnings("rawtypes") Map cache = (Map) ReflectionUtils.getField(field, filterLoader); cache.clear(); &#125;&#125; zuul filter 请求调用过123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657public class ZuulServletFilter implements Filter &#123; private ZuulRunner zuulRunner; @Override public void init(FilterConfig filterConfig) throws ServletException &#123; String bufferReqsStr = filterConfig.getInitParameter("buffer-requests"); boolean bufferReqs = bufferReqsStr != null &amp;&amp; bufferReqsStr.equals("true") ? true : false; zuulRunner = new ZuulRunner(bufferReqs); &#125; @Override public void doFilter(ServletRequest servletRequest, ServletResponse servletResponse, FilterChain filterChain) throws IOException, ServletException &#123; try &#123; init((HttpServletRequest) servletRequest, (HttpServletResponse) servletResponse); try &#123; preRouting(); &#125; catch (ZuulException e) &#123; error(e); postRouting(); return; &#125; // Only forward onto to the chain if a zuul response is not being sent if (!RequestContext.getCurrentContext().sendZuulResponse()) &#123; filterChain.doFilter(servletRequest, servletResponse); return; &#125; try &#123; routing(); &#125; catch (ZuulException e) &#123; error(e); postRouting(); return; &#125; try &#123; postRouting(); &#125; catch (ZuulException e) &#123; error(e); return; &#125; &#125; catch (Throwable e) &#123; error(new ZuulException(e, 500, "UNCAUGHT_EXCEPTION_FROM_FILTER_" + e.getClass().getName())); &#125; finally &#123; RequestContext.getCurrentContext().unset(); &#125; &#125; void postRouting() throws ZuulException &#123; zuulRunner.postRoute(); &#125; // 省略其他代码&#125; 12345678910public class ZuulRunn&#123; // 省略其他代码 public void postRoute() throws ZuulException &#123; FilterProcessor.getInstance().postRoute(); &#125; // 省略其他代码&#125; 12345678910111213141516171819202122232425262728293031public class FilterProcessor &#123; public void postRoute() throws ZuulException &#123; try &#123; runFilters("post"); &#125; catch (ZuulException e) &#123; throw e; &#125; catch (Throwable e) &#123; throw new ZuulException(e, 500, "UNCAUGHT_EXCEPTION_IN_POST_FILTER_" + e.getClass().getName()); &#125; &#125; public Object runFilters(String sType) throws Throwable &#123; if (RequestContext.getCurrentContext().debugRouting()) &#123; Debug.addRoutingDebug("Invoking &#123;" + sType + "&#125; type filters"); &#125; boolean bResult = false; List&lt;ZuulFilter&gt; list = FilterLoader.getInstance().getFiltersByType(sType); if (list != null) &#123; for (int i = 0; i &lt; list.size(); i++) &#123; ZuulFilter zuulFilter = list.get(i); Object result = processZuulFilter(zuulFilter); if (result != null &amp;&amp; result instanceof Boolean) &#123; bResult |= ((Boolean) result); &#125; &#125; &#125; return bResult; &#125; // 省略其他代码&#125; 核心路由的实现Zuul 的路由有一个顶级接口 RouteLocator。所有关于路由的功能都是由此而来，其中定义了三个方法：获取忽略的 path 集合、获取路由列表、根据 path 获取路由信息。 SimpleRouteLocator 是一个基本实现，主要功能是对 ZuulServer 的配置文件中路由规则的维护，实现了 Ordered 接口，可以对定位器优先级进行设置。Spring 是一个大量使用策略模式的框架，在策略模式下，接口的实现类有一个优先级问题，Spring 通过 Ordered 接口实现优先级。 ZuulProperties$ZuulRoute 类就是维护路由规则的类，具体属性如下：123456789101112131415161718public static class ZuulRoute &#123; private String id; private String path; private String serviceId; private String url; private boolean stripPrefix = true; private Boolean retryable; private Set&lt;String&gt; sensitiveHeaders = new LinkedHashSet&lt;&gt;(); private boolean customSensitiveHeaders = false;&#125; RefreshableRouteLocator 扩展了 RouteLocator 接口，在 ZuulHandlerMapping 中才实质性生效：凡是实现了 RefreshableRouteLocator，都会被时间监听器所刷新：123456public void setDirty(boolean dirty) &#123; this.dirty = dirty; if (this.routeLocator instanceof RefreshableRouteLocator) &#123; ((RefreshableRouteLocator) this.routeLocator).refresh(); &#125; &#125; DiscoveryClientRouteLocator 实现了 RefreshableRouteLocator，扩展了 SimpleRouteLocator。其作用是整合配置文件与注册中心的路由信息。 CompositeRouteLocator，在 ZuulServerAutoConfiguration 中配置加载时，有一个很重要的注解：@Primary，表示所有的 RouteLocator 中，优先加载它，也就是说，所有的定位器都要在这里装配，可以看做其他路由定位器的处理器。zuul 通过它来将请求域路由规则进行关联，这个操作在 ZuulHandlerMapping 中：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748public class ZuulHandlerMapping extends AbstractUrlHandlerMapping &#123; // 省略其他代码 private final RouteLocator routeLocator; private final ZuulController zuul; public ZuulHandlerMapping(RouteLocator routeLocator, ZuulController zuul) &#123; this.routeLocator = routeLocator; this.zuul = zuul; setOrder(-200); &#125; @Override protected Object lookupHandler(String urlPath, HttpServletRequest request) throws Exception &#123; if (this.errorController != null &amp;&amp; urlPath.equals(this.errorController.getErrorPath())) &#123; return null; &#125; if (isIgnoredPath(urlPath, this.routeLocator.getIgnoredPaths())) return null; RequestContext ctx = RequestContext.getCurrentContext(); if (ctx.containsKey("forward.to")) &#123; return null; &#125; if (this.dirty) &#123; synchronized (this) &#123; if (this.dirty) &#123; registerHandlers(); this.dirty = false; &#125; &#125; &#125; return super.lookupHandler(urlPath, request); &#125; private void registerHandlers() &#123; Collection&lt;Route&gt; routes = this.routeLocator.getRoutes(); if (routes.isEmpty()) &#123; this.logger.warn("No routes found from RouteLocator"); &#125; else &#123; for (Route route : routes) &#123; registerHandler(route.getFullPath(), this.zuul); &#125; &#125; &#125;&#125; ZuulHandlerMapping 将映射规则交给 ZuulController 处理，而 ZuulController 又到 ZuulServlet 中处理，最后到达异域或源服务发送 http 请求的 route 类型的 filter 中，默认有三种发送 http 请求的 filter RibbonRoutingFilter：优先级 10，使用 Ribbon、Hystrix、嵌入式 HTTP 客户端发送请求 SimpleHostRoutingFilter：优先级 100，室友 Apache HttpClient 发送请求 SendForwardFilter：优先级 500，使用 Servlet 发送请求]]></content>
      <categories>
        <category>spring-cloud</category>
      </categories>
      <tags>
        <tag>SpringCloud</tag>
        <tag>Zuul</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring Cloud 微服务（25） --- Zuul(六) Zuul 文件上传、使用技巧]]></title>
    <url>%2Fspring-cloud%2Fspring-cloud-25.html</url>
    <content type="text"><![CDATA[之前在 https://www.laiyy.top/java/2019/01-24/spring-cloud-10.html 介绍了使用 Feign 做文件上传的操作，使用 Zuul 做文件上传，实际上是在 feign 调用之外增加了一层 zuul 路由。 Zuul 文件上传源码：https://gitee.com/laiyy0728/spring-cloud/tree/master/spring-cloud-zuul/spring-cloud-zuul-file-upload Zuul Server123456789101112131415161718192021222324252627282930server: port: 5555spring: application: name: spring-cloud-zuul-file-upload servlet: multipart: enabled: true # 使用 http multipart 上传 max-file-size: 100MB # 文件最大大小，默认 1M，不配置则为 -1 max-request-size: 100MB # 请求最大大小，默认 10M，不配置为 -1 file-size-threshold: 1MB # 当上传文件达到 1NB 时进行磁盘写入 location: / # 上传的临时目录eureka: client: service-url: defaultZone: http://localhost:8761/eureka/ instance: prefer-ip-address: true instance-id: $&#123;spring.application.name&#125;:$&#123;server.port&#125;hystrix: command: default: execution: isolation: thread: timeoutInMilliseconds: 30000 # 超时时间 30 秒，防止大文件上传出现超时ribbon: ConnectionTimeout: 3000 # Ribbon 链接超时时间 ReadTimeout: 30000 # Ribbon 读超时时间 1234567891011121314151617181920@SpringBootApplication@EnableZuulProxy@EnableDiscoveryClient@RestControllerpublic class SpringCloudZuulFileUploadApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(SpringCloudZuulFileUploadApplication.class, args); &#125; @PostMapping(value = "/upload") public String uploadFile(@RequestParam(value = "file") MultipartFile file) throws Exception &#123; byte[] bytes = file.getBytes(); File fileToSave = new File(file.getOriginalFilename()); FileCopyUtils.copy(bytes, fileToSave); return fileToSave.getAbsolutePath(); &#125;&#125; 测试结果 注意事项如果使用的 cloud 版本是 Finchley 之前的版本，在上传中文名称的文件时，会出现乱码的情况。解决办法：在调用接口上加上 /zuul 根节点。如： http://localhost:5555/zuul/upload 需要注意的是，在 @RequestMapping、@PostMapping 上不能加 /zuul，这个节点是 zuul 自带的。也就是说，即是在项目中没有 /zuul 开头的映射，使用 zuul 后都会加上 /zuul 根映射。 Zuul 使用技巧Zuul 饥饿加载Zuul 内部使用 Ribbon 远程调用，根据 Ribbon 的特性，第一次调用会去注册中心获取注册表，初始化 Ribbon 负载信息，这是一种懒加载策略，但是这个过程很耗时。为了避免这个问题，可以使用饥饿加载 1234zuul: ribbon: eager-load: enabled: true 修改请求体源码：https://gitee.com/laiyy0728/spring-cloud/tree/master/spring-cloud-zuul/spring-cloud-zuul-change-param zuul server123456789101112131415161718192021222324252627282930313233@Configurationpublic class ChangeParamZuulFilter extends ZuulFilter &#123; @Override public String filterType() &#123; return FilterConstants.PRE_TYPE; &#125; @Override public int filterOrder() &#123; return FilterConstants.PRE_DECORATION_FILTER_ORDER + 1; &#125; @Override public boolean shouldFilter() &#123; return true; &#125; @Override public Object run() throws ZuulException &#123; RequestContext currentContext = RequestContext.getCurrentContext(); Map&lt;String, List&lt;String&gt;&gt; requestQueryParams = currentContext.getRequestQueryParams(); if (requestQueryParams == null) &#123; requestQueryParams = Maps.newHashMap(); &#125; List&lt;String&gt; arrayList = Lists.newArrayList(); // 增加一个参数 arrayList.add("1111111"); requestQueryParams.put("test", arrayList); currentContext.setRequestQueryParams(requestQueryParams); return null; &#125;&#125; provider1234567891011121314@RestControllerpublic class TestController &#123; @PostMapping("/change-params") public Map&lt;String, Object&gt; modifyRequestEntity (HttpServletRequest request) &#123; Map&lt;String, Object&gt; bodyParams = new HashMap&lt;&gt;(); Enumeration enu = request.getParameterNames(); while (enu.hasMoreElements()) &#123; String paraName = (String)enu.nextElement(); bodyParams.put(paraName, request.getParameter(paraName)); &#125; return bodyParams; &#125;&#125; 验证访问 http://localhost:5555/provider/change-params zuul 中使用 OkHttp1234&lt;dependency&gt; &lt;groupId&gt;com.squareup.okhttp3&lt;/groupId&gt; &lt;artifactId&gt;okhttp&lt;/artifactId&gt;&lt;/dependency&gt; 123456ribbon: okhttp: enabled: true http: client: enabled: false zuul 重试12345&lt;!-- retry --&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.retry&lt;/groupId&gt; &lt;artifactId&gt;spring-retry&lt;/artifactId&gt;&lt;/dependency&gt; 123456789101112131415spring: cloud: loadbalancer: retry: enabled: truezuul: retryable: trueribbon: ConnectTimeout: 3000 ReadTimeout: 60000 MaxAutoRetries: 1 # 对第一次请求的服务的重试次数 MaxAutoRetriesNextServer: 1 # 要重试的下一个服务的最大数量（不包括第一个服务） OkToRetryOnAllOperations: true header 传递123456789101112131415161718192021222324@Configurationpublic class AddHeaderZuulFilter extends ZuulFilter &#123; @Override public String filterType() &#123; return FilterConstants.PRE_TYPE; &#125; @Override public int filterOrder() &#123; return FilterConstants.PRE_DECORATION_FILTER_ORDER + 1; &#125; @Override public boolean shouldFilter() &#123; return true; &#125; @Override public Object run() throws ZuulException &#123; RequestContext currentContext = RequestContext.getCurrentContext(); currentContext.addZuulRequestHeader("key", "value"); return null; &#125;&#125; 在下游 spring-cloud-change-param-provider 中查看 header 传递123456789101112131415161718192021@RestControllerpublic class TestController &#123; @PostMapping("/change-params") public Map&lt;String, Object&gt; modifyRequestEntity (HttpServletRequest request) &#123; Map&lt;String, Object&gt; bodyParams = new HashMap&lt;&gt;(); Enumeration enu = request.getParameterNames(); while (enu.hasMoreElements()) &#123; String paraName = (String)enu.nextElement(); bodyParams.put(paraName, request.getParameter(paraName)); &#125; Enumeration&lt;String&gt; headerNames = request.getHeaderNames(); while (headerNames.hasMoreElements()) &#123; String header = headerNames.nextElement(); String value = request.getHeader(header); System.out.println(header + " ---&gt; " + value); &#125; return bodyParams; &#125;&#125; 访问 http://localhost:5555/provider/change-params ，查看控制台：1234567891011121314151617user-agent ---&gt; Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/71.0.3578.98 Safari/537.36cache-control ---&gt; no-cacheorigin ---&gt; chrome-extension://fhbjgbiflinjbdggehcddcbncdddomoppostman-token ---&gt; a99dcd1c-7c76-2d7e-8a4c-fa5c2bdb6222accept ---&gt; */*accept-encoding ---&gt; gzip, deflate, braccept-language ---&gt; zh-CN,zh;q=0.9x-forwarded-host ---&gt; localhost:5555x-forwarded-proto ---&gt; httpx-forwarded-prefix ---&gt; /providerx-forwarded-port ---&gt; 5555x-forwarded-for ---&gt; 0:0:0:0:0:0:0:1key ---&gt; value ---------------------- zuul server 中增加的 headercontent-type ---&gt; application/x-www-form-urlencoded;charset=UTF-8content-length ---&gt; 12host ---&gt; 10.10.10.141:7070connection ---&gt; Keep-Alive Zuul 整合 Swaggerprovider123456789101112&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.springfox&lt;/groupId&gt; &lt;artifactId&gt;springfox-swagger2&lt;/artifactId&gt; &lt;version&gt;2.7.0&lt;/version&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 12345678910@SpringBootApplication@EnableDiscoveryClient@EnableSwagger2 // 这个注解必须加，否则解析不到public class SpringCloudChangeParamProviderApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(SpringCloudChangeParamProviderApplication.class, args); &#125;&#125; Zuul Server1234567891011&lt;!-- swagger --&gt;&lt;dependency&gt; &lt;groupId&gt;io.springfox&lt;/groupId&gt; &lt;artifactId&gt;springfox-swagger-ui&lt;/artifactId&gt; &lt;version&gt;2.9.2&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;io.springfox&lt;/groupId&gt; &lt;artifactId&gt;springfox-swagger2&lt;/artifactId&gt; &lt;version&gt;2.9.2&lt;/version&gt;&lt;/dependency&gt; 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485/** * @author laiyy * @date 2019/2/25 15:24 * @description */@Configuration@EnableSwagger2 // 这个注解必须加public class Swagger2Configuration &#123; private final ZuulProperties zuulProperties; @Autowired public Swagger2Configuration(ZuulProperties zuulProperties) &#123; this.zuulProperties = zuulProperties; &#125; @Bean public Docket createRestApi() &#123; return new Docket(DocumentationType.SWAGGER_2) .apiInfo(apiInfo()); &#125; private ApiInfo apiInfo() &#123; return new ApiInfoBuilder().title("spring cloud swagger 2") .description("spring cloud 整合 swagger2") .termsOfServiceUrl("") .contact(new Contact("laiyy", "laiyy0728@gmail.com", "laiyy0728@gmail.com")).version("1.0") .build(); &#125;// 第一种配置方式 @Primary @Bean public SwaggerResourcesProvider swaggerResourcesProvider() &#123; return () -&gt; &#123; List&lt;SwaggerResource&gt; resources = new ArrayList&lt;&gt;(); zuulProperties.getRoutes().values().stream() .forEach(route -&gt; resources.add(createResource(route.getServiceId(), route.getServiceId(), "2.0"))); return resources; &#125;; &#125; private SwaggerResource createResource(String name, String location, String version) &#123; SwaggerResource swaggerResource = new SwaggerResource(); swaggerResource.setName(name); swaggerResource.setLocation("/" + location + "/v2/api-docs"); swaggerResource.setSwaggerVersion(version); return swaggerResource; &#125;// 第二种配置方式（推荐使用）// @Component// @Primary// public class ZuulSwaggerResourceProvider implements SwaggerResourcesProvider &#123;//// private final RouteLocator routeLocator;//// @Autowired// public ZuulSwaggerResourceProvider(RouteLocator routeLocator) &#123;// this.routeLocator = routeLocator;// &#125;//// @Override// public List&lt;SwaggerResource&gt; get() &#123;// List&lt;SwaggerResource&gt; resources = Lists.newArrayList();// routeLocator.getRoutes().forEach(route -&gt; &#123;// resources.add(createResource(route.getId(), route.getFullPath().replace("**", "v2/api-docs")));// &#125;);// return resources;// &#125;//// private SwaggerResource createResource(String name, String location) &#123;// SwaggerResource swaggerResource = new SwaggerResource();// swaggerResource.setName(name);// swaggerResource.setLocation(location);//// swaggerResource.setLocation("/" + location + "/api-docs");// swaggerResource.setSwaggerVersion("2.0");// return swaggerResource;// &#125;// &#125;&#125; 验证访问 http://localhost:5555/swagger-ui.html]]></content>
      <categories>
        <category>spring-cloud</category>
      </categories>
      <tags>
        <tag>SpringCloud</tag>
        <tag>Zuul</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring Cloud 微服务（24） --- Zuul(五) 动态路由、灰度发布]]></title>
    <url>%2Fspring-cloud%2Fspring-cloud-24.html</url>
    <content type="text"><![CDATA[在了解了动态路由的改造原理、方式后，就可以自实现一个小 demo。可以使用 mysql 作为持久化方式，目的是方面、易于管理。 动态路由实战源码：https://gitee.com/laiyy0728/spring-cloud/tree/master/spring-cloud-zuul/spring-cloud-dynamic-route-zuul-server Zuul Server123456789101112131415161718&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-zuul&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-jpa&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 1234567891011121314151617181920spring: application: name: spring-cloud-dynamic-route-zuul-server datasource: url: jdbc:mysql://localhost:3306/springcloud?useUnicode=true&amp;characterEncoding=utf-8&amp;serverTimezone=Hongkong driver-class-name: com.mysql.cj.jdbc.Driver username: root password: 123456 jpa: hibernate: ddl-auto: updateserver: port: 5555eureka: instance: instance-id: $&#123;spring.application.name&#125;:$&#123;server.port&#125; prefer-ip-address: true client: service-url: defaultZone: http://localhost:8761/eureka/ 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104// zuul 路由实体@Entity@Table(name = "zuul_route")@Datapublic class ZuulRouteEntity &#123; @Id @GeneratedValue(strategy = GenerationType.AUTO) private int id; private String path; @Column(name = "service_id") private String serviceId; private String url; @Column(name = "strip_prefix") private boolean stripPrefix = true; private boolean retryable; private boolean enabled; private String description;&#125;// daopublic interface ZuulPropertiesDao extends JpaRepository&lt;ZuulRouteEntity, Integer&gt; &#123; @Query("FROM ZuulRouteEntity WHERE enabled = TRUE") List&lt;ZuulRouteEntity&gt; findAllByParams();&#125;// 动态路由实现public class DynamicZuulRouteLocator extends SimpleRouteLocator implements RefreshableRouteLocator &#123; @Autowired private ZuulProperties zuulProperties; @Autowired private ZuulPropertiesDao zuulPropertiesDao; public DynamicZuulRouteLocator(String servletPath, ZuulProperties properties) &#123; super(servletPath, properties); this.zuulProperties = properties; &#125; @Override public void refresh() &#123; doRefresh(); &#125; @Override protected Map&lt;String, ZuulProperties.ZuulRoute&gt; locateRoutes() &#123; Map&lt;String, ZuulProperties.ZuulRoute&gt; routeMap = new LinkedHashMap&lt;&gt;(); routeMap.putAll(super.locateRoutes()); routeMap.putAll(getProperties()); Map&lt;String, ZuulProperties.ZuulRoute&gt; values = new LinkedHashMap&lt;&gt;(); routeMap.forEach((path, zuulRoute) -&gt; &#123; path = path.startsWith("/") ? path : "/" + path; if (StringUtils.hasText(this.zuulProperties.getPrefix())) &#123; path = this.zuulProperties.getPrefix() + path; path = path.startsWith("/") ? path : "/" + path; &#125; values.put(path, zuulRoute); &#125;); return values; &#125; private Map&lt;String, ZuulProperties.ZuulRoute&gt; getProperties() &#123; Map&lt;String, ZuulProperties.ZuulRoute&gt; routeMap = new LinkedHashMap&lt;&gt;(); List&lt;ZuulRouteEntity&gt; list = zuulPropertiesDao.findAllByParams(); list.forEach(entity -&gt; &#123; if (org.apache.commons.lang.StringUtils.isBlank(entity.getPath())) &#123; return; &#125; ZuulProperties.ZuulRoute route = new ZuulProperties.ZuulRoute(); BeanUtils.copyProperties(entity, route); route.setId(String.valueOf(entity.getId())); routeMap.put(route.getPath(), route); &#125;); return routeMap; &#125;&#125;// 注册到 Spring@Configurationpublic class DynamicZuulConfig &#123; private final ZuulProperties zuulProperties; private final ServerProperties serverProperties; @Autowired public DynamicZuulConfig(ZuulProperties zuulProperties, ServerProperties serverProperties) &#123; this.zuulProperties = zuulProperties; this.serverProperties = serverProperties; &#125; @Bean public DynamicZuulRouteLocator dynamicZuulRouteLocator()&#123; return new DynamicZuulRouteLocator(serverProperties.getServlet().getContextPath(), zuulProperties); &#125;&#125; 验证在数据库中增加三条数据123INSERT INTO `springcloud`.`zuul_route` (`id`, `description`, `enabled`, `path`, `retryable`, `service_id`, `strip_prefix`, `url`) VALUES ('1', '重定向到百度', '\1', '/baidu/**', '\0', NULL, '\1', 'http://www.baidu.com');INSERT INTO `springcloud`.`zuul_route` (`id`, `description`, `enabled`, `path`, `retryable`, `service_id`, `strip_prefix`, `url`) VALUES ('2', 'url', '\1', '/client/**', '\0', NULL, '\1', 'http://localhost:8081');INSERT INTO `springcloud`.`zuul_route` (`id`, `description`, `enabled`, `path`, `retryable`, `service_id`, `strip_prefix`, `url`) VALUES ('3', 'serviceId', '\1', '/client-1/**', '\0', 'client-a', '\1', NULL); 访问 http://localhost:5555/baidu/get-result 、http://localhost:5555/client/get-result 、http://localhost:5555/client-a/get-result 1this is provider service! this port is: 8081 headers: [user-agent]: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/71.0.3578.98 Safari/537.36; [cache-control]: no-cache; [postman-token]: a35929aa-9bcf-f5e4-b79a-0e684b1611ed; [token]: E477CA7B8E7CDCDCE3331742544DE9F1; [content-type]: application/x-www-form-urlencoded;charset=UTF-8; [accept]: */*; [accept-encoding]: gzip, deflate, br; [accept-language]: zh-CN,zh;q=0.9; [x-forwarded-host]: localhost:5555; [x-forwarded-proto]: http; [x-forwarded-prefix]: /client; [x-forwarded-port]: 5555; [x-forwarded-for]: 0:0:0:0:0:0:0:1; [host]: localhost:8081; [connection]: Keep-Alive; 1234567&#123; &quot;timestamp&quot;: &quot;2019-02-21T03:15:18.997+0000&quot;, &quot;status&quot;: 404, &quot;error&quot;: &quot;Not Found&quot;, &quot;message&quot;: &quot;No message available&quot;, &quot;path&quot;: &quot;/client-a/get-result&quot;&#125; 由此可以证明，动态路由配置成功。 灰度发布灰度发布是指在系统迭代新功能时的一种平滑过渡的上线发布方式。灰度发布是在原有的系统基础上，额外增加一个新版本，在这个新版本中，有需要验证的功能修改或添加，使用负载均衡器，引入一小部分流量到新版本应用中，如果这个新版本没有出现差错，再平滑地把线上系统或服务一步步替换成新版本，直至全部替换上线结束。 灰度发布实现方式灰度发布可以使用元数据来实现，元数据有两种 标准元数据：标准元数据是服务的各种注册信息，如：ip、端口、健康信息、续约信息等，存储于专门为服务开辟的注册表中，用于其他组件取用以实现整个微服务生态 自定义元数据：自定义元数据是使用 eureka.instance.metadata-map.{key}={value} 配置，其内部实际上是维护了一个 map 来保存子弹元数据信息，可配置再远端服务，随服务一并注册保存在 Eureka 注册表，对微服务生态没有影响。 灰度发布实战源码：https://gitee.com/laiyy0728/spring-cloud/tree/master/spring-cloud-zuul/spring-cloud-zuul-metadata provider123456789101112131415161718192021222324252627282930313233343536373839eureka: client: service-url: defaultZone: http://localhost:8761/eureka/ instance: prefer-ip-address: true instance-id: $&#123;spring.application.name&#125;:$&#123;server.port&#125;spring: application: name: spring-cloud-metadata-provider-service---server: port: 7070spring: profiles: node1 # 设定 profile，可以使用 mvn spring-boor:run -Dspring.profiles.active=node1 启动，或者在启动类使用 SpringApplication.run(SpringCloudMetadataProviderServiceApplication.class, "--spring.profiles.active=node1"); 启动eureka: instance: metadata-map: host-mark: running # 设定当前节点的 metadata，zuul server 使用这个标注来进行路由转发---spring: profiles: node2server: port: 7071eureka: instance: metadata-map: host-mark: running---spring: profiles: node3server: port: 7072eureka: instance: metadata-map: host-mark: gray # 当前节点是灰度节点 123456789101112131415161718@SpringBootApplication@EnableDiscoveryClient@RestControllerpublic class SpringCloudMetadataProviderServiceApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(SpringCloudMetadataProviderServiceApplication.class, args); // SpringApplication.run(SpringCloudMetadataProviderServiceApplication.class, "--Dspring.profiles.active=node1"); // 非 maven 启动 &#125; @Value("$&#123;server.port&#125;") private int port; @GetMapping(value = "/get-result") public String getResult()&#123; return "metadata provider service result, port: " + port; &#125;&#125; Zuul Server123456789101112131415161718&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-zuul&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- 实现通过 metadata 进行灰度路由 --&gt; &lt;dependency&gt; &lt;groupId&gt;io.jmnarloch&lt;/groupId&gt; &lt;artifactId&gt;ribbon-discovery-filter-spring-cloud-starter&lt;/artifactId&gt; &lt;version&gt;2.1.0&lt;/version&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 12345678910111213141516171819202122232425spring: application: name: spring-cloud-metadata-zuul-serverserver: port: 5555eureka: instance: instance-id: $&#123;spring.application.name&#125;:$&#123;server.port&#125; prefer-ip-address: true client: service-url: defautlZone: http://localhost:8761/eureka/zuul: routes: spring-cloud-metadata-provider-service: path: /provider/** serviceId: spring-cloud-metadata-provider-servicemanagement: endpoints: web: exposure: include: '*' endpoint: health: show-details: always 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748// 实现灰度的 Filterpublic class GrayFilter extends ZuulFilter &#123; @Override public String filterType() &#123; return FilterConstants.PRE_TYPE; &#125; @Override public int filterOrder() &#123; return FilterConstants.PRE_DECORATION_FILTER_ORDER - 1; &#125; @Override public boolean shouldFilter() &#123; RequestContext context = RequestContext.getCurrentContext(); return !context.containsKey(FilterConstants.FORWARD_TO_KEY) &amp;&amp; !context.containsKey(FilterConstants.SERVICE_ID_KEY); &#125; @Override public Object run() throws ZuulException &#123; HttpServletRequest request = RequestContext.getCurrentContext().getRequest(); String grayMark = request.getHeader("gray_mark"); if (StringUtils.isNotBlank(grayMark) &amp;&amp; StringUtils.equals("enable", grayMark)) &#123; RibbonFilterContextHolder.getCurrentContext().add("host-mark", "gray"); &#125; else &#123; RibbonFilterContextHolder.getCurrentContext().add("host-mark", "running"); &#125; return null; &#125;&#125;@SpringBootApplication@EnableDiscoveryClient@EnableZuulProxypublic class SpringCloudMetadataZuulServerApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(SpringCloudMetadataZuulServerApplication.class, args); &#125; @Bean public GrayFilter grayFilter()&#123; return new GrayFilter(); &#125;&#125; 验证正常访问： http://localhost:5555/provider/get-result ，查看返回值， port 在 7070 和 7071 之间轮询。 启用 gray_mark header，再次访问，发现 port 始终都是 7072，由此验证灰度成功]]></content>
      <categories>
        <category>spring-cloud</category>
      </categories>
      <tags>
        <tag>SpringCloud</tag>
        <tag>Zuul</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring Cloud 微服务（23） --- Zuul(四) 限流、动态路由概念]]></title>
    <url>%2Fspring-cloud%2Fspring-cloud-23.html</url>
    <content type="text"><![CDATA[之前利用 Hystrix，通过熔断器实现了通过某个阈值来对异常流量进行降级处理。除了对异常流量进行降级之外，还可以通过 流量排队、限流、分流等操作，防止系统出错。 限流算法限流算法一般分为 漏桶、令牌桶 两种。 漏桶漏桶的圆形是一个底部有漏孔的桶，桶的上方有一个入水口，水不断流进桶内，桶下方的漏孔会以一个相对恒定的速度漏水，在入大于出的情况下，桶在一段时间内就会被装满，这时候多余的水就会溢出；而在入小于出的情况下，漏桶起不到任何作用。 当请求或者具有一定体量的数据进入系统时，在漏桶作用下，流量被整形，不能满足要求的部分被削减掉，漏桶算法能强制限定流量速度。溢出的流量可以被再次利用起来，并非完全丢弃，可以把溢出的流量收集到一个队列中，做流量排队，尽量合理利用所有资。 令牌桶令牌桶与漏桶的区别是，桶里放的是令牌而不是流量，令牌以一个恒定的速度被加入桶内，可以积压，可以溢出。当流量涌入时，量化请求用于获取令牌，如果取到令牌则方形，同时桶内丢掉这个令牌；如果取不到令牌，则请求被丢弃。由于桶内可以存一定量的令牌，那么就可能会解决一定程度的流量突发。这个也是漏桶与令牌桶的适用场景不同之处。 限流实例在 Zuul 中实现限流，最简单的方式是使用 Filter 加上相关的限流算法，其中可能会考虑到 Zuul 多节点部署。因为算法的原因，这是需要一个 K/V 存储工具（Redis等）。 spring-cloud-zuul-ratelimit 是一个针对 Zuul 的限流库限流粒度的策略： user：认证用户名或匿名，针对某用户粒度进行限流 origin：客户机 ip，针对请求客户机 ip 粒度进行限流 url：特定 url，针对某个请求 url 粒度进行限流 serviceId：特定服务，针对某个服务 id 粒度进行限流 限流粒度临时变量存储方式： IN_MEMORY：基于本地内存，底层是 ConcurrentHashMap REDIS：基于 Redis K/V 存储 CONSUL：基于 Consul K/V 存储 JPA：基于 SpringData JPA，数据库存储 BUKET4J：使用 Java 编写的基于令牌桶算法的限流库，四种模：JCache、Hazelcast、Apache Ignite、Inifinispan，后面三种支持异步 源码：https://gitee.com/laiyy0728/spring-cloud/tree/master/spring-cloud-zuul/spring-cloud-zuul-ratelimit Zuul Server123456789101112131415&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-zuul&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.marcosbarbero.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-zuul-ratelimit&lt;/artifactId&gt; &lt;version&gt;2.0.6.RELEASE&lt;/version&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 123456789101112131415161718192021222324252627282930server: port: 5555spring: application: name: spring-cloud-ratelimit-zuul-servereureka: instance: instance-id: $&#123;spring.application.name&#125;:$&#123;server.port&#125; prefer-ip-address: true client: service-url: defaultZone: http://localhost:8761/eureka/zuul: routes: spring-cloud-ratelimit-provider-service: path: /provider/** serviceId: spring-cloud-ratelimit-provider-service ratelimit: key-prefix: springcloud # 按粒度拆分的临时变量 key 的前缀 enabled: true # 启用开关 repository: in_memory # key 的存储类型，默认是 in_memory behind-proxy: true # 表示代理之后 default-policy: limit: 2 # 在一个单位时间内的请求数量 quota: 1 # 在一个单位时间内的请求时间限制 refresh-interval: 3 # 单位时间窗口 type: - user # 可指定用户粒度 - origin # 可指定客户端地址粒度 - url # 可指定 url 粒度 Provider123456&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 123456789101112spring: application: name: spring-cloud-ratelimit-provider-serviceserver: port: 7070eureka: client: service-url: defaultZone: http://localhost:8761/eureka/ instance: prefer-ip-address: true instance-id: $&#123;spring.application.name&#125;:$&#123;server.port&#125; 验证快速访问几次 http://localhost:5555/provider/get-result ，返回值如下：123456&#123; "timestamp": "2019-02-20T06:52:51.220+0000", "status": 429, "error": "Too Many Requests", "message": "429"&#125; 控制台打印异常如下：123456789com.netflix.zuul.exception.ZuulException: 429 at com.marcosbarbero.cloud.autoconfigure.zuul.ratelimit.support.RateLimitExceededException.&lt;init&gt;(RateLimitExceededException.java:13) ~[spring-cloud-zuul-ratelimit-core-2.0.6.RELEASE.jar:2.0.6.RELEASE] at com.marcosbarbero.cloud.autoconfigure.zuul.ratelimit.filters.RateLimitPreFilter.lambda$run$0(RateLimitPreFilter.java:106) ~[spring-cloud-zuul-ratelimit-core-2.0.6.RELEASE.jar:2.0.6.RELEASE] at java.util.ArrayList.forEach(ArrayList.java:1257) ~[na:1.8.0_171] at com.marcosbarbero.cloud.autoconfigure.zuul.ratelimit.filters.RateLimitPreFilter.run(RateLimitPreFilter.java:79) ~[spring-cloud-zuul-ratelimit-core-2.0.6.RELEASE.jar:2.0.6.RELEASE] at com.netflix.zuul.ZuulFilter.runFilter(ZuulFilter.java:117) ~[zuul-core-1.3.1.jar:1.3.1] at com.netflix.zuul.FilterProcessor.processZuulFilter(FilterProcessor.java:193) ~[zuul-core-1.3.1.jar:1.3.1] at com.netflix.zuul.FilterProcessor.runFilters(FilterProcessor.java:157) ~[zuul-core-1.3.1.jar:1.3.1] ... 正常访问结果如下：1zuul rate limit result ! 动态路由之前配置路由映射规则的方式，为“静态路由”。如果在迭代过程中，可能需要动态将路由映射规则写入内存。在“静态路由”配置中，需要重启 Zuul 应用。不需要重启 Zuul，又能修改映射规则的方式，称为“动态路由”。 SpringCloud Config + Bus，动态刷新配置文件。好处是不用 Zuul 维护映射规则，可以随时修改，随时生效。缺点是需要单独集成一些使用并不频繁的组件。SpringCloud Config 没有可视化界面，维护也麻烦 重写 Zuul 配置读取方式，采用事件刷新机制，从数据库读取路由映射规则。此方式基于数据库，可轻松实现管理页面，灵活度高。 动态路由实现原理 DiscoveryClientRouteLocator1234567891011121314public class DiscoveryClientRouteLocator extends SimpleRouteLocator implements RefreshableRouteLocator &#123; // 省略其他方法 // 路由 protected LinkedHashMap&lt;String, ZuulRoute&gt; locateRoutes() &#123; // 省略方法实现 &#125; // 刷新 public void refresh() &#123; this.doRefresh(); &#125;&#125; locateRoutes 方法继承自 SimpleRouteLocator 类，并重写规则，该方法主要的功能就是将配置文件中的映射规则信息包装成 LinkedHashMap&lt;String, ZuulRoute&gt;，键为路径 path，值 ZuulRoute 是配置文件的封装类。之前的映射配置信息就是使用 ZuulRoute 封装的。refresh 实现自 RefreshableRouteLocator 接口，添加刷新功能必须实现此方法，doRefresh 方法来自 SimpleRouteLocator 类 SimpleRouteLocatorSimpleRouteLocator 是 DiscoveryClientRouteLocator 的父类，此类基本实现了 RouteLocator 接口，对读取配置文件信息做一些处理，提供方法 doRefresh、locateRoutes 供子类实现刷新策略与映射规则加载策略 12345678910111213141516171819/** * Calculate all the routes and set up a cache for the values. Subclasses can call * this method if they need to implement &#123;@link RefreshableRouteLocator&#125;. */protected void doRefresh() &#123; this.routes.set(locateRoutes());&#125;/** * Compute a map of path pattern to route. The default is just a static map from the * &#123;@link ZuulProperties&#125;, but subclasses can add dynamic calculations. */protected Map&lt;String, ZuulRoute&gt; locateRoutes() &#123; LinkedHashMap&lt;String, ZuulRoute&gt; routesMap = new LinkedHashMap&lt;&gt;(); for (ZuulRoute route : this.properties.getRoutes().values()) &#123; routesMap.put(route.getPath(), route); &#125; return routesMap;&#125; 这两个方法都是 protectted 修饰，是为了让子类不用维护此类一些成员变量就能实现刷新或读取路由的功能。从注释上可以看到，调用 doRedresh 方法需要实现 RefreshableRouteLocator；locateRoutes 默认是一个静态的映射读取方法，如果需要动态记载映射，需要子类重写此方法。 ZuulServerAutoConfigurationZuulServerAutoConfiguration 是 Spring Cloud Zuul 的配置类，主要目的是注册各种过滤器、监听器以及其他功能。Zuul 在注册中心新增服务后刷新监听器也是在这个类中注册的，底层是 Spring 的 ApplicationListener 12345678910111213141516171819202122232425262728293031323334353637383940414243444546@Configuration@EnableConfigurationProperties(&#123; ZuulProperties.class &#125;)@ConditionalOnClass(ZuulServlet.class)@ConditionalOnBean(ZuulServerMarkerConfiguration.Marker.class)public class ZuulServerAutoConfiguration &#123; // 省略其他功能注册 // Zuul 刷新监听器 private static class ZuulRefreshListener implements ApplicationListener&lt;ApplicationEvent&gt; &#123; @Autowired private ZuulHandlerMapping zuulHandlerMapping; private HeartbeatMonitor heartbeatMonitor = new HeartbeatMonitor(); @Override public void onApplicationEvent(ApplicationEvent event) &#123; if (event instanceof ContextRefreshedEvent || event instanceof RefreshScopeRefreshedEvent || event instanceof RoutesRefreshedEvent || event instanceof InstanceRegisteredEvent) &#123; reset(); &#125; else if (event instanceof ParentHeartbeatEvent) &#123; ParentHeartbeatEvent e = (ParentHeartbeatEvent) event; resetIfNeeded(e.getValue()); &#125; else if (event instanceof HeartbeatEvent) &#123; HeartbeatEvent e = (HeartbeatEvent) event; resetIfNeeded(e.getValue()); &#125; &#125; private void resetIfNeeded(Object value) &#123; if (this.heartbeatMonitor.update(value)) &#123; reset(); &#125; &#125; private void reset() &#123; this.zuulHandlerMapping.setDirty(true); &#125; &#125;&#125; 其中，由方法 onApplicationEvent可知，Zuul 会接收 4 种事件通知 ContextRefreshedEvent、RefreshScopeRefreshedEvent、RoutesRefreshedEvent、InstanceRegisteredEvent，这四种通知都会去刷新路由映射配置信息，此外，心跳续约监视器 HeartbeatEvent 也会触发这个动作 ZuulHandlerMapping在 ZuulServerAutoConfiguration#ZuulRefreshListener 中，注入了 ZuulHandlerMapping，此类是将本地配置的映射关系，映射到远程的过程控制器 12345678910111213141516/** * MVC HandlerMapping that maps incoming request paths to remote services. */public class ZuulHandlerMapping extends AbstractUrlHandlerMapping &#123; // 省略其他配置 private volatile boolean dirty = true; public void setDirty(boolean dirty) &#123; this.dirty = dirty; if (this.routeLocator instanceof RefreshableRouteLocator) &#123; ((RefreshableRouteLocator) this.routeLocator).refresh(); &#125; &#125;&#125; dirty 属性很重要，它是用来控制当前是否需要重新加载映射配置信息的标记，在 Zuul 每次进行路由操作的时候都会检查这个值。如果为 true，则会触发配置信息的重新加载，同时再将其审核制为 false。由 setDirty 方法体可知，启动刷新动作必须实现 RefreshableRouteLocator，否则会出现类转换异常。]]></content>
      <categories>
        <category>spring-cloud</category>
      </categories>
      <tags>
        <tag>SpringCloud</tag>
        <tag>Zuul</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring Cloud 微服务（22） --- Zuul(三) Zuul 权限集成]]></title>
    <url>%2Fspring-cloud%2Fspring-cloud-22.html</url>
    <content type="text"><![CDATA[在原本的单体应用中，通常使用 Apache Shiro、Spring Security 等权限框架，但是在 Spring Cloud 中，面对成千上万的微服务，而且每个服务之间无状态，使用 Shiro、Security 难免力不从心。在解决方案的选择上，传统的单点登录SSO、分布式 session 等，要么致使权限服务器集中化，导致流量臃肿，要么需要实现一套复杂的存储同步机制，都不是最好的解决方案。 可以使用 Spring Cloud Zuul 自定义实现权限认证方式 源码：https://gitee.com/laiyy0728/spring-cloud/tree/master/spring-cloud-zuul/spring-cloud-zuul-security 自定义权限认证FilterZuul 对于请求的转发是通过 Filter 链控制的，可以在 RequestContext 的基础上做任何事。所以只需要在 spring-cloud-zuul-filter 的基础上，设置一个执行顺序比较靠前的 Filter，就可以专门用于对请求特定内容做权限认证。 优点：实现灵活度高，可整合已有的权限系统，对原始系统违法化友好缺点：需要开发一套新的逻辑，维护成本增加，调用链紊乱 OAuth2.0 + JWTOAuth2.0 是对于“授权-认证”比较成熟的面向资源的授权协议。整个授权流程中，用户是资源拥有者，服务端需要资源拥有者的授权，这个过程相当于键入密码或者其他第三方登录。触发了这个操作后，客户端就可以向授权服务器申请 Token，拿到后，再携带 Token 到资源所在服务器拉取响应资源。 JWT(JSON Web Token)是一种使用 JSON 格式来规范 Token 或 Session 的协议。由于传统认证方式会生成一个凭证，这个凭证可以是 Token 或 Session，保存于服务端或其他持久化工具中，这样一来，凭证的存取或十分麻烦。JWT 实现了“客户端 Session”。 JWT 的组成部分： Header 头部：指定 JWT 使用的签名算法 Payload 载荷：包含一些自定义与非自定义的认证信息 Signature：将头部、载荷使用“.”连接后，使用头部的签名算法生成签名信息，并拼装到末尾 OAuth2.0 + JWT 的意义在于，使用 OAuth2.0 协议思想拉取认证生成 TToken，使用 JWT 瞬时保存这个 Token，在客户端与资源端进行对称或非对称加密，是的这个规约具有定时、定量的授权认证功能，从而免去 Token 存储带来的安全或者系统扩展问题。 实现Zuul Server123456789101112131415161718 &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-zuul&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-security&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-oauth2&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 123456789101112131415161718192021222324252627spring: application: name: spring-cloud-zuul-security-serverserver: port: 5555eureka: client: service-url: defaultZone: http://localhost:8761/eureka/ instance: prefer-ip-address: true instance-id: $&#123;spring.application.name&#125;:$&#123;server.port&#125;zuul: routes: spring-cloud-zuul-security-provider-service: path: /provider/** serviceId: spring-cloud-zuul-security-provider-servicesecurity: oauth2: client: access-token-uri: http://localhost:7777/uaa/oauth/token # 令牌端点 user-authorization-uri: http://localhost:7777/uaa/oauth/authorize # 授权端点 client-id: zuul_server # OAuth2 客户端id client-secret: secret # OAuth2 客户端秘钥 resource: jwt: key-value: spring-cloud # 使用对称加密，默认算法为 HS256，加密秘钥为 spring-cloud 123456789101112131415161718@SpringBootApplication@EnableDiscoveryClient@EnableZuulProxy@EnableOAuth2Sso // 开启 OAuth2.0 sso认证public class SpringCloudZuulSecurityServerApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(SpringCloudZuulSecurityServerApplication.class, args); &#125; @Override protected void configure(HttpSecurity http) throws Exception &#123; http.authorizeRequests() // 声明要鉴权的 urls .antMatchers("/login", "/provider/**") .permitAll().anyRequest().authenticated().and().csrf().disable(); &#125;&#125; auth server12345678910&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-oauth2&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 1234567891011121314spring: application: name: spring-cloud-zuul-security-auth-serverserver: port: 7777 servlet: context-path: /uaa # web 访问根节点eureka: instance: instance-id: $&#123;spring.application.name&#125;:$&#123;server.port&#125; prefer-ip-address: true client: service-url: defaultZone: http://localhost:8761/eureka/ 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485// 启动类@SpringBootApplication@EnableDiscoveryClientpublic class SpringCloudZuulSecurityAuthServerApplication extends WebSecurityConfigurerAdapter &#123; public static void main(String[] args) &#123; SpringApplication.run(SpringCloudZuulSecurityAuthServerApplication.class, args); &#125; @Bean(name = BeanIds.AUTHENTICATION_MANAGER) // 设置 Bean 的名称 @Override public AuthenticationManager authenticationManagerBean() throws Exception &#123; return super.authenticationManagerBean(); &#125; @Bean public static PasswordEncoder passwordEncoder()&#123; // password 编码器 return NoOpPasswordEncoder.getInstance(); &#125; @Override protected void configure(AuthenticationManagerBuilder auth) throws Exception &#123; // 设置用户和权限 auth.inMemoryAuthentication().withUser("guest").password("guest").authorities("WRIGHT_READ") .and() .withUser("admin").password("admin").authorities("WRIGHT_READ", "WRIGHT_WRITE"); &#125;&#125;// OAuth 配置@Configuration@EnableAuthorizationServer // 开启认证服务器public class OAuthConfiguration extends AuthorizationServerConfigurerAdapter &#123; private final AuthenticationManager authenticationManager; @Autowired public OAuthConfiguration(AuthenticationManager authenticationManager) &#123; this.authenticationManager = authenticationManager; &#125; @Override public void configure(ClientDetailsServiceConfigurer clients) throws Exception &#123; clients.inMemory() // 此处的 client 是 zuul server 中 security.oauth2.client.client-id .withClient("zuul_server") // 此处的 secret 是 zuul server 中 security.oauth2.client.client-secret .secret("secret") // 作用域 .scopes("WRIGHT", "READ") // 跳过认证确认的过程 .autoApprove(true) // 权限 .authorities("WRIGHT_READ", "WRIGHT_WRITE") // 可以使用的授权类型，默认为空 // implicit：隐式授权类型 // refresh_token：刷新令牌获取新的令牌 // password：资源所有者密码类型 // authorization_code：授权码类型 // client_credentials：客户端凭据（客户端ID以及key）类型 .authorizedGrantTypes("implicit", "refresh_token", "password", "authorization_code"); &#125; @Override public void configure(AuthorizationServerEndpointsConfigurer endpoints) throws Exception &#123; endpoints.tokenStore(jwtTokenStore()) .tokenEnhancer(jwtAccessTokenConverter()) .authenticationManager(authenticationManager); &#125; @Bean public TokenStore jwtTokenStore()&#123; return new JwtTokenStore(jwtAccessTokenConverter()); &#125; @Bean public JwtAccessTokenConverter jwtAccessTokenConverter()&#123; JwtAccessTokenConverter jwtAccessTokenConverter = new JwtAccessTokenConverter(); // 设置秘钥，需要与 zuul_server 中配置的一样 jwtAccessTokenConverter.setSigningKey("spring-cloud"); return jwtAccessTokenConverter; &#125;&#125; provider12345678910&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-oauth2&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 123456789101112server: port: 7070spring: application: name: spring-cloud-zuul-security-provider-serviceeureka: client: service-url: defaultZone: http://localhost:8761/eureka/ instance: prefer-ip-address: true instance-id: $&#123;spring.application.name&#125;:$&#123;server.port&#125; 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950@SpringBootApplication@EnableDiscoveryClient@RestController@EnableResourceServerpublic class SpringCloudZuulSecurityProviderServiceApplication extends ResourceServerConfigurerAdapter &#123; private static final Logger LOGGER = LoggerFactory.getLogger(SpringCloudZuulSecurityProviderServiceApplication.class); public static void main(String[] args) &#123; SpringApplication.run(SpringCloudZuulSecurityProviderServiceApplication.class, args); &#125; @GetMapping(value = "/test") public String test(HttpServletRequest request) &#123; LOGGER.info("&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; header start! &lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;"); Enumeration&lt;String&gt; headerNames = request.getHeaderNames(); while (headerNames.hasMoreElements())&#123; String header = headerNames.nextElement(); String value = request.getHeader(header); LOGGER.info("&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; &#123;&#125; : &#123;&#125; &lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;", header, value); &#125; LOGGER.info("&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; header end! &lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;"); return " test!"; &#125; @Override public void configure(HttpSecurity http) throws Exception &#123; http.csrf().disable().authorizeRequests().antMatchers("/**").authenticated() .antMatchers(HttpMethod.GET, "/test") .hasAuthority("WRIGHT_READ"); &#125; @Override public void configure(ResourceServerSecurityConfigurer resources) throws Exception &#123; resources.resourceId("WRIGHT") .tokenStore(tokenStore()); &#125; @Bean public TokenStore tokenStore()&#123; return new JwtTokenStore(jwtAccessTokenConverter()); &#125; @Bean protected JwtAccessTokenConverter jwtAccessTokenConverter()&#123; JwtAccessTokenConverter converter = new JwtAccessTokenConverter(); converter.setSigningKey("spring-cloud"); return converter; &#125;&#125; 验证访问 http://localhost:5555/provider/test 页面返回值如下 访问 http://localhost:5555/login 将会自动跳转到 http://localhost:7777/uaa/login 使用 admin/admin 登录 访问成功后会返回一个 404 页面，这是因为没有配置成功后跳转页面导致的，暂时不管 再次访问 http://localhost:5555/provider/test 页面返回值如下 同时查看 provider-service，控制台输出如下123456789101112131415161718&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; header start! &lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; upgrade-insecure-requests : 1 &lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; user-agent : Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/71.0.3578.98 Safari/537.36 &lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; dnt : 1 &lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; accept : text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8 &lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; accept-language : zh-CN,zh;q=0.9 &lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; authorization : bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJleHAiOjE1NTA2MDcxODQsInVzZXJfbmFtZSI6ImFkbWluIiwiYXV0aG9yaXRpZXMiOlsiV1JJR0hUX1dSSVRFIiwiV1JJR0hUX1JFQUQiXSwianRpIjoiZTJjYmNjNDktMzE5ZC00NDdhLTlmMWYtZmY0YzI5ZDFmZWM4IiwiY2xpZW50X2lkIjoic3ByaW5nLWNsb3VkLXp1dWwtc2VjdXJpdHktc2VydmVyIiwic2NvcGUiOlsiV1JJR0hUIiwicmVhZCJdfQ.vOibf3j0seQqsJuH66eLi_zU_P3KeiTn07baUx78T5A &lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; x-forwarded-host : localhost:5555 &lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; x-forwarded-proto : http &lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; x-forwarded-prefix : /provider &lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; host : localhost:5555 &lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; x-forwarded-port : 5555 &lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; x-forwarded-for : 0:0:0:0:0:0:0:1 &lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; accept-encoding : gzip &lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; content-length : 0 &lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; connection : Keep-Alive &lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; header end! &lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt; 其中，authorization 就是 JWT Token，这个 Token 是使用 base64 加密的，将 authorization 去掉 bearer 后，其余部分按 “.” 分隔，每个部分分别解密eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9 解码后为：1234&#123; "alg": "HS256", "typ": "JWT"&#125; eyJleHAiOjE1NTA2MDcxODQsInVzZXJfbmFtZSI6ImFkbWluIiwiYXV0aG9yaXRpZXMiOlsiV1JJR0hUX1dSSVRFIiwiV1JJR0hUX1JFQUQiXSwianRpIjoiZTJjYmNjNDktMzE5ZC00NDdhLTlmMWYtZmY0YzI5ZDFmZWM4IiwiY2xpZW50X2lkIjoic3ByaW5nLWNsb3VkLXp1dWwtc2VjdXJpdHktc2VydmVyIiwic2NvcGUiOlsiV1JJR0hUIiwicmVhZCJdfQ 解码后为：12345678&#123; "exp": 1550607184, "user_name": "admin", "authorities": ["WRIGHT_WRITE", "WRIGHT_READ"], "jti": "e2cbcc49-319d-447a-9f1f-ff4c29d1fec8", "client_id": "spring-cloud-zuul-security-server", "scope": ["WRIGHT", "read"]&#125; vOibf3j0seQqsJuH66eLi_zU_P3KeiTn07baUx78T5A：这一部分是密文，不能使用 base64 解密]]></content>
      <categories>
        <category>spring-cloud</category>
      </categories>
      <tags>
        <tag>SpringCloud</tag>
        <tag>Zuul</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring Cloud 微服务（21） --- Zuul(二) Zuul Filter 链]]></title>
    <url>%2Fspring-cloud%2Fspring-cloud-21.html</url>
    <content type="text"><![CDATA[Zuul 的核心逻辑是由一系列紧密配合工作的 Filter 来实现的，能够在进行 HTTP 请求或响应的时候执行相关操作。 Zuul FilterZuul Filter 的特点 Filter 类型：Filter 类型决定了当前的 Filter 在整个 Filter 链中的执行顺序。 Filter 执行顺序：同一种类型的 Filter 通过 filterOrder() 来设置执行顺序 Filter 执行条件：Filter 执行所需的标准、条件 Filter 执行效果：符合某个条件，产生的执行结果 Zuul 内部提供了一个动态读取、编译、运行这些 Filter 的机制。Filter 之间不直接通信，在请求线程中会通过 RequestContext 共享状态，内部使用 ThreadLocal 实现，也可以在 Filter 之间使用 ThreadLocal 收集自己需要的状态、数据 Zuul Filter 的执行逻辑源码在 com.netflix.zuul.http.ZuulServlet 中123456789101112131415161718192021222324252627282930313233public void service(ServletRequest servletRequest, ServletResponse servletResponse) throws ServletException, IOException &#123; try &#123; this.init((HttpServletRequest)servletRequest, (HttpServletResponse)servletResponse); RequestContext context = RequestContext.getCurrentContext(); // 通过 RequestContext 获取共享状态 context.setZuulEngineRan(); try &#123; this.preRoute(); // 执行请求之前的操作 &#125; catch (ZuulException var13) &#123; this.error(var13); // 出现错误的操作 this.postRoute(); return; &#125; try &#123; this.route(); // 路由操作 &#125; catch (ZuulException var12) &#123; this.error(var12); this.postRoute(); return; &#125; try &#123; this.postRoute(); // 请求操作 &#125; catch (ZuulException var11) &#123; this.error(var11); &#125; &#125; catch (Throwable var14) &#123; this.error(new ZuulException(var14, 500, "UNHANDLED_EXCEPTION_" + var14.getClass().getName())); &#125; finally &#123; RequestContext.getCurrentContext().unset(); &#125;&#125; Zuul 生命周期Zuul 官方文档中，生命周期图。 但官方文档的生命周期图不太准确。 在 postRoute 执行之前，即 postFilter 执行之前，如果没有出现过错误，会调用 error 方法，并调用 this.error(new ZuulException) 打印堆栈信息 在 postRoute 执行之前就已经报错，会调用 error 方法，再调用 postRoute，但是之后会直接 return，不会调用 this.error(new ZuulException) 打印堆栈信息 由此可以看出，整个 Filter 调用链的重点可能是 postFilter 也可能是 errorFilter pre、route 出现错误后，进入 error，再进入 post，再返回pre、route 没有出现错误，进入 post，如果出现错误，再进入 error，再返回 pre：在 Zuul 按照规则路由到下级服务之前执行。如果需要对请求进行预处理，如：鉴权、限流等，都需要在此 Filter 实现 route：Zuul 路由动作的执行者，是 Http Client、Ribbon 构建和发送原始 HTTP 请求的地方 post：源服务返回结果或异常信息发生后执行，如果需要对返回值信息做处理，需要实现此类 Filter error：整个生命周期发生异常，都会进入 error Filter，可做全局异常处理。 Filter 之间，通过 com.netflix.zuul.context.RequestContext 类进行通信，内部采用 ThreadLocal 保存每个请求的一些信息，包括：请求路由、错误信息、HttpServletRequest、HTTPServletResponse，扩展了 ConcurrentHashMap，目的是为了在处理过程中保存任何形式的信息 Zuul 原生 Filter整合 spring-boot-starter-actuator 后，查看 idea 控制台 endpoints 栏的 mappings，可以看到多了几个 Actuator 端点 routes 端点访问 http://localhost:8989/actuator/routes 可以查看当前 zuul server 映射了几个路径、服务1234&#123; "/provider/**": "spring-cloud-provider-service-simple", "/spring-cloud-provider-service-simple/**": "spring-cloud-provider-service-simple"&#125; 访问 http://localhost:8989/actuator/routes/details 可以查看具体的映射信息12345678910111213141516171819202122&#123; "/provider/**": &#123; "id": "spring-cloud-provider-service-simple", // serviceId "fullPath": "/provider/**", // 映射 path "location": "spring-cloud-provider-service-simple", // 服务名称，实际上也是 serviceId "path": "/**", // 实际访问路径 "prefix": "/provider", // 访问前缀 "retryable": false, // 是否开启重试 "customSensitiveHeaders": false, // 是否自定义了敏感 header "prefixStripped": true // 是否去掉前缀（如果为 false，则实际访问时需要加 前缀，且实际请求的访问路径也会加上前缀） &#125;, "/spring-cloud-provider-service-simple/**": &#123; "id": "spring-cloud-provider-service-simple", "fullPath": "/spring-cloud-provider-service-simple/**", "location": "spring-cloud-provider-service-simple", "path": "/**", "prefix": "/spring-cloud-provider-service-simple", "retryable": false, "customSensitiveHeaders": false, "prefixStripped": true &#125;&#125; filters 端点访问 http://localhost:8989/actuator/filters ，返回当前 zuul 的所有 filters 内置 Filters 名称 类型 顺序 描述 ServletDetectionFilter pre -3 通过 Spring Dispatcher 检查请求是否通过 Servlet30WrapperFilter pre -2 适配 HttpServletRequest 为 Servlet30RequestWrapper 对象 FormBodyWrapperFilter pre -1 解析表单数据，并为下游请求进行重新编码 DebugFilter pre 1 Debug 路由标识 PreDecorationFilter pre 5 处理请求上下文供后续使用，设置下游相关头信息 RibbonRoutingFilter route 10 使用 Ribbon、Hystrix、嵌入式 HTTP 客户端发送请求 SimpleHostRoutingFilter route 100 使用 Apache Httpclient 发送请求 SendForwardFilter route 500 使用 Servlet 转发请求 SendResponseFilter post 1000 将代理请求的响应写入当前响应 SendErrorFilter error 0 如果 RequestContext.getThrowable() 不为空，则转发到 error.path 哦诶之的路径 如果使用 @EnableZuulServer 注解，将减少 PreDecorationFilter、RibbonRoutingFilter、SimpleHostRoutingFilter 如果要替换到某个原生的 Filter，可以自实现一个和原生 Filter 名称、类型一样的 Filter，并替换。或者禁用掉某个filter，并自实现一个新的。禁用语法： zuul.{SimpleClassName}.{filterType}.disable=true，如 zuul.SendErrorFilter.error.disable=true 多级业务处理在 Zuul Filter 链体系中，可以把一组业务逻辑细分，然后封装到一个个紧密结合的 Filter，设置处理顺序，组成一组 Filter 链。 自定义实现 Filter在 Zuul 中实现自定义 Filter，继承 ZuulFilter 类即可，ZuulFilter 是一个抽象类，需要实现以下几个方法 String filterType：使用返回值设定 Filter 类型，可以设置为 pre、route、post、error int filterOrder：使用返回值设置 Filter 执行次序 boolean shouldFilter：使用返回值设定该 Filter 是否执行，可以作为开关来使用 Object run：Filter 的核心执行逻辑 123456789101112131415161718192021222324252627282930// 自定义 ZuulFilterpublic class FirstPreFilter extends ZuulFilter &#123; @Override public String filterType() &#123; return FilterConstants.PRE_TYPE; &#125; @Override public int filterOrder() &#123; return 0; &#125; @Override public boolean shouldFilter() &#123; return true; &#125; @Override public Object run() throws ZuulException &#123; System.out.println("自定义 Filter，类型为 pre！"); return null; &#125;&#125;// 注入 Spring 容器@Beanpublic FirstPreFilter firstPreFilter()&#123; return new FirstPreFilter();&#125; 此时访问 http://localhost:8989/provider/get-result ，查看控制台：12345Initializing Servlet &apos;dispatcherServlet&apos;Completed initialization in 0 ms自定义 Filter，类型为 pre！Flipping property: spring-cloud-provider-service-simple.ribbon.ActiveConnectionsLimit to use NEXT property: niws.loadbalancer.availabilityFilteringRule.activeConnectionsLimit = 2147483647Shutdown hook installed for: NFLoadBalancer-PingTimer-spring-cloud-provider-service-simple 业务处理使用 SecondFilter 验证是否传入参数 a，ThirdPreFilter 验证是否传入参数 b，在 PostFilter 统一处理返回内容。 SecondPreFilter123456789101112131415161718192021222324252627282930313233343536373839404142public class SecondPreFilter extends ZuulFilter &#123; private static final Logger LOGGER = LoggerFactory.getLogger(SecondPreFilter.class); @Override public String filterType() &#123; return FilterConstants.PRE_TYPE; &#125; @Override public int filterOrder() &#123; return 2; &#125; @Override public boolean shouldFilter() &#123; return true; &#125; @Override public Object run() throws ZuulException &#123; LOGGER.info("&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; SecondPreFilter ！ &lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;"); // 获取上下文 RequestContext requestContext = RequestContext.getCurrentContext(); // 从上下文获取 request HttpServletRequest request = requestContext.getRequest(); // 从 request 获取参数 a String a = request.getParameter("a"); // 如果参数 a 为空 if (StringUtils.isBlank(a)) &#123; LOGGER.info("&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; 参数 a 为空！ &lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;"); // 禁止路由，禁止访问下游服务 requestContext.setSendZuulResponse(false); // 设置 responseBody，供 postFilter 使用 requestContext.setResponseBody("&#123;\"status\": 500, \"message\": \"参数 a 为空！\"&#125;"); // 用于下游 Filter 判断是否执行 requestContext.set("logic-is-success", false); // Filter 结束 return null; &#125; requestContext.set("logic-is-success", true); return null; &#125;&#125; ThirdPreFilter12345678910111213141516171819202122232425262728293031323334353637383940414243444546public class ThirdPreFilter extends ZuulFilter &#123; private static final Logger LOGGER = LoggerFactory.getLogger(ThirdPreFilter.class); @Override public String filterType() &#123; return FilterConstants.PRE_TYPE; &#125; @Override public int filterOrder() &#123; return 3; &#125; @Override public boolean shouldFilter() &#123; RequestContext context = RequestContext.getCurrentContext(); // 获取上下文中的 logic-is-success 中的值，用于判断当前 filter 是否执行 return (boolean) context.get("logic-is-success"); &#125; @Override public Object run() throws ZuulException &#123; LOGGER.info("&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; ThirdPreFilter ！ &lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;"); // 获取上下文 RequestContext requestContext = RequestContext.getCurrentContext(); // 从上下文获取 request HttpServletRequest request = requestContext.getRequest(); // 从 request 获取参数 a String a = request.getParameter("b"); // 如果参数 a 为空 if (StringUtils.isBlank(a)) &#123; LOGGER.info("&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; 参数 b 为空！ &lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;"); // 禁止路由，禁止访问下游服务 requestContext.setSendZuulResponse(false); // 设置 responseBody，供 postFilter 使用 requestContext.setResponseBody("&#123;\"status\": 500, \"message\": \"参数 b 为空！\"&#125;"); // 用于下游 Filter 判断是否执行 requestContext.set("logic-is-success", false); // Filter 结束 return null; &#125; requestContext.set("logic-is-success", true); return null; &#125;&#125; PostFilter1234567891011121314151617181920212223242526272829303132333435363738public class PostFilter extends ZuulFilter &#123; private static final Logger LOGGER = LoggerFactory.getLogger(PostFilter.class); @Override public String filterType() &#123; return FilterConstants.POST_TYPE; &#125; @Override public int filterOrder() &#123; return 0; &#125; @Override public boolean shouldFilter() &#123; return true; &#125; @Override public Object run() throws ZuulException &#123; LOGGER.info("&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; Post Filter! &lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;"); RequestContext context = RequestContext.getCurrentContext(); // 处理返回中文乱码 context.getResponse().setCharacterEncoding("UTF-8"); // 获取上下文保存的 responseBody String responseBody = context.getResponseBody(); // 如果 responseBody 不为空，则证明流程中有异常发生 if (StringUtils.isNotBlank(responseBody)) &#123; // 设置返回状态码 context.setResponseStatusCode(500); // 替换响应报文 context.setResponseBody(responseBody); &#125; return null; &#125;&#125; 访问 http://localhost:8989/provider/add 、http://localhost:8989/provider/add?a=1 、http://localhost:8989/provider/add?a=1&amp;b=1 ，查看控制台 控制台：12342019-02-18 14:09:44.890 INFO 5800 --- [nio-8989-exec-7] c.l.g.z.s.filter.FirstPreFilter : &gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; 自定义 Filter，类型为 pre！ &lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;2019-02-18 14:09:44.890 INFO 5800 --- [nio-8989-exec-7] c.l.g.z.s.filter.SecondPreFilter : &gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; SecondPreFilter ！ &lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;2019-02-18 14:09:44.890 INFO 5800 --- [nio-8989-exec-7] c.l.g.z.s.filter.SecondPreFilter : &gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; 参数 a 为空！ &lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;2019-02-18 14:09:44.890 INFO 5800 --- [nio-8989-exec-7] c.l.g.z.s.filter.PostFilter : &gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; Post Filter! &lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt; 123452019-02-18 14:10:13.004 INFO 5800 --- [nio-8989-exec-5] c.l.g.z.s.filter.FirstPreFilter : &gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; 自定义 Filter，类型为 pre！ &lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;2019-02-18 14:10:13.004 INFO 5800 --- [nio-8989-exec-5] c.l.g.z.s.filter.SecondPreFilter : &gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; SecondPreFilter ！ &lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;2019-02-18 14:10:13.004 INFO 5800 --- [nio-8989-exec-5] c.l.g.z.s.filter.ThirdPreFilter : &gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; ThirdPreFilter ！ &lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;2019-02-18 14:10:13.004 INFO 5800 --- [nio-8989-exec-5] c.l.g.z.s.filter.ThirdPreFilter : &gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; 参数 b 为空！ &lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;2019-02-18 14:10:13.005 INFO 5800 --- [nio-8989-exec-5] c.l.g.z.s.filter.PostFilter : &gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; Post Filter! &lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt; 12342019-02-18 14:10:28.488 INFO 5800 --- [nio-8989-exec-9] c.l.g.z.s.filter.FirstPreFilter : &gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; 自定义 Filter，类型为 pre！ &lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;2019-02-18 14:10:28.488 INFO 5800 --- [nio-8989-exec-9] c.l.g.z.s.filter.SecondPreFilter : &gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; SecondPreFilter ！ &lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;2019-02-18 14:10:28.488 INFO 5800 --- [nio-8989-exec-9] c.l.g.z.s.filter.ThirdPreFilter : &gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; ThirdPreFilter ！ &lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;2019-02-18 14:10:28.500 INFO 5800 --- [nio-8989-exec-9] c.l.g.z.s.filter.PostFilter : &gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; Post Filter! &lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt; 返回值：1&#123;"status": 500, "message": "参数 a 为空！"&#125; 1&#123;"status": 500, "message": "参数 b 为空！"&#125; 1result is : a + b = 2 由此验证自定义 Zuul Filter 成功。]]></content>
      <categories>
        <category>spring-cloud</category>
      </categories>
      <tags>
        <tag>SpringCloud</tag>
        <tag>Zuul</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring Cloud 微服务（20） --- Zuul(一) 基本概念、配置]]></title>
    <url>%2Fspring-cloud%2Fspring-cloud-20.html</url>
    <content type="text"><![CDATA[Zuul 是由 Netflix 孵化的一个致力于“网关”的解决方案的开源组件。Zuul 在动态路由、监控、弹性、服务治理、安全等方面有着举足轻重的作用。Zuul 底层为 Servlet，本质组件是一系列 Filter 构成的责任链。 Zuul 具备的功能 认证、鉴权 压力控制 金丝雀测试（灰度发布） 动态路由 负载削减 静态响应处理 主动流量控制 Zuul 入门案例Zuul ServerServer源码：https://gitee.com/laiyy0728/spring-cloud/tree/master/spring-cloud-zuul/spring-cloud-zuul-simpleClient源码：https://gitee.com/laiyy0728/spring-cloud/tree/master/spring-cloud-zuul/spring-cloud-zuul-provider-service-simple pom、yml12345678910&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-zuul&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 1234567891011121314151617spring: application: name: spring-cloud-zuul-simpleserver: port: 8989eureka: client: service-url: defaultZone: http://localhost:8761/eureka/ instance: instance-id: $&#123;spring.application.name&#125;:$&#123;server.port&#125; prefer-ip-address: truezuul: routes: # zuul 路由配置，map 结构 spring-cloud-provider-service-simple: # 针对哪个服务进行路由 path: /provider/** # 路由匹配什么规则。 当前配置为 provider 开头的请求路由到 provider-service 上 # serviceId: spring-cloud-provider-service-simple # 路由到哪个 serviceId 上（即哪个服务），可不设置 启动类12345678910@SpringBootApplication@EnableDiscoveryClient@EnableZuulProxy // 开启 Zuul 代理public class SpringCloudZuulSimpleApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(SpringCloudZuulSimpleApplication.class, args); &#125;&#125; 验证先请求 provider-service： http://localhost:8081/get-result 再请求 zuul server： http://localhost:8989/provider/get-result 可以看到，响应结果一致，但通过 Zuul Server 的请求路径多了 /provider，由此验证 zuul server 路由代理成功 典型配置在上例中，路由规则的配置12345zuul: routes: spring-cloud-provider-service-simple: path: /provider/** serviceId: spring-cloud-provider-service-simple 实际上，可以将这个配置进行简化 指定路由的简化123zuul: routes: spring-cloud-provider-service-simple: /provider/** 默认简化默认简化可以不指定路由规则： 123zuul: routes: spring-cloud-provider-service-simple: 此时简化配置，相当于：12345zuul: routes: spring-cloud-provider-service-simple: path: /spring-cloud-provider-service-simple/** serviceId: spring-cloud-provider-service-simple 多实例路由一般情况下，一个服务会有多个实例，此时需要对这个服务进行负载均衡。默认情况下，Zuul 会使用 Eureka 中集成的基本负载均衡功能（轮询）。 如果需要使用 Ribbon 的负载均衡功能，有两种方式： Ribbon 脱离 Eureka 使用需要在 routes 配置中指定 serviceId，这个操作需要禁止 Ribbon 使用 Eureka。此方式必须指定 serviceId1234567891011121314zuul: routes: spring-cloud-provider-service-simple: # 服务名称，需要和下方配置一致 path: /ribbon-route/** serviceId: spring-cloud-provider-service-simple # serviceId，需要和下方配置一致ribbon: eureka: enabled: false # 禁用掉 Eurekaspring-cloud-provider-service-simple: # 服务名称，需要和上方配置一致 ribbon: NIWSServerListClassName: com.netflix.loadbalancer.ConfigurationBasedServerList # 设置 ServerList 的配置 NFLoadBalancerRuleClassName: com.netflix.loadbalancer.RandomRule # 设置负载均衡策略 listOfServers: http://localhost:8080,http://localhost:8081 # 负载的 server 列表 Ribbon 不脱离 Eureka 使用直接使用 ribbon 路由配置即可此方式可以不指定 serviceId12345678zuul: routes: spring-cloud-provider-service-simple: path: /ribbon-route/**spring-cloud-provider-service-simple: ribbon: NFLoadBalancerRuleClassName: com.netflix.loadbalancer.RandomRule Zuul 本地跳转如果在 zuul 中做一些逻辑处理，在访问某个接口时，跳转到 zuul 中的这个方法上来处理，就需要用到 zuul 本地跳转 12345zuul: routes: spring-cloud-provider-service-simple: path: /provider/** # 只有访问 /provider 的时候才会 forward，但凡后面多一个路径就不行了。。。 为啥。。。 url: forward:/client 此时，访问：http://localhost:8989/client ，可以访问到，访问 http://localhost:8989/provider ，也能访问到，如果访问 http://localhost:8989/provider/get-result ，理论上应该也能跳转到 /client，但是实际上会报 404 错误1234567&#123; "timestamp": "2019-02-15T06:50:12.565+0000", "status": 404, "error": "Not Found", "message": "No message available", "path": "/provider/get-result"&#125; 如果去掉 url: forward:/client，再访问 http://localhost:8989/provider/get-result ，结果正常：12345678910111213```## Zuul 相同路径加载规则```ymlzuul: routes: spring-cloud-provider-service-simple-a: path: /provider/** serviceId: spring-cloud-provider-service-simple-a spring-cloud-provider-service-simple-b: path: /provider/** serviceId: spring-cloud-provider-service-simple-b 可以发现，/provider/ 匹配了2个 serviceId，这个匹配结果只会路由到最后一个服务上。即：/provider/ 只会被路由到 simple-b 服务上。yml 解释器在工作时，如果同一个映射路径对应了多个服务，按照加载顺序，后面的规则会把前面的规则覆盖掉。 路由通配符 规则 解释 示例 /** 匹配任意数据量的路径与字符 /client/aa，/client/aa/bb/cc /* 匹配任意数量的字符 /client/aa，/client/aaaaaaaaaaaaaa /? 匹配单个字符 /client/a，/client/b，/client/c 功能配置路由配置在配置路由规则时，可以配置一个统一的前缀123456zuul: routes: spring-cloud-provider-service-simple: path: /provider/** serviceId: spring-cloud-provider-service-simple prefix: /api 访问 http://localhost:8989/provider/get-result1234567&#123; "timestamp": "2019-02-15T07:16:46.625+0000", "status": 404, "error": "Not Found", "message": "No message available", "path": "/provider/get-result"&#125; 访问 http://localhost:8989/api/provider/get-result1this is provider service! this port is: 8081 这样的设置，会将每个访问访问前都加上 prefix 前缀，但是实际上访问的是 path 配置的路径。如果某个服务不需要前缀，访问路径就是 prefix + path，则只需要在对应的服务配置设置 stripPrefix: false 即可 1234567zuul: routes: spring-cloud-provider-service-simple: path: /provider/** serviceId: spring-cloud-provider-service-simple stripPrefix: false prefix: /api 此时访问： http://localhost:8989/pre/provider/get-result ，返回值为：1234567&#123; "timestamp": "2019-02-15T07:24:33.271+0000", "status": 404, "error": "Not Found", "message": "No message available", "path": "/pre/provider/get-result"&#125; 对比两个 404 错误，可以看到，同样是访问 /pre/provider/get-result，没有设置 stripPrefix: false 时，path 为 /provider/get-result，设置 stripPrefix: false 时，path 为 /pre/provider/get-result。即：设置 stripPrefix: false 时，请求路径和实际路径是一致的。 服务屏蔽、路径屏蔽为了避免某些服务、路径被侵入，可以将其屏蔽掉12345678zuul: routes: spring-cloud-provider-service-simple: path: /provider/** serviceId: spring-cloud-provider-service-simple ignored-services: spring-cloud-provider-service-simple # 此配置会在 zuul 路由时，忽略掉该服务 ignored-patterns: /**/get-result/** # 此配置会在 zuul 路由时，忽略掉可以匹配的路径 prefix: /pre 敏感头信息正常访问时，provider-service 接收到的 headers 为：1234567891011121314cache-control: no-cacheuser-agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/71.0.3578.98 Safari/537.36postman-token: 43dbfb6e-f529-543e-99d9-5d0a06bf79e6accept: */*accept-encoding: gzip, deflate, braccept-language: zh-CN,zh;q=0.9x-forwarded-host: localhost:8989x-forwarded-proto: httpx-forwarded-prefix: /providerx-forwarded-port: 8989x-forwarded-for: 0:0:0:0:0:0:0:1content-length: 0host: 10.10.10.141:8081connection: Keep-Alive 设置敏感头：123456zuul: routes: spring-cloud-provider-service-simple: path: /provider/** serviceId: spring-cloud-provider-service-simple sensitiveHeaders: postman-token,x-forwarded-for,Cookie 此时再次访问，获取 headers123456789101112cache-control: no-cacheuser-agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/71.0.3578.98 Safari/537.36accept: */*accept-encoding: gzip, deflate, braccept-language: zh-CN,zh;q=0.9x-forwarded-host: localhost:8989x-forwarded-proto: httpx-forwarded-prefix: /providerx-forwarded-port: 8989content-length: 0host: 10.10.10.141:8081connection: Keep-Alive 对比发现，sensitiveHeaders 配置的 headers 在 provider-service 中已经接收不到了。默认情况下，sensitiveHeaders 会忽略三个 header：Cookie、Set-Cookie、Authorization]]></content>
      <categories>
        <category>spring-cloud</category>
      </categories>
      <tags>
        <tag>SpringCloud</tag>
        <tag>Zuul</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring Cloud 微服务（19） --- Actuator(二) 运行时度量]]></title>
    <url>%2Fspring-cloud%2Fspring-cloud-19.html</url>
    <content type="text"><![CDATA[运行时度量端点，包括： /metrics、/trace、/threaddump、/health 等 运行时度量端点metrics 端点访问结果metrics 端点主要用于在项目运行中，查看计数器、度量器等，如：当前可用内存、空闲内存等 访问：http://localhost:8080/actuator/metrics ，可用查看所有的计数器、度量器名称， 访问 http://localhost:8080/actuator/metrics/{name} 可以查看具体信息 http://localhost:8080/actuator/metrics123456789&#123; "names": [ "jvm.memory.max", "jvm.threads.states", "jvm.gc.pause", "http.server.requests", "jvm.gc.memory.promoted" ]&#125; http://localhost:8080/actuator/metrics/jvm.memory.max12345678910111213141516171819202122232425262728&#123; "name": "jvm.memory.max", // 名称 "description": "The maximum amount of memory in bytes that can be used for memory management", // 介绍 "baseUnit": "bytes", // 单位 "measurements": [&#123; "statistic": "VALUE", "value": 5579472895 // 大小，单位 bytes &#125;], "availableTags": [&#123; "tag": "area", "values": [ "heap", "nonheap" ] &#125;, &#123; "tag": "id", "values": [ "Compressed Class Space", "PS Survivor Space", "PS Old Gen", "Metaspace", "PS Eden Space", "Code Cache" ] &#125; ]&#125; http://localhost:8080/actuator/metrics/http.server.requests1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768&#123; "name": "http.server.requests", "description": null, "baseUnit": "seconds", "measurements": [&#123; "statistic": "COUNT", "value": 28 // 发起的请求总数 &#125;, &#123; "statistic": "TOTAL_TIME", "value": 1.9647074519999999 // 总时长 &#125;, &#123; "statistic": "MAX", "value": 0.002769728 &#125; ], "availableTags": [&#123; "tag": "exception", "values": [ "None" ] &#125;, &#123; "tag": "method", "values": [ "GET" ] &#125;, &#123; "tag": "uri", "values": [ // 访问过的 uri "/actuator/caches", "/**/favicon.ico", "/actuator/threaddump", "/actuator/env/&#123;toMatch&#125;", "/actuator/loggers", "/actuator/mappings", "/actuator/auditevents", "/**", "/actuator/env", "/actuator/metrics/&#123;requiredMetricName&#125;", "/actuator", "/actuator/beans", "/actuator/httptrace", "/actuator/loggers/&#123;name&#125;", "/actuator/scheduledtasks", "/actuator/conditions", "/actuator/heapdump", "/actuator/metrics" ] &#125;, &#123; "tag": "outcome", "values": [ "CLIENT_ERROR", "SUCCESS" ] &#125;, &#123; "tag": "status", "values": [ "404", "200" ] &#125; ]&#125; metrics 端点介绍 前缀 分类 介绍 jvm.gc.* 垃圾收集器 已经发生过的垃圾收集次数、消耗时间，使用与标记-请求垃圾收集器和并行垃圾收集器java.lang.management.GarbageCollectorMXBean jvm.memory.* 内存相关 分配给应用程序的内存数量和空闲的内容数量等 java.lang.Runtime jvm.classes.* 类加载器 JVM 类加载器加载与卸载的类的数量 java.lang.management.ClassLoadingMXBean process.*、system.cpu 系统 系统信息，如：处理器数量java.lang.Runtime、运行时间java.lang.management.RuntimeMXBean、平均负载java.lang.management.OperatingSystemMXBean jvm.threads.* JVM 线程池 JVM 线程、守护线程数量、峰值等 java.lang.management.ThreadMXBean tomcat.* tomcat tomcat 相关内容 datasource.* 数据源 数据源链接数据等，仅当 Spring 上下文存在 DataSource 才会有这个信息 httptrace 端点httptrace 端点主要用于报告所有的 web 请求的详细信息，包括：请求方法、路径、时间戳、头信息等。http://localhost:8080/actuator/httptrace/ 1234567891011121314151617181920212223242526&#123; "traces": [&#123; "timestamp": "2019-02-13T06:29:35.039Z", // 时间戳 "principal": null, "session": null, "request": &#123; // 请求 "method": "GET", // 请求方式 "uri": "http://localhost:8080/actuator/httptrace/", // 请求路径 "headers": &#123; // 请求 Headers "cookie": [ "yfx_c_g_u_id_10000001=_ck19021309350014873926766957773; yfx_f_l_v_t_10000001=f_t_1550021700485__r_t_1550021700485__v_t_1550021700485__r_c_0" ] &#125;, "remoteAddress": null // 远程地址 &#125;, "response": &#123; // 响应 "status": 200, // 响应码 "headers": &#123; // 响应 Header "Content-Type": [ "application/vnd.spring-boot.actuator.v2+json;charset=UTF-8" ] &#125; &#125;, "timeTaken": 36 // 用时 &#125;]&#125; 需要注意，/httptrace 端点只能显示最近的 100 个请求信息，其中也包含对 /httptrace 端点自己的请求。 threaddump 端点threaddump 端点可以查看的应用程序的每个线程，其中包含线程的阻塞状态、所状态等，http://localhost:8080/actuator/threaddump/ 123456789101112131415161718192021&#123; "threads": [&#123; "threadName": "DestroyJavaVM", // 线程名称 "threadId": 44, // 线程 id "blockedTime": -1, "blockedCount": 0, "waitedTime": -1, "waitedCount": 0, "lockName": null, "lockOwnerId": -1, "lockOwnerName": null, "inNative": false, "suspended": false, "threadState": "RUNNABLE", // 线程状态 "stackTrace": [], // 跟踪栈 "lockedMonitors": [], "lockedSynchronizers": [], "lockInfo": null &#125; ]&#125; health 端点health 端点：查看当前应用程序的运行状态。 http://localhost:8080/actuator/health/123&#123; "status": "UP"&#125; health 端点在特定情况下，会有额外的信息，如：登录状态、数据库状态等 Spring Boot 自带的监控指示器 键 健康指示器 说明 none ApplicationHealthIndicator 永远为 UP db DataSourceHealthIndicator 如果数据库能连上，则内容为 UP 和数据库类型；否则为 DOWN diskSpace DiskSpaceHealthIndicator 如果可用空间大于阈值，则内容为 UP 和可用磁盘内容；否则为 DOWN jms JmsHealthIndicator 如果能连上消息代理，则为 UP 和 JMS 提供方名称；否则为 DOWN mail MailHealthIndicator 如果能连上邮件服务器，则内容为 UP 个邮件服务器主机、端口；否则为 DOWN mongo MongoHealthIndicator 如果能连上 MongoDb 服务器，则内容为 UP 和 MongoDB 服务器版本；否则为 DOWN rabbit RabbitHealthIndicator 如果能连上 Rabbit 服务器，则内容为 UP 和 Rabbit 版本号；否则为 DOWN redis RedisHealthIndicator 如果能连上 Redis 服务器，则内容为 UP 和 Redis 服务器版本；否则为 DOWN solr SolrHealthIndicator 如果能连上 Solr 服务器，则内容为 UP ；否则为 DOWN 关闭应用程序关闭应用程序可以使用 /actuator/shutdown 端点，使用 POST 请求 http://localhost:8080/actuator/shutdown1234567&#123; "timestamp": "2019-02-13T07:46:54.614+0000", "status": 404, "error": "Not Found", "message": "No message available", "path": "/actuator/shutdown"&#125; 这是因为为了保护应用程序，shutdown 端点没有打开的原因，需要打开 shutdown 端点1234management: endpoint: shutdown: enabled: true 再次请求：123&#123; "message": "Shutting down, bye..."&#125; 获取应用信息获取应用信息使用 /actuator/info 端点，默认的响应是：1&#123;&#125; 可以通过带 info 前缀的属性，向 info 端点的响应增加内容，如：1234info: contect: email: laiyy0728@gmail.com phone: 18888888888 再次请求：123456&#123; "contect": &#123; "email": "laiyy0728@gmail.com", "phone": 18888888888 &#125;&#125;]]></content>
      <categories>
        <category>spring-cloud</category>
      </categories>
      <tags>
        <tag>SpringCloud</tag>
        <tag>SpringBoot</tag>
        <tag>Actuator</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring Cloud 微服务（18） --- Actuator(一) 常见端点、配置明细端点]]></title>
    <url>%2Fspring-cloud%2Fspring-cloud-18.html</url>
    <content type="text"><![CDATA[在 Hystrix Dashboard 中，使用了 /actuator/hystrix.stream，查看正在运行的项目的运行状态。 其中 /actuator 代表 SpringBoot 中的 Actuator 模块。该模版提供了很多生产级别的特性，如：监控、度量应用。Actuator 的特性可以通过众多的 REST 端点，远程 shell、JMX 获得。 源码：https://gitee.com/laiyy0728/spring-cloud/tree/master/spring-boot-actuator 常见 Actuator 端点 路径省略前缀：/actuator 路径 HTTP 动作 描述 /conditions GET 提供了一份自动配置报告，记录哪些自动配置条件通过了，哪些没通过 /configprops GET 描述配置属性（包含默认值）如何注入 Bean /caches GET 获取所有的 Cachemanager /caches/{cache} DELETE 移除某个 CacheManager /beans GET 描述应用程序上下文全部 bean，以及他们的关系 /threaddump GET 获取线程活动快照 /env GET 获取全部环境属性 /env/{toMatch} GET 获取指定名称的特定环境的属性值 /health GET 报告应用长须的健康指标，由 HealthIndicator 的实现提供 /httptrace GET 提供基本的 HTTP 请求跟踪信息(时间戳、HTTP 头等) /info GET 获取应用程序定制信息，由 Info 开头的属性提供 /loggers GET 获取 bean 的日志级别 /loggers/{name} GET 获取某个 包、类 路径端点的日志级别 /loggers/{name} POST 新增某个 包、类 路径端点的日志级别 /mappings GET 描述全部的 URL 路径，以及它们和控制器(包含Actuator端点)的映射关系 /metrics GET 报告各种应用程序度量信息，如：内存用量、HTTP 请求计数 /metrics/{name} GET 根据名称获取度量信息 /shutdown POST 关闭应用，要求 endpoints.shutdown.enabled 为 true /scheduledtasks GET 获取所有定时任务信息 SpringCloud 中，默认开启了 /actuator/health、/actuator/info 端点，其他端点都屏蔽掉了。如果需要开启，自定义开启 endpoints 即可12345management: endpoints: web: exposure: exclude: ['health','info','beans','env'] 如果要开启全部端点，设置 exclude: * 即可 配置明细端点引入pom文件，设置 yml123456&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt; 12345management: endpoints: web: exposure: include: '*' beans 端点使用 /actuator/beans 端点，获取 JSON 格式的 bean 装配信息。访问： http://localhost:8080/actuator/beans12345678910111213141516171819&#123; "contexts": &#123; "application": &#123; "beans": &#123; "webEndpointDiscoverer": &#123; // bean 名称 "aliases": [], // bean 别名 "scope": "singleton", // bean 作用域 "type": "org.springframework.boot.actuate.endpoint.web.annotation.WebEndpointDiscoverer", // bean 类型 "resource": "class path resource [org/springframework/boot/actuate/conditionsure/endpoint/web/WebEndpointconditionsuration.class]", // class 文件物理地址 "dependencies": [ // 当前 bean 注入的 bean 的列表 "endpointOperationParameterMapper", "endpointMediaTypes" ] &#125;, "parentId": null &#125; &#125; &#125;&#125; conditions 端点/beans 端点可以看到当前 Spring 上下文有哪些 bean， /conditions 端点可以看到为什么有这个 beanSpringBoot 自动配置构建与 Spring 的条件化配置之上，提供了众多的 @Conditional 注解的配置类，根据 @Conditional 条件决定是否自动装配这些 bean。/conditions 端点提供了一个报告，列出了所有条件，根据条件是否通过进行分组 访问 http://localhost:8080/actuator/conditions 123456789101112131415161718192021222324252627282930&#123; "contexts": &#123; "application": &#123; "positiveMatches": &#123; // 成功的自动装配 "AuditEventsEndpointAutoConfiguration#auditEventsEndpoint": [&#123; "condition": "OnBeanCondition", // 装配条件 "message": "@ConditionalOnBean (types: org.springframework.boot.actuate.audit.AuditEventRepository; SearchStrategy: all) found bean 'auditEventRepository'; @ConditionalOnMissingBean (types: org.springframework.boot.actuate.audit.AuditEventsEndpoint; SearchStrategy: all) did not find any beans" // 装配信息 &#125;, &#123; "condition": "OnEnabledEndpointCondition", "message": "@ConditionalOnEnabledEndpoint no property management.endpoint.auditevents.enabled found so using endpoint default" &#125; ], &#125;, "negativeMatches": &#123; // 失败的自动装配 "RabbitHealthIndicatorAutoConfiguration": &#123; "notMatched": [ // 没有匹配到的条件 &#123; "condition": "OnClassCondition", "message": "@ConditionalOnClass did not find required class 'org.springframework.amqp.rabbit.core.RabbitTemplate'" &#125;], "matched": [] // 匹配到的条件 &#125;, &#125;, "unconditionalClasses": [ // 无条件装配 "org.springframework.boot.actuate.autoconfigure.management.HeapDumpWebEndpointAutoConfiguration" ] &#125; &#125;&#125; 可以看到，在 negativeMatches 的 RabbitHealthIndicatorAutoConfiguration 自动状态，没有匹配到 org.springframework.amqp.rabbit.core.RabbitTemplate 类，所有没有自动装配。 env 端点123456789101112131415161718192021222324252627282930313233343536373839404142&#123; "activeProfiles": [], // 启用的 profile "propertySources": [&#123; "name": "server.ports", // 端口设置 "properties": &#123; "local.server.port": &#123; "value": 8080 // 本地端口 &#125; &#125; &#125;, &#123; "name": "servletContextInitParams", // servlet 上下文初始化参数信息 "properties": &#123;&#125; &#125;, &#123; "name": "systemProperties", // 系统配置 "properties": &#123; "java.runtime.name": &#123; // 配置名称 "value": "Java(TM) SE Runtime Environment" // 配置值 &#125; &#125; &#125;, &#123; "name": "systemEnvironment", // 系统环境 "properties": &#123; "USERDOMAIN_ROAMINGPROFILE": &#123; "value": "DESKTOP-QMHTL6V", // 环境名称 "origin": "System Environment Property \"USERDOMAIN_ROAMINGPROFILE\"" // 环境值 &#125; &#125; &#125;, &#123; "name": "applicationConfig: [classpath:/application.yml]", // 配置文件信息 "properties": &#123; "management.endpoints.web.exposure.include": &#123; // 配置文件 key "value": "*", // 配置文件 value "origin": "class path resource [application.yml]:5:18" // 位置 &#125; &#125; &#125; ]&#125; mappings 端点mappings 端点可以生成一份 控制器到端点 的映射，即 访问路径与控制器 的映射 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970&#123; "contexts": &#123; "application": &#123; "mappings": &#123; "dispatcherServlets": &#123; // 所有的 DispatcherServlet "dispatcherServlet": [&#123; // DispatcherServlet "handler": "ResourceHttpRequestHandler [class path resource [META-INF/resources/], class path resource [resources/], class path resource [static/], class path resource [public/], ServletContext resource [/], class path resource []]", // 处理器 "predicate": "/**/favicon.ico", // 映射路径 "details": null &#125;, &#123; "handler": "public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map&lt;java.lang.String, java.lang.String&gt;)", "predicate": "&#123;[/actuator/auditevents],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]&#125;", // 断言（包含端点、请求方式、类型等） "details": &#123; // 详细信息 "handlerMethod": &#123; // 处理器 "className": "org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping.OperationHandler", // handle 实现类 "name": "handle", // 处理器名称 "descriptor": "(Ljavax/servlet/http/HttpServletRequest;Ljava/util/Map;)Ljava/lang/Object;" // 描述符 &#125;, "requestMappingConditions": &#123; // 请求映射条件 "consumes": [], // 入参类型 "headers": [], // 入参头 "methods": [ // 请求方式 "GET" ], "params": [], // 参数 "patterns": [ "/actuator/auditevents" // 请求 URL ], "produces": [&#123; // 返回值类型 "mediaType": "application/vnd.spring-boot.actuator.v2+json", "negated": false &#125;, &#123; "mediaType": "application/json", "negated": false &#125; ] &#125; &#125; &#125; ] &#125;, "servletFilters": [&#123; // 所有 Filters "servletNameMappings": [], // servlet 名称映射 "urlPatternMappings": [ "/*" // filter 过滤路径 ], "name": "webMvcMetricsFilter", // filter 名称 "className": "org.springframework.boot.actuate.metrics.web.servlet.WebMvcMetricsFilter" // Filter 实现类 &#125; ], "servlets": [&#123; // 所有 Servlet "mappings": [], // 映射 "name": "default", // servlet 名称 "className": "org.apache.catalina.servlets.DefaultServlet" // servlet 实现类 &#125;, &#123; "mappings": [ "/" ], "name": "dispatcherServlet", "className": "org.springframework.web.servlet.DispatcherServlet" &#125; ] &#125;, "parentId": null &#125; &#125;&#125;]]></content>
      <categories>
        <category>spring-cloud</category>
      </categories>
      <tags>
        <tag>SpringCloud</tag>
        <tag>SpringBoot</tag>
        <tag>Actuator</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring Cloud 微服务（17） ---Hystrix(五) Hystrix 优化]]></title>
    <url>%2Fspring-cloud%2Fspring-cloud-17.html</url>
    <content type="text"><![CDATA[Hystrix Collapser 是 Hystrix 退出的针对多个请求，调用单个后端依赖的一种优化和节约网络开销的方法。在一般情况下，每个请求会开启一个线程，并开启一个对服务调用的网络连接，而 Collapser 可以将多个请求的线程合并起来，只需要一个线程和一个网络开销来调用服务，大大减少了并发和请求执行所需的线程数和网络连接，尤其是在一个时间段内非常多的请求情况下，能极大提高资源利用率。 Hystrix Collapser源码：https://gitee.com/laiyy0728/spring-cloud/tree/master/spring-cloud-hystrix/spring-cloud-hsytrix-collapser 实例pom、yml1234567891011121314&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-openfeign&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-hystrix&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 1234567891011121314server: port: 8989spring: application: name: spring-cloud-hystrix-collapsereureka: client: service-url: defaultZone: http://localhost:8761/eureka instance: instance-id: $&#123;spring.application.name&#125;:$&#123;server.port&#125; prefer-ip-address: true service、config、controller123456789public interface ICollapserService &#123; Future&lt;Animal&gt; collapsing(Integer id); Animal collapsingSyn(Integer id); Future&lt;Animal&gt; collapsingGlobal(Integer id);&#125; 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960@Componentpublic class CollpaserServiceImpl implements ICollapserService &#123; @Override @HystrixCollapser(batchMethod = "collapsingList", collapserProperties = &#123; @HystrixProperty(name = HystrixPropertiesManager.TIMER_DELAY_IN_MILLISECONDS, value = "1000") &#125;) public Future&lt;Animal&gt; collapsing(Integer id) &#123; return null; &#125; @Override @HystrixCollapser(batchMethod = "collapsingList", collapserProperties = &#123; @HystrixProperty(name = HystrixPropertiesManager.TIMER_DELAY_IN_MILLISECONDS, value = "1000") &#125;) public Animal collapsingSyn(Integer id) &#123; return null; &#125; @Override @HystrixCollapser(batchMethod = "collapsingListGlobal", scope = com.netflix.hystrix.HystrixCollapser.Scope.GLOBAL, collapserProperties = &#123; @HystrixProperty(name = HystrixPropertiesManager.TIMER_DELAY_IN_MILLISECONDS, value = "10000") &#125;) public Future&lt;Animal&gt; collapsingGlobal(Integer id) &#123; return null; &#125; @HystrixCommand public List&lt;Animal&gt; collapsingList(List&lt;Integer&gt; animalParam) &#123; System.out.println("collapsingList 当前线程：" + Thread.currentThread().getName()); System.out.println("当前请求参数个数：" + animalParam.size()); List&lt;Animal&gt; animalList = Lists.newArrayList(); animalParam.forEach(num -&gt; &#123; Animal animal = new Animal(); animal.setName(" Cat - " + num); animal.setAge(num); animal.setSex("male"); animalList.add(animal); &#125;); return animalList; &#125; @HystrixCommand public List&lt;Animal&gt; collapsingListGlobal(List&lt;Integer&gt; animalParam) &#123; System.out.println("collapsingList 当前线程：" + Thread.currentThread().getName()); System.out.println("当前请求参数个数：" + animalParam.size()); List&lt;Animal&gt; animalList = Lists.newArrayList(); animalParam.forEach(num -&gt; &#123; Animal animal = new Animal(); animal.setName(" Dog - " + num); animal.setAge(num); animal.setSex("female"); animalList.add(animal); &#125;); return animalList; &#125;&#125; 123456789101112131415161718192021222324252627@Configurationpublic class CollapserConfiguration &#123; @Bean @ConditionalOnClass(Controller.class) public HystrixCollapserInterceptor hystrixCollapserInterceptor()&#123; return new HystrixCollapserInterceptor(); &#125; @Configuration @ConditionalOnClass(Controller.class) public class WebMvcConfig extends WebMvcConfigurationSupport&#123; private final HystrixCollapserInterceptor interceptor; @Autowired public WebMvcConfig(HystrixCollapserInterceptor interceptor) &#123; this.interceptor = interceptor; &#125; @Override protected void addInterceptors(InterceptorRegistry registry) &#123; registry.addInterceptor(interceptor); &#125; &#125;&#125; 1234567891011121314151617181920212223242526272829303132333435363738@RestControllerpublic class CollapserController &#123; private final ICollapserService collapserService; @Autowired public CollapserController(ICollapserService collapserService) &#123; this.collapserService = collapserService; &#125; @GetMapping("/get-animal") public String getAnimal() throws Exception&#123; Future&lt;Animal&gt; animal = collapserService.collapsing(1); Future&lt;Animal&gt; animal2 = collapserService.collapsing(2); System.out.println(animal.get().getName()); System.out.println(animal2.get().getName()); return "success"; &#125; @GetMapping(value = "/get-animal-syn") public String getAnimalSyn() throws Exception&#123; Animal animal1 = collapserService.collapsingSyn(1); Animal animal2 = collapserService.collapsingSyn(2); System.out.println(animal1.getName()); System.out.println(animal2.getName()); return "success"; &#125; @GetMapping(value = "/get-animal-global") public String getAnimalGlobal() throws Exception &#123; Future&lt;Animal&gt; animal1 = collapserService.collapsingGlobal(1); Future&lt;Animal&gt; animal2 = collapserService.collapsingGlobal(2); System.out.println(animal1.get().getName()); System.out.println(animal2.get().getName()); return "success"; &#125;&#125; 验证访问： http://localhost:8989/get-animal 、http://localhost:8989/get-animal-syn 、 http://localhost:8989/get-animal-global ，查看控制台： http://localhost:8989/get-animal：1234collapsingList 当前线程：hystrix-CollpaserServiceImpl-1当前请求参数个数：2 Cat - 1 Cat - 2 http://localhost:8989/get-animal-syn：123456collapsingList 当前线程：hystrix-CollpaserServiceImpl-2当前请求参数个数：1collapsingList 当前线程：hystrix-CollpaserServiceImpl-3当前请求参数个数：1 Cat - 1 Cat - 2 http://localhost:8989/get-animal-global：1234collapsingListGlobal 当前线程：hystrix-CollpaserServiceImpl-4当前请求参数个数：2 Dog - 1 Dog - 2 可以看到，get-animal、gei-animal-global 合并了请求，get-animal-syn 没有合并请求 注意点 要合并的请求，必须返回 Future，通过在实现类上增加 @HystrixCollapser 注解，之后调用该方法来实现请求合并。（需要特别注意：方法返回值不是 Future 无法合并请求） @HystrixCollapser 表示合并请求，调用该注解标注的方法时，实际上调用的是 batchMethod 方法，且利用 HystrixProperty 指定 timerDelayInMilliseconds，表示合并多少 ms 之内的请求。默认是 10ms 如果不在 @HystrixCollapser 中添加 scope=GLOBAL ，则只会合并服务的多次请求。当 scope=GLOBAL 时，会合并规定时间内的所有服务的多次请求。 scope 有两个值， REQUEST\GLOBAL。 REQUEST 表示合并单个服务的调用，GLOBAL 表示合并所有服务的调用。默认为 REQUEST。 总结Hystrix Collapser 主要用于请求合并的场景。当在某个时间内有大量或并发的相同请求时，适用于请求合并；如果在某个时间内只有很少的请求，且延迟也不高，使用请求反而会增加复杂度和延迟，Collapser 本身也需要时间进行处理。 Hystrix 线程传递、并发源码：https://gitee.com/laiyy0728/spring-cloud/tree/master/spring-cloud-hystrix/spring-cloud-hystrix-thread Hystrix 的两种隔离策略：线程隔离、信号量隔离。 如果是信号量隔离，则 Hystrix 在请求时会尝试获取一个信号量，如果成功拿到，则继续请求，该请求在一个线程内完成。如果是线程隔离，Hystrix 会把请求放入线程池执行，这是可能产生线程变化，导致线程1的上下文在线程2中无法获取到。 不适应 Hystrix 调用pom、yml 等不再赘述 service、controller12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364// 接口public interface IThreadService &#123; String getUser(int id);&#125;// 具体调用实现@Componentpublic class ThreadServiceImpl implements IThreadService &#123; private static final Logger LOGGER = LoggerFactory.getLogger(ThreadServiceImpl.class); private final RestTemplate restTemplate; @Autowired public ThreadServiceImpl(RestTemplate restTemplate) &#123; this.restTemplate = restTemplate; &#125; @Override public String getUser(int id) &#123; LOGGER.info("================================== Service =================================="); LOGGER.info(" ThreadService, Current thread id : &#123;&#125;", Thread.currentThread().getId()); LOGGER.info(" ThreadService, HystrixThreadLocal: &#123;&#125;", HystrixThreadLocal.threadLocal.get()); LOGGER.info(" ThreadService, RequestContextHolder: &#123;&#125;", RequestContextHolder.currentRequestAttributes().getAttribute("userId", RequestAttributes.SCOPE_REQUEST)); // 这里调用的是 spring-cloud-hystrix-cache 的 provider return restTemplate.getForObject("http://spring-cloud-hystrix-cache-provider-user/get-user/&#123;1&#125;", String.class, id); &#125;&#125;// thread localpublic class HystrixThreadLocal &#123; public static ThreadLocal&lt;String&gt; threadLocal = new InheritableThreadLocal&lt;&gt;();&#125;// controller@RestControllerpublic class ThreadController &#123; private static final Logger LOGGER = LoggerFactory.getLogger(ThreadController.class); private final IThreadService threadService; @Autowired public ThreadController(IThreadService threadService) &#123; this.threadService = threadService; &#125; @GetMapping(value = "/get-user/&#123;id&#125;") public String getUser(@PathVariable int id) &#123; // 放入上下文 HystrixThreadLocal.threadLocal.set("userId:" + id); // 利用 RequestContextHolder RequestContextHolder.currentRequestAttributes().setAttribute("userId", "userId:" + id, RequestAttributes.SCOPE_REQUEST); LOGGER.info("================================== Controller =================================="); LOGGER.info(" ThreadService, Current thread id : &#123;&#125;", Thread.currentThread().getId()); LOGGER.info(" ThreadService, HystrixThreadLocal: &#123;&#125;", HystrixThreadLocal.threadLocal.get()); LOGGER.info(" ThreadService, RequestContextHolder: &#123;&#125;", RequestContextHolder.currentRequestAttributes().getAttribute("userId", RequestAttributes.SCOPE_REQUEST)); return threadService.getUser(id); &#125;&#125; 验证访问 http://localhost:8989/get-user/1 ，查看控制台输出12345678================================== Controller ==================================ThreadService, Current thread id : 37ThreadService, HystrixThreadLocal: userId:1ThreadService, RequestContextHolder: userId:1================================= Service ==================================ThreadService, Current thread id : 37ThreadService, HystrixThreadLocal: userId:1ThreadService, RequestContextHolder: userId:1 可以看到， thread id 是一样的，userid 也是一样的，这说明了此时是使用一个线程进行调用。 Hystrix 分线程调用在 Service 的实现类上增加 @HystrixCommand 注解，重启再次访问，查看可控制台输出如下：1234567================================== Controller ==================================ThreadService, Current thread id : 36ThreadService, HystrixThreadLocal: userId:1ThreadService, RequestContextHolder: userId:1================================= Service ==================================ThreadService, Current thread id : 60ThreadService, HystrixThreadLocal: userId:1 并在 ThreadService, RequestContextHolder 的位置抛出如下异常：12345678910java.lang.IllegalStateException: No thread-bound request found: Are you referring to request attributes outside of an actual web request, or processing a request outside of the originally receiving thread? If you are actually operating within a web request and still receive this message, your code is probably running outside of DispatcherServlet: In this case, use RequestContextListener or RequestContextFilter to expose the current request. at org.springframework.web.context.request.RequestContextHolder.currentRequestAttributes(RequestContextHolder.java:131) ~[spring-web-5.1.2.RELEASE.jar:5.1.2.RELEASE] at com.laiyy.gitee.hystrix.thread.springcloudhystrixthread.service.ThreadServiceImpl.getUser(ThreadServiceImpl.java:36) ~[classes/:na] at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[na:1.8.0_171] at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[na:1.8.0_171] at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:1.8.0_171] at java.lang.reflect.Method.invoke(Method.java:498) ~[na:1.8.0_171] at com.netflix.hystrix.contrib.javanica.command.MethodExecutionAction.execute(MethodExecutionAction.java:116) ~[hystrix-javanica-1.5.12.jar:1.5.12] at com.netflix.hystrix.contrib.javanica.command.MethodExecutionAction.executeWithArgs(MethodExecutionAction.java:93) ~[hystrix-javanica-1.5.12.jar:1.5.12] ... 可以看到，在 controller 中，线程id是 36，在 service 中，线程id是 60，线程id不一致，可以证明线程隔离已经生效了。此时 controller 调用 @HystrixCommand 标注的方法时，是分线程处理的；RequestContextHolder 中报错：没有线程变量绑定。 解决办法解决办法有两种：修改 Hystrix 隔离策略，使用信号量即可；使用 HystrixConcurrencyStrategy(官方推荐) 使用 HystrixConcurrencyStrategy 实现 wrapCallable 方法，对于依赖的 ThreadLocal 状态以实现应用程序功能的系统至关重要。 官方文档wrapCallable 方法源码：12345678910111213141516/** * Provides an opportunity to wrap/decorate a &#123;@code Callable&lt;T&gt;&#125; before execution. * &lt;p&gt; * This can be used to inject additional behavior such as copying of thread state (such as &#123;@link ThreadLocal&#125;). * &lt;p&gt; * &lt;b&gt;Default Implementation&lt;/b&gt; * &lt;p&gt; * Pass-thru that does no wrapping. * * @param callable * &#123;@code Callable&lt;T&gt;&#125; to be executed via a &#123;@link ThreadPoolExecutor&#125; * @return &#123;@code Callable&lt;T&gt;&#125; either as a pass-thru or wrapping the one given */public &lt;T&gt; Callable&lt;T&gt; wrapCallable(Callable&lt;T&gt; callable) &#123; return callable;&#125; 通过重写这个方法，实现想要封装的线程参数方法。可以看到，返回值是一个 Callable，所以需要首先实现一个 Callable 类，在该类中，在执行请求之前，包装 HystrixThreadCallable 对象，传递 RequestContextHolder、HystrixThreadLocal 类，将需要的对象信息设置进去，这样在下一个线程中就可以拿到了。 具体实现1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889// Callablepublic class HystrixThreadCallable&lt;S&gt; implements Callable&lt;S&gt; &#123; private final RequestAttributes requestAttributes; private final Callable&lt;S&gt; callable; private String params; public HystrixThreadCallable(RequestAttributes requestAttributes, Callable&lt;S&gt; callable, String params) &#123; this.requestAttributes = requestAttributes; this.callable = callable; this.params = params; &#125; @Override public S call() throws Exception &#123; try &#123; // 在执行请求之前，包装请求参数 RequestContextHolder.setRequestAttributes(requestAttributes); HystrixThreadLocal.threadLocal.set(params); // 执行具体请求 return callable.call(); &#125; finally &#123; RequestContextHolder.resetRequestAttributes(); HystrixThreadLocal.threadLocal.remove(); &#125; &#125;&#125;// HystrixConcurrencyStrategypublic class SpringCloudHystrixConcurrencyStrategy extends HystrixConcurrencyStrategy &#123; private HystrixConcurrencyStrategy hystrixConcurrencyStrategy; @Override public &lt;T&gt; Callable&lt;T&gt; wrapCallable(Callable&lt;T&gt; callable) &#123; // 传入需要传递到分线程的参数 return new HystrixThreadCallable&lt;&gt;(RequestContextHolder.currentRequestAttributes(), callable, HystrixThreadLocal.threadLocal.get()); &#125; public SpringCloudHystrixConcurrencyStrategy() &#123; init(); &#125; private void init() &#123; try &#123; this.hystrixConcurrencyStrategy = HystrixPlugins.getInstance().getConcurrencyStrategy(); if (this.hystrixConcurrencyStrategy instanceof SpringCloudHystrixConcurrencyStrategy)&#123; return; &#125; HystrixCommandExecutionHook commandExecutionHook = HystrixPlugins.getInstance().getCommandExecutionHook(); HystrixEventNotifier eventNotifier = HystrixPlugins.getInstance().getEventNotifier(); HystrixMetricsPublisher metricsPublisher = HystrixPlugins.getInstance().getMetricsPublisher(); HystrixPropertiesStrategy propertiesStrategy = HystrixPlugins.getInstance().getPropertiesStrategy(); HystrixPlugins.reset(); HystrixPlugins.getInstance().registerConcurrencyStrategy(this); HystrixPlugins.getInstance().registerCommandExecutionHook(commandExecutionHook); HystrixPlugins.getInstance().registerEventNotifier(eventNotifier); HystrixPlugins.getInstance().registerMetricsPublisher(metricsPublisher); HystrixPlugins.getInstance().registerPropertiesStrategy(propertiesStrategy); &#125;catch (Exception e)&#123; throw e; &#125; &#125; @Override public ThreadPoolExecutor getThreadPool(HystrixThreadPoolKey threadPoolKey, HystrixProperty&lt;Integer&gt; corePoolSize, HystrixProperty&lt;Integer&gt; maximumPoolSize, HystrixProperty&lt;Integer&gt; keepAliveTime, TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue) &#123; return this.hystrixConcurrencyStrategy.getThreadPool(threadPoolKey, corePoolSize, maximumPoolSize, keepAliveTime, unit, workQueue); &#125; @Override public ThreadPoolExecutor getThreadPool(HystrixThreadPoolKey threadPoolKey, HystrixThreadPoolProperties threadPoolProperties) &#123; return this.hystrixConcurrencyStrategy.getThreadPool(threadPoolKey, threadPoolProperties); &#125; @Override public BlockingQueue&lt;Runnable&gt; getBlockingQueue(int maxQueueSize) &#123; return this.hystrixConcurrencyStrategy.getBlockingQueue(maxQueueSize); &#125; @Override public &lt;T&gt; HystrixRequestVariable&lt;T&gt; getRequestVariable(HystrixRequestVariableLifecycle&lt;T&gt; rv) &#123; return this.hystrixConcurrencyStrategy.getRequestVariable(rv); &#125;&#125; 验证重启后访问： http://localhost:8989/get-user/1 ，查看控制台输出12345678================================= Controller ==================================ThreadService, Current thread id : 39ThreadService, HystrixThreadLocal: userId:1ThreadService, RequestContextHolder: userId:1================================= Service ==================================ThreadService, Current thread id : 73ThreadService, HystrixThreadLocal: userId:1ThreadService, RequestContextHolder: userId:1 可以看到，线程id不一样，但是 RequestContextHolder、HystrixThreadLocal 的值都可以在分线程中拿到了。 注意点在 SpringCloudHystrixConcurrencyStrategy#init() 中，HystrixPlugins.getInstance().registerConcurrencyStrategy() 方法，只能被调用一次，否则会出现错误。源码解释：1234567891011121314/** * Register a &#123;@link HystrixConcurrencyStrategy&#125; implementation as a global override of any injected or default implementations. * * @param impl * &#123;@link HystrixConcurrencyStrategy&#125; implementation * @throws IllegalStateException * // 如果多次调用或在初始化默认值之后（如果在尝试注册之前发生了使用） 会抛出异常 * if called more than once or after the default was initialized (if usage occurs before trying to register) */public void registerConcurrencyStrategy(HystrixConcurrencyStrategy impl) &#123; if (!concurrencyStrategy.compareAndSet(null, impl)) &#123; throw new IllegalStateException("Another strategy was already registered."); &#125;&#125; Hystrix 命令注解HystrixCommand作用：封装执行的代码，具有故障延迟容错、断路器、统计等功能，是阻塞命令，可以与 Observable 公用 com.netflix.hystrix.HystrixCommand 类123456789101112/** * Used to wrap code that will execute potentially risky functionality (typically meaning a service call over the network) * with fault and latency tolerance, statistics and performance metrics capture, circuit breaker and bulkhead functionality. * This command is essentially a blocking command but provides an Observable facade if used with observe() * * @param &lt;R&gt; * the return type * * @ThreadSafe */public abstract class HystrixCommand&lt;R&gt; extends AbstractCommand&lt;R&gt; implements HystrixExecutable&lt;R&gt;, HystrixInvokableInfo&lt;R&gt;, HystrixObservable&lt;R&gt; &#123;&#125; 用于包装将执行潜在风险功能的代码（通常意味着通过网络进行服务调用）具有故障和延迟限，统计和性能指标捕获，断路器和隔板功能。该命令本质上是一个阻塞命令，但如果与observe（）一起使用，则提供一个Observable外观 HystrixObservableCommand123456789101112/** * Used to wrap code that will execute potentially risky functionality (typically meaning a service call over the network) * with fault and latency tolerance, statistics and performance metrics capture, circuit breaker and bulkhead functionality. * This command should be used for a purely non-blocking call pattern. The caller of this command will be subscribed to the Observable&lt;R&gt; returned by the run() method. * * @param &lt;R&gt; * the return type * * @ThreadSafe */public abstract class HystrixObservableCommand&lt;R&gt; extends AbstractCommand&lt;R&gt; implements HystrixObservable&lt;R&gt;, HystrixInvokableInfo&lt;R&gt; &#123;&#125; 用于包装将执行潜在风险功能的代码（通常意味着通过网络进行服务调用）具有故障和延迟限，统计和性能指标捕获，断路器和隔板功能。此命令应该用于纯粹的非阻塞调用模式。 此命令的调用者将订阅run（）方法返回的Observable 。 区别 HystrixCommand 默认是阻塞的可以提供同步、异步两种方式；HystrixObservableCommand 是非阻塞的，只能提供异步的方式 HystrixCommand 的方法是 run；HystrixObservableCommand 的方法是 construct HystrixCommand 一个实例一次只能发一条数据，HystrixObservableCommand 可以发送多条数据 HystrixCommand 注解： commandKey：全局唯一标识符，如果不设置，默认是方法名 defaultFallback：默认 fallback 方法，不能有入参，返回值和方法保持一致，比 fallbackMethod 的优先级低 fallbackMethod：指定处理回退逻辑的方法，必须和 HystrixCommand 标注的方法在通一个类里，参数、返回值要保持一致 ignoreExceptions：定义不希望哪些异常被 fallback，而是直接抛出 commandProperties：配置命名属性，如隔离策略 threadPoolProperties：配置线程池相关属性 groupKey：全局唯一分组名称，内部会根据这个值展示统计数、仪表盘等，默认使的线程划分是根据组名称进行的，一般会在创建 HystrixCommand 时指定组来实现默认的线程池划分 threadPoolKey：对服务的线程池信息进行设置，用于 HystrixThreadPool 监控、metrics、缓存等。]]></content>
      <categories>
        <category>spring-cloud</category>
      </categories>
      <tags>
        <tag>SpringCloud</tag>
        <tag>Hystrix</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring Cloud 微服务（16） --- Hystrix(四) Hystrix 优化]]></title>
    <url>%2Fspring-cloud%2Fspring-cloud-16.html</url>
    <content type="text"><![CDATA[Hystrix 的优化可以从线程、请求缓存、线程传递与并发、命令注解、Collapser 请求合并 等方面入手优化 Hystrix 线程调整线程的调整主要依赖于在生产环境中的实际情况与服务器配置进行相对应的调整，由于生产环境不可能完全一致，所以没有一个具体的值。 请求缓存Hystrix 请求缓存是 Hystrix 在同一个上下文请求中缓存请求结果，与传统缓存有区别。Hystrix 的请求缓存是在同一个请求中进行，在第一次请求调用结束后对结果缓存，然后在接下来同参数的请求会使用第一次的结果。Hystrix 请求缓存的声明周期为一次请求。传统缓存的声明周期根据时间需要设定，最长可能长达几年。 Hystrix 请求有两种方式：继承 HystrixCommand 类、使用 @HystrixCommand 注解。Hystrix 缓存同时支持这两种方案。 Cache Consumer源码：https://gitee.com/laiyy0728/spring-cloud/tree/master/spring-cloud-hystrix/spring-cloud-hystrix-cache/spring-cloud-hystrix-cache-impl pom、yml1234567891011121314&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-openfeign&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-hystrix&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 12345678910111213server: port: 8989spring: application: name: spring-cloud-hystrix-cache-impleureka: instance: instance-id: $&#123;spring.application.name&#125;:$&#123;server.port&#125; prefer-ip-address: true client: service-url: defaultZone: http://localhost:8761/eureka/ Interceptor12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667public class CacheContextInterceptor implements HandlerInterceptor &#123; private HystrixRequestContext context; /** * 请求前 */ @Override public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception &#123; context = HystrixRequestContext.initializeContext(); return true; &#125; /** * 请求 */ @Override public void postHandle(HttpServletRequest request, HttpServletResponse response, Object handler, ModelAndView modelAndView) throws Exception &#123; &#125; /** * 请求后 */ @Override public void afterCompletion(HttpServletRequest request, HttpServletResponse response, Object handler, Exception ex) throws Exception &#123; context.shutdown(); &#125;&#125;/** * 将 Interceptor 注册到Spring MVC 控制器 */@Configurationpublic class CacheConfiguration &#123; /** * 声明一个 cacheContextInterceptor 注入 Spring 容器 */ @Bean @ConditionalOnClass(Controller.class) public CacheContextInterceptor cacheContextInterceptor()&#123; return new CacheContextInterceptor(); &#125; @Configuration @ConditionalOnClass(Controller.class) public class WebMvcConfig extends WebMvcConfigurationSupport&#123; private final CacheContextInterceptor interceptor; @Autowired public WebMvcConfig(CacheContextInterceptor interceptor) &#123; this.interceptor = interceptor; &#125; /** * 将 cacheContextInterceptor 添加到拦截器中 */ @Override protected void addInterceptors(InterceptorRegistry registry) &#123; registry.addInterceptor(interceptor); &#125; &#125;&#125; @HystrixCommand 方式12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849// feign 调用接口public interface IHelloService &#123; String hello(int id); String getUserToCommandKey(@CacheKey int id); String updateUser(@CacheKey int id);&#125;// 具体实现@Componentpublic class HelloServiceImpl implements IHelloService &#123; private final RestTemplate restTemplate; @Autowired public HelloServiceImpl(RestTemplate restTemplate) &#123; this.restTemplate = restTemplate; &#125; @Override @CacheResult @HystrixCommand public String hello(int id) &#123; String result = restTemplate.getForObject("http://spring-cloud-hystrix-cache-provider-user/get-user/&#123;1&#125;", String.class, id); System.out.println("正在进行远程调用：hello " + result); return result; &#125; @Override @CacheResult @HystrixCommand(commandKey = "getUser") public String getUserToCommandKey(int id) &#123; String result = restTemplate.getForObject("http://spring-cloud-hystrix-cache-provider-user/get-user/&#123;1&#125;", String.class, id); System.out.println("正在进行远程调用：getUserToCommandKey " + result); return result; &#125; @Override @CacheRemove(commandKey = "getUser") @HystrixCommand public String updateUser(int id) &#123; System.out.println("正在进行远程调用：updateUser " + id); return "update success"; &#125;&#125; 继承 HystrixCommand 类形式123456789101112131415161718192021222324252627282930313233343536public class HelloCommand extends HystrixCommand&lt;String&gt; &#123; private RestTemplate restTemplate; private int id; public HelloCommand(RestTemplate restTemplate, int id)&#123; super(HystrixCommandGroupKey.Factory.asKey("springCloudCacheGroup")); this.id = id; this.restTemplate = restTemplate; &#125; @Override protected String run() throws Exception &#123; String result = restTemplate.getForObject("http://spring-cloud-hystrix-cache-provider-user/get-user/&#123;1&#125;", String.class, id); System.out.println("正在使用继承 HystrixCommand 方式进行远程调用：" + result); return result; &#125; @Override protected String getFallback() &#123; return "hello command fallback"; &#125; @Override protected String getCacheKey() &#123; return String.valueOf(id); &#125; public static void cleanCache(int id) &#123; HystrixRequestCache.getInstance( HystrixCommandKey.Factory.asKey("springCloudCacheGroup"), HystrixConcurrencyStrategyDefault.getInstance()) .clear(String.valueOf(id)); &#125;&#125; Controller12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970@RestControllerpublic class CacheController &#123; private final RestTemplate restTemplate; private final IHelloService helloService; @Autowired public CacheController(RestTemplate restTemplate, IHelloService helloService) &#123; this.restTemplate = restTemplate; this.helloService = helloService; &#125; /** * 缓存测试 */ @GetMapping(value = "/get-user/&#123;id&#125;") public String getUser(@PathVariable int id) &#123; helloService.hello(id); helloService.hello(id); helloService.hello(id); helloService.hello(id); return "getUser success!"; &#125; /** * 缓存更新 */ @GetMapping(value = "/get-user-id-update/&#123;id&#125;") public String getUserIdUpdate(@PathVariable int id)&#123; helloService.hello(id); helloService.hello(id); helloService.hello(5); helloService.hello(5); return "getUserIdUpdate success!"; &#125; /** * 继承 HystrixCommand 方式 */ @GetMapping(value = "/get-user-id-by-command/&#123;id&#125;") public String getUserIdByCommand(@PathVariable int id)&#123; HelloCommand helloCommand = new HelloCommand(restTemplate, id); helloCommand.execute(); System.out.println("from Cache:" + helloCommand.isResponseFromCache()) ; helloCommand = new HelloCommand(restTemplate, id); helloCommand.execute(); System.out.println("from Cache:" + helloCommand.isResponseFromCache()) ; return "getUserIdByCommand success!"; &#125; /** * 缓存、清除缓存 */ @GetMapping(value = "/get-and-update/&#123;id&#125;") public String getAndUpdateUser(@PathVariable int id)&#123; // 缓存数据 helloService.getUserToCommandKey(id); helloService.getUserToCommandKey(id); // 缓存清除 helloService.updateUser(id); // 再次缓存 helloService.getUserToCommandKey(id); helloService.getUserToCommandKey(id); return "getAndUpdateUser success!"; &#125;&#125; Cache Service源码：https://gitee.com/laiyy0728/spring-cloud/tree/master/spring-cloud-hystrix/spring-cloud-hystrix-cache/spring-cloud-hystrix-cache-provider-user pom、yml123456789101112131415&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-hystrix&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-openfeign&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 12345678910111213server: port: 9999spring: application: name: spring-cloud-hystrix-cache-provider-usereureka: instance: prefer-ip-address: true instance-id: $&#123;spring.application.name&#125;:$&#123;server.port&#125; client: service-url: defaultZone: http://localhost:8761/eureka/ Controller12345678910111213141516@RestControllerpublic class UserController &#123; @GetMapping(value = "/get-user/&#123;id&#125;") public User getUser(@PathVariable int id) &#123; switch (id) &#123; case 1: return new User("zhangsan", "list", 22); case 2: return new User("laiyy", "123456", 24); default: return new User("hahaha", "error", 0); &#125; &#125;&#125; 验证验证 @HystrixCommand 注解形式缓存请求 http://localhost:8989/get-user/2 ，查看控制台输出，发现控制台输出一次：1正在进行远程调用：hello &#123;&quot;username&quot;:&quot;laiyy&quot;,&quot;password&quot;:&quot;123456&quot;,&quot;age&quot;:24&#125; 在 HelloServiceImpl 中，去掉 hello 方法的 @CacheResult 注解，重新启动后请求，发现控制台输出了 4 次：1234正在进行远程调用：hello &#123;&quot;username&quot;:&quot;laiyy&quot;,&quot;password&quot;:&quot;123456&quot;,&quot;age&quot;:24&#125;正在进行远程调用：hello &#123;&quot;username&quot;:&quot;laiyy&quot;,&quot;password&quot;:&quot;123456&quot;,&quot;age&quot;:24&#125;正在进行远程调用：hello &#123;&quot;username&quot;:&quot;laiyy&quot;,&quot;password&quot;:&quot;123456&quot;,&quot;age&quot;:24&#125;正在进行远程调用：hello &#123;&quot;username&quot;:&quot;laiyy&quot;,&quot;password&quot;:&quot;123456&quot;,&quot;age&quot;:24&#125; 由此验证 @HystrixCommand 注解形式缓存成功 验证 @HystrixCommand 形式中途修改参数请求 http://localhost:8989/get-user-id-update/2 ，查看控制台，发现控制台输出：12正在进行远程调用：hello &#123;&quot;username&quot;:&quot;laiyy&quot;,&quot;password&quot;:&quot;123456&quot;,&quot;age&quot;:24&#125;正在进行远程调用：hello &#123;&quot;username&quot;:&quot;hahaha&quot;,&quot;password&quot;:&quot;error&quot;,&quot;age&quot;:0&#125; 由此验证在调用 hello 方法时，hello 的参数改变后，会再次进行远程调用 验证清理缓存请求 http://localhost:8989/get-and-update/2 ，查看控制，发现控制台输出： 123正在进行远程调用：getUserToCommandKey &#123;&quot;username&quot;:&quot;laiyy&quot;,&quot;password&quot;:&quot;123456&quot;,&quot;age&quot;:24&#125;正在进行远程调用：updateUser 2正在进行远程调用：getUserToCommandKey &#123;&quot;username&quot;:&quot;laiyy&quot;,&quot;password&quot;:&quot;123456&quot;,&quot;age&quot;:24&#125; 修改 update 方法的 commandKey，重新启动项目，再次请求，发现控制台输出：12正在进行远程调用：getUserToCommandKey &#123;&quot;username&quot;:&quot;laiyy&quot;,&quot;password&quot;:&quot;123456&quot;,&quot;age&quot;:24&#125;正在进行远程调用：updateUser 2 比较后发现，修改 commandKey 后，没有进行再次调用，证明 update 没有清理掉 getUserToCommandKey 的缓存。由此验证在调用 getUserToCommandKey 方法时，会根据 commandKey 进行缓存，在调用 updateUser 方法时，会根据 commandKey 进行缓存删除。缓存删除后再次调用，会再次调用远程接口。 继承 HystrixCommand 方式访问 http://localhost:8989/get-user-id-by-command/2 ，查看控制台： 123正在使用继承 HystrixCommand 方式进行远程调用：&#123;&quot;username&quot;:&quot;laiyy&quot;,&quot;password&quot;:&quot;123456&quot;,&quot;age&quot;:24&#125;from Cache:falsefrom Cache:true 可以看到，第二次请求中，isResponseFromCache 为 true，证明缓存生效。 由上面几种方式请求可以验证，Husyrix 的缓存可以由 @HystrixCommand 实现，也可以由继承 HystrixCommand 实现。 总结 @CacheResult：使用该注解后，调用结果会被缓存，要和 @HystrixCommand 同时使用，注解参数用 cacheKeyMethod @CacheRemove：清除缓存，需要指定 commandKey，参数为 commandKey、cacheKeyMethod @CacheKey：指定请求参数，默认使用方法的所有参数作为缓存 key，直接属性为 value。一般在读操作接口上使用 @CacheResult、在写操作接口上使用 @CacheRemove 注意事项：再一些请求量大或者重复调用接口的情况下，可以利用缓存有效减轻请求压力，但是在使用 Hystrix 缓存时，需要注意： 需要开启 @EnableHystrix 需要初始化 HystrixRequestContext 在指定了 HystrixCommand 的 commandKey 后，在 @CacheRemove 也要指定 commandKey 如果不初始化 HystrixRequestContext，即在 CacheContextInterceptor 中不使用 HystrixRequestContext.initializeContext() 初始化，进行调用时会出现如下错误：1234java.lang.IllegalStateException: Request caching is not available. Maybe you need to initialize the HystrixRequestContext? at com.netflix.hystrix.HystrixRequestCache.get(HystrixRequestCache.java:104) ~[hystrix-core-1.5.12.jar:1.5.12] at com.netflix.hystrix.AbstractCommand$7.call(AbstractCommand.java:478) ~[hystrix-core-1.5.12.jar:1.5.12] ... 另外，使用 RestTemplate 进行远程调用时，在指定远程服务时，如果出现如下错误，需要在 RestTemplate 上使用 @LoadBalance1234567java.net.UnknownHostException: spring-cloud-hystrix-cache-provider-user at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184) ~[na:1.8.0_171] at java.net.PlainSocketImpl.connect(PlainSocketImpl.java:172) ~[na:1.8.0_171] at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392) ~[na:1.8.0_171] at java.net.Socket.connect(Socket.java:589) ~[na:1.8.0_171] at java.net.Socket.connect(Socket.java:538) ~[na:1.8.0_171] ...]]></content>
      <categories>
        <category>spring-cloud</category>
      </categories>
      <tags>
        <tag>SpringCloud</tag>
        <tag>Hystrix</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring Cloud 微服务（15） --- Hystrix(三) Turbine、异常处理]]></title>
    <url>%2Fspring-cloud%2Fspring-cloud-15.html</url>
    <content type="text"><![CDATA[Hystrix Dashboard 需要输入单个服务的 hystrix.stream 监控端点，只能监控单个服务，当需要监控整个系统和集群的时候，这种方式就显得很鸡肋，此时可以使用 Turbine 来做监控。 Turbine 是为了聚合所有相关的 hystrix.stream 流的方案，然后在 hystrix dashboard 中展示。 Turbine源码：https://gitee.com/laiyy0728/spring-cloud/tree/master/spring-cloud-hystrix/spring-cloud-hystrix-dashboard/spring-cloud-hystrix-dashboard-turbine 微服务继续沿用上例中的 hello-service、provider-service，新建 Turbine 项目 pom123456789101112131415161718&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-turbine&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-hystrix&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-hystrix-dashboard&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 配置文件1234567891011121314151617181920212223server: port: 9999spring: application: name: spring-cloud-hystrix-dashboard-turbneeureka: instance: prefer-ip-address: true instance-id: $&#123;spring.application.name&#125;:$&#123;server.port&#125; client: service-url: defaultZone: http://localhost:8761/eureka/management: endpoints: web: exposure: exclude: hystrix.stream # Turbine 要监控的端点turbine: app-config: spring-cloud-hystrix-dashboard-hello-service,spring-cloud-hystrix-dashboard-provider-service # Turbine 要监控的服务 cluster-name-expression: "'default'" # 集群名称，默认 default 启动类1234567891011@SpringBootApplication@EnableDiscoveryClient@EnableHystrixDashboard@EnableTurbine // 开启 Turbinepublic class SpringCloudHystrixDashboardTurbineApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(SpringCloudHystrixDashboardTurbineApplication.class, args); &#125;&#125; 验证浏览器中访问 Turbine： http://localhost:9999/hystrix ，输入 Turbine 监控端点：http://localhost:9999/turbine.stream 访问 hello-service(http://localhost:8080/get-provider-data)、provider-service(http://localhost:8081/get-hello-service)，再次查看 turbine 异常处理源码：https://gitee.com/laiyy0728/spring-cloud/tree/master/spring-cloud-hystrix/spring-cloud-hystrix-dashboard/spring-cloud-hystrix-dashboard-exception Hystrix 的异常处理中，有五种出错情况会被 Fallback 截获，触发 Fallbac FAILURE：执行失败，抛出异常 TIMEOUT：执行超时 SHORT_CIRCUITED：断路器打开 THREAD_POOL_REJECTED：线程池拒绝 SEMAPHORE_REJECTED：信号量拒绝 但是有一种类型的异常不会触发 Fallback 且不会被计数、不会熔断——BAD_REQUEST。BAD_ERQUEST 会抛出 HystrixBadRequestException，这种异常一般是因为对应的参数或系统参数异常引起的，对于这类异常，可以根据响应创建对应的异常进行异常封装或直接处理。 BAD_REQUEST 处理pom1234567891011121314&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-hystrix&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-openfeign&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 配置文件123456789101112131415161718192021222324server: port: 9999spring: application: name: spring-cloud-hystrix-dashboard-exceptioneureka: client: service-url: defaultZone: http://localhost:8761/eureka/ instance: prefer-ip-address: true instance-id: $&#123;spring.application.name&#125;:$&#123;server.port&#125;management: endpoints: web: exposure: exclude: hystrix.streamfeign: hystrix: enabled: true 异常处理在 Hystrix 中处理异常，需要继承 HystrixCommand 并重写 run、getFallback 方法 bad request12345678910111213141516171819202122public class FallBackBadRequestException extends HystrixCommand&lt;String&gt; &#123; private static final Logger LOGGER = LoggerFactory.getLogger(FallBackBadRequestException.class); public FallBackBadRequestException() &#123; // HystrixCommand 分组 key super(HystrixCommandGroupKey.Factory.asKey("GroupBadRequestException")); &#125; @Override protected String run() throws Exception &#123; // 直接抛出异常，模拟 BAD_REQUEST throw new HystrixBadRequestException("this is HystrixBadRequestException！"); &#125; // Fallback 回调 @Override protected String getFallback() &#123; System.out.println("Fallback 错误信息：" + getFailedExecutionException().getMessage()); return "this is HystrixBadRequestException Fallback method!"; &#125;&#125; 其他错误12345678910111213141516public class FallBackOtherException extends HystrixCommand&lt;String&gt; &#123; public FallBackOtherException() &#123; super(HystrixCommandGroupKey.Factory.asKey("otherException")); &#125; @Override protected String run() throws Exception &#123; throw new Exception("other exception"); &#125; @Override protected String getFallback() &#123; return "fallback!"; &#125;&#125; 模拟 feign 调用1234567891011121314151617181920public class ProviderServiceCommand extends HystrixCommand&lt;String&gt; &#123; private final String name; public ProviderServiceCommand(String name)&#123; super(HystrixCommandGroupKey.Factory.asKey("springCloud")); this.name = name; &#125; @Override protected String run() throws Exception &#123; // 模拟 feign 远程调用返回 return "spring cloud!" + name; &#125; @Override protected String getFallback() &#123; return "spring cloud fail!"; &#125;&#125; Controller1234567891011121314151617181920212223242526272829303132333435@RestControllerpublic class ExceptionController &#123; private static final Logger LOGGER = LoggerFactory.getLogger(ExceptionController.class); // 模拟 feign 调用 @GetMapping(value = "provider-service-command") public String providerServiceCommand()&#123; return new ProviderServiceCommand("laiyy").execute(); &#125; // bad Request @GetMapping(value = "fallback-bad-request") public String fallbackBadRequest()&#123; return new FallBackBadRequestException().execute(); &#125; // 其他错误 @GetMapping(value = "fallback-other") public String fallbackOther()&#123; return new FallBackOtherException().execute(); &#125; // @HystrixCommand 处理 Fallback @GetMapping(value = "fallback-method") @HystrixCommand(fallbackMethod = "fallback") public String fallbackMethod(String id)&#123; throw new RuntimeException("fallback method !"); &#125; public String fallback(String id, Throwable throwable)&#123; LOGGER.error("&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; 进入 @HystrixCommand fallback！"); return "this is @HystrixCommand fallback!"; &#125;&#125; 验证依次请求 Controller 中的接口，可以看到，除了 fallback-bad-request 外，其他的接口都进入了 Fallback 方法中。证明了 BAD_REQUEST 不会触发 Fallback。 BAD_REQUEST Fallback可以使用 ErrorDecoder 对 BAD_REQUEST 进行包装 12345678910111213141516@Componentpublic class BadRequestErrorDecoder implements ErrorDecoder &#123; @Override public Exception decode(String methodKey, Response response) &#123; if (response.status() &gt;= 400 &amp;&amp; response.status() &lt;= 499) &#123; String error = null; try &#123; error = Util.toString(response.body().asReader()); &#125; catch (IOException e) &#123; System.out.println("BadRequestErrorDecoder 出错了！" + e.getLocalizedMessage()); &#125; return new HystrixBadRequestException(error); &#125; return FeignException.errorStatus(methodKey, response); &#125;&#125; 之后在 yml 配置文件中增加对微服务调用的 ErrorDecoder 配置 1234567feign: hystrix: enabled: true client: config: spring-cloud-hystrix-dashboard-provider-service: # 针对哪个服务 errorDecoder: com.laiyy.gitee.dashboard.springcloudhystrixdashboardexception.decoder.BadRequestErrorDecoder # 错误解码器 Hystrix 配置一个简单的 Hystrix 配置，基本有一下几个内容12345678910111213141516171819202122232425hystrix: command: default: # default 为全局配置，如果需要针对某个 Fallback 配置，需要使用 HystrixCommandKey circuitBreaker: errorThresholdPercentage: 50 # 这是打开 Fallback 并启动 Fallback 的错误比例。默认 50% forceOpen: false # 是否强制打开断路器，拒绝所有请求。默认 false execution: isolation: strategy: THREAD # SEMAPHORE 请求隔离策略，默认 THREAD # 当 strategy 为 THREAD 时 thread: timeoutInMilliseconds: 5000 # 执行超时时间 默认 1000 interruptOnTimeout: true # 超时时是否中断执行，默认 true # 当 strategy 为 SEMAPHORE 时 semaphore: maxConcurrentRequests: 10 # 最大允许请求数，默认 10 # 是否开启超时 timeout: enabled: true # 默认 true # 当隔离策略为 thread 时 threadpool: default: # default 为全局配置，如果需要再很对某个 线程池 配置，需要使用 HystrixThreadPoolKey coreSize: 10 # 默认线程池大小，默认 10 maximumSize: 10 # 最大线程池，默认 10 allowMaximumSizeToDivergeFromCoreSize: false # 是否允许 maximumSize 配置生效 隔离策略123456hystrix: command: default: execution: isolation: strategy: THREAD # SEMAPHORE 请求隔离策略，默认 THREAD 隔离策略有两种：线程隔离策略和信号量隔离策略。分别对应：THREAD、SEMAPHORE。 线程隔离Hystrix 默认的隔离策略，通过线程池大小可以控制并发量，当线程饱和时，可以拒绝服务，防止出现问题。 优点： 完全隔离第三方应用，请求线程可以快速收回 请求线程可以继续接受新的请求，如果出现线程问题，线程池隔离是独立的，不会影响其他应用 当失败的应用再次变得可用时，线程池将清理并可以立即恢复 独立的线程池提高了并发性 缺点： 增加CPU开销，每个命令的执行都涉及到线程的排队、调度、上下文切换等。 信号量隔离使用一个原子计数器(信号量)来记录当前有多少线程正在运行，当请求进来时，先判断计数器的数值(默认10)，如果超过设置则拒绝请求，否则正常执行，计数器+1。成功执行后，计数器-1。 与线程隔离的最大区别是，执行请求的线程依然是请求线程，而不是线程隔离中分配的线程池。 对单个 HystrixCommand 配置隔离策略等1234@HystrixCommand(fallbackMethod = "defaultUser", commandProperties = &#123; // 配置线程隔离策略， value 可以是 THREAD 或 SEMAPHORE @HystrixProperty(name = HystrixPropertiesManager.EXECUTION_ISOLATION_STRATEGY, value = "THREAD")&#125;) 应用场景线程隔离：第三方应用、接口；并发量大信号量隔离：内部应用、中间件(redis)；并发量不大 HystrixCommandKey、HystrixThreadPoolKeyHystrixCommandKey 是一个 @HystrixCommand 注解标注的方法的 key，默认为标注方法的方法名，也可以使用 @HystrixCommand 进行配置HystrixThreadPoolKey 是 Hystrix 开启线程隔离策略后，指定的线程池名称，可以使用 @HystrixCommand 配置 12345678910111213@HystrixCommand(fallbackMethod = "defaultUser", // 隔离策略 commandProperties = &#123; @HystrixProperty(name = HystrixPropertiesManager.EXECUTION_ISOLATION_STRATEGY, value = "THREAD")&#125;, // HystrixCommandKey commandKey = "commandKey", // HystrixThreadPoolKey threadPoolKey = "threadPoolKey", // 线程隔离策略配置超时时间 threadPoolProperties = &#123; @HystrixProperty(name = HystrixPropertiesManager.EXECUTION_ISOLATION_THREAD_INTERRUPT_ON_TIMEOUT, value = "5000")&#125;)]]></content>
      <categories>
        <category>spring-cloud</category>
      </categories>
      <tags>
        <tag>SpringCloud</tag>
        <tag>Hystrix</tag>
        <tag>Turbine</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring Cloud 微服务（14） --- Hystrix(二) Hystrix Dashboard]]></title>
    <url>%2Fspring-cloud%2Fspring-cloud-14.html</url>
    <content type="text"><![CDATA[Hystrix Dashboard 仪表盘，是根据系统一段时间内发生的请求情况来展示的可视化面板，这些信息是每个 HystrixCommand 执行过程中的信息，这些信息是一个指标集合，和具体的系统运行情况。 Hystrix DashboardHystrix 的指标需要 actuator 端点进行支撑，所以需要 actuator 依赖，并公开 hsytrix.stream 端点，以便能够被顺利访问。关于 Actuator 在后面会有详细解释。 示例hello-service、provider-service 是两个集成 hystrix 的微服务，服务互相调用。hello-service 调用 provider-service 的 get-dashboard 接口。provider-servoce 调用 hello-service 的 hello-service 接口。 hello-service源码：https://gitee.com/laiyy0728/spring-cloud/tree/master/spring-cloud-hystrix/spring-cloud-hystrix-dashboard/spring-cloud-hystrix-dashboard-hello-service pom1234567891011121314&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-hystrix&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-openfeign&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; ymlapplication.yml12345678910111213spring: application: name: spring-cloud-hystrix-dashboard-hello-serviceserver: port: 8080eureka: instance: prefer-ip-address: true instance-id: $&#123;spring.application.name&#125;:$&#123;server.port&#125; client: service-url: defaultZone: http://localhost:8761/eureka/ bootstrap.yml12345678management: endpoints: web: exposure: include: hystrix.stream # 开启 hystrix.stream actuator端点feign: hystrix: enabled: true feign、Controller、启动类12345678910111213141516171819202122232425262728293031323334353637383940414243// feign@FeignClient(name = "spring-cloud-hystrix-dashboard-provider-service")public interface ProviderService &#123; @RequestMapping(value = "/get-dashboard", method = RequestMethod.GET) List&lt;String&gt; getProviderData();&#125;// controller@RestControllerpublic class HelloController &#123; private final ProviderService providerService; @Autowired public HelloController(ProviderService providerService) &#123; this.providerService = providerService; &#125; public List&lt;String&gt; getProviderData()&#123; return providerService.getProviderData(); &#125; @GetMapping(value = "/hello-service") public String helloService()&#123; return "hello service!"; &#125;&#125;// 启动类@SpringBootApplication@EnableFeignClients@EnableHystrix@EnableDiscoveryClientpublic class SpringCloudHystrixDashboardHelloServiceApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(SpringCloudHystrixDashboardHelloServiceApplication.class, args); &#125;&#125; provider-service源码：https://gitee.com/laiyy0728/spring-cloud/tree/master/spring-cloud-hystrix/spring-cloud-hystrix-dashboard/spring-cloud-hystrix-dashboard-provider-service pom、yml 配置、启动类与 hello-sercice 基本一致，需要修改 server.port、spring.application.name feign、Controller1234567891011121314151617181920212223242526272829303132// feign@FeignClient(name = "spring-cloud-hystrix-dashboard-hello-service")public interface ProviderService &#123; @RequestMapping(value = "/hello-service", method = RequestMethod.GET) String helloService();&#125;// Controller@RestControllerpublic class ProviderController &#123; private final ProviderService providerService; @Autowired public ProviderController(ProviderService providerService) &#123; this.providerService = providerService; &#125; @GetMapping(value = "/get-dashboard") public List&lt;String&gt; getProviderData()&#123; List&lt;String&gt; provider = Lists.newArrayList(); provider.add("hystrix dashboard"); return provider; &#125; @GetMapping(value = "/get-hello-service") public String getHelloService()&#123; return providerService.helloService(); &#125;&#125; hystrix-dashboard源码：https://gitee.com/laiyy0728/spring-cloud/tree/master/spring-cloud-hystrix/spring-cloud-hystrix-dashboard/spring-cloud-hystrix-dashboard-index pom1234567891011&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-hystrix-dashboard&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; ymlapplication.yml1234567eureka: client: service-url: defaultZone: http://localhost:8761/eureka/ instance: instance-id: $&#123;spring.application.name&#125;:$&#123;server.port&#125; prefer-ip-address: true bootstrap.yml1234567891011spring: application: name: spring-cloud-hystrix-dashboard-indexserver: port: 9999management: endpoints: web: exposure: include: hystrix.stream 启动类12345678910@SpringBootApplication@EnableHystrixDashboard@EnableDiscoveryClientpublic class SpringCloudHystrixDashboardIndexApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(SpringCloudHystrixDashboardIndexApplication.class, args); &#125;&#125; @EnableHystrixDashboard 开启 hystrix Dashboard 页面 Dashboard验证 hystrix Dashboard 分别启动 hello-service、provider-sercice、hystrix-dashboard，访问 hystrix Dashboard 页面 http://localhost:9999/hystrix 可以看到 hystrix Dashboard 启动成功。 Dashboard actuator在页面上可以看到有三种监控方式 默认集群监控：http://turbine-hostname:port/turbine.stream 指定集群监控：http://turbine-hostname:port/turbine.stream?cluster=[clusterName] 单个应用：http://hystrix-app:port/hystrix.stream 其中： turbine-hostname 需要继承 Turbine。 hystrix-app 就是 instance-id 对 hello-service 监控在老版本中，监控端点为： instance-id/hystrix.stream，在新版本中，需要加上 actuator ：instance-id/actuator/hystrix.stream hello-sercice： http://localhost:8080/actuator/hystrix.stream 可以看到，此时监控页面一直是 loading，这是因为暂时没有访问的原因。此时在 postman 多次请求 hello service 接口（localhost:8080/get-provider-data），再次查看 dashboard 图形解释 ①：访问的是哪个服务、调用的哪个方法 ②：表示请求次数、成功数等。其中：左上角绿色代表请求成功数，左边第二个代表短路数/熔断数，右边第一个代表请求超时数，右边第二个代表线程池拒绝数，右边第三个代表失败/异常数。最右边的百分比代表最近 10 秒内的错误比例。 ③：表示两分钟内的流量变化：流量变化越大，曲线的变化也越大；流量越大，灰色的圆圈就越大。 ④：表示机器和集群的请求频率。host 代表当前host的请求频率；cluster 代表当前集群的请求频率 ⑤：集群下的报告，延迟数等。hosts 代表当前集群有几个 host；median 代表请求延迟中位数；mean 请求延迟的平均数 ⑥：最后一分钟延迟比：90th 代表 90% 的请求响应时间，99th 代表 99% 请求响应时间，99.5th 代表 99.5% 请求响应时间 ⑦：断路器打开状态：正常情况下为 CLOED，表示断路器关闭，当一段时间内连续出现错误时，会自动变为 OPEN，代表断路器打开。 ⑧：服务的线程状态：active：正在执行的线程，queued：队列中的请求，pool size：线程池大小，max active：最大可用线程，executions：被拒绝的线程， queue size：队列大小 断路器打开关闭 provider-service 服务，多次请求 hello-service，观察 dashboard 断路器打开状态变化]]></content>
      <categories>
        <category>spring-cloud</category>
      </categories>
      <tags>
        <tag>SpringCloud</tag>
        <tag>Hystrix</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring Cloud 微服务（13） --- Hystrix(一) Hystrix 介绍、Feign Hystrix 断路器]]></title>
    <url>%2Fspring-cloud%2Fspring-cloud-13.html</url>
    <content type="text"><![CDATA[Hystrix 是一个延迟和容错库，目的在隔离远程系统、服务、第三方库，组织级联故障，在负载的分布式系统中实现恢复能力。在多系统和微服务的情况下，需要一种机制来处理延迟和故障，并保护整合系统处于可用的稳定状态。Hystrix 就是实现这个功能的一个组件。 通过客户端库对延迟和故障进行保护和控制。 在一个复杂的分布式系统中停止级联故障 快速失败、迅速恢复 在合理的情况下回退、优雅降级 开启近实时监控、告警、操作控制 实例源码：https://gitee.com/laiyy0728/spring-cloud/tree/master/spring-cloud-hystrix/spring-cloud-hystrix-simple pom 依赖1234567891011&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-hystrix&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt; 配置文件123456789101112spring: application: name: spring-cloud-hystrix-simpleeureka: client: service-url: defaultZone: http://localhost:8761/eureka/ instance: instance-id: $&#123;spring.application.name&#125;:$&#123;server.port&#125; prefer-ip-address: trueserver: port: 8888 Service、ServiceImpl、Controller、启动类1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859// Servicepublic interface HystrixService &#123; String getUser(String username) throws Exception;&#125;// Service Impl@Servicepublic class HystrixServiceImpl implements HystrixService &#123; @Override @HystrixCommand(fallbackMethod = "defaultUser") public String getUser(String username) throws Exception &#123; if ("laiyy".equals(username)) &#123; return "this is real user, name:" + username; &#125; throw new Exception(); &#125; /** * 在 getUser 出错时调用 */ public String defaultUser(String username) &#123; return "this is error user, name: " + username; &#125;&#125;// Controller@RestControllerpublic class HystrixController &#123; private final HystrixService hystrixService; @Autowired public HystrixController(HystrixService hystrixService) &#123; this.hystrixService = hystrixService; &#125; @GetMapping(value = "get-user") public String getUser(@RequestParam String username) throws Exception&#123; return hystrixService.getUser(username); &#125;&#125;// Controller@SpringBootApplication@EnableDiscoveryClient@EnableHystrixpublic class SpringCloudHystrixSimpleApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(SpringCloudHystrixSimpleApplication.class, args); &#125;&#125; 验证访问 http://localhost:8888/get-user 传入正确 username 传入错误 username 注解、解释在上例中，可以发现，在启动类上多了 @EnableHystrix 注解，在 Service 中多了 @HystrixCommand(fallbackMethod = &quot;defaultUser&quot;) 和一个名称为 defaultUser 的方法。 @EnableHystrix：开启 Hystrix 断路器 @HystrixCommand：fallbackMethod 指定当该注解标记的方法出现失败、错误时，调用哪一个方法进行优雅的降级返回，对用户屏蔽错误，做优雅提示。 @HystrixCommand 需要注意 fallbackMethod 的值，为方法名。如果方法指定的方法名不存在，会出现如下错误： 123456com.netflix.hystrix.contrib.javanica.exception.FallbackDefinitionException: fallback method wasn't found: defaultUser1([class java.lang.String]) at com.netflix.hystrix.contrib.javanica.utils.MethodProvider$FallbackMethodFinder.doFind(MethodProvider.java:190) ~[hystrix-javanica-1.5.12.jar:1.5.12] at com.netflix.hystrix.contrib.javanica.utils.MethodProvider$FallbackMethodFinder.find(MethodProvider.java:159) ~[hystrix-javanica-1.5.12.jar:1.5.12] at com.netflix.hystrix.contrib.javanica.utils.MethodProvider.getFallbackMethod(MethodProvider.java:73) ~[hystrix-javanica-1.5.12.jar:1.5.12] at com.netflix.hystrix.contrib.javanica.utils.MethodProvider.getFallbackMethod(MethodProvider.java:59) ~[hystrix-javanica-1.5.12.jar:1.5.12] ... fallbackMethod 方法的参数与 @HystrixCommand 标注的参数类型、顺序一致，如果不一致，会出现如下错误： 1234com.netflix.hystrix.contrib.javanica.exception.FallbackDefinitionException: fallback method wasn't found: defaultUser([class java.lang.String]) at com.netflix.hystrix.contrib.javanica.utils.MethodProvider$FallbackMethodFinder.doFind(MethodProvider.java:190) ~[hystrix-javanica-1.5.12.jar:1.5.12] at com.netflix.hystrix.contrib.javanica.utils.MethodProvider$FallbackMethodFinder.find(MethodProvider.java:159) ~[hystrix-javanica-1.5.12.jar:1.5.12] ... 断路器源码：https://gitee.com/laiyy0728/spring-cloud/tree/master/spring-cloud-hystrix/spring-cloud-hystrix-feign-broker 断路器的作用：在服务出现错误的时候，熔断该服务，保护调用者，防止出现雪崩。 在使用 feign 断路器时，feign 默认是不开启 Hystrix 断路器的，需要手动配置。 pom1234567891011121314&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-openfeign&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-hystrix&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 配置文件application.yml123feign: hystrix: enabled: true boorstrap.yml123456789101112spring: application: name: spring-cloud-hystrix-feign-brokereureka: client: service-url: defaultZone: http://localhost:8761/eureka/ instance: instance-id: $&#123;spring.application.name&#125;:$&#123;server.port&#125; prefer-ip-address: trueserver: port: 8888 feign、Fallback、Controller、启动类12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849// feign@FeignClient(name = "spring-cloud-ribbon-provider",fallback = FeignHystrixClientFallback.class)public interface FeignHystrixClient &#123; @RequestMapping(value = "/check", method = RequestMethod.GET) String feignHystrix();&#125;// fallback@Componentpublic class FeignHystrixClientFallback implements FeignHystrixClient &#123; @Override public String feignHystrix() &#123; return "error! this is feign hystrix"; &#125;&#125;// controller@RestControllerpublic class FeignHystrixController &#123; private final FeignHystrixClient feignHystrixClient; @Autowired public FeignHystrixController(FeignHystrixClient feignHystrixClient) &#123; this.feignHystrixClient = feignHystrixClient; &#125; @GetMapping(value = "feign-hystrix") public String feignHystrix()&#123; return feignHystrixClient.feignHystrix(); &#125;&#125;// 启动类@SpringBootApplication@EnableHystrix@EnableDiscoveryClient@EnableFeignClientspublic class SpringCloudHystrixFeignBrokerApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(SpringCloudHystrixFeignBrokerApplication.class, args); &#125;&#125; 验证使用 spring-cloud-ribbon-provider 作为服务提供者，当前项目作为服务调用者 spring-cloud-ribbon-provider 正常访问 停止 spring-cloud-ribbon-provider 服务，再次访问 可以看到，当 spring-cloud-ribbon-provider 服务停止时，会进入 Fallback 声明的 Class 中。 Fallback class 必须是 @FeignClient 标注的 interface 的实现类，且每个方法都需要自定义实现。]]></content>
      <categories>
        <category>spring-cloud</category>
      </categories>
      <tags>
        <tag>SpringCloud</tag>
        <tag>Hystrix</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring Cloud 微服务（12） --- Ribbon(二) 工作原理]]></title>
    <url>%2Fspring-cloud%2Fspring-cloud-12.html</url>
    <content type="text"><![CDATA[Ribbon 核心接口 接口 描述 默认实现类 IClientConfig 定义 Ribbon 中管理配置的接口 DefaultClientConfigImpl IRule 定义 Ribbon 中负载均衡策略的接口 RoundRobinRule IPing 定义定期 ping 服务检查可用性的接口 DummyPing ServerList 定义获取服务列表方法的接口 ConfigurationBasedServerList ServerListFilter 定义特定期望获取服务列表方法的接口 ZonePreferenceServerListFilter ILoadBalanacer 定义负载均衡选择服务的核心方法的接口 BaseLoadBalancer ServerListUpdater 为 DynamicServerListLoadBalancer 定义动态更新服务列表的接口 PollingServerListUpdater Ribbon 的运行原理Ribbon 实现负载均衡，基本用法是注入一个 RestTemplate，并在 RestTemplate 上使用 @LoadBalanced，才能使 RestTemplate 具备负载均衡能力。 @LoadBalanced1234567891011/** * Annotation to mark a RestTemplate bean to be configured to use a LoadBalancerClient * @author Spencer Gibb */@Target(&#123; ElementType.FIELD, ElementType.PARAMETER, ElementType.METHOD &#125;)@Retention(RetentionPolicy.RUNTIME)@Documented@Inherited@Qualifierpublic @interface LoadBalanced &#123;&#125; 这个注解标注一个 RestTemplate，使用 LoadBalancerClient，那么 LoadBalancerClient 又是什么？ LoadBalancerClient123456789101112/** * Represents a client side load balancer * @author Spencer Gibb */public interface LoadBalancerClient extends ServiceInstanceChooser &#123; &lt;T&gt; T execute(String serviceId, LoadBalancerRequest&lt;T&gt; request) throws IOException; &lt;T&gt; T execute(String serviceId, ServiceInstance serviceInstance, LoadBalancerRequest&lt;T&gt; request) throws IOException; URI reconstructURI(ServiceInstance instance, URI original);&#125; LoadBalancerClient 又扩展了 ServiceInstanceChooser 接口1234public interface ServiceInstanceChooser &#123; ServiceInstance choose(String serviceId);&#125; 方法解释 ServiceInstance choose(String serviceId)：根据 serviceId，结合负载均衡器，选择一个服务实例 &lt;T&gt; T execute(String serviceId, LoadBalancerRequest&lt;T&gt; request)：使用 LoadBalancer 的 serviceInstance 为置顶的服务执行请求 &lt;T&gt; T execute(String serviceId, ServiceInstance serviceInstance, LoadBalancerRequest&lt;T&gt; request)：使用来自 LoadBalancer 的 ServiceInstance 为指定的服务执行请求，是上一个方法的重载，是上一个方法的细节实现 URI reconstructURI(ServiceInstance instance, URI original)：使用主机 ip、port 构建特定的 URI，供 RIbbon 内部使用。Ribbon 使用服务名称的 URI 作为host。如：http://instance-id/path/to/service LoadBalancer 初始化LoadBalancerAutoConfiguration 是 Ribbon 负载均衡初始化加载类，启动的关键核心代码如下： 1234567891011121314151617181920212223242526272829303132333435@Configuration@ConditionalOnClass(RestTemplate.class)@ConditionalOnBean(LoadBalancerClient.class)@EnableConfigurationProperties(LoadBalancerRetryProperties.class)public class LoadBalancerAutoConfiguration &#123; @Bean @ConditionalOnMissingBean public LoadBalancerRequestFactory loadBalancerRequestFactory( LoadBalancerClient loadBalancerClient) &#123; return new LoadBalancerRequestFactory(loadBalancerClient, transformers); &#125; @Configuration @ConditionalOnMissingClass("org.springframework.retry.support.RetryTemplate") static class LoadBalancerInterceptorConfig &#123; @Bean public LoadBalancerInterceptor ribbonInterceptor( LoadBalancerClient loadBalancerClient, LoadBalancerRequestFactory requestFactory) &#123; return new LoadBalancerInterceptor(loadBalancerClient, requestFactory); &#125; @Bean @ConditionalOnMissingBean public RestTemplateCustomizer restTemplateCustomizer( final LoadBalancerInterceptor loadBalancerInterceptor) &#123; return restTemplate -&gt; &#123; List&lt;ClientHttpRequestInterceptor&gt; list = new ArrayList&lt;&gt;( restTemplate.getInterceptors()); list.add(loadBalancerInterceptor); restTemplate.setInterceptors(list); &#125;; &#125; &#125;&#125; 可以看到，在类注解上，@ConditionalOnClass(RestTemplate.class)、@ConditionalOnBean(LoadBalancerClient.class)，必须在当前工程下有 RestTemplate 的实例、必须已经初始化了 LoadBalancerClient 的实现类，才会加载 LoadBalancer 的自动装配。 其中 LoadBalancerRequestFactory 用于创建 LoadBalancerRequest，以供 LoadBalancerInterceptor 使用(在低版本没有)，LoadBalancerInterceptorConfig 中维护了 LoadBalancerInterceptor、RestTemplateCustomizer 的实例。 LoadBalancerInterceptor：拦截每一次 HTTP 请求，将请求绑定进 Ribbon 负载均衡的生命周期 RestTemplateCustomizer：为每个 RestTemplate 绑定 LoadBalancerInterceptor 拦截器 LoadBalancerInterceptor123456789101112131415161718192021222324public class LoadBalancerInterceptor implements ClientHttpRequestInterceptor &#123; private LoadBalancerClient loadBalancer; private LoadBalancerRequestFactory requestFactory; public LoadBalancerInterceptor(LoadBalancerClient loadBalancer, LoadBalancerRequestFactory requestFactory) &#123; this.loadBalancer = loadBalancer; this.requestFactory = requestFactory; &#125; public LoadBalancerInterceptor(LoadBalancerClient loadBalancer) &#123; // for backwards compatibility this(loadBalancer, new LoadBalancerRequestFactory(loadBalancer)); &#125; @Override public ClientHttpResponse intercept(final HttpRequest request, final byte[] body, final ClientHttpRequestExecution execution) throws IOException &#123; final URI originalUri = request.getURI(); String serviceName = originalUri.getHost(); Assert.state(serviceName != null, "Request URI does not contain a valid hostname: " + originalUri); return this.loadBalancer.execute(serviceName, requestFactory.createRequest(request, body, execution)); &#125;&#125; LoadBalancerInterceptor 利用 ClientHttpRequestInterceptor 对每次 HTTP 请求进行拦截，这个类是 Spring 中维护的请求拦截器。可以看到，拦截的请求使用了 LoadBalancerClient 的 execute 方法处理请求(由于 RestTemplate 中使用服务名当做 host，所以此时 getHosts() 获取到的服务名)，LoadBalancerClient 只有一个实现类：RibbonLoadBalancerClient，具体是 execute 方法如下： 123456789101112@Overridepublic &lt;T&gt; T execute(String serviceId, LoadBalancerRequest&lt;T&gt; request) throws IOException &#123; ILoadBalancer loadBalancer = getLoadBalancer(serviceId); Server server = getServer(loadBalancer); if (server == null) &#123; throw new IllegalStateException("No instances available for " + serviceId); &#125; RibbonServer ribbonServer = new RibbonServer(serviceId, server, isSecure(server, serviceId), serverIntrospector(serviceId).getMetadata(server)); return execute(serviceId, ribbonServer, request);&#125; 可以看到，源码中首先获取一个 LoadBalancer，再去获取一个 Server，那么，这个 Server 就是具体服务实例的封装了。既然 Server 是一个具体的服务实例，那么， getServer(loadBalancer) 就是发生负载均衡的地方。 123456protected Server getServer(ILoadBalancer loadBalancer) &#123; if (loadBalancer == null) &#123; return null; &#125; return loadBalancer.chooseServer("default"); // TODO: better handling of key&#125; 查看 chooseServer 方法具体实现（BaseLoadBalancer）：12345678910111213141516public Server chooseServer(Object key) &#123; if (counter == null) &#123; counter = createCounter(); &#125; counter.increment(); if (rule == null) &#123; return null; &#125; else &#123; try &#123; return rule.choose(key); &#125; catch (Exception e) &#123; logger.warn("LoadBalancer [&#123;&#125;]: Error choosing server for key &#123;&#125;", name, key, e); return null; &#125; &#125;&#125; rule.choose(key) 的中的 rule，就是 IRule，而 IRule 就是 Ribbon 的负载均衡策略。由此可以证明，HTTP 请求域负载均衡策略关联起来了。 IRuleIRule 源码：123456789101112131415public interface IRule&#123; /* * choose one alive server from lb.allServers or * lb.upServers according to key * * @return choosen Server object. NULL is returned if none * server is available */ public Server choose(Object key); public void setLoadBalancer(ILoadBalancer lb); public ILoadBalancer getLoadBalancer(); &#125; IRule 中一共定义了 3 个方法，实现类实现 choose 方法，会加入具体的负载均衡策略逻辑，另外两个方法与 ILoadBalancer 关联起来。在调用过程中，Ribbon 通过 ILoadBalancer 关联 IRule，ILoadBalancer 的 chooseServer 方法会转为为调用 IRRule 的 choose 方法，抽象类 AbstractLoadBalancerRule 实现了这两个方法，从而将 ILoadBalancer 与 IRule 关联起来。]]></content>
      <categories>
        <category>spring-cloud</category>
      </categories>
      <tags>
        <tag>SpringCloud</tag>
        <tag>Ribbon</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring Cloud 微服务（11） --- Ribbon(一) 负载均衡与 Ribbon]]></title>
    <url>%2Fspring-cloud%2Fspring-cloud-11.html</url>
    <content type="text"><![CDATA[通常所说的负载均衡，一般来说都是在服务器端使用 Ngnix 或 F5 做 Server 的负载均衡策略，在 Ribbon 中提到的负载均衡，一般来说是指的客户端负载均衡，即 ServiceA 调用 ServiceB，有多个 ServiceB 的情况下，由 ServiceA 选择调用哪个 ServiceB。 负载均衡与 Ribbon负载均衡(Load Balance)，是一种利用特定方式，将流量分摊到多个操作单元上的手段，它对系统吞吐量、系统处理能力有着质的提升。最常见的负载均衡分类方式有：软负载、硬负载，对应 Ngnix、F5；集中式负载均衡、进程内负载均衡。集中式负载均衡是指位于网络和服务提供者之间，并负责把忘了请求转发到各个提供单位，代表产品有 Ngnix、F5；进程负载均衡是指从一个实例库选取一个实例进行流量导入，在微服务范畴，实例库一般是存储在 Eureka、Consul、Zookeeper 等注册中心，此时的负载均衡器类似 Ribbon 的 IPC（进程间通信）组件，因此进程内负载均衡也叫做客户端负载均衡。 Ribbon 是一个客户端负载均衡器，赋予了应用一些支配 HTTP 与 TCP 行为的能力，由此可以得知，这里的客户端负载均衡也是进程内负载均衡的一周。 Ribbon 在 SpringCloud 生态内的不可缺少的组件，没有了 Ribbon，服务就不能横向扩展。Feign、Zuul 已经集成了 Ribbon。 示例Eureka Server 不再赘述，可以直接使用 spring-cloud-eureka-server-simple。 Consumer源码：https://gitee.com/laiyy0728/spring-cloud/tree/master/spring-cloud-ribbon/spring-cloud-ribbon-consumer yml：1234567891011121314spring: application: name: spring-cloud-ribbon-consumerserver: port: 9999eureka: client: service-url: defaultZone: http://localhost:8761/eureka instance: prefer-ip-address: true instance-id: $&#123;spring.application.name&#125;:$&#123;server.port&#125; 配置类：12345@Bean@LoadBalancedpublic RestTemplate restTemplate()&#123; return new RestTemplate();&#125; @LoadBalanced：对 RestTemplate 启动负载均衡 Consumer Controller12345678910111213141516@RestControllerpublic class ConsumerController &#123; private final RestTemplate restTemplate; @Autowired public ConsumerController(RestTemplate restTemplate) &#123; this.restTemplate = restTemplate; &#125; @GetMapping(value = "/check") public String checkRibbonProvider()&#123; return restTemplate.getForObject("http://spring-cloud-ribbon-provider/check", String.class); &#125;&#125; provider源码：https://gitee.com/laiyy0728/spring-cloud/tree/master/spring-cloud-ribbon/spring-cloud-ribbon-provider pom 依赖：1234567891011&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-ribbon&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 配置文件：1234567891011spring: application: name: spring-cloud-ribbon-providereureka: client: service-url: defaultZone: http://localhost:8761/eureka instance: prefer-ip-address: true instance-id: $&#123;spring.application.name&#125;:$&#123;server.port&#125; ProviderContr1234567891011@RestControllerpublic class ProviderController &#123; @Value("$&#123;server.port&#125;") private int port; @GetMapping(value = "/check") public String providerPort()&#123; return "Provider Port: " + port; &#125;&#125; 验证分别启动 Eureka Server、Consumer、Provider，其中，Provider 以 mvn 形式启动，绑定不同的端口号：12mvn spring-boot:run -Dserver.port=8080mvn spring-boot:run -Dserver.port=8081 postman 访问 Consumer 可以看到，Provider 两次返回值不一样，验证了负载均衡成功。 负载均衡策略Ribbon 中提供了 七种 负载均衡策略 策略类 命名 描述 RandomRule 随机策略 随机选择 Server RoundRobinRule 轮询策略 按照顺序循环选择 Server RetryRule 重试策略 在一个配置时间段内，当选择的 Server 不成功，则一直尝试选择一个可用的 Server BestAvailableRule 最低并发策略 逐个考察 Server，如果 Server 的断路器被打开，则忽略，在不被忽略的 Server 中选择并发连接最低的 Server AvailabilityFilteringRule 可用过滤测试 过滤掉一直连接失败，并被标记未 circuit tripped（即不可用） 的 Server，过滤掉高并发的 Server ResponseTimeWeightedRule 响应时间加权策略 根据 Server 的响应时间分配权重，响应时间越长，权重越低，被选择到的几率就越低 ZoneAvoidanceRule 区域权衡策略 综合判断 Server 所在区域的性能和 Server 的可用性轮询选择 Server，并判定一个 AWS Zone 的运行性能是否可用，剔除不可用的 Zone 中的所有 Server Ribbon 默认的负载均衡策略是 轮询策略。 设置负载均衡策略设置全局负载均衡创建一个声明式配置，即可实现全局负载均衡配置： 1234567891011@Configurationpublic class RibbonConfig &#123; /** * 全局负载均衡配置：随机策略 */ @Bean public IRule ribbonRule()&#123; return new RandomRule(); &#125;&#125; 重启 Consumer，访问测试 基于注解的配置空注解声明一个空注解，用于使用注解配置 Ribbon 负载均衡 12public @interface RibbonAnnotation &#123;&#125; 负载均衡配置类12345678910111213141516@Configuration@RibbonAnnotationpublic class RibbonAnnoConfig &#123; private final IClientConfig clientConfig; @Autowired(required = false) public RibbonAnnoConfig(IClientConfig clientConfig) &#123; this.clientConfig = clientConfig; &#125; @Bean public IRule ribbonRule(IClientConfig clientConfig)&#123; return new RandomRule(); &#125;&#125; 启动类123456789101112131415161718@SpringBootApplication@EnableDiscoveryClient@RibbonClient(name = "spring-cloud-ribbon-provider", configuration = RibbonAnnoConfig.class)@ComponentScan(excludeFilters = &#123;@ComponentScan.Filter(type = FilterType.ANNOTATION, value = RibbonAnnotation.class)&#125;)public class SpringCloudRibbonConsumerApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(SpringCloudRibbonConsumerApplication.class, args); &#125; @Bean @LoadBalanced public RestTemplate restTemplate()&#123; return new RestTemplate(); &#125;&#125; @RibbonClient：针对 spring-cloud-ribbon-provider 服务，使用负载均衡，配置类是 configuration 标注的类。@ComponentScan：让 Spring 不去扫描被 @RibbonAnnotation 类标记的配置类，因为我们的配置对单个服务生效，不能应用于全局，如果不排除，启动就会报错 如果需要对多个服务进行配置，可以使用 @RibbonClients 注解123@RibbonClients(value = &#123; @RibbonClient(name = "spring-cloud-ribbon-provider", configuration = RibbonAnnoConfig.class) &#125;) 重启 Consumer，验证基于注解的负载均衡是否成功 基于配置文件的负载均衡策略语法：123&#123;instance-id&#125;: # instance-id 即被调用服务名称 ribbon: NFLoadBalancerRuleClassName: com.netflix.loadbalancer.RandomRule Ribbon 配置源码：https://gitee.com/laiyy0728/spring-cloud/tree/master/spring-cloud-ribbon/spring-cloud-ribbon-config 超时与重试HTTP 请求难免会出现请求超时，此时对调用进行时限的控制以及在时限之后的重试尤为重要。对于超时重试的配置如下：1234567&#123;instance-id&#125;: # instance-id 指的是被调用者的服务名称 ribbon: ConnectTimeout: 30000 # 链接超时时间 ReadTimeout: 30000 # 读超时时间 MaxAutoRetries: 1 # 对第一次请求的服务的重试次数 MaxAutoRetriesNextServer: 1 # 要重试的下一个服务的最大数量（不包括第一个服务） OkToRetryOnAllOperations: true # 是否对 连接超时、读超时、写超时 都进行重试 Ribbon 饥饿加载Ribbon 在进行负载均衡时，并不是启动时就加载上线文，而是在实际的请求发送时，才去请求上下文信息，获取被调用者的 ip、端口，这种方式在网络环境较差时，往往会使得第一次引起超时，导致调用失败。此时需要指定 Ribbon 客户端，进行饥饿加载，即：在启动时就加载好上下文。 1234ribbon: eager-load: enabled: true clients: spring-cloid-ribbon-provider 此时启动 consumer，会看到控制打印信息如下：123Client: spring-cloid-ribbon-provider instantiated a LoadBalancer: DynamicServerListLoadBalancer:&#123;NFLoadBalancer:name=spring-cloid-ribbon-provider,current list of Servers=[],Load balancer stats=Zone stats: &#123;&#125;,Server stats: []&#125;ServerList:nullUsing serverListUpdater PollingServerListUpdaterDynamicServerListLoadBalancer for client spring-cloid-ribbon-provider initialized: DynamicServerListLoadBalancer:&#123;NFLoadBalancer:name=spring-cloid-ribbon-provider,current list of Servers=[],Load balancer stats=Zone stats: &#123;&#125;,Server stats: []&#125;ServerList:org.springframework.cloud.netflix.ribbon.eureka.DomainExtractingServerList@79e7188e 可以看到启动时就加载了 spring-cloid-ribbon-provider，并绑定了LoadBalancer Ribbon 常用配置 配置项 说明 {instance-id}:ribbon.NFLoadBalancerClassName 指负载均衡器类路径 {instance-id}:ribbon:NFLoadBalancerRuleClassName 指定负载均衡算法类路径 {instance-id}:ribbom:NFLoadBalancerPingClassName 指定检测服务存活的类路径 {instance-id}:ribbon:NIWSServerListClassName 指定获取服务列表的实现类路径 {instance-id}:ribbon:NIWSServerListFilterClassName 指定服务的 Filter 实现类路径 Ribbon 脱离 Eureka默认情况下，Ribbon 客户端会从 Eureka Server 读取服务注册信息列表，达到动态负载均衡的功能。如果 Eureka 是一个提供多人使用的公共注册中心(如 SpringCloud 中文社区公益 Eureka：http://eureka.springcloud.cn)，此时极易产生服务侵入问题，此时就不能从 Eureka 中读取服务列表，而应该在 Ribbon 客户端自行制定源服务地址 1234567ribbon: eureka: enabled: false # Ribbon 脱离 Eureka 使用&#123;instance-id&#125;: ribbon: listOfServers: http://localhost:8888 # 制定源服务地址]]></content>
      <categories>
        <category>spring-cloud</category>
      </categories>
      <tags>
        <tag>SpringCloud</tag>
        <tag>Ribbon</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring Cloud 微服务 （10） --- Feign(四) 文件上传、首次调用失败问题]]></title>
    <url>%2Fspring-cloud%2Fspring-cloud-10.html</url>
    <content type="text"><![CDATA[Feign 在远程调用时，除了 GET 方式传递 POJO 外，还有几个很重要的功能：文件上传、调用返回图片流、传递 Token 等 文件上传源码：https://gitee.com/laiyy0728/spring-cloud/tree/master/spring-cloud-feign/spring-cloud-feign-file Feign 的子项目 feign-form(https://github.com/OpenFeign/feign-form) 支持文件上传，其中实现了上传所需要的 Encoder 模拟文件上传：spring-cloud-feign-file-server、spring-cloud-feign-file-client，其中 server 模拟文件服务器，作为服务提供者；client 模拟文件上传，通过 FeignClient 发送文件到文件服务器 FileClientpom 依赖1234567891011121314151617181920212223&lt;!-- eureka client --&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt;&lt;/dependency&gt;&lt;!-- feign --&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-openfeign&lt;/artifactId&gt;&lt;/dependency&gt;&lt;!-- Feign文件上传依赖--&gt;&lt;dependency&gt; &lt;groupId&gt;io.github.openfeign.form&lt;/groupId&gt; &lt;artifactId&gt;feign-form&lt;/artifactId&gt; &lt;version&gt;3.0.3&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;io.github.openfeign.form&lt;/groupId&gt; &lt;artifactId&gt;feign-form-spring&lt;/artifactId&gt; &lt;version&gt;3.0.3&lt;/version&gt;&lt;/dependency&gt; 配置文件12345678910111213spring: application: name: spring-cloud-feign-file-clienteureka: client: service-url: defaultZone: http://localhost:8761/eureka/ instance: instance-id: $&#123;spring.application.name&#125;:$&#123;server.port&#125; prefer-ip-address: trueserver: port: 8888 启动类、FeignClient、配置、Controller1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162// 启动类@SpringBootApplication@EnableDiscoveryClient@EnableFeignClientspublic class SpringCloudFeignFileClientApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(SpringCloudFeignFileClientApplication.class, args); &#125;&#125;// FeignClient@FeignClient(value = "spring-cloud-feign-file-server", configuration = FeignMultipartConfiguration.class)public interface FileUploadFeignClient &#123; /** * feign 上传图片 * * produces、consumes 必填 * 不要将 @RequestPart 写成 @RequestParam * * @param file 上传的文件 * @return 上传的文件名 */ @RequestMapping(value = "/upload-file", method = RequestMethod.POST, produces = MediaType.APPLICATION_JSON_UTF8_VALUE, consumes = MediaType.MULTIPART_FORM_DATA_VALUE) String fileUpload(@RequestPart(value = "file")MultipartFile file);&#125;// configuration@Configurationpublic class FeignMultipartConfiguration &#123; /** * Feign Spring 表单编码器 * @return 表单编码器 */ @Bean @Primary @Scope("prototype") public Encoder multipartEncoder()&#123; return new SpringFormEncoder(); &#125;&#125;// Controller@RestControllerpublic class FileUploadController &#123; private final FileUploadFeignClient feignClient; @Autowired public FileUploadController(FileUploadFeignClient feignClient) &#123; this.feignClient = feignClient; &#125; @PostMapping(value = "upload") public String upload(MultipartFile file)&#123; return feignClient.fileUpload(file); &#125;&#125; FileServerpom1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt;&lt;/dependency&gt; 配置文件1234567891011121314spring: application: name: spring-cloud-feign-file-servereureka: instance: prefer-ip-address: true instance-id: $&#123;spring.application.name&#125;:$&#123;server.port&#125; client: service-url: defaultZone: http://localhost:8761/eureka/server: port: 8889 启动类、Controller1234567891011121314151617181920@SpringBootApplication@EnableDiscoveryClientpublic class SpringCloudFeignFileServerApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(SpringCloudFeignFileServerApplication.class, args); &#125;&#125;// Controller 模拟文件上传的处理@RestControllerpublic class FileUploadController &#123; @PostMapping(value = "/upload-file") public String fileUpload(MultipartFile file) &#123; return file.getOriginalFilename(); &#125;&#125; 验证文件上传POST MAN 调用 client 上传接口 图片流源码：https://gitee.com/laiyy0728/spring-cloud/tree/master/spring-cloud-feign/spring-cloud-feign-file 通过 Feign 返回图片，一般是字节数组 在文件上传代码的基础上，再加上图片获取 FeignClient123456789101112/** * 获取图片 * @return 图片 */@RequestMapping(value = "/get-img")ResponseEntity&lt;byte[]&gt; getImage();@GetMapping(value = "/get-img")public ResponseEntity&lt;byte[]&gt; getImage()&#123; return feignClient.getImage();&#125; FeignServer12345678@GetMapping(value = "/get-img")public ResponseEntity&lt;byte[]&gt; getImages() throws IOException &#123; FileSystemResource resource = new FileSystemResource(getClass().getResource("/").getPath() + "Spring-Cloud.png"); HttpHeaders headers = new HttpHeaders(); headers.add("Content-Type", MediaType.APPLICATION_OCTET_STREAM_VALUE); headers.add("Content-Disposition", "attachment; filename=Spring-Cloud.png"); return ResponseEntity.status(HttpStatus.OK).headers(headers).body(FileCopyUtils.copyToByteArray(resource.getInputStream()));&#125; 验证在浏览器访问：http://localhost:8888/get-img ，实现图片流下载 Feign 传递 Headers源码：https://gitee.com/laiyy0728/spring-cloud/tree/master/spring-cloud-feign/spring-cloud-feign-multi-params 在认证、鉴权中，无论是哪种权限控制框架，都需要传递 header，但在使用 Feign 的时候，会发现外部请求 ServiceA 时，可以获取到 header，但是在 ServiceA 调用 ServiceB 时，ServiceB 无法获取到 Header，导致 Header 丢失。 在 spring-cloud-feign-multi-params 基础上，实现传递 Header。 验证 Header 无法传递问题 consumer 打印 header provider 打印 header HeaderInterceptor在 Consumer 增加 HeaderInterceptor，做 header 传递 12345678910111213141516171819202122232425262728293031@Componentpublic class FeignHeaderInterceptor implements RequestInterceptor &#123; @Override public void apply(RequestTemplate template) &#123; if (null == getRequest())&#123; return; &#125; template.header("oauth-token", getHeaders(getRequest()).get("oauth-token")); &#125; private HttpServletRequest getRequest()&#123; try &#123; return ((ServletRequestAttributes) RequestContextHolder.currentRequestAttributes()).getRequest(); &#125;catch (Exception e)&#123; return null; &#125; &#125; private Map&lt;String, String&gt; getHeaders(HttpServletRequest request) &#123; Map&lt;String, String&gt; headers = new HashMap&lt;&gt;(); Enumeration&lt;String&gt; headerNames = request.getHeaderNames(); while (headerNames.hasMoreElements()) &#123; String key = headerNames.nextElement(); String value = request.getHeader(key); headers.put(key, value); &#125; return headers; &#125;&#125; 验证 header用 postman 重新请求一遍，查看 provider 控制台打印：]]></content>
      <categories>
        <category>spring-cloud</category>
      </categories>
      <tags>
        <tag>SpringCloud</tag>
        <tag>Feign</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring Cloud 微服务（9） --- Feign(三) http client 替换、GET 方式传递 POJO等]]></title>
    <url>%2Fspring-cloud%2Fspring-cloud-9.html</url>
    <content type="text"><![CDATA[在了解了 FeignClient 的配置、请求响应的压缩后，基本的调用已经没有问题。接下来就需要了解 Feign 多参数传递、文件上传、header 传递 token、请求失败、图片流 等问题的解决，以及 HTTP Client 替换的问题。 Http Client 替换源码：https://gitee.com/laiyy0728/spring-cloud/tree/master/spring-cloud-feign/spring-cloud-feign-httpclient Feign 默认情况下使用的是 JDK 原生的 URLConnection 发送 HTTP 请求，没有连接池，但是对每个地址都会保持一个长连接。可以利用 Apache HTTP Client 替换原始的 URLConnection，通过设置连接池、超时时间等，对服务调用进行调优。 在类 feign/Client$Default.java 中，可以看到，默认执行 http 请求的是 URLConnection12345678public static class Default implements Client &#123; @Override public Response execute(Request request, Options options) throws IOException &#123; HttpURLConnection connection = convertAndSend(request, options); return convertResponse(connection).toBuilder().request(request).build(); &#125;&#125; 在类 org/springframework/cloud/openfeign/ribbon/FeignRibbonClientAutoConfiguration.java 中，可以看到引入了三个类：HttpClientFeignLoadBalancedConfiguration、OkHttpFeignLoadBalancedConfiguration、DefaultFeignLoadBalancedConfiguration 可以看到在 DefaultFeignLoadBalancedConfiguration 中，使用的是 Client.Default，即使用 URLConnection 使用 Apache Http Client 替换 URLConnectionpom 依赖123456789101112&lt;!-- 引入 httpclient --&gt;&lt;dependency&gt; &lt;groupId&gt;org.apache.httpcomponents&lt;/groupId&gt; &lt;artifactId&gt;httpclient&lt;/artifactId&gt;&lt;/dependency&gt;&lt;!-- 引入 feign 对 httpclient 的支持 --&gt;&lt;dependency&gt; &lt;groupId&gt;com.netflix.feign&lt;/groupId&gt; &lt;artifactId&gt;feign-httpclient&lt;/artifactId&gt; &lt;version&gt;8.18.0&lt;/version&gt;&lt;/dependency&gt; 配置文件123feign: httpclient: enabled: true 查看验证配置在类 HttpClientFeignLoadBalancedConfiguration 上，有注解：@ConditionalOnClass(ApacheHttpClient.class)、@ConditionalOnProperty(value = &quot;feign.httpclient.enabled&quot;, matchIfMissing = true)：在 ApacheHttpClient 类存在且 feign.httpclient.enabled 为 true 时启用配置。 在 HttpClientFeignLoadBalancedConfiguration 123 行打上断点，重新启动项目，可以看到确实进行了 ApacheHttpClient 的声明。在将 feign.httpclient.enabled 设置为 false 后，断点就进不来了。由此可以验证 ApacheHttpClient 替换成功。 使用 OkHttp 替换 URLConnectionpom 依赖12345&lt;dependency&gt; &lt;groupId&gt;io.github.openfeign&lt;/groupId&gt; &lt;artifactId&gt;feign-okhttp&lt;/artifactId&gt; &lt;version&gt;10.1.0&lt;/version&gt;&lt;/dependency&gt; 配置文件12345feign: httpclient: enabled: false okhttp: enabled: true 验证配置在 OkHttpFeignLoadBalancedConfiguration 第 84 行打断点，重新启动项目，可以看到成功进入断点；当把 feign.okhttp.enabled 设置为 false 后，重新启动项目，没进入断点。证明 OkHttp 替换成功。 GET 方式传递 POJO等源码：https://gitee.com/laiyy0728/spring-cloud/tree/master/spring-cloud-feign/spring-cloud-feign-multi-params SpringMVC 是支持 GET 方法直接绑定 POJI 的，但是 Feign 的实现并未覆盖所有 SpringMVC 的功能，常用的解决方式： 把 POJO 拆散成一个一个单独的属性放在方法参数里 把方法参数变成 Map 传递 使用 GET 传递 @RequestBody，这种方式有违 RESTFul。 实现 Feign 的 RequestInterceptor 中的 apply 方法，统一拦截转换处理 Feign 中 GET 方法传递 POJO 问题。而 Feign 进行 POST 多参数传递要比 Get 简单。 providerprovider 用于模拟用户查询、修改操作，作为服务生产者 pom 依赖：123456789 &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt;&lt;/dependency&gt; 配置文件：1234567891011eureka: client: service-url: defaultZone: http://localhost:8761/eureka/ instance: instance-id: $&#123;spring.application.name&#125;:$&#123;server.port&#125;spring: application: name: spring-cloud-feign-multi-params-providerserver: port: 8888 实体、启动类、Controller1234567891011121314151617181920212223242526272829303132333435363738394041// 实体@Data@NoArgsConstructor@AllArgsConstructorpublic class User &#123; private int id; private String name;&#125;// 启动类@SpringBootApplication@EnableDiscoveryClientpublic class SpringCloudFeignMultiParamsProviderApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(SpringCloudFeignMultiParamsProviderApplication.class, args); &#125;&#125;// Controller@RestController@RequestMapping(value = "/user")public class UserController &#123; @GetMapping(value = "/add") public String addUser(User user)&#123; return "hello!" + user.getName(); &#125; @PostMapping(value = "/update") public String updateUser(@RequestBody User user)&#123; return "hello! modifying " + user.getName(); &#125;&#125; consumerconsumer 用于模拟服务调用，属于服务消费者，调用 provider 的具体实现 pom 依赖：1234567891011121314&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-openfeign&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt;&lt;/dependency&gt; 配置文件：1234567891011121314151617181920eureka: client: service-url: defaultZone: http://localhost:8761/eureka/ instance: instance-id: $&#123;spring.application.name&#125;:$&#123;server.port&#125;spring: application: name: spring-cloud-feign-multi-params-consumerserver: port: 8889feign: client: config: spring-cloud-feign-multi-params-provider: loggerLevel: fulllogging: level: com.laiyy.gitee.feign.multi.params.springcloudfeignmultiparamscomsumer.MultiParamsProviderFeignClient: debug 实体、启动类、Controller、FeignClient1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859// 实体与 provider 一致，不再赘述// 启动类@SpringBootApplication@EnableDiscoveryClient@EnableFeignClientspublic class SpringCloudFeignMultiParamsComsumerApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(SpringCloudFeignMultiParamsComsumerApplication.class, args); &#125;&#125;// Controller@RestControllerpublic class UserController &#123; private final MultiParamsProviderFeignClient feignClient; @Autowired public UserController(MultiParamsProviderFeignClient feignClient) &#123; this.feignClient = feignClient; &#125; @GetMapping(value = "add-user") public String addUser(User user)&#123; return feignClient.addUser(user); &#125; @PostMapping(value = "update-user") public String updateUser(@RequestBody User user)&#123; return feignClient.updateUser(user); &#125;&#125;// FeignClient@FeignClient(name = "spring-cloud-feign-multi-params-provider")public interface MultiParamsProviderFeignClient &#123; /** * GET 方式 * @param user user * @return 添加结果 */ @RequestMapping(value = "/user/add", method = RequestMethod.GET) String addUser(User user); /** * POST 方式 * @param user user * @return 修改结果 */ @RequestMapping(value = "/user/update", method = RequestMethod.POST) String updateUser(@RequestBody User user);&#125; 验证调用使用 POST MAN 测试工具，调用 consumer 接口，利用 Feign 进行远程调用 调用 update-user，验证调用成功 调用 add-user，验证调用失败 控制台报错：12345678&#123;&quot;timestamp&quot;:&quot;2019-01-24T08:24:42.887+0000&quot;,&quot;status&quot;:405,&quot;error&quot;:&quot;Method Not Allowed&quot;,&quot;message&quot;:&quot;Request method &apos;POST&apos; not supported&quot;,&quot;path&quot;:&quot;/user/add&quot;&#125;] with root causefeign.FeignException: status 405 reading MultiParamsProviderFeignClient#addUser(User); content:&#123;&quot;timestamp&quot;:&quot;2019-01-24T08:24:42.887+0000&quot;,&quot;status&quot;:405,&quot;error&quot;:&quot;Method Not Allowed&quot;,&quot;message&quot;:&quot;Request method &apos;POST&apos; not supported&quot;,&quot;path&quot;:&quot;/user/add&quot;&#125; at feign.FeignException.errorStatus(FeignException.java:62) ~[feign-core-9.5.1.jar:na] at feign.codec.ErrorDecoder$Default.decode(ErrorDecoder.java:91) ~[feign-core-9.5.1.jar:na] at feign.SynchronousMethodHandler.executeAndDecode(SynchronousMethodHandler.java:138) ~[feign-core-9.5.1.jar:na] ... 命名是 GET 调用，为什么到底层就变成了 POST 调用？ GET 传递 POJO 解决方案Feign 的远程调用中，GET 是不能传递 POJO 的，否则就是 POST，为了解决这个错误，可以实现 RequestInterceptor，解析 POJO，传递 Map 即可解决 在 consumer 中，增加一个实体类，用于解析 POJO 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566/** * @author laiyy * @date 2019/1/24 10:33 * @description 实现 Feign Request 拦截器，实现 GET 传递 POJO */@Componentpublic class FeignRequestInterceptor implements RequestInterceptor &#123; private final ObjectMapper objectMapper; @Autowired public FeignRequestInterceptor(ObjectMapper objectMapper) &#123; this.objectMapper = objectMapper; &#125; @Override public void apply(RequestTemplate template) &#123; if ("GET".equals(template.method()) &amp;&amp; template.body() != null) &#123; try &#123; JsonNode jsonNode = objectMapper.readTree(template.body()); template.body(null); Map&lt;String, Collection&lt;String&gt;&gt; queries = new HashMap&lt;&gt;(); // 构建 Map buildQuery(jsonNode, "", queries); // queries 就是 POJO 解析为 Map 后的数据 template.queries(queries); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; &#125; private void buildQuery(JsonNode jsonNode, String path, Map&lt;String, Collection&lt;String&gt;&gt; queries) &#123; if (!jsonNode.isContainerNode()) &#123; // 如果是叶子节点 if (jsonNode.isNull()) &#123; return; &#125; Collection&lt;String&gt; values = queries.get(path); if (CollectionUtils.isEmpty(values)) &#123; values = new ArrayList&lt;&gt;(); queries.put(path, values); &#125; values.add(jsonNode.asText()); return; &#125; if (jsonNode.isArray())&#123; // 如果是数组节点 Iterator&lt;JsonNode&gt; elements = jsonNode.elements(); while (elements.hasNext()) &#123; buildQuery(elements.next(), path, queries); &#125; &#125; else &#123; Iterator&lt;Map.Entry&lt;String, JsonNode&gt;&gt; fields = jsonNode.fields(); while (fields.hasNext()) &#123; Map.Entry&lt;String, JsonNode&gt; entry = fields.next(); if (StringUtils.hasText(path)) &#123; buildQuery(entry.getValue(), path + "." + entry.getKey(), queries); &#125; else &#123; // 根节点 buildQuery(entry.getValue(), entry.getKey(), queries); &#125; &#125; &#125; &#125;&#125; 重新启动 consumer，再次调用 add-user，验证结果： 由此验证，GET 方式传递 POJO 成功。]]></content>
      <categories>
        <category>spring-cloud</category>
      </categories>
      <tags>
        <tag>SpringCloud</tag>
        <tag>Feign</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring Cloud 微服务（8） --- Feign(二) GZIP、配置]]></title>
    <url>%2Fspring-cloud%2Fspring-cloud-8.html</url>
    <content type="text"><![CDATA[在理解了 Feign 的运行原理之后，可以很轻松的搭建起一个基于 Feign 的微服务调用。 Feign 是通过 http 调用的，那么就牵扯到一个数据大小的问题。如果不经过压缩就发送请求、获取响应，那么会因为流量过大导致浪费流量，这时就需要使用数据压缩，将大流量压缩成小流量。 Feign GZIP 压缩源码：https://gitee.com/laiyy0728/spring-cloud/tree/master/spring-cloud-feign/spring-cloud-feign-gzip Spring Cloud Feign 支持对请求和响应进行 GZIP 压缩，以调高通信效率。 开启 gzip 压缩application.yml 12345678910111213feign: compression: request: enabled: true mime-type: text/html,application/xml,application/json min-request-size: 2048 response: enabled: true# 开启日志logging: level: com.laiyy.gitee.feign.springcloudfeigngzip.feign.GiteeFeignClient: debug 由于使用 gzip 压缩，压缩后的数据是二进制，那么在获取 Response 的时候，就不能和之前一样直接使用 String 来接收了，需要使用 ResponseEntity&lt;byte[]&gt; 接收 1234567@FeignClient(name = "gitee-client", url = "https://www.gitee.com/", configuration = GiteeFeignConfiguration.class)public interface GiteeFeignClient &#123; @RequestMapping(value = "/search", method = RequestMethod.GET) ResponseEntity&lt;byte[]&gt; searchRepo(@RequestParam("q") String query);&#125; 对应的 Controller 也需要改为 ResponseEntity&lt;byte[]&gt;1234@GetMapping(value = "feign-gitee")public ResponseEntity&lt;byte[]&gt; feign(String query)&#123; return giteeFeignClient.searchRepo(query);&#125; 验证 gzip 压缩开启 FeignClient 日志 没有使用 GZIP 压缩在 spring-cloud-feign-simple 项目中，开启日志： 123logging: level: com.laiyy.gitee.feign.springcloudfeignsimple.feign.GiteeFeignClient: debug 访问：http://localhost:8080/feign-gitee?query=spring-cloud-openfeign ，可以看到，在控制台中打印了日志信息： 使用了 GZIP 压缩在 spring-cloud-feign-gzip 中开启日志：123logging: level: com.laiyy.gitee.feign.springcloudfeigngzip.feign.GiteeFeignClient: debug 访问：http://localhost:8080/feign-gitee?query=spring-cloud-openfeign ，可以看到，在控制台中打印了日志信息： 对比Request 对比经过对比，可以看到在没有开启 gzip 之前，request 是：12---&gt; GET https://www.gitee.com/search?q=spring-cloud-openfeign HTTP/1.1---&gt; END HTTP (0-byte body) 开启 gzip 之后，request 是：1234---&gt; GET https://www.gitee.com/search?q=spring-cloud-openfeign HTTP/1.1Accept-Encoding: gzipAccept-Encoding: deflate---&gt; END HTTP (0-byte body) 可以看到，request 中增加了 Accept-Encoding: gzip，证明 request 开启了 gzip 压缩。 Response 对比在没有开启 gzip 之前，response 是：12345678910111213141516171819202122232425262728293031cache-control: no-cacheconnection: keep-alivecontent-type: text/html; charset=utf-8date: Wed, 23 Jan 2019 07:22:45 GMTexpires: Sun, 1 Jan 2000 01:00:00 GMTpragma: must-revalidate, no-cache, privateserver: nginxset-cookie: gitee-session-n=BAh7CEkiD3Nlc3Npb25faWQGOgZFVEkiJTIyM2VlNjhkMWVmZGJlMWY5YmIxN2M5MGVlODEzY2Q5BjsAVEkiF21vYnlsZXR0ZV9vdmVycmlkZQY7AEY6CG5pbEkiEF9jc3JmX3Rva2VuBjsARkkiMTlsSDZmQk1CWXpWWVFTSTFtbkwzb0VJTjZjbVdVKzhYZjE0ako0djIvRUk9BjsARg%3D%3D--97ef4dc9c69d79b8f6ca42b9d0b6eaeb121d8048; domain=.gitee.com; path=/; HttpOnlyset-cookie: oschina_new_user=false; path=/; expires=Sun, 23-Jan-2039 07:22:44 GMTset-cookie: user_locale=; path=/; expires=Sun, 23-Jan-2039 07:22:44 GMTset-cookie: aliyungf_tc=AQAAAAq0GH/W3wsAygAc2kkmdVRPGWZs; Path=/; HttpOnlystatus: 200 OKtransfer-encoding: chunkedx-rack-cache: missx-request-id: 437df6eccbd8a2b93912a7b84644b33dx-runtime: 0.646640x-ua-compatible: IE=Edge,chrome=1x-xss-protection: 1; mode=block&lt;!DOCTYPE html&gt;&lt;html lang=&apos;zh-CN&apos;&gt;&lt;head&gt;&lt;title&gt;spring-cloud-openfeign · Search - Gitee&lt;/title&gt;&lt;link href=&quot;https://assets.gitee.com/assets/favicon-e87ded4710611ed62adc859698277663.ico&quot; rel=&quot;shortcut icon&quot; type=&quot;image/vnd.microsoft.icon&quot; /&gt;&lt;meta charset=&apos;utf-8&apos;&gt;&lt;meta content=&apos;always&apos; name=&apos;referrer&apos;&gt;&lt;meta content=&apos;Gitee&apos; property=&apos;og:site_name&apos;&gt;...&lt;/html&gt;&lt;--- END HTTP (48623-byte body) 在开启 gzip 之后，response 是：1234567891011121314151617181920212223&lt;--- HTTP/1.1 200 OK (987ms)cache-control: no-cacheconnection: keep-alivecontent-encoding: gzip ----------------------------- 第一处不同content-type: text/html; charset=utf-8date: Wed, 23 Jan 2019 07:20:59 GMTexpires: Sun, 1 Jan 2000 01:00:00 GMTpragma: must-revalidate, no-cache, privateserver: nginxset-cookie: gitee-session-n=BAh7CEkiD3Nlc3Npb25faWQGOgZFVEkiJTVmYmMwNTQyNWU4OGMzMmYyN2M3MDQ1ZmZiNjY5ZDIzBjsAVEkiF21vYnlsZXR0ZV9vdmVycmlkZQY7AEY6CG5pbEkiEF9jc3JmX3Rva2VuBjsARkkiMVdaQ2tqYTVuTjd6WU1UKzU5R1hNbnRlbUNQaXhoSzRLRmJreXduTU51cUU9BjsARg%3D%3D--8843239d46616524d58af2611f2db9614b8518b1; domain=.gitee.com; path=/; HttpOnlyset-cookie: oschina_new_user=false; path=/; expires=Sun, 23-Jan-2039 07:20:58 GMTset-cookie: user_locale=; path=/; expires=Sun, 23-Jan-2039 07:20:58 GMTset-cookie: aliyungf_tc=AQAAAHojVAEggQsAygAc2ugaNNgiXCKR; Path=/; HttpOnlystatus: 200 OKtransfer-encoding: chunkedx-rack-cache: missx-request-id: 53b45c93d5062be2c5643d9402d0a6dex-runtime: 0.412080x-ua-compatible: IE=Edge,chrome=1x-xss-protection: 1; mode=blockBinary data -------------------------------- 第二处不同&lt;--- END HTTP (11913-byte body) ---------------------------- 第三处不同 对比可以发现： 在 response 的 content-type 上面多了一个 content-encoding: gzip 在没有开启 gzip 之前控制台打印了 html 信息，开启后没有打印，换成了 Binary data 二进制 END HTTP 在没开启 gzip 之前为 48623 byte，开启后为 11913 byte 由此可以证明，response 开启 gzip 成功 Feign 配置源码：https://gitee.com/laiyy0728/spring-cloud/tree/master/spring-cloud-feign/spring-cloud-feign-config 对单个指定特定名称的 Feign 进行配置在之前的例子中，在对 FeignClient 的配置中，使用的是 @FeignClient 的 configuration 属性指定的配置类，也可以使用配置文件对 @FeignClient 注解的接口进行配置 FeignClient1234567@FeignClient(name = "gitee-client", url = "https://www.gitee.com")public interface GiteeFeignClient &#123; @RequestMapping(value = "/search", method = RequestMethod.GET) ResponseEntity&lt;byte[]&gt; searchRepo(@RequestParam("q") String query);&#125; application.yml1234567891011121314151617181920feign: client: config: gitee-client: # 这里指定的是 @FeignClient 的 name/value 属性的值 connectTimeout: 5000 # 链接超时时间 readTimeout: 5000 # 读超时 loggerLevel: none # 日志级别 # errorDecoder: # 错误解码器（类路径） # retryer: # 重试机制（类路径） # requestInterceptors: 拦截器配置方式 一：多个拦截器， 需要注意如果有多个拦截器，"-" 不能少 # - Intecerptor1 类路径， # - Interceptpt2 类路径 # requestInterceptors: 拦截器配置方式 二：多个拦截器，用 [Interceptor, Interceptor] 配置，需要配置类路径 # decode404: false 是否 404 解码 # encoder： 编码器（类路径） # decoder： 解码器（类路径） # contract： 契约（类路径）logging: level: com.laiyy.gitee.feign.springcloudfeignconfig.feign.GiteeFeignClient: debug 验证此时配置的 loggerLevel 为 none，不打印日志，访问： http://localhost:8080/feign-gitee?query=spring-cloud-openfeign ，可以看到控制台没有任何消息 将 loggerLevel 改为 full，再次访问可以看到打印日志消息。 将 loggerLevel 改为 feign.Logger.Level 中没有的级别，再次测试：loggerLevel: haha，可以看到控制启动报错： 123456789101112131415161718192021***************************APPLICATION FAILED TO START***************************Description:Failed to bind properties under &apos;feign.client.config.gitee-client.logger-level&apos; to feign.Logger$Level: Property: feign.client.config.gitee-client.loggerlevel Value: haha Origin: class path resource [application.yml]:7:22 Reason: failed to convert java.lang.String to feign.Logger$LevelAction:Update your application&apos;s configuration. The following values are valid: BASIC FULL HEADERS NONE 可以验证此配置是正确的。 对全部 FeignClient 配置对全部 FeignClient 启用配置的方法也有两种：1、@EnableFeignClients 注解有一个 defaultConfiguration 属性，可以指定全局 FeignClient 的配置。2、使用配置文件对全局 FeignClient 进行配置 application.yml1234567feign: client: config: defautl: # 全局的配置需要把 client-name 指定为 default connectTimeout: 5000 # 链接超时时间 readTimeout: 5000 # 读超时 loggerLevel: full # 日志级别 如果有多个 FeignClient，每个 FeignClient 都需要单独配置，如果有一样的配置，可以提取到全局配置中，需要注意：全局配置需要放在最后一位。]]></content>
      <categories>
        <category>spring-cloud</category>
      </categories>
      <tags>
        <tag>SpringCloud</tag>
        <tag>Feign</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring Cloud 微服务 (7) --- Feign(一) 远程调用、RestTemplate、Feign]]></title>
    <url>%2Fspring-cloud%2Fspring-cloud-7.html</url>
    <content type="text"><![CDATA[在使用 SpringCloud 时，远程服务都是以 HTTP 接口形式对外提供服务，因此服务消费者在调用服务时，需要使用 HTTP Client 方式访问。在通常进行远程 HTTP 调用时，可以使用 RestTemplate、HttpClient、URLConnection、OkHttp 等，也可以使用 SpringCloud Feign 进行远程调用 RestTemplate源码：https://gitee.com/laiyy0728/spring-cloud/tree/master/spring-cloud-feign/spring-cloud-feign-simple 脱离 Eureka 的使用在脱离 Eureka 使用 RestTemplate 调用远程接口时，只需要引入 web 依赖即可。 在使用 RestTemplate 时，需要先将 RestTemplate 交给 Spring 管理 123456789@Configurationpublic class RestTemplateConfiguration &#123; @Bean public RestTemplate restTemplate()&#123; return new RestTemplate(); &#125;&#125; 编写一个 Controller，注入 RestTemplate，调用远程接口 12345678910111213141516@RestControllerpublic class RestTemplateController &#123; private final RestTemplate restTemplate; @Autowired public RestTemplateController(RestTemplate restTemplate) &#123; this.restTemplate = restTemplate; &#125; @GetMapping(value = "rest-get", produces = "text/html;charset=utf-8") public String restTemplateGet()&#123; return restTemplate.getForObject("https://gitee.com", String.class); &#125;&#125; 访问 http://localhost:8080/rest-get 关联 Eureka 使用将服务注册到 Eureka Server，并使用 RestTemplate 调用远程 Eureka Client 服务 此时，只需要按照一个标准的 Eureka Client 编写步骤，将项目改造成一个 Eureka Client，并编写另外一个 Client。将要使用 RestTemplate 的 Client 当做服务消费者，另外一个当做服务提供者。在进行远程调用时，只需要将 getForObject 的 url，改为 http://service-id 即可，具体传入参数使用 ?、&amp;、= 拼接即可。 在注册到 Eureka Server 后，进行 RestTemplate 远程调用时，service-id 会被 Eureka Client 解析为 Server 中注册的 ip、端口，以此进行远程调用。 Rest TemplateRestTemplate 提供了 11 个独立的方法，这 11 个方法对应了各种远程调用请求 方法名 http 动作 说明 getForEntity() GET 发送 GET 请求，返回的 ResponseEntity 包含了响应体所映射成的对象 getForObject() GET 发送 GET 请求，返回的请求体将映射为一个对象 postForEntity() POST 发送 POST 请求，返回包含一个对象的 ResponseEntity，这个对象是从响应体中映射得到的 postForObject() POST 发送 POST 请求，返回根据响应体匹配形成的对象 postForLocation() POST 发送 POST 请求，返回新创建资源的 URL put() PUT PUT 资源到指定 URL delete() DELETE 发送 DELETE 请求，执行删除操作 headForHeaders() HEAD 发送 HEAD 请求，返回包含指定资源 URL 的 HTTP 头 optionsFOrAllow() OPTIONS 发送 OPTIONS 请求，返回指定 URL 的 Allow 头信息 execute() 执行非响应 ResponseEntity 的请求 exchange() 执行响应 ResponseEntity 的请求 Feign使用 RestTemplate 进行远程调用，非常方便，但是也有一个致命的问题：硬编码。 在 RestTemplate 调用中，我们每个调用远程接口的方法，都将远程接口对应的 ip、端口，或 service-id 硬编码到了 URL 中，如果远程接口的 ip、端口、service-id 有修改的话，需要将所有的调用都修改一遍，这样难免会出现漏改、错改等问题，且代码不便于维护。为了解决这个问题，Netflix 推出了 Feign 来统一管理远程调用。 什么是 FeignFeign 是一个声明式的 Web Service 客户端，只需要创建一个接口，并加上对应的 Feign Client 注解，即可进行远程调用。Feign 也支持编码器、解码器，Spring Cloud Open Feign 也对 Feign 进行了增强，支持了 SpringMVC 注解，可以像 SpringMVC 一样进行远程调用。 Feign 是一种声明式、模版化的 HTTP 客户端，在 Spring Cloud 中使用 Feign，可以做到使用 HTTP 请求访问远程方法就像调用本地方法一样简单，开发者完全感知不到是在进行远程调用。 Feign 的特性： 可插拔的注解支持 可插拔的 HTTP 编码器、解码器 支持 Hystrix 断路器、Fallback 支持 Ribbon 负载均衡 支持 HTTP 请求、响应压缩 简单示例源码：https://gitee.com/laiyy0728/spring-cloud/tree/master/spring-cloud-feign/spring-cloud-feign-simple 使用 Feign 进行 github 接口调用 pom 依赖123456&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-openfeign&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 配置文件只是进行一个简单的远程调用，不需要注册 Eureka、不需要配置文件。 启动类123456789@SpringBootApplication@EnableFeignClientspublic class SpringCloudFeignSimpleApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(SpringCloudFeignSimpleApplication.class, args); &#125;&#125; Feign Client 配置123456789101112131415161718192021@Configurationpublic class GiteeFeignConfiguration &#123; /** * 配置 Feign 日志级别 * &lt;p&gt; * NONE：没有日志 * BASIC：基本日志 * HEADERS：header * FULL：全部 * &lt;p&gt; * 配置为打印全部日志，可以更方便的查看 Feign 的调用信息 * * @return Feign 日志级别 */ @Bean public Logger.Level feignLoggerLevel() &#123; return Logger.Level.FULL; &#125; &#125; FeignClient1234567@FeignClient(name = "gitee-client", url = "https://www.gitee.com/", configuration = GiteeFeignConfiguration.class)public interface GiteeFeignClient &#123; @RequestMapping(value = "/search", method = RequestMethod.GET) String searchRepo(@RequestParam("q") String query);&#125; @FeignClient：声明为一个 Feign 远程调用name：给远程调用起个名字url：指定要调用哪个 urlconfiguration：指定配置信息 @RequestMapping：如同 SpringMVC 一样调用。 Feign Controller12345678910111213141516@RestControllerpublic class FeignController &#123; private final GiteeFeignClient giteeFeignClient; @Autowired public FeignController(GiteeFeignClient giteeFeignClient) &#123; this.giteeFeignClient = giteeFeignClient; &#125; @GetMapping(value = "feign-gitee") public String feign(String query)&#123; return giteeFeignClient.searchRepo(query); &#125;&#125; 验证调用结果在浏览器中访问： http://localhost:8080/feign-gitee?query=spring-cloud-openfeign @FeignClient、@RequestMapping在 Feign 中使用 MVC 注解的注意事项在 FeignClient 中使用 @RequestMapping 注解调用远程接口，需要注意： 注解必须为 @RequestMapping，不能为组合注解 @GetMapping 等，否则解析不到 必须指定 method，否则会出问题 value 必须指定被调用方的 url，不能包含域名、ip 等 使用 @FeignClient 的注意事项 在启动类上必须加上 @FeignClients 注解，开启扫描 在 FeignClient 接口上必须指定 @FeignClient 注解，声明是一个 Feign 远程调用 @FeignClient源码 123456789101112131415161718192021222324252627282930@Target(&#123;ElementType.TYPE&#125;)@Retention(RetentionPolicy.RUNTIME)@Documentedpublic @interface FeignClient &#123; @AliasFor("name") String value() default ""; /** @deprecated */ @Deprecated String serviceId() default ""; @AliasFor("value") String name() default ""; String qualifier() default ""; String url() default ""; boolean decode404() default false; Class&lt;?&gt;[] configuration() default &#123;&#125;; Class&lt;?&gt; fallback() default void.class; Class&lt;?&gt; fallbackFactory() default void.class; String path() default ""; boolean primary() default true;&#125; 字段名 含义 name 指定 FeignClient 的名称，如果使用到了 Eureka，且使用了 Ribbon 负载均衡，则 name 为被调用者的微服务名称，用于服务发现 url 一般用于调试，可以手动指定 feign 调用的地址 decode404 当 404 时，如果该字段为 true，会调用 decoder 进行解码，否则会抛出 FeignException configuration Feign 配置类，可以自定义 Feign 的 Encoder、Decoder、LogLevel、Contract 等 fallback 容错处理类，当远程调用失败、超时时，会调用对应接口的容错逻辑。Fallback 指定的类，必须实现 @FeignClient 标记的接口 fallbackFactory 工厂类，用于生成 fallback 类的示例，可以实现每个接口通用的容错逻辑，减少重复代码 path 定义当前 FeignClient 的统一前缀 Feign 的运行原理 在启动类上加上 @EnableFeignClients 注解，开启对 Feign Client 扫描加载 在启用时，会进行包扫描，扫描所有的 @FeignClient 的注解的类，并将这些信息注入 Spring IOC 容器，当定义的 Feign 接口中的方法被调用时，通过 JDK 的代理方式，来生成具体的 RestTemplate。当生成代理时，Feign 会为每个接口方法创建一个 RestTemplate 对象，该对象封装了 HTTP 请求需要的全部信息，如：参数名、请求方法、header等 然后由 RestTemplate 生成 Request，然后把 Request 交给 Client 处理，这里指的 Client 可以是 JDK 原生的 URLConnection、Apache 的 HTTP Client、OkHttp。最后 Client 被封装到 LoadBalanceClient 类，结合 Ribbon 负载均衡发起服务间的调用。]]></content>
      <categories>
        <category>spring-cloud</category>
      </categories>
      <tags>
        <tag>SpringCloud</tag>
        <tag>Feign</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring Cloud 微服务（6） --- Eureka(四) Https]]></title>
    <url>%2Fspring-cloud%2Fspring-cloud-6.html</url>
    <content type="text"><![CDATA[在生产环境下，一般来说都是 https 协议访问，现在的 http 协议访问可能会出现问题，在 Eureka Server、Client 中开启 Https 访问。 HTTP Basic 基于 base64 编码，容易被抓包，如果暴露在公网会非常不安全，可以通过开启 https 达到保护数据的目的。 Server 证书生成1keytool -genkeypair -alias server -storetype PKCS12 -keyalg RSA -keysize 2048 -keystore server.p12 -validity 3650 密码为：123456 在当前目录生成了一个 server.p12 文件 Client 证书生成1keytool -genkeypair -alias client -storetype PKCS12 -keyalg RSA -keysize 2048 -keystore client.p12 -validity 3650 密码为：654321 在当前目录生成了一个 client.p12 文件 导出 p12 文件12keytool -export -alias server -file server.crt --keystore server.p12keytool -export -alias client -file client.crt --keystore client.p12 信任证书Client 信任 Server 证书将 server.crt 导入 client.p12 1keytool -import -alias server -file server.crt -keystore client.p12 秘钥口令是 client.p12 的口令 Server 信任 Client 证书将 client.crt 导入 server.p12 1keytool -import -alias client -file client.crt -keystore server.p12 秘钥口令是 server.p12 的口令 Eureka Server源码：https://gitee.com/laiyy0728/spring-cloud/tree/master/spring-cloud-eureka/spring-cloud-eureka-server-https 将生成的最后的 server.p12 文件放在 resources 下 application.yml12345678910111213141516171819202122server: port: 8761 ssl: enabled: true key-store-type: PKCS12 # type 与 keytool 的 storetype 一致 key-alias: server # 与 keytool 的 alias 一致 key-store: classpath:server.p12 # p12 文件地址 key-store-password: 123456 # server.p12 口令eureka: instance: hostname: localhost secure-port: $&#123;server.port&#125; # https 端口 secure-port-enabled: true # 是否开启 https port non-secure-port-enabled: false home-page-url: https://$&#123;eureka.instance.hostname&#125;:$&#123;server.port&#125; # https 协议 status-page-url: https://$&#123;eureka.instance.hostname&#125;:$&#123;server.port&#125; # https 协议 client: register-with-eureka: false fetch-registry: false service-url: defaultZone: https://$&#123;eureka.instance.hostname&#125;:$&#123;server.port&#125;/eureka/ # https 协议 验证 Eureka Server访问 http://localhost:8761 访问 https://localhost:8761 Eureka Client源码：https://gitee.com/laiyy0728/spring-cloud/tree/master/spring-cloud-eureka/spring-cloud-eureka-client-https Client 只在连接 Eureka Server 的时候使用 https 协议，如果要全局都使用 https，则和 Server 的 https 配置一致，只需要将配置换成 client.p12 的配置即可。 application.yml123456789101112131415server: port: 8081spring: application: name: client1eureka: client: securePortEnabled: true ssl: key-store: client.p12 key-store-password: 654321 serviceUrl: defaultZone: https://localhost:8761/eureka/ Https 连接配置123456789101112131415161718192021222324252627@Configurationpublic class EurekaHttpsClientConfiguration &#123; @Value("$&#123;eureka.client.ssl.key-store&#125;") private String ketStoreFileName; @Value("$&#123;eureka.client.ssl.key-store-password&#125;") private String ketStorePassword; @Bean public DiscoveryClient.DiscoveryClientOptionalArgs discoveryClientOptionalArgs() throws CertificateException, NoSuchAlgorithmException, KeyStoreException, IOException, KeyManagementException &#123; EurekaJerseyClientImpl.EurekaJerseyClientBuilder builder = new EurekaJerseyClientImpl.EurekaJerseyClientBuilder(); builder.withClientName("eureka-https-client"); URL url = this.getClass().getClassLoader().getResource(ketStoreFileName); SSLContext sslContext = new SSLContextBuilder() .loadTrustMaterial(url, ketStorePassword.toCharArray()).build(); builder.withCustomSSL(sslContext); builder.withMaxTotalConnections(10); builder.withMaxConnectionsPerHost(10); DiscoveryClient.DiscoveryClientOptionalArgs optionalArgs = new DiscoveryClient.DiscoveryClientOptionalArgs(); optionalArgs.setEurekaJerseyClient(builder.build()); return optionalArgs; &#125;&#125; 验证 Client访问 https://localhost:8761 使用 http 注册]]></content>
      <categories>
        <category>spring-cloud</category>
      </categories>
      <tags>
        <tag>SpringCloud</tag>
        <tag>Eureka</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring Cloud（5） --- Eureka(三) 集群、Region Zone、Http Basic]]></title>
    <url>%2Fspring-cloud%2Fspring-cloud-5.html</url>
    <content type="text"><![CDATA[在了解了 Euerka 的 REST API、核心类、核心操作、参数调优等概念之后，在实际的项目中来验证这些概念。 Eureka Server 集群扩展在之前的例子中，和 SpringCloud 中文社区的公益 Eureka Server 都是单节点的，如果 Server 挂掉了，那么整个微服务的注册将不在可用。在这时，就需要搭建 Eureka Server 高可用集群，保证整个微服务不会因为一个 Server 挂掉而导致整个微服务不可用。 使用 profile，搭建高可用集群有两种常用的方式启动多个 eureka server 在一个配置文件中，指定多个配置源码：https://gitee.com/laiyy0728/spring-cloud/tree/master/spring-cloud-eureka/spring-cloud-eureka-server-ha 可以使用如下配置，在一个 application.yml 文件中，配置多个 Eureka Server，相互注册指定 defaultZone，并使用 profile 区别每个 Server 的配置。 1234567891011121314151617181920212223242526272829303132333435363738394041spring: application: name: spring-cloud-eureka-server-ha---server: port: 8761eureka: client: fetch-registry: false register-with-eureka: false service-url: defaultZone: http://localhost:8762/eureka,http://localhost:8763/eurekaspring: profiles: peer1---spring: profiles: peer2server: port: 8762eureka: client: fetch-registry: false register-with-eureka: false service-url: defaultZone: http://localhost:8761/eureka,http://localhost:8763/eureka---spring: profiles: peer3server: port: 8763eureka: client: fetch-registry: false register-with-eureka: false service-url: defaultZone: http://localhost:8761/eureka,http://localhost:8762/eureka 验证多 Server 启动使用 mvn spring-boot:run -Dspring.profiles.active=peer1peer1 可以换为 peer2、peer3，启动其他的 profile 在浏览器中输入： http://localhost:8761、http://localhost:8762、http://localhost:8763，都可以访问到 Eureka Server 使用这种方式启动存在的问题： 在一个配置文件中存在多个 Server 的配置，太过杂乱无章，不好管理如果 Server 在不同的机器上，由于 ip 地址不同，在第一个 Server 启动时由于找不到注册中心，必报错，当第二个 Server 启动后正常 使用多配置文件将 application.yml 复制多份，改名为 application-peer1.yml、application-peer2.yml、application-peer3.yml，然后使用 mvn spring-boot:run -Dspring.profiles.active=peer1 启动项目。 为验证此种配置方式可用，将 peer3 的端口该为 8764，启动测试 使用这种方式的问题： 可能存在同样的配置在多个配置文件都存在，需要修改时需要修改每个文件，太过冗余Server 在不同机器上的时候，出现的问题和 在一个配置文件中，指定多个配置 的问题一致 接口验证12345678910111213141516171819@SpringBootApplication@EnableEurekaServer@RestControllerpublic class SpringCloudEurekaServerHaApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(SpringCloudEurekaServerHaApplication.class, args); &#125; @Autowired private EurekaClientConfigBean eurekaClientConfigBean; @GetMapping(value = "eureka-service-url") public Object getEurekaServerUrl() &#123; return eurekaClientConfigBean.getServiceUrl(); &#125;&#125; 重启 3 个Server，浏览器访问 http://localhost:8764/eureka-service-url 可以看到，peer3 中注册了两个 eureka server。 Eureka Client 注册到多 ServerClient 注册到多 Server，只需要在配置文件中指定对应 Server 的 defauleZone 即可。 1234567891011121314spring: application: name: eureka-client server: port: 8001 eureka: instance: hostname: localhost client: service-url: defaultZone: http://localhost:8761/eureka/,http://localhost:8762/eureka/,http://localhost:8764/eureka/, server: enable-self-preservation: false 使用 Region、Zone 搭建高可用集群源码：https://gitee.com/laiyy0728/spring-cloud/tree/master/spring-cloud-eureka/spring-cloud-eureka-client-region-zone 配置文件 application-zone1a.yml：1234567891011121314151617181920spring: application: name: spring-cloud-eureka-server-region-zoneserver: port: 8761eureka: client: fetch-registry: false register-with-eureka: false service-url: zone1: http://localhost:8761/eureka/,http://localhost:8762/eureka/ zone2: http://localhost:8763/eureka/,http://localhost:8764/eureka/ region: region-east # 设置 region availability-zones: region-east: zone1,zone2 # 设置可用 region-zone instance: hostname: localhost prefer-ip-address: true metadata-map: zone: zone1 # 设置 zone application-zone1b.yml： 将 server.port 修改为 8762application-zone2a.yml： 将 server.port 修改为 8763，eureka.instance.metadata-map.zone 修改为 zone2application-zone2b.yml： 将 server.port 修改为 8764，eureka.instance.metadata-map.zone 修改为 zone2 验证 Eureka Server在浏览器访问 http://localhost:8761 创建 Eureka Client源码：https://gitee.com/laiyy0728/spring-cloud/tree/master/spring-cloud-eureka/spring-cloud-eureka-client-region-zone 创建两个 Eureka Client，分别对应两个 Zone application-zone1.yml12345678910111213141516server: port: 8081spring: application: name: spring-cloud-eureka-client-region-zoneeureka: instance: metadata-map: zone: zone1 client: region: region-east availability-zones: region-east: zone1,zone2 service-url: zone1: http://localhost:8761/eureka/,http://localhost:8762/eureka/ zone2: http://localhost:8763/eureka/,http://localhost:8764/eureka/ application-zone2.yml：修改 server.port=8082，eureka.instance.metadata-map.zone=zone2 暴露服务端点application.yml：12345management: endpoints: web: exposure: include: '*' 引入 pom 依赖：123456789101112&lt;dependencies&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt;&lt;/dependency&gt;&lt;!-- 暴露端点 --&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt;&lt;/dependency&gt;&lt;/dependencies&gt; 验证 region、zone访问 client 暴露的环境端点，验证 region、zone http://localhost:8081/actuator/env、http://localhost:8082/actuator/env 由此，可以验证 client1、client2 的 zone 是指定的 zone。 开启 Http Basic现在的实例中，访问 Eureka Server 是不需要用户名、密码的，不需要安全验证。为了防止微服务暴露，可以开启 Http Basic 安全教研。 Eureka Server 开启 Http Basic源码：https://gitee.com/laiyy0728/spring-cloud/tree/master/spring-cloud-eureka/spring-cloud-eureka-server-http-basic 引入 pom 依赖1234567891011&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-server&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-security&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 创建配置文件1234567891011121314server: port: 8761spring: security: user: name: laiyy # 访问 Eureka Server 的用户名 password: 123456 # 访问 Eureka Server 的密码eureka: client: service-url: defaultZone: http://localhost:$&#123;server.port:8761&#125;/eureka/ register-with-eureka: false fetch-registry: false 访问 http://localhost:8761 Eureka Client 开启 Http Basic源码：https://gitee.com/laiyy0728/spring-cloud/tree/master/spring-cloud-eureka/spring-cloud-eureka-client-http-basic 引入 pom 依赖1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt;&lt;/dependency&gt; 配置文件123456789101112131415161718spring: application: name: spring-cloud-eureka-client-http-basiceureka: client: security: basic: user: laiyy password: 123456 service-url: defaultZone: http://$&#123;eureka.client.security.basic.user&#125;:$&#123;eureka.client.security.basic.password&#125;@localhost:8761/eureka instance: prefer-ip-address: true instance-id: $&#123;spring.application.name&#125;:$&#123;server.port&#125;server: port: 8081 需要注意，defaultZone 需要设置为： http://user:password@ip:port/eureka/ 启动 Eureka Client，验证 Http Basic在启动 Client 后，观察日志，可以看到出现了 403 错误： 明明已经指定了 Eureka Server 的用户名、密码、ip、端口，为什么还是注册失败？是因为 Http Basic 默认是同源的，而 client、server 的 ip、端口不一致，会出现跨域访问请求，导致 403. 解决办法：在 Eureka Server 端关闭 csrf 访问。 123456789@EnableWebSecuritypublic class HttpBasicConfiguration extends WebSecurityConfigurerAdapter &#123; @Override protected void configure(HttpSecurity http) throws Exception &#123; super.configure(http); http.csrf().disable(); &#125;&#125; 重新启动 Server、Client，访问 Server，可以看到 Client 注册成功]]></content>
      <categories>
        <category>spring-cloud</category>
      </categories>
      <tags>
        <tag>SpringCloud</tag>
        <tag>Eureka</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring Cloud 微服务（4） --- Eureka(二) REST API、核心类、调优]]></title>
    <url>%2Fspring-cloud%2Fspring-cloud-4.html</url>
    <content type="text"><![CDATA[在上一篇已经了解到了服务注册与发现、Eureka、Eureka 简单示例、Eureka Server 中查看 Client 状态等。接下来需要了解 Eureka 的 REST API、核心类、调优等惭怍。 REST API在 Eureka Server 的可视化页面中，我们可以看到每个微服务的注册信息。在 Server、Client 的配置文件中，都指定了一个 defaultZone: ip:port/eureka/，那么这个配置的作用是什么？为什么在 ip、端口 后面要加上一个 /eureka ？ /eureka 就是 Eureka 的 REST API 的端点地址。 /eureka/ 端点启动 Eureka Server、Client，在浏览器中输入： http://localhost:8761/eureka/apps ，可以看到如下信息： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657&lt;!-- 所有工程 --&gt;&lt;applications&gt; &lt;versions__delta&gt;1&lt;/versions__delta&gt; &lt;apps__hashcode&gt;UP_1_&lt;/apps__hashcode&gt; &lt;application&gt; &lt;!-- 单个实例的名称 --&gt; &lt;name&gt;SPRING-CLOUD-EUREKA-CLIENT-SIMPLE&lt;/name&gt; &lt;instance&gt; &lt;!-- 单个实例的 instance-id --&gt; &lt;instanceId&gt;spring-cloud-eureka-client-simple:8081&lt;/instanceId&gt; &lt;!-- 实例的 hostname，没有指定时用 ip --&gt; &lt;hostName&gt;10.10.10.141&lt;/hostName&gt; &lt;app&gt;SPRING-CLOUD-EUREKA-CLIENT-SIMPLE&lt;/app&gt; &lt;!-- 实例的ip --&gt; &lt;ipAddr&gt;10.10.10.141&lt;/ipAddr&gt; &lt;!-- 实例状态 --&gt; &lt;status&gt;UP&lt;/status&gt; &lt;overriddenstatus&gt;UNKNOWN&lt;/overriddenstatus&gt; &lt;!-- 端口 --&gt; &lt;port enabled="true"&gt;8081&lt;/port&gt; &lt;!-- https --&gt; &lt;securePort enabled="false"&gt;443&lt;/securePort&gt; &lt;countryId&gt;1&lt;/countryId&gt; &lt;dataCenterInfo class="com.netflix.appinfo.InstanceInfo$DefaultDataCenterInfo"&gt; &lt;name&gt;MyOwn&lt;/name&gt; &lt;/dataCenterInfo&gt; &lt;leaseInfo&gt; &lt;!-- 每多长时间续约一次，单位 秒 --&gt; &lt;renewalIntervalInSecs&gt;30&lt;/renewalIntervalInSecs&gt; &lt;!-- 续约过期时间，单位秒。规定时间内没有续约会剔除 Eureka Server --&gt; &lt;durationInSecs&gt;90&lt;/durationInSecs&gt; &lt;!-- 注册时间 --&gt; &lt;registrationTimestamp&gt;1547800471059&lt;/registrationTimestamp&gt; &lt;!-- 上一次续约时间 --&gt; &lt;lastRenewalTimestamp&gt;1547800471059&lt;/lastRenewalTimestamp&gt; &lt;evictionTimestamp&gt;0&lt;/evictionTimestamp&gt; &lt;serviceUpTimestamp&gt;1547800471059&lt;/serviceUpTimestamp&gt; &lt;/leaseInfo&gt; &lt;metadata&gt; &lt;management.port&gt;8081&lt;/management.port&gt; &lt;jmx.port&gt;10235&lt;/jmx.port&gt; &lt;/metadata&gt; &lt;!-- 主页面 --&gt; &lt;homePageUrl&gt;http://10.10.10.141:8081/&lt;/homePageUrl&gt; &lt;!-- 实例信息 --&gt; &lt;statusPageUrl&gt;http://10.10.10.141:8081/actuator/info&lt;/statusPageUrl&gt; &lt;!-- 实例健康检查 --&gt; &lt;healthCheckUrl&gt;http://10.10.10.141:8081/actuator/health&lt;/healthCheckUrl&gt; &lt;vipAddress&gt;spring-cloud-eureka-client-simple&lt;/vipAddress&gt; &lt;secureVipAddress&gt;spring-cloud-eureka-client-simple&lt;/secureVipAddress&gt; &lt;isCoordinatingDiscoveryServer&gt;false&lt;/isCoordinatingDiscoveryServer&gt; &lt;lastUpdatedTimestamp&gt;1547800471059&lt;/lastUpdatedTimestamp&gt; &lt;lastDirtyTimestamp&gt;1547800470997&lt;/lastDirtyTimestamp&gt; &lt;actionType&gt;ADDED&lt;/actionType&gt; &lt;/instance&gt; &lt;/application&gt; &lt;/applications&gt; 此时看到的信息，是在 Eureka Server 中注册的所有Client 的信息。如果想要查询单个 Client 的信息，可以访问 http://localhost:8761/eureka/apps/{application.name} ，如：http://localhost:8761/eureka/apps/SPRING-CLOUD-EUREKA-CLIENT-SIMPLE 常用的 REST API常用的 Eureka REST API 除了 /eureka/apps 之外，还有如下接口 操作 http 动作 接口 描述 注册新的应用实例 POST /eureka/apps/{appId} 可以输入 json 或者 xml 格式的 body，成功返回 204 注销实例 DELETE /eureka/apps/{appId}/{instanceId} 成功返回 200 发送心跳 PUT /eureka/apps/{appId}/{instanceId} 成功返回 200，instanceId 不存在返回 404 查询所有实例 GET /eureka/apps 成功返回 200，输出 json 或 xml 格式的 body 查询单个实例 GET /eureka/apps/{appId} 成功返回 200，输出json 或 xml 格式的 body 根据 appId、instanceId 查询 GET /eureka/apps/{appId}/{instanceId} 成功返回 200，输出 json 或 xml 格式的 body 暂停某个实例 PUT /eureka/apps/{appId}/{instanceId}/status?value=OUT_OF_SERVICE 成功返回 200，失败返回 500 恢复某个实例 DELETE /eureka/apps/{appId}/{instanceId}/status?vlaue=UP(value 可不传) 成功返回 200，失败返回 500 更新元数据 PUT /euerka/apps/{appId}/{instanceId}/metadata?key=value 成功返回 200，失败返回 500 根据虚拟 ip 查询 GET /eureka/vip/{vipAddr} 成功返回 200，输出 json 或 xml 格式的 body 根据基于 htpps 的虚拟 ip 查询 GET /eureka/svip/{svipAddr} 成功返回 200，输出 json 或 xml 格式的 body 在进行新实例的注册时，传入的 json、xml 的格式需要与调用获取单个实例所返回的数据格式一致。具体的数据需要自己指定，需要注意的是，如果要注册的实例的ip、端口已经存在的话，不会再次注册，需要修改 instanceId。 Eureka 核心类Eureka 提供了一些核心的类，这些类中保存了 Eureka Server、Client 的注册信息、运行时的信息等。 InstanceInfoInstanceInfo 代表了注册的服务实例(位置： com/netflix/appinfo/InstanceInfo.java) 字段 说明 app 应用名称 appGroupName 应用所属群组 ipAddr ip 地址 sid 已废弃，默认 na port 端口号 securePort https 端口 homePageUrl 应用实例的首页 url statusPageUrl 应用实例的状态页 url healthPageUrl 应用实例的健康检查 url secureHealthPageUrl 应用实例的健康检查 https url vipAddress 虚拟 ip 地址 secureVipAddress https 的虚拟 ip 地址 countryId 已废弃，默认 1，代表 US dataCenterI dataCenter 信息，Netflix、Amazon、MyOwen hostName 主机名称（默认 ip status 状态，如：UP、DOWN、STATING、OUT_OF_SERVICE、UNKNOWN overrideenstatus 外界需要强制覆盖的状态，默认为 UNKNOWN leaseInfo 租约信息 isCorrdinatindDiscoveryServer 首先标示是否是 DiscoveryServer，其次标示该 DiscoveryServer 是否是响应你请求的实例 metadata 应用实例的元数据信息 lastUpdateTimestamp 状态信息最后更新时间 lastDirtyTimestamp 实例信息的最新过期时间，在 Client 端用于标志该实例信息是否与 Eureka Server 一致，在 Server 端则与多个 Server 之间进行信息同步 actionType 标示 Server 对该实例进行的操作，包括：ADDED、MODIFIED、DELETED args 在 AWS 的 autoscaling group 名称 可以看出，整个 InstanceInfo 的返回值信息，就是访问 /eureka/apps/{appId} 的返回值，也是通过 REST API 向 Eureka Server 注册时的 body。 LeaseInfoLeaseInfo 标识应用实例的租约信息(位置： com/netflix/appinfo/LeaseInfo.java) 字段 说明 renewalIntervalInSecs Client 续约时间间隔(秒) durationInSecs Client 的租约有效时间长(秒) registreationTimestamp 第一次注册时间(毫秒时间戳) laseRenewalTimestamp 最后一次续约时间(毫秒时间戳) evicationTimestamp 租约被剔除时间(毫秒时间戳) serviceUpTimestamp Client 被标记为 UP 状态的时间(毫秒时间戳) ServiceInstanceInfoServiceInstanceInfo 是一个标识一个应用实例的接口，约定了服务的发现的实例应用有哪些通用信息(位置： org/springframework/cloud/client/ServiceInstanceInfo.java) 方法 说明 getSercieId() 获取服务 id getHost() 获取实例的 HOST getPort() 获取实例的端口 isSecure() 是否开启 https getUri() 实例的 uri 地址 getMetadata() 实例的元数据信息 getScheme() 实例的 scheme 对于 ServiceInstanceInfo 接口的实现为：EurekaRegistration(位置：org/springframework/cloud/netflix/eureka/serviceregistry/EurekaRegistration.java)，EurekaRegistration 同时还实现了 Closeable 接口，这个接口的作用之一是在 close 的时候调用 eurekaClient.shutdown() 方法，实现优雅关闭 Eureka Client。 InstanceStatusInstanceStatus 是一个枚举类型，源码如下：12345678910111213141516171819202122public static enum InstanceStatus &#123; UP, DOWN, STARTING, OUT_OF_SERVICE, UNKNOWN; private InstanceStatus() &#123; &#125; public static InstanceInfo.InstanceStatus toEnum(String s) &#123; if (s != null) &#123; try &#123; return valueOf(s.toUpperCase()); &#125; catch (IllegalArgumentException var2) &#123; InstanceInfo.logger.debug("illegal argument supplied to InstanceStatus.valueOf: &#123;&#125;, defaulting to &#123;&#125;", s, UNKNOWN); &#125; &#125; return UNKNOWN; &#125;&#125; 其中定义了 5 种状态，对应 Client 的 5 种状态。 服务的核心操作对于服务发现来说，一般都是围绕几个核心的概念进行设计： 服务发现（register）服务下线（cancel）服务租约（renew）服务剔除（evict） 围绕这几个概念，Eureka 设计了一些核心的操作类： com/netflix/eureka/lease/LeaseManager.java com/netflix/discovery/shared/LookupService.java com/netflix/eureka/registry/InstanceRegistry.java com/netflix/eureka/registry/AbstractInstanceRegistry.java com/netflix/eureka/registry/PeerAwareInstanceRegistry.java 在 Netflix Eureka 的基础上，Spring Cloud 抽象或定义了几个核心类: org/springframewor/cloud/netflix/eureka/server/InstanceRegistry.java org/springframewor/cloud/client/serviceregistry/ServiceRegistry.kava org/springframewor/cloud/netflix/eureka/serviceregistry/EurekaServiceRegistry.java org/springframewor/cloud/netflix/eureka/serviceregistry/EurekaRegistration.java org/springframewor/cloud/netflix/eureka/EurekaClientAutoConfiguration.java org/springframewor/cloud/netflix/eureka/EurekaClientConfigBean.java org/springframewor/cloud/netflix/eureka/EurekaInstanceConfigBean.java 其中：LeaseManager、LookupService 是 Eureka 关于服务发现相关操作操作定义的接口类，LeaseManager 定义了服务写操作相关方法，LookupService 定义查询操作的相关方法。 LeaseManager12345678910public interface LeaseManager&lt;T&gt; &#123; void register(T r, int leaseDuration, boolean isReplication); boolean cancel(String appName, String id, boolean isReplication); boolean renew(String appName, String id, boolean isReplication); void evict();&#125;、 register：用于注册服务实例信息 cancel：用于删除服务实例信息 renew：用于和 Eureka Server 进行心跳操作，维持租约 evict：Server 端的方法，用于剔除租约过期的服务实例。 LoopupService12345678910public interface LookupService&lt;T&gt; &#123; Application getApplication(String appName); Applications getApplications(); List&lt;InstanceInfo&gt; getInstancesById(String id); InstanceInfo getNextServerFromEureka(String virtualHostname, boolean secure);&#125; getApplication：根据 appName 获取服务信息 getApplications：获取所有注册的服务信息 getInstancesById：根据 appid，获取所有实例 getNextServerFromEureka：根据虚拟hostname、是否是 https，获取下一个服务实例方法（默认轮训获取） Eureka 参数调优Client 端基本参数 参数 默认值 说明 eureka.client.avaliability-zones 告知 Client 有哪些 regin 和 zone，支持配置修改运行时生效 eureka.client.filter-only-up-instances true 是否滤出 InstanceStatus 为 UP 的实例 eureka.clint.region us-east-1 指定 region，当 datacenters 为 AWS 时适用 eureka.client.register-with-eureka true 是否将实例注册到 Eureka Server eureka.client.prefer-same-zone-eureka true 是否优先使用和该应用实例处于相同 Zone 的 Eureka Server eureka.client.on-demand-update-status-change trye 是否将本地实例状态的更新，通过 ApplicationInfoManager 实时同步到 Eureka Server(这个同步请求有流量限制) eureka.instance.matadata-map 指定实例的元数据信息 eureka.instance.prefer-ip-address false 是否优先使用 ip 地址来代替 hostname 作为实例的 hostname 字段值 eureka.instance.lease-exporation-duration-in-seconds 90 指定 Eureka Client 间隔多久向 Server 发送心跳 定时任务参数 参数 默认值(时间单位：秒，非时间单位：个) 说明 eureka.client.cache-refresh-executor-thread-pool-size 2 刷新缓存的 CacheRefreshThread 线程池大小 eureka.client.cache-refresh-executor-exponential-back-off-bound 10 调度任务执行时，下次调度的延迟时间 eureka.client.heartbeat-executor-thread-pool-size 2 执行心跳 HeartbeatThread 的线程池大小 eureka.client.heartbeat-executor-exponential-back-off-bound 10 调度任务执行时，下次调度的延迟时间 eureka.client.registry-fetch-interval-seconds 30 CachaRefreshThread 线程调度频率 eureka.client.eureka-service-url-poll-interval-seconds 5*60 AsyncResolver.updateTask 刷新 Eureka Server 地址的时间间隔 eureka.client.initial-instance-info-replication-interval-seconds 40 InstanceInfoReplicator 将实例信息变更同步到 Eureka Server 的初始延时时间 eureka.client.instance-infi-replication-interval-seconds 30 InstanceInfiReplicator 将实例信息变更同步到 Eureka Server 的时间间隔 eureka.client.lease-renewal-interval-in-seconds 30 Eureka Client 向 Eureka Server 发送心跳的时间间隔 http 参数Eureka Client 底层使用 HttpClient 与 Eureka Server 通信。 参数 默认值 说明 eureka.client.eureka-server-connect-timeout-seconds 5 连接超时时间 eureka.client.eureka-server-read-timeout-seconds 8 读超时时间 eureka.client.eureka-server-total-connections 200 连接池最大连接数 eureka.client.eureka-server-total-connections-per-host 50 每个 host 能使用的最大链接数 eureka.client.eureka-connection-idle-timeout-seconds 30 连接池空闲连接时间 Server 端Server 端的参数调优分为：基本参数，Response Cache、Peer、Http 等 基本参数 参数 默认值 说明 eureka.server.enable-self-preservation true 是否开启自我保护模式 eureka.server.renewal-percent-threshold 0.85 每分钟需要收到的续约次数阈值(心跳数/client实例数) eureka.instance.registry.expected-number-of-renews-per-min 1 指定每分钟需要收到的续约次数，实际上，在源码中被写死为 count * 2 eureka.server-renrewal-threshold-update-interval-ms 15 分钟 指定 updateRenewalThreshold 定时任务的调度频率，动态更新 expectedNumberOfRenewsMin 以及 numberOfNewsPerMinThreshold 的值 eureka.server.evication-interval-timer-in-ms 60*1000 指定 EvicationTask 定时任务调度频率，用于剔除过期的实例 Response Cache 参数Eureka Server 为了提升自身 REST API 接口的性能，提供了两个缓存：一个是基于 ContioncurrentMap 的 readOnlyCacheMap，一个是基于 Guava Chahe 的 readWriteCacheMap。 参数 默认值 说明 eureka.server.use-read-only-response-cache true 是否使用只读的 Response Cache eureka.server.response-cache-update-interval-ms 30 * 1000 设置 CacheUpdateTask 的调度时间间隔，用于从 readWriteCacheMap 更新数据到 readOnlyCacheMap。仅在 eureka.server.use-read-only-response-cache 为 true 时生效 eureka.server.response-cache-auto-expiration-in-seconds 180 设置 readWriteCacheMap 的过期时间 peer 参数 参数 默认值 说明 eureka.server.peer.eureka-nodes-update-interval-ms 10分钟 指定 peersUpdateTask 调度的时间间隔，用于配置文件刷新 peerEurekaNodes 节点的配置信息 eureka.server.peer-eureka-status-refresh-time-interval-ms 30*1000 指定更新 Peer nodes 状态的时间间隔 http 参数 参数 默认值 说明 eureka.server.peer-node-connect-timeout-ms 200 链接超时时间 eureka.server.peer-node-read-timeout-ms 200 读超时时间 eureka.server.peer-node-total-connections 1000 连接池最大连接数 eureka.server.peer-node-total-connections-per-host 500 每个 host 能使用的最大连接数 eureka.server.peer-node-connection-idle-timeout-seconds 30 连接池中链接的空闲时间]]></content>
      <categories>
        <category>spring-cloud</category>
      </categories>
      <tags>
        <tag>SpringCloud</tag>
        <tag>Eureka</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring Cloud 微服务（3） --- Eureka(一) 注册中心与 Eureka]]></title>
    <url>%2Fspring-cloud%2Fspring-cloud-3.html</url>
    <content type="text"><![CDATA[Eureka 最初是针对 AWS 不提供中间服务层的负载均衡的限制开发的。 Eureka 一方面给内部服务做服务发现，另一方面可以结合 Ribbon 组件提供各种个性化的负载均衡算法。 Spring Cloud 微服务系列版本 Spring Boot 版本： 2.1.x.RELEASESpring Cloud 版本：Greenwich.RELEASE 或 SpringBoot 版本：2.0.x.RELEASESpringCloud 版本：Finchley.RELEASE 此博客采用 2.0.0 + Finchley.RELEASE 版本 服务发现的技术选型方案 名称 类型 CAP 语言 依赖 集成 一致性算法 Zookeeper General CP Java JVM Client Binding Paxos Doozer General CP Go Client Binding Paxos Consul General CP GO HTTP/DNS Library Raft Etcd General CP or Mixed(1) Go Client Binding/HTTP Raft SmartStack Dedicated AP Ruby Haproxy/Zookeeper Sidekick(nerve/synapse) Eureka Dedicated AP Java JVM Java Client NSQ(lookupd) Dedicated AP Go Client Binding Serf Dedicated AP Go Local CLI Spotify(DNS) 15973840029 AP N/A Bind DNS Library SkyDNS 808376 Mixed(2) Go HTTP/DNS Library Eureka 的设计理念服务实例注册到服务中心服务的注册，本质上就是在服务启动的时候，调用 Eureka Server 的 REST API 的 Registrer 方法，注册应用实例的信息。对于 Java 应用，可以使用 Netflix 的 Eureka Client 封装 API 调用；对于 Spring Cloud 应用，可以使用 spring-cloud-starter-netflix-eureka-client 基于 Spring Boot 自动配置，自动注册服务。 服务实体从服务中心剔除正常情况下，服务实例在关闭应用的时候，应该通过钩子方法或其他生命周期回调方法，调用 Eureka Server 的 REST API 的 de-register 方法，来删除自身服务实例的信息。另外，为了解决服务挂掉，或网络中断等其他异常情况没有及时删除自身信息的问题，Eureka Server 要求 Client 定时进行续约，也就是发送心跳，来证明自己是存活的、健康的、可调用的。如果超过一定时间没有续约，则认为 Client 停掉了，Server 端会主动剔除。 服务实例一致性问题由于注册中心（Eureka Server）通常来说是一个集群，就需要 Client 在集群中保持一致。Eureka 通过 CAP、Peer to Peer、Zone + Region、SELF PRESERVATION 四个方面保证一致性。 CAP在 微服务与 Spring Cloud、 服务发现技术选型、服务一致性 都提到了 CAP、CP、AP，那么 CAP 到底是个啥 C：Consistency，数据一致性。即数据在存在多个副本的情况下，可能由于网络、机器故障、软件系统等问题早上数据写入部分副本成功，副本副本失败，进而造成副本之间数据不一致，存在冲突。满足一致性则要求对数据的更新操作成功后，多副本的数据保持一致。 A：Availablility，服务可用性。在任何时候，客户端对集群进行读写操作时，请求能够正常响应，即，在一定的时间内完成。 P：Partition Tolerance，分区容忍性，即发生通信故障的时候，整个集群被分隔成多个无法相互通信的分区时，集群仍然可用。 在分布式系统中，网络条件一般是不可控的，网络分区是不可避免的，因此分布式系统必须满足分区容忍性，所以分布式系统的设计需要在 AP、CP 之间进行选择。 Zookeeper 是 “C”P 的，C 之所以加引号，是因为 Zookeeper 默认并不说严格的强一致性。如：A 进行写操作，Zookeeper 在过半节点数操作成功就返回，此时如果 B 读取到的是 A 写操作没有同步到的节点，那么就读取不到 A 写入的数据。如果需要在使用的时候强一致，需要在读取的时候先执行 sync 操作，与 leader 节点先同步数据，才能保证强一致。 Eureka 在大规模部署的情况下，失败是不可避免的，可能会因为 Eureka 自身部署的失败，导致注册的服务不可用，或者由于网络分区，导致服务不可用。Eureka 服务注册、发现中心，保留了可用及过期的数据，以此来实现在网络分区的时候，还能正常提供服务注册发现功能。 Peer to Peer分布式系统的数据在多个副本直接的复制方式，可分为：主从复制、对等复制 主从复制主从复制，就是 Master-Slave 模式，有一个主副本，其他为从副本。所有的对数据的写操作，都提交到主副本，然后由主副本更新到其他的从副本。具体的更新方式有：同步更新、异步更新、同步异步混合更新。对于主从复制的模式，写操作都要经过主副本，所有主副本的压力会很大。但是，从副本会分担主副本的读请求，而一个系统最大的请求都是读请求，所有可以一般情况下都是一主多从的架构。 对等复制即 Peer to Peer 模式。副本之间不分主从，任何副本都能接收写操作，然后每个副本之间相互进行数据更新。对于对等复制模式来说，由于任何副本都可以接收到写操作，所以不存在写操作的压力瓶颈。但是由于每个副本都能进行写操作，各个副本之间的数据同步及冲突处理是一个比较棘手的问题。 Eureka 采用的就是 Peer to Peer Zone 及 RegionNetflix 的服务大部分在 Amazon Video 上，因此 Eureka 的设计有一部分也是基于 Amazon 的 Zone、Region 基础上托管。 每个 Region 下，还分了几个 Zone，一个 Region 对应多个 Zone，每个 Region 之间是相互独立及隔离的，默认情况下，资源只在单个 Region 之间的 Zone 进行复制，跨 Region 之间不会进行资源复制。 SELF PRESERVATION在分布式系统中，通常需要对应用实例的存活进行健康检查，需要处理好网络抖动或短暂的不可用造成的误判；另外，Eureka Server 和 Client 之间如果存在网络分区，在极端情况下可能会导致 Eureka Server 情况部分服务的实例列表，这个将严重影响到 Eureka Server 的高可用。因此，Eureka 引入了自我保护机制(SELF PRESERVATION)。 Client 与 Server 之间有租约，Client 需要定时发送心跳维持租约，表示自己存活。Eureka 通过当前注册的实例数，计算每分钟应该从应用实例接收到的心跳数，如果最近一分钟接收到的续约次数小于指定的阈值的话，则关闭租约失效剔除，进制定时任务剔除失效的实例，从而保护注册信息。 Eureka 入门案例父 pom123456789101112131415161718192021222324252627282930313233&lt;packaging&gt;pom&lt;/packaging&gt;&lt;!-- 父工程是 2.1.0.RELEASE 版本的 boot --&gt;&lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.1.0.RELEASE&lt;/version&gt;&lt;/parent&gt;&lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;!-- 设置全局 SpringCloud 依赖版本为 F.RELEASE --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt; &lt;version&gt;Finchley.RELEASE&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/dependencyManagement&gt;&lt;!-- 设置全局依赖 SpringBoot、Web --&gt;&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 建立 Eureka Server 子项目源码：https://gitee.com/laiyy0728/spring-cloud/tree/master/spring-cloud-eureka/spring-cloud-eureka-server-simple 在父pom中建立 Eureka Server 子项目 module：spring-cloud-eureka-server pom 依赖1234567891011121314&lt;!-- 父工程 --&gt;&lt;parent&gt; &lt;groupId&gt;com.laiyy.gitee&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;&lt;/parent&gt;&lt;dependencies&gt; &lt;!-- 引入 eureka server 依赖，注意不能少了 starter --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-server&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 启动类1234567@SpringBootApplication@EnableEurekaServer // 开启 Eureka Server public class SpringCloudEurekaServerApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(SpringCloudEurekaServerApplication.class, args); &#125;&#125; 配置文件12345678910111213141516spring: application: name: eureka-server # 服务名称server: port: 8761 # 服务端口eureka: instance: hostname: localhost # host name client: fetch-registry: false # 是否获取注册表 service-url: defaultZone: http://localhost:$&#123;server.port:8761&#125;/eureka/ # 默认 Zone register-with-eureka: false # 是否注册自己 server: enable-self-preservation: false # 是否开启自我保护，默认 true。在本机测试可以使用 false，但是在生产环境下必须为 true 验证 Eureka Server 启动结果在浏览器输入： http://localhost:8761 ，进入 Eureka Server 可视化页面 Eureka Server UI 提示信息在 Eureka Server 检测到异常时，会在中间以红色加粗字体提示信息。 在没有 Eureka Client 或 Eureka Server 检测心跳的阈值小于指定阈值，且关闭自我保护时： RENEWALS ARE LESSER THAN THE THRESHOLD. THE SELF PRESERVATION MODE IS TURNED OFF.THIS MAY NOT PROTECT INSTANCE EXPIRY IN CASE OF NETWORK/OTHER PROBLEMS.提示说明了：1、eureka client 的心跳发送次数小于阈值(没有client，肯定小于)；2、自我保护被关闭了 在有 Eureka Client，且关闭了自我保护时： THE SELF PRESERVATION MODE IS TURNED OFF.THIS MAY NOT PROTECT INSTANCE EXPIRY IN CASE OF NETWORK/OTHER PROBLEMS. 在没有 Eureka Client 或 Eureka Server 检测心跳的阈值小于指定阈值，且开启了自我保护时： EMERGENCY! EUREKA MAY BE INCORRECTLY CLAIMING INSTANCES ARE UP WHEN THEY’RE NOT. RENEWALS ARE LESSER THAN THRESHOLD AND HENCE THE INSTANCES ARE NOT BEING EXPIRED JUST TO BE SAFE. 在有 Eureka Client 且 Eureka Server 检测心跳的阈值大于指定阈值，且开启了自我保护时，Eureka Server 会认为整个服务正常，不会有任何信息提示。 建立 Eureka Client 项目源码：https://gitee.com/laiyy0728/spring-cloud/tree/master/spring-cloud-eureka/spring-cloud-eureka-client-simple 在 在父pom中建立 Eureka Server 子项目 module：spring-cloud-eureka-client-simple，建立一个简单的 eureka client 工程 pom12345678&lt;!-- parent 都和 Eureka Server 一致，不再赘述 --&gt;&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 启动类123456789// EurekaClient、DiscoveryClient 本质上都是注册到服务中心的实现，EurekaClient 只针对 Eureka 使用，// DiscoveryClient 针对不同的注册中心都可以使用。可以说 DiscoveryClient 的 EurekaClient 的一个抽象@SpringBootApplication@EnableDiscoveryClient //@EnableEurekaClient public class SpringCloudEurekaClientSimpleApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(SpringCloudEurekaClientSimpleApplication.class, args); &#125;&#125; 配置文件1234567891011121314spring: application: name: spring-cloud-eureka-client-simple # 工程名称，也是注册到 server 后的实例名称eureka: client: service-url: defaultZone: http://localhost:8761/eureka # 指定 Zone，需要与 Eureka Server 一样 instance: prefer-ip-address: true # 使用 ip 注册，默认为 false。为 false 时是 机器名 instance-id: $&#123;spring.application.name&#125;:$&#123;server.port&#125; # 注册到 server 后显示的名字，默认是 机器名:name:端口server: port: 8081 # 端口 在 Eureka Server 验证服务注册 可以看到，eureka client 已经注册成功。 status 大致有 5 个状态：UP(正常运行)、DOWN(停机)、STATING(正在启动)、OUT_OF_SERVICE(下线)、UNKNOWN(为止) 公益 Eureka Server如果不想在本机启动 Eureka Server，SpringCloud 中文社区提供了一个公益的 Eureka Server：http://eureka.springcloud.cn/，在使用时只需要将 defaultZone 替换为 http://eureka.springcloud.cn/eureka 即可。 不过需要注意的是，虽然省去了启动 Eureka Server 的时间，节省了维护 Eureka Server 的资源，但是这个 Eureka Server 是一个单节点的，如果想要测试 Eureka Server 的集群高可用，还是需要在本机启动多个 Eureka Server。 公益的 Eureka Server 只能使用在本机测试中，禁止在测试环境、成产环境上使用，否则将暴露 ip、端口，造成严重的安全隐患。]]></content>
      <categories>
        <category>spring-cloud</category>
      </categories>
      <tags>
        <tag>SpringCloud</tag>
        <tag>Eureka</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring Cloud 微服务（2） 微服务与 Spring Cloud]]></title>
    <url>%2Fspring-cloud%2Fspring-cloud-2.html</url>
    <content type="text"><![CDATA[应用是可以独立运行的程序代码，提供相对完善的业务功能。架构分为：业务架构、应用架构、技术架构。业务架构决定应用架构，技术架构支撑应用架构。架构的发展历程：单体架构 --&gt; 分布式架构 --&gt; SOA 架构 --&gt; 微服务架构 微服务概述单体应用架构单体架构可以理解为一个 Java Web 工程，包含：表现成、业务层、数据访问层。从 Controller 到 Service 到 Dao，没有任何应用拆分，开发完毕后打包成一个大型的 war 部署。 优点 便于发开：开发人员使用当前开发工具在短时间内就可以完成开发 便于测试：不需要依赖其他接口，节约时间 便于部署：只需将 war 部署到运行环境即可 缺点 灵活度不够：如果程序有任何修改，需要自上而下全部修改，测试的时候也不要整个程序部署完才能看到效果。在开发过程中，可能会需要等待其他开发人员开发完成才能进行自己开发的内容。 降低系统性能：原本可以直接访问数据库，但多出了一个 Service 层 启动慢：一个进程中包含了所以的业务逻辑，涉及的模块过多 扩展性差：增加新的功能不能针对单个点增加，要全局性的增加，牵一发动全身 分布式架构按照业务垂直切分，每个应用都是单体架构，通过 API 互相调用 面向服务的 SOA 架构SOA 架构有两个主要角色：服务的提供者（provider）、服务的消费者（consumer）。阿里的 Dubbo 的 SOA 的一个典型实现 优点 模块拆分，使用接口通信，降低了模块之间的耦合度 把一个大项目拆分成多个子项目，可以并行开发 增加功能时只需要增加一个子项目，调用其他系统接口即可 可以灵活分布式部署 缺点 系统之间需要远程通信，增加了开发的工作量 微服务架构微服务架构是一种架构风格，对于大型复杂的业务系统，可以将业务功能拆分成多个相互独立的微服务，各个微服务之间是松耦合的，通过各种远程协议进行同步/异步通信，各个微服务可单独部署，扩容/缩容以及升级/降级。 微服务技术选型对比 Spring Cloud Dubbo Motan MSEC 其他 功能 微服务完整方案 服务治理框架 服务治理框架 服务开发运营框架 略 通信方式 REST / http RPC 协议 RPC / Hessian2 Protocol Buffers gRPC、thrift 服务发现 / 注册 Eureka（AP） ZK、Nacos ZK / Consul 只有服务发现 Etcd 负载均衡 Ribbon 客户端负载 客户端负载 客户端负载 Ngnix + Lua 容错机制 6 种 6 种 2 种 自动容错 keepalived、heartbeat 熔断机制 Hystrix 无 无 过载保护 无 配置中心 Spring Cloud Config Nacos 无 无 Apollo、Nacos 网关 Zuul、Gateway 无 无 无 Kong、自研 服务监控 Hystrix + Turbine Dubbo + Monitor 无 Monitor ELK 链路监控 Sleuth + Zipkik 无 无 无 Pinpoint 多语言 REST 支持多语言 Java Java Java、C++、PHP Java、PHP、Node.js 社区活跃度 高（Spring） 高（阿里） 一般 未知 略 基于 Spring Cloud 的微服务解决方案 组件方案1方案2方案3服务发现EurekaConsuletcd、Nacos共用组件服务调用：Feign、负载均衡：Ribbon、熔断器：Hystrix网关Zuul：性能低，SpringCloud Gateway：性能高自研配置中心SpringCloud Config、携程 Apollo、阿里 Nacos全链路监控Zipkin、Pinpoint、SkyWalking（推荐）其他分布式事务、Docker、gRPC、领域驱动 Halo 基于 Dubbo 的解决方案使用 Dubbo + Nacos。Nacos 是阿里开源的一个构建云原生应用的动态服务发现、配置、服务管理平台。 Spring CloudSpring Cloud 介绍中间件：中间件是一种独立的系统软件或服务程序，分布式应用软件借助这种软件在不同的技术之间共享资源。中间件位于客户机/ 服务器的操作系统之上，管理计算机资源和网络通讯。是连接两个独立应用程序或独立系统的软件。常见的中间件分别是：服务治理(如 RPC)、配置中心、全链路监控、分布式事务、分布式定时任务、消息中间件、API 网关、分布式缓存、数据库中间件等。 Spring Cloud 像是一个中间件，基于 Spring Boot 开发，提供一套完整的微服务解决方案。包括服务注册与发现、配置中心、全链路监控、API 网关、熔断器 等选型的中立的开源组件，可以随需扩展和替换组装。 Spring Cloud 项目模块 组件名称 所属项目 组件分类 Eureka spring-cloud-netflix 注册中心 Zuul spring-cloud-netflix 第一代网关 Sidecar spring-cloud-netflix 多语言支持 Ribbon spring-cloud-netflix 负载均衡 Hystrix spring-cloud-netflix 熔断器 Turbine spring-cloud-netflix 集群监控 Feign spring-cloud-openfeign 声明式的 HTTP 客户端 Consul spring-cloud-consul 注册中心 Gateway spring-cloud-gateway 第二代网关 Sleuth spring-cloud-sleuth 链路监控 Config spring-cloud-config 配置中心 Bus spring-cloud-bus 总线 Pipeline spring-cloud-pipelines 部署管道 Dataflow spring-cloud-dataflow 数据处理 Stream spring-cloud-stream 消息驱动 服务治理中间件服务治理中间件包含：服务注册与发现、服务路由、负载均衡、自我保护、管理机制等。其中，服务路由包含：服务上下线、在线测试、机房就近选择、AB测试、灰度发布等。负载均衡包含：支持根据目标状态和目标权重进行负载均衡。自我保护包含：服务降级、优雅降级、流量控制 注册中心对比 特性 Consul Zookeeper etcd Eureka 服务健康检查 服务状态、内存、硬盘等 (弱)长连接、keepalive 连接心跳 可配置支持 多数据中心 支持 - - - kv 存储服务 支持 支持 支持 - 一致性 raft paxos raft - CAP CA CP CP AP 多语言支持 https、dns 客户端 http/grpc http(sidecar) watch支持 全量/支持long polling 支持 支持long polling 支持 long polling/大部分增量 自身健康 metrics - metrics metrics 安全 acl/https acl https支持(弱) - Spring Cloud 集成 支持 支持 支持 支持 Spring Cloud 配置中心功能需求场景支持： 面向全公司，充分考虑各部门需求，支持不同语言接入，充分考虑兼容性 运维集成： 统一数据源标准化运维流程 权限管理： 接入权限、审核权限、下发权限… Spring Cloud API 网关API 网关是出现在系统边界上的一个面向 API 的、串行集中式的强管控服务，可以理解为应用的防火墙，主要起隔离外部访问与内部系统的作用。主要为了解决访问认证、报文转发、访问统计等问题。 API 网关需要提供的功能： 统一接入功能：为各种服务提供统一接入服务，提供三高(高可用、高并发、高可靠)的网关服务，还需要支持负载均衡、容灾切换、异地多活协议适配：对外提供 HTTP、HTTPS 访问，对内提供各种协议，如：HTTP、HTTPS、RPC、REST 等流量监控：当大流量请求时，进行流量监控、流量挑拨；当后端出现异常时，需要进行服务熔断、服务降级；在异地多活中，需要进行流量分片等。网关防护：所有请求进行安全过滤，对 IP 黑名单、URL 黑名单封禁、风控防刷、防恶意攻击等。 Zuul、Gateway 的比较 Zuul Gateway 实现难度 低 高 底层 http、https、rest Netty 灰度、降级、标签路由、限流、WAF封禁 需要自定义 Filter 配置 安全、监控/埋点 自定义 Intercepter 自定义配置 Spring Cloud 全链路监控全链路监控需要包含的功能： 定位慢调用：慢 web 服务、慢 rest/rpc 服务、慢 SQL定位错误：4XX、5XX、Service Error定位异常：Error Exception、Fatal Exception展现依赖和拓扑：域拓扑、服务拓扑、trace 拓扑trace 调用链：将端到端的调用以及附加的上下文信息、异常日志信息、每个调用点的耗时都进行展示应用警告：根据设置的警告规则，扫描指标数据，并进行信息上报]]></content>
      <categories>
        <category>spring-cloud</category>
      </categories>
      <tags>
        <tag>SpringCloud</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring Cloud 微服务（1） 思维导图]]></title>
    <url>%2Fspring-cloud%2Fspring-cloud-1.html</url>
    <content type="text"><![CDATA[Spring Cloud 微服务系列脑图：点此查看]]></content>
      <categories>
        <category>spring-cloud</category>
      </categories>
      <tags>
        <tag>SpringCloud</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring Batch 学习（8） JobLauncher、JobOperator、事务处理]]></title>
    <url>%2Fspring-batch%2Fspring-batch-study-8.html</url>
    <content type="text"><![CDATA[现在是所有实例，都是在 SpringBoot 中，在启动项目的同时，进行任务、步骤的构建，任务的启动。但是有时需要在一个 Controoler、或者一个 Scheduler 中进行任务的调度，这时使用现在的方式就不合适了。 在 SpringBoot 中禁用 batch 自启动在 application.yml 文件中，将 spring.batch.job.enabked 设置为 false，即可禁用自启动 SpringBatch，但是任务仍然会构造，只是不会自动执行。 JobLauncherJobLaunch 是手动启动 SpringBatch 任务的启动类。需要参数：任务实例、任务执行中的参数(JobParameters) 实现方式：在需要启动任务的地方，如：Controoler 中注入 JobLauncher，构建 JobParameters，启动指定的任务 1234567891011121314151617181920212223242526@RestControllerpublic class JobController &#123; @Autowired private JobLauncher jobLauncher; @Autowired private Job job; @GetMapping(value = "/job/&#123;msg&#125;") public String jobRun1(@PathVariable String msg)&#123; // 构建 JobParameters JobParameters jobParameters = new JobParametersBuilder() .addString("msg", msg) .toJobParameters(); // 启动任务，并把参数传给任务 try &#123; jobLauncher.run(jobLauncherDemoJob, jobParameters); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; return "job success"; &#125;&#125; 需要注意的点： 构建的 JobParameters 会在调用 jobLauncher.run 时，实例化到数据库中，如果执行过一次之后，再次执行需要保证参数不一样，否则会任务该任务已经执行过，不能再次执行。 如果有多个 Job，需要使用 @Qualifier 指定要注入的 Job 这种方式启动任务，任务的运行是 同步 的，不是异步的。 异步 JobLauncher：异步的 JobLauncher 需要手动设置线程池、任务执行的 repository 持久化123456789101112@Autowiredprivate JobRepository jobRepository;@Beanpublic JobLauncher jobLauncher() &#123; SimpleJobLauncher jobLauncher = new SimpleJobLauncher(); // jobRepository 需要注入 jobLauncher.setJobRepository(jobRepository); // 使用 Spring 线程池，可以自定义 jobLauncher.setTaskExecutor(new SimpleAsyncTaskExecutor()); return jobLauncher;&#125; 自定义线程池：12345678910111213@Beanpublic Executor getExecutor()&#123; ThreadPoolTaskExecutor executor = new ThreadPoolTaskExecutor(); executor.setCorePoolSize(20); executor.setMaxPoolSize(100); executor.setQueueCapacity(150); executor.setWaitForTasksToCompleteOnShutdown(true); executor.setAwaitTerminationSeconds(60); executor.setThreadNamePrefix("batch-"); executor.setRejectedExecutionHandler(new DiscardOldestPolicy()); executor.initialize(); return executor;&#125; JobOperatorJobOperator 可以任务是对 JobLauncher 的再次封装，所有在 JobOperator 中需要注入 JobLauncher 构建 JobOperator123456789101112131415161718192021222324252627 @Autowiredprivate JobLauncher jobLauncher;@Autowiredprivate JobRepository jobRepository;@Autowiredprivate JobExplorer jobExplorer;@Autowiredprivate JobRegistry jobRegistry;@Beanpublic JobOperator jobOperator()&#123; SimpleJobOperator jobOperator = new SimpleJobOperator(); // 注入 JobLauncher jobOperator.setJobLauncher(jobLauncher); // 设置参数转换器 jobOperator.setJobParametersConverter(new DefaultJobParametersConverter()); // 注入 jobRepository 持久化 jobOperator.setJobRepository(jobRepository); // 注入 任务注册器 jobOperator.setJobRegistry(jobRegistry); // 注入任务探测器 jobOperator.setJobExplorer(jobExplorer); return jobOperator;&#125; 构建 jobRegistry Processor12345678910111213141516171819202122public class JobOperatorConfig implements ApplicationContextAware &#123; private ApplicationContext applicationContext; @Bean public JobRegistryBeanPostProcessor jobRegistry()&#123; JobRegistryBeanPostProcessor processor = new JobRegistryBeanPostProcessor(); processor.setJobRegistry(jobRegistry); processor.setBeanFactory(applicationContext.getAutowireCapableBeanFactory()); try &#123; processor.afterPropertiesSet(); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; return processor; &#125; @Override public void setApplicationContext(ApplicationContext applicationContext) throws BeansException &#123; this.applicationContext = applicationContext; &#125;&#125; 执行任务12345try &#123; jobOperator.start("jobName", "msg="+msg);&#125; catch (NoSuchJobException | JobInstanceAlreadyExistsException | JobParametersInvalidException e) &#123; e.printStackTrace();&#125; JobLauncher 与 JobOperator 的比较 执行方法： JobLauncher 使用 run 方法执行，JobOperator 使用 start 方法执行任务注入： JobLauncher 使用 Job 实例注入，JobOperator 使用任务名称注入参数传递： JobLauncher 使用 JobParameters 传递，JobOperator 使用字符串传递、且参数传递方式为 key1=value1&amp;key2=value2…参数转换： JobLauncher 不需要转换，JobOperator 需要设置参数转换器才能转换为 JobParameters 事务处理 – 重中之重在一些批处理任务重，可能会需要用到数据库。如果用到了数据库的读、写操作，就一定会牵扯到事务问题。 在 SpringBoot 中的事务处理在构建 Job 时，需要显式注入需要使用的事务处理器，并传入 Step。 12345678910111213141516171819@Beanpublic Job jobDemo(PlatformTransactionManager transactionManager)&#123; return jobBuilderFactory.get("jobDemo") .start(steoDemo(transactionManager)) .build();&#125;@Beanpublic Step steoDemo(PlatformTransactionManager transactionManager) &#123; return stepBuilderFactory.get("steoDemo") .transactionManager(transactionManager) .tasklet(new Tasklet() &#123; @Override public RepeatStatus execute(StepContribution stepContribution, ChunkContext chunkContext) throws Exception &#123; System.out.println("childJobStep1"); return RepeatStatus.FINISHED; &#125; &#125;).build();&#125; 这种方式是使用 SpringBatch 的自带事务处理器进行事务处理，但是在一些集成了 Hibernate、MyBatis 的系统中，需要用到 Hibernate、MyBatis 的事务处理器。如果此时，使用的是 SpringBoot 项目，且事务处理器没有自定义的话，是没有用问题的。如果是使用的 SpringMVC 进行任务调用，且自定义了事务处理器，这时可能出现问题。 在 SpringMVC 自定义事务处理器的问题自定义事务处理器：123456789101112131415161718192021&lt;!-- 定义事务 --&gt;&lt;bean id="txAdvice" class="org.springframework.orm.hibernate5.HibernateTransactionManager"&gt; &lt;property name="sessionFactory" ref="sessionFactory" /&gt;&lt;/bean&gt;&lt;tx:annotation-driven transaction-manager="txAdvice"/&gt;&lt;!-- 拦截器方式配置事物 --&gt;&lt;tx:advice id="transactionAdvice" transaction-manager="txAdvice"&gt; &lt;tx:attributes&gt; &lt;tx:method name="update*" propagation="REQUIRED" /&gt; &lt;tx:method name="add*" propagation="REQUIRED" /&gt; &lt;tx:method name="save*" propagation="REQUIRED" /&gt; &lt;tx:method name="edit*" propagation="REQUIRED" /&gt; &lt;tx:method name="delete*" propagation="REQUIRED" /&gt; &lt;tx:method name="del*" propagation="REQUIRED"/&gt; &lt;tx:method name="remove*" propagation="REQUIRED" /&gt; &lt;tx:method name="repair*" propagation="REQUIRED"/&gt; &lt;tx:method name="*" read-only="true" /&gt; &lt;/tx:attributes&gt;&lt;/tx:advice&gt; 在批处理任务中，没有显示注入事务处理器，此时在执行批处理时，会有如下问题： 控制台错误打印12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788892018-12-24 15:05:11.809 WARN [NettyClientWorkerThread_1][NettyRemotingAbstract.java:258] - RemotingCommand [code=17, language=JAVA, version=252, opaque=10, flag(B)=1, remark=No topic route info in name server for the topic: TBW102See http://rocketmq.apache.org/docs/faq/ for further details., extFields=null, serializeTypeCurrentRPC=JSON]2018-12-24 15:05:11.811 ERROR [SimpleAsyncTaskExecutor-2][AbstractStep.java:229] - Encountered an error executing step firstStepOfFindSite in job batchGenerateChannelJoborg.springframework.transaction.CannotCreateTransactionException: Could not open Hibernate Session for transaction; nested exception is java.lang.IllegalStateException: Already value [org.springframework.jdbc.datasource.ConnectionHolder@76ce6385] for key [&#123; CreateTime:"2018-12-24 15:01:21", ActiveCount:2, PoolingCount:18, CreateCount:20, DestroyCount:0, CloseCount:30, ConnectCount:32, Connections:[ &#123;ID:428371115, ConnectTime:"2018-12-24 15:01:21", UseCount:0, LastActiveTime:"2018-12-24 15:01:21"&#125;, ... &#123;ID:1832136599, ConnectTime:"2018-12-24 15:01:22", UseCount:0, LastActiveTime:"2018-12-24 15:01:22"&#125; ]&#125;[ &#123; ID:428371115, poolStatements:[ ] &#125;, ... &#123; ID:1832136599, poolStatements:[ ] &#125;]] bound to thread [SimpleAsyncTaskExecutor-2] at org.springframework.orm.hibernate5.HibernateTransactionManager.doBegin(HibernateTransactionManager.java:542) ~[spring-orm-4.3.18.RELEASE.jar:4.3.18.RELEASE] at org.springframework.transaction.support.AbstractPlatformTransactionManager.getTransaction(AbstractPlatformTransactionManager.java:377) ~[spring-tx-4.3.18.RELEASE.jar:4.3.18.RELEASE] at org.springframework.transaction.interceptor.TransactionAspectSupport.createTransactionIfNecessary(TransactionAspectSupport.java:461) ~[spring-tx-4.3.18.RELEASE.jar:4.3.18.RELEASE] at org.springframework.transaction.interceptor.TransactionAspectSupport.invokeWithinTransaction(TransactionAspectSupport.java:277) ~[spring-tx-4.3.18.RELEASE.jar:4.3.18.RELEASE] at org.springframework.transaction.interceptor.TransactionInterceptor.invoke(TransactionInterceptor.java:96) ~[spring-tx-4.3.18.RELEASE.jar:4.3.18.RELEASE] at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179) ~[spring-aop-4.3.18.RELEASE.jar:4.3.18.RELEASE] at com.alibaba.druid.support.spring.stat.DruidStatInterceptor.invoke(DruidStatInterceptor.java:72) ~[druid-1.1.6.jar:1.1.6] at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179) ~[spring-aop-4.3.18.RELEASE.jar:4.3.18.RELEASE] at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:213) ~[spring-aop-4.3.18.RELEASE.jar:4.3.18.RELEASE] at com.sun.proxy.$Proxy79.getOne(Unknown Source) ~[?:?] at com.dahe.wang.batch.BatchGenerateConfig$2.execute(BatchGenerateConfig.java:195) ~[classes/:?] at org.springframework.batch.core.step.tasklet.TaskletStep$ChunkTransactionCallback.doInTransaction(TaskletStep.java:406) ~[spring-batch-core-3.0.9.RELEASE.jar:3.0.9.RELEASE] at org.springframework.batch.core.step.tasklet.TaskletStep$ChunkTransactionCallback.doInTransaction(TaskletStep.java:330) ~[spring-batch-core-3.0.9.RELEASE.jar:3.0.9.RELEASE] at org.springframework.transaction.support.TransactionTemplate.execute(TransactionTemplate.java:133) ~[spring-tx-4.3.18.RELEASE.jar:4.3.18.RELEASE] at org.springframework.batch.core.step.tasklet.TaskletStep$2.doInChunkContext(TaskletStep.java:272) ~[spring-batch-core-3.0.9.RELEASE.jar:3.0.9.RELEASE] at org.springframework.batch.core.scope.context.StepContextRepeatCallback.doInIteration(StepContextRepeatCallback.java:81) ~[spring-batch-core-3.0.9.RELEASE.jar:3.0.9.RELEASE] at org.springframework.batch.repeat.support.RepeatTemplate.getNextResult(RepeatTemplate.java:374) ~[spring-batch-infrastructure-3.0.9.RELEASE.jar:3.0.9.RELEASE] at org.springframework.batch.repeat.support.RepeatTemplate.executeInternal(RepeatTemplate.java:215) ~[spring-batch-infrastructure-3.0.9.RELEASE.jar:3.0.9.RELEASE] at org.springframework.batch.repeat.support.RepeatTemplate.iterate(RepeatTemplate.java:144) ~[spring-batch-infrastructure-3.0.9.RELEASE.jar:3.0.9.RELEASE] at org.springframework.batch.core.step.tasklet.TaskletStep.doExecute(TaskletStep.java:257) ~[spring-batch-core-3.0.9.RELEASE.jar:3.0.9.RELEASE] at org.springframework.batch.core.step.AbstractStep.execute(AbstractStep.java:200) [spring-batch-core-3.0.9.RELEASE.jar:3.0.9.RELEASE] at org.springframework.batch.core.job.SimpleStepHandler.handleStep(SimpleStepHandler.java:148) [spring-batch-core-3.0.9.RELEASE.jar:3.0.9.RELEASE] at org.springframework.batch.core.job.AbstractJob.handleStep(AbstractJob.java:392) [spring-batch-core-3.0.9.RELEASE.jar:3.0.9.RELEASE] at org.springframework.batch.core.job.SimpleJob.doExecute(SimpleJob.java:135) [spring-batch-core-3.0.9.RELEASE.jar:3.0.9.RELEASE] at org.springframework.batch.core.job.AbstractJob.execute(AbstractJob.java:306) [spring-batch-core-3.0.9.RELEASE.jar:3.0.9.RELEASE] at org.springframework.batch.core.launch.support.SimpleJobLauncher$1.run(SimpleJobLauncher.java:135) [spring-batch-core-3.0.9.RELEASE.jar:3.0.9.RELEASE] at java.lang.Thread.run(Thread.java:748) [?:1.8.0_171]Caused by: java.lang.IllegalStateException: Already value [org.springframework.jdbc.datasource.ConnectionHolder@76ce6385] for key [&#123; CreateTime:"2018-12-24 15:01:21", ActiveCount:2, PoolingCount:18, CreateCount:20, DestroyCount:0, CloseCount:30, ConnectCount:32, Connections:[ &#123;ID:428371115, ConnectTime:"2018-12-24 15:01:21", UseCount:0, LastActiveTime:"2018-12-24 15:01:21"&#125;, ... &#123;ID:1832136599, ConnectTime:"2018-12-24 15:01:22", UseCount:0, LastActiveTime:"2018-12-24 15:01:22"&#125; ]&#125;[ &#123; ID:428371115, poolStatements:[ ] &#125;, ... &#123; ID:1832136599, poolStatements:[ ] &#125;]] bound to thread [SimpleAsyncTaskExecutor-2] at org.springframework.transaction.support.TransactionSynchronizationManager.bindResource(TransactionSynchronizationManager.java:190) ~[spring-tx-4.3.18.RELEASE.jar:4.3.18.RELEASE] at org.springframework.orm.hibernate5.HibernateTransactionManager.doBegin(HibernateTransactionManager.java:516) ~[spring-orm-4.3.18.RELEASE.jar:4.3.18.RELEASE] ... 26 more 使用 debeug，在第一个进行数据库操作的位置打断点，可以看到 debugger 下的如下错误： debugger 显示：不能创建事务。 错误原因： SpringBatch 默认使用 jdbc 的事务管理器，而没有使用自定义的 Hibernate 事务管理器。这时，在整个项目中，同时存在 Hibernate 和 Jdbc 的事务管理器，SpringBatch 无法判断使用哪个事务管理器，导致事务嵌套，从而抛出异常。 SpringBatch 会使用名为 transactionManager 的事务管理器，而在本例中， xml 设置的事务管理器，名为 txAdvice，从而导致出现多事务。 解决办法： 将声明式事务 txAdvice 名称修改为 transactionManager 即可。 在 Spring + SpringBatch 项目中，要严防出现事务嵌套！！！]]></content>
      <categories>
        <category>spring-batch</category>
      </categories>
      <tags>
        <tag>SpringBatch</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Activiti 工作流引擎（7） 流程分支、排他网关、动态处理人]]></title>
    <url>%2Factiviti%2Factiviti-7.html</url>
    <content type="text"><![CDATA[除了一个流程进行到底的工作流之外，还有一些有分支的工作流。如：下属在申报审批一条信息的时候，如果这条信息不算太重要，可以由经理审批；如果这条信息重要，需要由老板进行审批。 这时，就需要有流程分支。流程分支的作用就是处理一个流程中存在多个子分支时，根据不同的子分支条件，进行不同的子分支处理。 在流程图连线中确定条件依照上图做出一个有分支的流程，在这个流程中，处理当天信息有 2 个分支，一个是 不重要 的信息交给经理处理，而 重要 的分支交给老板处理。无论谁处理过，这个流程都结束。 流程图中确定条件点击分支流程：处理当天信息 —&gt; 经理(老板) 的连线， 在Name中填入备注信息，在Condition中填入条件信息。需要注意： 1、Condition必须为布尔类型；2、判断条件必须作为参数在执行中传入；3、尽量不使用中文 Condition：满足这个条件的时候，走这一步流程。即：满足 ${message==&#39;no&#39;} 走经理流程；满足${message==&#39;yes&#39;}走老板流程。 代码示例流程部署、启动不再示例。直接从流程分支开始。12345String taskId = "85005";Map&lt;String, Object&gt; params = new HashMap&lt;&gt;();params.put("message", "yes");processEngine.getTaskService().complete(taskId, params);System.out.println("执行“老板”分支，执行完毕"); 在执行任务时，直接传入 message，需要保证 message 与 Condition 一致。如果在传入message时，指定的值与Contidition不一致，在本例中即message传入值不是 yes/no，这时在执行时，由于判断条件错误，会导致后台报错，但流程不会进行。 错误信息：1234567891011121314org.activiti.engine.ActivitiException: No outgoing sequence flow of element '_4' could be selected for continuing the process at org.activiti.engine.impl.agenda.TakeOutgoingSequenceFlowsOperation.leaveFlowNode(TakeOutgoingSequenceFlowsOperation.java:172) at org.activiti.engine.impl.agenda.TakeOutgoingSequenceFlowsOperation.handleFlowNode(TakeOutgoingSequenceFlowsOperation.java:87) at org.activiti.engine.impl.agenda.TakeOutgoingSequenceFlowsOperation.run(TakeOutgoingSequenceFlowsOperation.java:75) at org.activiti.engine.impl.interceptor.CommandInvoker.executeOperation(CommandInvoker.java:73) at org.activiti.engine.impl.interceptor.CommandInvoker.executeOperations(CommandInvoker.java:57) at org.activiti.engine.impl.interceptor.CommandInvoker.execute(CommandInvoker.java:42) at org.activiti.engine.impl.interceptor.TransactionContextInterceptor.execute(TransactionContextInterceptor.java:48) at org.activiti.engine.impl.interceptor.CommandContextInterceptor.execute(CommandContextInterceptor.java:63) at org.activiti.engine.impl.interceptor.LogInterceptor.execute(LogInterceptor.java:29) at org.activiti.engine.impl.cfg.CommandExecutorImpl.execute(CommandExecutorImpl.java:44) at org.activiti.engine.impl.cfg.CommandExecutorImpl.execute(CommandExecutorImpl.java:39) at org.activiti.engine.impl.TaskServiceImpl.complete(TaskServiceImpl.java:186) at com.laiyy.activiti.config.SequenceFlow.sequenceFlowStart(SequenceFlow.java:40) _4 是执行这个任务的流程id，bpmn 文件中指定的处理当天信息这个步骤的 id。即在执行流程分支时，由于判断条件出错，导致流程不能往下执行。 排他网关排他网关主要用于在一个流程中，存在多个分支流程，但是无默认分支的情况。可以解决上面例子中出现的Condition不匹配的问题。在不能匹配Condition时进入默认流程分支。 如在银行办理业务时，有 普通窗口、VIP窗口 和银行的 后台窗口，在申请办理业务人为后台用户时，走 后台窗口，为 VIP 用户时，走 VIP窗口，其余默认走 普通窗口。与上例中的 经理/老板 流程不同的是，在 普通窗口 的流程中，是没有判断条件的。这是一个简单的排他网关。 此时按照上例中的代码继续执行时，会发现，如果 visitor 满足 3，则进入后台窗口，满足 2 则进入 vip窗口，否则都进入普通窗口 动态指定处理人可以使用类似于el表达式的方式：$userId，设置一个变量，在处理过程中动态的给这个变量赋值，即可实现动态指定。 设置处理人在进行流程处理时，设置下一步执行人1234567891011121314151617181920Map&lt;String, Object&gt; params =~ new HashMap&lt;&gt;();params.put("userId", "zhangsan");ProcessInstance processInstance = processEngine.getRuntimeService() .startProcessInstanceByKey(processDefikey, params);// 执行结束后，根据处理人查看任务信息String user = "zhangsan";// 获取任务服务TaskService taskService = processEngine.getTaskService();// 创建任务查询对象TaskQuery taskQuery = taskService.createTaskQuery();// 指定办理人，获取办理人的任务列表List&lt;Task&gt; list = taskQuery.taskAssignee(user).list();// 连理任务列表if (!CollectionUtils.isEmpty(list)) &#123;for (Task task : list) &#123; System.out.println("任务办理人：" + task.getAssignee() + " --&gt; 任务id：" + task.getId() + " --&gt; 任务名称：" + task.getName());&#125;]]></content>
      <categories>
        <category>activiti</category>
      </categories>
      <tags>
        <tag>Activiti</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Activiti 工作流引擎（6） 历史流程、流程变量]]></title>
    <url>%2Factiviti%2Factiviti-6.html</url>
    <content type="text"><![CDATA[Activiti 不仅仅能执行流程、获取到当前流程的信息，也可以获取到已经执行过的流程信息、任务信息。历史任务：流程执行的每一步都是一个任务，历史任务列表是所有流程的每一步执行情况。需要用到的表：act_hi_taskinst、act_hi_procinst 查询历史流程 查看历史执行实例： 代码示例1234567891011HistoryService historyService = processEngine.getHistoryService();List&lt;HistoricProcessInstance&gt; list = historyService.createHistoricProcessInstanceQuery().list();if (!CollectionUtils.isEmpty(list)) &#123; list.forEach(item -&gt; &#123; System.out.println("流程实例id" + item.getId()); System.out.println("流程实例定义id" + item.getProcessDefinitionId()); System.out.println("流程开始时间" + item.getStartTime()); System.out.println("流程结束时间" + item.getEndTime()); System.out.println("================="); &#125;);&#125; 查看历史任务（每一步） 代码实例1234567891011HistoryService historyService = processEngine.getHistoryService();List&lt;HistoricTaskInstance&gt; list = historyService.createHistoricTaskInstanceQuery().list();if (!CollectionUtils.isEmpty(list))&#123; list.forEach(item -&gt; &#123; System.out.println("历史流程实例id：" + item.getId()); System.out.println("历史流程定义id：" + item.getTaskDefinitionKey()); System.out.println("任务名称：" + item.getName()); System.out.println("处理人：" + item.getAssignee()); System.out.println("================"); &#125;);&#125; 流程变量如：在支付流程中，支付 —&gt; 填写金额 —&gt; 确认/取消，在确认/取消时，需要查看到当前支付金额，这个金额就是在支付流程中的变量。 流程变量设计到的表：1、act_ru_variable：正在执行的流程变量表2、act_hi_varinst：流程变量历史表 设置流程变量值可以设置普通的 POJO，但是需要实现序列化接口 通过 taskService 设置变量 通过 setVariable 设置12345678910111213141516/** * 通过 set 设置 */// taskId 任务id，范围比 runtime 小// variableName 变量名// value 变量值taskService.setVariable(taskId, variableName, value);// 设置本执行对象的变量，该对象的作用域只在当前的执行对象taskService.setVariableLocal(taskId, variableName, value);// 设置多个变量，values： Map&lt;String, Object&gt;taskService.setVariables(taskId, values);/** * 完成任务时设置 */taskService.complete(taskId, values [, localScope]) 通过 runtimeService 设置1234567891011121314151617/** * 通过 set 设置 */// executionId 执行对象id// variableName 变量名// value 变量值runtimeService.setVariable(executionId, variableName, value);// 设置本执行对象的变量，该对象的作用域只在当前的执行对象runtimeService.setVariableLocal(executionId, variableName, value);// 设置多个变量，values： Map&lt;String, Object&gt;runtimeService.setVariables(executionId, values);/** * 启动时设置 */// processKey 任务 key， values Map&lt;String, Object&gt;runtimeService.startProcessInstanceByKey(processKey, values) 获取流程变量使用 taskService 获取流程变量123runtimeService.getVariable(executionId, key) 去单个变量runtimeService.getVariableLocal(executionId, key) 取本执行对象的单个变量runtimeService.getVariables(executionId) // 取多个变量 使用 runtimeService 获取流程变量123taskService.getVariable(taskId, key)taskService.getVariableLocal(taskId, key)taskService.getVariables(taskId) 变量支持的类型 简单类型 String、boolean、Integer、double、Date 等 自定义对象 自定义的 POJO]]></content>
      <categories>
        <category>activiti</category>
      </categories>
      <tags>
        <tag>Activiti</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Activiti 工作流引擎（5） 流程定义]]></title>
    <url>%2Factiviti%2Factiviti-5.html</url>
    <content type="text"><![CDATA[在上两篇博文中，已经介绍了如何创建、启动、完成一个流程，以及在流程运转过程中的一些注意点和需要用到的表结构的分析。那么，一个流程定义该如何管理？比如流程删除、流程中变量的使用、指定任务处理人等操作该如何操作？ 流程定义管理涉及对象、表 流程定义中涉及到的对象主要是 ProcessEngine、RepositoryService、Deployment、ProcessDefinition，即：Activiti 核心类和仓库服务。ProcessDefinition：解析 .bpmn 文件后得到的流程定义规则信息，工作流就是按照流程定义的规则执行的。Deployment：部署对象，一次部署多个文件的信息。对于不需要的流程可以删除和修改。涉及到的表结构主要有： act_re_deployment：部署对象表 act_re_procdef：流程定义表 act_ge_bytearray：资源文件表 act_ge_property：主键生成策略表 查询流程、资源新建一个采购审批流程，如图： 以 Zip 形式上传并自解压12345678InputStream inputStream = getClass().getClassLoader().getResourceAsStream("BuyBill.zip");RepositoryService repositoryService = processEngine.getRepositoryService();Deployment deploy = repositoryService.createDeployment() .name("采购流程") // 以 zip 形式上传 bpmn 文件 .addZipInputStream(new ZipInputStream(inputStream)) .deploy();System.out.println(deploy.getId() + " --&gt; " + deploy.getName()); 查看流程定义信息1234567891011121314151617181920212223// 查看流程定义ProcessDefinitionQuery query = processEngine.getRepositoryService().createProcessDefinitionQuery();// 查询（类比 SQL 的 where 条件）// 流程定义的id，myProcess_1:2:22503，组成方式： key + 版本 + 自动生成的id// query = query.processDefinitionId("myProcess_1:2:22503");// 流程定义的 key，有 bpmn 文件的 key 决定query.processDefinitionKey("myProcess_1");// 流程定义名称// query.processDefinitionName("");// 流程定义版本// query.processDefinitionVersion(1);// 最新版本// query.latestVersion();// 版本降序排序List&lt;ProcessDefinition&gt; list = query.orderByProcessDefinitionVersion().desc() // 总数// .count() // 列表 .list();if (!CollectionUtils.isEmpty(list))&#123; list.forEach( temp -&gt; System.out.println("流程定义id：" + temp.getId() + " ---&gt; 流程定义key：" + temp.getKey() + " ---&gt; 流程版本：" + temp.getVersion() + " 部署id：" + temp.getDeploymentId() + " 流程定义名称：" + temp.getName()));&#125; 查询资源文件并拷贝到本地123456789101112// 通过部署资源的 deployment id 获取资源String resourceName = "";String deploymentId = "22501";List&lt;String&gt; resourceNames = processEngine.getRepositoryService().getDeploymentResourceNames(deploymentId);if (!CollectionUtils.isEmpty(resourceNames)) &#123; resourceName = resourceNames.get(0); // 读取资源，根据 deploy id 和 资源名称 InputStream inputStream = processEngine.getRepositoryService().getResourceAsStream(deploymentId, resourceName); // 拷贝到本地 File file = new File("d:/" + resourceName); FileUtils.copyInputStreamToFile(inputStream, file);&#125; 删除流程定义 通过部署 id 删除流程定义 12String deployId = "2501";processEngine.getRepositoryService().deleteDeployment(deployId); 操作成功后，act_re_deploy、act_ge_bytearray、act_re_procdef 表中会级联删除相关数据。但是 act_hi_* 中保存的是历史记录，历史记录不会删除。 流程实例、任务的执行主要核心类：Execution、ProcessInstance、Task Execution：执行对象，按照流程定义的规则执行一次的过程。 对应的表： act_ru_exection：正在执行的信息 act_hi_procinst：已经执行完的历史流程实例信息 act_hi_actinst：存放历史所有完成的活动 ProcessInstance：流程实例，特质流程从开始导结束的最大执行分支。一个执行的流程中，流程实例只有一个。 需要注意： 如果是单例流程，执行对象 id 就是流程实例 id 如果一个流程有分值和聚合，那么执行对象 id 和流程实例 id 就不相同 一个流程中，流程实例只有一个，执行对象可以存在多个 Task 任务：执行到某任何环节时生成的任务信息。 对应的表： act_ru_task：正在执行的任务 act_hi_taskinst：已经执行完的历史任务信息 理解流程实例和执行对象流程实例和执行对象是两个不通的概念，可以粗略理解为，执行对象是由流程实例创建的。在一个流程中，流程的实例只能有一个，即：一个流程就是一个实例。但是执行对象可以有多个，即：一个流程可以委派给多个执行对象去执行这个流程。 举个例子：一个人执行跑步 —&gt; 打球 —&gt; 回家 流程，如果此时在 跑步 完成之后，有一个快递需要拿，拿完直接回家的话，就是一个 跑步 —&gt; 拿快递 —&gt; 回家 流程。在这个流程里面，此人只能执行其中一个流程，但是 打球、拿快递 都在主流程：跑步 —&gt;… —&gt; 回家 中。但是如果在 拿快递 这个流程执行的时候，把这个流程交给了一个朋友去执行，自己还可以继续去打球的。在这个例子里面，跑步 —&gt; 打球(拿快递) —&gt; 回家 是一个流程实例。 执行打球、拿快递 的是执行对象。 即：一个流程只能有一个实例，但是可以交给多个对象去执行。]]></content>
      <categories>
        <category>activiti</category>
      </categories>
      <tags>
        <tag>Activiti</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Activiti 工作流引擎（4） 启动流程]]></title>
    <url>%2Factiviti%2Factiviti-4.html</url>
    <content type="text"><![CDATA[ProcessEngine 的几个重要的 Service RepositoryService：管理流程的定义 RuntimeService：执行管理，包括流程的启动、推进、删除流程实例等操作 TaskService：任务管理 HistoryService：历史管理（执行完的数据管理） IdentityService：可选服务，任务表单管理 启动流程在上一篇末尾，已经实现了使用 RepositoryService 定义、部署一个流程。部署完成的流程需要使用 RuntimeService 来启动 代码示例12345678// 执行流程 -- 执行流程属于运行，需要获取运行时服务 RuntimeServiceRuntimeService runtimeService = processEngine.getRuntimeService();// startProcessInstanceById 使用 act_re_procdef 中的 ID_ 字段，该字段自动生成，不便于理解// startProcessInstanceByKey 使用 act_re_procdef 中的 KEY_ 字段，该字段手动执行，便于理解，但是需要格外注意不能重复// 如果一个流程进行了多次修改，那么 KEY_ 和 NAME_ 必须一样，且运行时执行最后一个 VERSION_ 版本// 取得流程实例ProcessInstance instance = runtimeService.startProcessInstanceByKey("levelBill");System.out.println("流程实例id：" + instance.getId() + " ---&gt; 流程定义id： " + instance.getProcessDefinitionId()); 控制台打印结果为：1流程实例id：5001 ---&gt; 流程定义id： levelBill:2:2503 查看 act_ru_execution PROC_INST_ID_：对应 act_ge_property 中的 next.dbid 的值 PARENT_ID_：对应上一步的 act_ru_execution 的 ID_ ROOT_PROC_INST_ID_：对应运行实例的 id ACT_ID_：对应当前流程进行到哪一步了 PROC_DEF_ID_：对应流程定义的 id(act_re_procdef 中的 ID_) 任务查询在第一步启动任务后，任务流程自动进入第一步中。在本例中，相当于 请假流程已经开始，需要 zhangsan 进行审批。那么，就需要获取 zhangsan 的任务列表。 获取任务列表，顾名思义就需要任务服务，通过任务服务查询出任务列表 代码示例1234567891011121314// 任务办理人（第一步是zhangsan办理）String user = "zhangsan";// 获取任务服务TaskService taskService = processEngine.getTaskService();// 创建任务查询对象TaskQuery taskQuery = taskService.createTaskQuery();// 指定办理人，获取办理人的任务列表List&lt;Task&gt; list = taskQuery.taskAssignee(user).list();// 连理任务列表if (!CollectionUtils.isEmpty(list))&#123; for (Task task : list) &#123; System.out.println("任务办理人：" + task.getAssignee() + " --&gt; 任务id：" + task.getId() + " --&gt; 任务名称：" + task.getName()); &#125;&#125; 在控制台中可以看到，需要张三办理的任务完整打印：12任务办理人：zhangsan --&gt; 任务id：5005 --&gt; 任务名称：first任务办理人：zhangsan --&gt; 任务id：7505 --&gt; 任务名称：first 对照数据库查询 act_ru_task 表，可以看到当前正在执行的流程数据 EXECUTION_ID：流程实例的id，对应 act_ru_exection 的 ID_ PROC_DEF_ID_：流程定义的id，对应 act_re_procdef 的 ID_ TASK_DEF_KEY_：当前流程 id，对应 act_ru_exection 的 ACT_ID_ ASSIGNEE_：执行人，对应 BPMN 文件中指定的当前流程执行人 NAME_：任务名称，对应 BPMN 文件中指定的当前流程的名称 任务完成完成一个任务，即结束当前步骤，进入下一个步骤（并不是完成整改流程） 代码示例123456// 完成这个任务，即：当前步骤完成，进行下一个步骤String taskId = "5005"; // 指定需要完成的任务 id// 完成任务，也需要任务服务TaskService taskService = processEngine.getTaskService();// 完成任务taskService.complete(taskId); 对照数据库查询 act_ru_task 表 与上面任务执行后获取到的表进行对比，可以看到，ID_、NAME_、TASK_DEK_KEY_、ASSIGENEE_ 均已变更为当前步骤的数据，而上一步的数据已经自动删除。 自动删除执行过的步骤，可以保证正在运行的任务表足够小，无冗余，可以更大程度的保证流程处理的效率 任务结束如果修改 taskId，运行任务完成操作，在最后一步以后，会自动完成流程。完成后的流程，在 act_ru_task、act_ru_execution 是没有记录的，因为这些流程已经完成，不是进行中的状态。这样做可以保证运行中的任务表足够小，效率足够快。 任务结束后，历史流程可以在 act_hi_* 中查看到。]]></content>
      <categories>
        <category>activiti</category>
      </categories>
      <tags>
        <tag>Activiti</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Activiti 工作流引擎（3） 添加一个简单的工作流]]></title>
    <url>%2Factiviti%2Factiviti-3.html</url>
    <content type="text"><![CDATA[创建一个简单的工作流引擎，需要准备：数据库、工作流文件（BPMN）。创建工作流的基本流程： 构建 ProcessEngineConfiguration 对象 –&gt; 设置数据库连接 –&gt; 设置数据库表创建属性 –&gt; 构建一个流程引擎。其中：ProcessEngineConfiguration 对象，是构建一个简单工作流的核心 API。为了简单的示例操作，使用 Junit 创建测试用例创建即可。 创建简单的工作流引擎创建工作流引擎的三个方法： 使用 ProcessEngineConfiguration 硬编码配置数据库连接创建 使用 ProcessEngineConfiguration + activiti.cfg.xml 文件创建 使用 ProcessEngines 默认配置创建 使用 ProcessEngineConfiguration 创建使用 ProcessEngineConfiguration 创建工作流引擎时，需要指定好数据库、库表创建策略等1234567891011121314151617// 1、取得 ProcessEngineConfiguration 对象ProcessEngineConfiguration configuration = ProcessEngineConfiguration.createStandaloneProcessEngineConfiguration();// 2、设置数据库属性configuration.setJdbcDriver("com.mysql.jdbc.Driver");configuration.setJdbcUrl("jdbc:mysql:///activiti?createDatabaseIfNotExist=true&amp;useUnicode=true&amp;charsetEncoding=utf8&amp;serverTimezone=Hongkong");configuration.setJdbcUsername("root");configuration.setJdbcPassword("123456");// 3、设置创建表的策略，没有表时自动创建// DB_SCHEMA_UPDATE_TRUE 没有表时自动创建// DB_SCHEMA_UPDATE_FALSE 不自动创建// DB_SCHEMA_UPDATE_CREATE_DROP 先删除表再自动创建configuration.setDatabaseSchemaUpdate(ProcessEngineConfiguration.DB_SCHEMA_UPDATE_TRUE);// 创建流程引擎processEngine = configuration.buildProcessEngine();System.out.println("流程创建成功"); 使用 ProcessEngineConfiguration + activiti.cfg.xml 文件创建此种创建方式，实际上是将数据库的链接配置，设置在了 xml 文件中。 activiti.cfg.xml 文件1234567891011121314&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd"&gt; &lt;!-- ProcessEngineConfiguration 是一个抽象类，不能作为一个 Bean，需要指定具体的实现类作为 Bean --&gt; &lt;bean id="processEngineConfiguration" class="org.activiti.engine.impl.cfg.StandaloneProcessEngineConfiguration"&gt; &lt;property name="jdbcUrl" value="jdbc:mysql:///activiti?createDatabaseIfNotExist=true&amp;amp;useUnicode=true&amp;amp;charsetEncoding=utf8&amp;amp;serverTimezone=Hongkong" /&gt; &lt;property name="jdbcDriver" value="com.mysql.jdbc.Driver" /&gt; &lt;property name="jdbcUsername" value="root" /&gt; &lt;property name="jdbcPassword" value="123456" /&gt; &lt;property name="databaseSchemaUpdate" value="true" /&gt; &lt;/bean&gt;&lt;/beans&gt; 代码示例123ProcessEngineConfiguration configuration = ProcessEngineConfiguration.createProcessEngineConfigurationFromResource("activiti.cfg.xml");processEngine = configuration.buildProcessEngine();System.out.println("流程创建成功"); 使用 ProcessEngines 默认配置创建使用 ProcessEngines 默认配置，实际上和 使用 xml 配置是一样的，因为使用 ProcessEngines 时会默认读取 activiti.cfg.xml 文件 12processEngine = ProcessEngines.getDefaultProcessEngine();System.out.println("流程创建成功"); ProcessEngines 重点源码分析：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374// 默认配置ProcessEngines.getDefaultProcessEngine();// 获取默认配置public static ProcessEngine getDefaultProcessEngine() &#123; return getProcessEngine("default");&#125;// 是否已经初始化public static boolean isInitialized() &#123; return isInitialized;&#125;// 获取默认配置public static ProcessEngine getProcessEngine(String processEngineName) &#123; // 此时调用肯定是没有初始化的，所以会调用 init 方法 if (!isInitialized()) &#123; init(); &#125; return processEngines.get(processEngineName);&#125;// 初始化方法public synchronized static void init() &#123; // 此时 isInitialized 为 false if (!isInitialized()) &#123; // 如果 processEngines 为空，重新构造 if (processEngines == null) &#123; // Create new map to store process-engines if current map is // null processEngines = new HashMap&lt;String, ProcessEngine&gt;(); &#125; ClassLoader classLoader = ReflectUtil.getClassLoader(); Enumeration&lt;URL&gt; resources = null; try &#123; // 获取默认的 activiti.cfg.xml 配置 resources = classLoader.getResources("activiti.cfg.xml"); &#125; catch (IOException e) &#123; // 如果获取不到会报错 throw new ActivitiIllegalArgumentException("problem retrieving activiti.cfg.xml resources on the classpath: " + System.getProperty("java.class.path"), e); &#125; // Remove duplicated configuration URL's using set. Some // classloaders may return identical URL's twice, causing duplicate // startups // 解析 xml 文件 Set&lt;URL&gt; configUrls = new HashSet&lt;URL&gt;(); while (resources.hasMoreElements()) &#123; configUrls.add(resources.nextElement()); &#125; for (Iterator&lt;URL&gt; iterator = configUrls.iterator(); iterator.hasNext();) &#123; URL resource = iterator.next(); log.info("Initializing process engine using configuration '&#123;&#125;'", resource.toString()); initProcessEngineFromResource(resource); &#125; try &#123; // 获取 activiti-context.xml（和 activiti.cfg.xml 一样，不过是名字规定的不一样） resources = classLoader.getResources("activiti-context.xml"); &#125; catch (IOException e) &#123; throw new ActivitiIllegalArgumentException("problem retrieving activiti-context.xml resources on the classpath: " + System.getProperty("java.class.path"), e); &#125; while (resources.hasMoreElements()) &#123; URL resource = resources.nextElement(); log.info("Initializing process engine using Spring configuration '&#123;&#125;'", resource.toString()); initProcessEngineFromSpringResource(resource); &#125; // 设置 isInitialized 为 true，标记为已初始化 setInitialized(true); &#125; else &#123; log.info("Process engines already initialized"); &#125;&#125; 部署一个简单的工作流在创建工作流成功，并且创建 BPMN 文件后，可以进行流程的部署。流程部署需要用到仓库服务，即 RepositoryService 部署操作代码示例123456789// 获取仓库服务：管理定义流程RepositoryService repositoryService = processEngine.getRepositoryService();// 创建部署Deployment deploy = repositoryService.createDeployment() // 返回部署的构建器 .addClasspathResource("LevelBill.bpmn") // 从类路径下添加资源 .name("LevelBill：请假单流程") // 设置部署的名字 .category("办公类别") // 设置类别 .deploy(); // 部署System.out.println("部署成功后返回的 id：" + deploy.getId() + "，部署的名称：" + deploy.getName()); 查看部署结果 查看 act_re_deployment 表 查看 act_re_prrocdef 表 bpmn 文件：1&lt;process id="levelBill" isClosed="false" isExecutable="true" name="LevelBill" processType="None"&gt; 其中： KEY_ 指向 BPMN 文件中 的 id， NAME_ 指向 BPMN 文件中的 name，_DEPLOYMENT_ID_ 指向 act_re_deployment 表的 id，RESOURCE_NAME_ 指向 构建 deploy 时的 classpathResource 的值 查看 act_ge_property 表 其中：next.dbid 的值VALUE_ 即为下一步运行部署操作时，act_re_deployment 的 id。 再次运行部署操作再次运行部署操作，查看 act_ge_property 和 act_re_deployment 表，可以看到 act_ge_property 的 next.dbid 的值变了，且 act_re_deployment 的中 id 变为上一次运行后 act_ge_property 的 next.dbid 的值。]]></content>
      <categories>
        <category>activiti</category>
      </categories>
      <tags>
        <tag>Activiti</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Activiti 工作流引擎（2） 使用 IDEA 创建工作流]]></title>
    <url>%2Factiviti%2Factiviti-2.html</url>
    <content type="text"><![CDATA[安装 actiBPM 插件在 IDEA 中选择： File –&gt; Setting –&gt; Plugins –&gt; Browse repositories –&gt; 查询 actiBPM 并下载安装 创建一个 BPM 文件 在 resources（静态文件存储路径）上右键新建，选择 BpmnFile 或者 BPMN File 进行创建 设置流程一个已经设置好的流程： 常用的几个控制器： startEvent：流程开始 endEvent：流程结束 UserTask：用户操作任务 ScriptTask：脚本操作任务 ServiceTask：业务操作任务 MailTask：邮件任务 将右侧控制器拖拽至中间白板上，即可设置控制器属性。然后将鼠标放在控制器中央位置，会有一个圆点，选中圆点下拉至另外一个控制器，即可设置流程顺序。 设置整个 bpmn 文件属性点击空白处，可在右侧看到整个 bpmn 文件属性，可以根据自己的实际需求进行设置 常用属性： Id：可以看做 BPMN 在整个流程中的文件唯一标识 Name： 可以看做 BPMN 文件的别名（实际名称是创建 BPMN 文件时的名称） 设置开始、结束控制器点击开始、结束控制器，可根据自己实际需求设置控制器属性 常用属性： Id：这个开始、结束控制器的 id，尽量不要更改 Name：这个开始、结束控制器的名称，更改后可以在中间图标出立即显示；也可以双击图标进行更改 设置中间流程控制器点击中间流程控制器，设置控制器属性 常用属性： Id：流程控制器 Id，尽量不要更改 Name： 控制器的名称，更改后可以在中间图标出立即显示；也可以双击图标进行更改 Assignee：谁管理这个流程控制器（可以是用户、角色等） 设置 BPMN 需要注意的点：在流程控制器中，Id 尽量不要更改。如果更改的话，必须要保证 id 不能重复，否则会出现同一个 id 对应两个流程控制，导致无法确定进行哪一步的流程，这样会出现错误。 bpmn 文件将 bpmn 文件以文本形式打开，可以发现，bpmn 文件实际上是一个 xml 文件。以刚才创建好的 bpmn 文件为例123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687&lt;?xml version="1.0" encoding="UTF-8" standalone="yes"?&gt;&lt;definitions xmlns="http://www.omg.org/spec/BPMN/20100524/MODEL" xmlns:activiti="http://activiti.org/bpmn" xmlns:bpmndi="http://www.omg.org/spec/BPMN/20100524/DI" xmlns:dc="http://www.omg.org/spec/DD/20100524/DC" xmlns:di="http://www.omg.org/spec/DD/20100524/DI" xmlns:tns="http://www.activiti.org/testm1544000001944" xmlns:xsd="http://www.w3.org/2001/XMLSchema" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" expressionLanguage="http://www.w3.org/1999/XPath" id="m1544000001944" name="" targetNamespace="http://www.activiti.org/testm1544000001944" typeLanguage="http://www.w3.org/2001/XMLSchema"&gt; &lt;!-- id 即为刚才设置的 “整个 BPMN 文件” 的 id， name 为 Name --&gt; &lt;process id="levelBill" isClosed="false" isExecutable="true" name="LevelBill" processType="None"&gt; &lt;!-- 开始节点， id 为 _2， name 为 start --&gt; &lt;startEvent id="_2" name="start"/&gt; &lt;!-- 用户操作节点，id 为 _3，name 为 first，操作人为 zhangsan --&gt; &lt;userTask activiti:assignee="zhangsan" activiti:exclusive="true" id="_3" name="first"/&gt; &lt;userTask activiti:assignee="lsii" activiti:exclusive="true" id="_5" name="second"/&gt; &lt;userTask activiti:assignee="wangwu" activiti:exclusive="true" id="_7" name="third"/&gt; &lt;!-- 结束节点，id为 _9，name 为 end --&gt; &lt;endEvent id="_9" name="end"/&gt; &lt;!-- 流程控制（即两个控制器之间的箭头连线），从 _2 步骤指向 _3 步骤，即第一步为 _2：start，第二步为 _3：first --&gt; &lt;sequenceFlow id="_4" sourceRef="_2" targetRef="_3"/&gt; &lt;sequenceFlow id="_6" sourceRef="_3" targetRef="_5"/&gt; &lt;sequenceFlow id="_8" sourceRef="_5" targetRef="_7"/&gt; &lt;!-- 流程控制，从 _7 步骤执行 _9，即最后一步为 从 _7：third 向 _9：end 流通 --&gt; &lt;sequenceFlow id="_10" sourceRef="_7" targetRef="_9"/&gt; &lt;/process&gt; &lt;!-- 下方为 bpmn 各节点样式、坐标等，通过拖拽自动生成，可改文件微调 --&gt; &lt;bpmndi:BPMNDiagram documentation="background=#3C3F41;count=1;horizontalcount=1;orientation=0;width=842.4;height=1195.2;imageableWidth=832.4;imageableHeight=1185.2;imageableX=5.0;imageableY=5.0" id="Diagram-_1" name="New Diagram"&gt; &lt;bpmndi:BPMNPlane bpmnElement="levelBill"&gt; &lt;!-- 每个节点的位置、宽高等调整，bpmnElement 指向节点 id --&gt; &lt;bpmndi:BPMNShape bpmnElement="_2" id="Shape-_2"&gt; &lt;dc:Bounds height="32.0" width="32.0" x="450.0" y="70.0"/&gt; &lt;bpmndi:BPMNLabel&gt; &lt;dc:Bounds height="32.0" width="32.0" x="0.0" y="0.0"/&gt; &lt;/bpmndi:BPMNLabel&gt; &lt;/bpmndi:BPMNShape&gt; &lt;bpmndi:BPMNShape bpmnElement="_3" id="Shape-_3"&gt; &lt;dc:Bounds height="55.0" width="85.0" x="425.0" y="160.0"/&gt; &lt;bpmndi:BPMNLabel&gt; &lt;dc:Bounds height="55.0" width="85.0" x="0.0" y="0.0"/&gt; &lt;/bpmndi:BPMNLabel&gt; &lt;/bpmndi:BPMNShape&gt; &lt;bpmndi:BPMNShape bpmnElement="_5" id="Shape-_5"&gt; &lt;dc:Bounds height="55.0" width="85.0" x="425.0" y="260.0"/&gt; &lt;bpmndi:BPMNLabel&gt; &lt;dc:Bounds height="55.0" width="85.0" x="0.0" y="0.0"/&gt; &lt;/bpmndi:BPMNLabel&gt; &lt;/bpmndi:BPMNShape&gt; &lt;bpmndi:BPMNShape bpmnElement="_7" id="Shape-_7"&gt; &lt;dc:Bounds height="55.0" width="85.0" x="425.0" y="370.0"/&gt; &lt;bpmndi:BPMNLabel&gt; &lt;dc:Bounds height="55.0" width="85.0" x="0.0" y="0.0"/&gt; &lt;/bpmndi:BPMNLabel&gt; &lt;/bpmndi:BPMNShape&gt; &lt;bpmndi:BPMNShape bpmnElement="_9" id="Shape-_9"&gt; &lt;dc:Bounds height="32.0" width="32.0" x="455.0" y="465.0"/&gt; &lt;bpmndi:BPMNLabel&gt; &lt;dc:Bounds height="32.0" width="32.0" x="0.0" y="0.0"/&gt; &lt;/bpmndi:BPMNLabel&gt; &lt;/bpmndi:BPMNShape&gt; &lt;!-- 两个节点之间的链接，bpmnElement 指向流程链接 id --&gt; &lt;bpmndi:BPMNEdge bpmnElement="_4" id="BPMNEdge__4" sourceElement="_2" targetElement="_3"&gt; &lt;di:waypoint x="466.0" y="102.0"/&gt; &lt;di:waypoint x="466.0" y="160.0"/&gt; &lt;bpmndi:BPMNLabel&gt; &lt;dc:Bounds height="0.0" width="0.0" x="0.0" y="0.0"/&gt; &lt;/bpmndi:BPMNLabel&gt; &lt;/bpmndi:BPMNEdge&gt; &lt;bpmndi:BPMNEdge bpmnElement="_6" id="BPMNEdge__6" sourceElement="_3" targetElement="_5"&gt; &lt;di:waypoint x="467.5" y="215.0"/&gt; &lt;di:waypoint x="467.5" y="260.0"/&gt; &lt;bpmndi:BPMNLabel&gt; &lt;dc:Bounds height="0.0" width="0.0" x="0.0" y="0.0"/&gt; &lt;/bpmndi:BPMNLabel&gt; &lt;/bpmndi:BPMNEdge&gt; &lt;bpmndi:BPMNEdge bpmnElement="_8" id="BPMNEdge__8" sourceElement="_5" targetElement="_7"&gt; &lt;di:waypoint x="467.5" y="315.0"/&gt; &lt;di:waypoint x="467.5" y="370.0"/&gt; &lt;bpmndi:BPMNLabel&gt; &lt;dc:Bounds height="0.0" width="0.0" x="0.0" y="0.0"/&gt; &lt;/bpmndi:BPMNLabel&gt; &lt;/bpmndi:BPMNEdge&gt; &lt;bpmndi:BPMNEdge bpmnElement="_10" id="BPMNEdge__10" sourceElement="_7" targetElement="_9"&gt; &lt;di:waypoint x="471.0" y="425.0"/&gt; &lt;di:waypoint x="471.0" y="465.0"/&gt; &lt;bpmndi:BPMNLabel&gt; &lt;dc:Bounds height="0.0" width="0.0" x="0.0" y="0.0"/&gt; &lt;/bpmndi:BPMNLabel&gt; &lt;/bpmndi:BPMNEdge&gt; &lt;/bpmndi:BPMNPlane&gt; &lt;/bpmndi:BPMNDiagram&gt;&lt;/definitions&gt;]]></content>
      <categories>
        <category>activiti</category>
      </categories>
      <tags>
        <tag>Activiti</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Activiti 工作流引擎（1） 工作流基础了解]]></title>
    <url>%2Factiviti%2Factiviti-1.html</url>
    <content type="text"><![CDATA[什么是工作流工作流（Workflow），指“业务过程的部分或整体在计算机应用环境下的自动化”。是对工作流程及其各操作步骤之间业务规则的抽象、概括描述。在计算机中，工作流属于计算机支持的协同工作（CSCW）的一部分。后者是普遍地研究一个群体如何在计算机的帮助下实现协同工作的。工作流主要解决的主要问题是：为了实现某个业务目标，利用计算机在多个参与者之间按某种预定规则自动传递文档、信息或者任务。 常见的工作流的地方 OA 审批功能 电子政务上传下达 物流运输流程记录 … 使用工作流和不使用工作流的区别以学校请假为例，如果一个学生请假需要经过以下流程： 填写请见条 –&gt; 提交给老师 –&gt; 老师审批（通过，不通过） –&gt; 提交到年级处 –&gt; 年级处审批（通过，不通过） –&gt; 提交给教务处 –&gt; 教务处审批 （通过，不通过） –&gt; 提交到校长 –&gt; 校长审批（通过，不通过） –&gt; 结束 Activiti 工作流常见的开源工作流引擎框架有：OSWrokFlow、jBPM（jboss business process management）、Activiti（对 jBPM 的升级）、Spring WorkFlow 等 Activiti 的简单认识ProcessEngineProcessEngine 是 Activiti 的核心工作类，可以由该类获取到其他服务（历史服务、仓库服务、任务服务、角色 / 参与者服务） 历史服务：之前运行过的所有流程即为历史服务仓库服务：定义好的流程需要保存到一个仓库中（一般为数据库），该数据库中保存的流程，解析该流程的服务即为仓库服务任务服务：定义好的流程中的每一步即为一个任务服务角色 / 参与者服务：执行流程中步骤的人、角色，即为一个 角色 / 参与者服务 BPMNBPMN： 业务流程建模与标注（Business Process Model and Notation），描述流程的基本符号，包括这些土元如果组成一个业务流程图（Business Process Diagram） 以一个简单的业务流程图为例： 第一个圆圈代表流程开始，审批流程为： 提交 -&gt; 经纪人 -&gt; 老总，最后一个加粗的圆圈代表流程结束。每一个起始点、流程审批点、结束点，都是一个最基本的 BPMN，这些点组合在一起，整个图可以称为一个最基本的 业务流程图。 配置文件activiti.cfg.xml： Activiti 核心配置文件，配置流程引擎创建工具的基本参数和数据库连接参数 logging.properties： log4j 日志打印 数据库表Activiti 数据库总共有 23 张表，所有表都是以 ACT_ 开头，第二部分表示表的用途，一般用两个字母标示，用于和服务的 API 对应。 act_ge_* ： 通用数据，用于不同场景下，如：存放资源文件 act_hi_* ： hi 代表 history。包含历史数据，比如：历史流程实例、变量、任务等 act_re_* ： re 代表 repository。这个前缀的表包含了定义流程和流程静态资源（图片、规则等） act_ru_* ： ru 代表 runtime。包含了流程实例、任务、变量、异步任务等运行中的数据。Activiti 只在了流程实例执行过程中保存这些数据，在流程结束后就会删除这些记录，这样可以保证运行时表一直很小，速度很快） act_id_* ： id 代表 identity。包含身份信息，比如：用户、组等 流程规则表: act_re_* 表名 作用 act_re_deployment 部署信息 act_re_model 流程设计模型部署表 act_re_procdef 流程定义数据表 运行时数据库表：act_ru_* 表名 作用 act_ru_execution 运行时流程执行实例表 act_ru_identitylink 运行时流程人员表，主要存储任务节点与参与者的相关信息 act_ru_task 运行时任务节点表 act_ru_variable 运行时流程变量数据表 历史数据库表： act_hi_* 表名 作用 act_hi_actinst 历史节点表 act_hi_attachment 历史附件表 act_hi_comment 历史意见表 act_hi_identitylink 历史流程人员表 act_hi_detail 历史详情表，提供历史变量的查询 act_hi_procinst 历史流程实例表（常用） act_hi_taskinst 历史任务实例表（常用） act_hi_varinst 历史变量表（常用） 组织结构表：act_id_* 表名 作用 act_id_group 用户组信息 act_id_info 用户扩展信息 act_id_membership 用户与用户组队员信息 act_id_user 用户信息 通用数据表： act_ge_* 表名 作用 act_ge_bytearray 二进制数据表 act_ge_property 属性数据表，存储整个流程引擎级别的数据，初始化时会默认插入三条数据]]></content>
      <categories>
        <category>activiti</category>
      </categories>
      <tags>
        <tag>Activiti</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring Batch 学习（7） 错误处理]]></title>
    <url>%2Fspring-batch%2Fspring-batch-study-7.html</url>
    <content type="text"><![CDATA[SpringBatch 错误处理SpringBatch 的错误处理，大致分为：错误中断，重启后继续执行，错误重试，错误跳过 等 错误中断，重启后继续执行：在每次 chunk 后在 ExecutionContext 中打入标记，在重启执行该任务时，判断 ExecutionContext 中是否存在标记，如果存在，则从标记位重新读取执行 错误重试：在出现错误时，根据指定的需要重试的异常，进行重新读写处理，需要指定：需要重试的异常、重试次数 错误跳过：在出现错误时，根据指定的需要跳过的异常，跳过该条数据，需要指定：需要跳过的异常，跳过次数 错误中断，重启后继续执行在 读、处理、写 操作中任何一环出现问题都可以将任务中断 此项操作，需要 ItemReader、ItemWriter 实现 ItemStreamReader、ItemStreamWriter 接口，在实现类中定义规则 ItemStreamReader、ItemStreamWriter实现接口后有以下几个方法需要重写： read()：读取 / 写入 数据的规则 open(ExecutionContext executionContext)：在开始读取 / 写入 之前调用，用于第一次执行 或 重启后继续执行时的判断 update(ExecutionContext executionContext)：在 chunk 后执行，用于修改数据库中对 ExecutionContext 的记录 close()：读取 / 写入 结束后执行 代码示例数据来源(file1.txt)：1234&quot;1&quot;,&quot;Kabul&quot;,&quot;AFG&quot;,&quot;Kabol&quot;,&quot;1780000&quot;&quot;2&quot;,&quot;Qandahar&quot;,&quot;AFG&quot;,&quot;Qandahar&quot;,&quot;237500&quot;&quot;3&quot;,&quot;Herat&quot;,&quot;AFG&quot;,&quot;Herat&quot;,&quot;186800&quot;&quot;4&quot;,&quot;Mazar-e-Sharif&quot;,&quot;AFG&quot;,&quot;Balkh&quot;,&quot;127800&quot; 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108public class RestartReader implements ItemStreamReader&lt;City&gt; &#123; /** * 文件读取 */ private FlatFileItemReader&lt;City&gt; reader = new FlatFileItemReader&lt;&gt;(); /** * 当前读到第几行 */ private Long curLine = 0L; /** * 是否重启 */ private boolean restart = false; /** * 执行的上下文 */ private ExecutionContext executionContext; public RestartReader() &#123; reader.setResource(new ClassPathResource("file1.txt")); DelimitedLineTokenizer tokenizer = new DelimitedLineTokenizer(); tokenizer.setNames("id", "name", "countryCode", "district", "population"); // 解析后的数据映射为对象 DefaultLineMapper&lt;City&gt; mapper = new DefaultLineMapper&lt;&gt;(); mapper.setLineTokenizer(tokenizer); mapper.setFieldSetMapper(new FieldSetMapper&lt;City&gt;() &#123; @Override public City mapFieldSet(FieldSet fieldSet) throws BindException &#123; City city = new City(); city.setCountryCode(fieldSet.readString("countryCode")); city.setDistrict(fieldSet.readString("district")); city.setId(fieldSet.readInt("id")); city.setName(fieldSet.readString("name")); city.setPopulation(fieldSet.readLong("population")); return city; &#125; &#125;); // 数据校验 mapper.afterPropertiesSet(); // 绑定映射 reader.setLineMapper(mapper); &#125; @Override public City read() throws Exception, UnexpectedInputException, ParseException, NonTransientResourceException &#123; City city = null; // 每次读取数据，当前行 +1 this.curLine++; if (restart) &#123; // 如果是重启（出现错误之后），则从 chunk 记录行开始读取 reader.setLinesToSkip(this.curLine.intValue() - 1); // 将重启值置为 false，否则将会重复读取 restart = false; System.out.println("Start reading from line: " + this.curLine); &#125; reader.open(this.executionContext); city = reader.read();// 模拟出现错误：读到第 100 行数据时出错// if (city != null &amp;&amp; this.curLine == 100) &#123;// throw new RuntimeException("Something Wrong!");// &#125; return city; &#125; /** * 在开始读取之前调用 */ @Override public void open(ExecutionContext executionContext) throws ItemStreamException &#123; // 获取当前执行上下文 this.executionContext = executionContext; if (executionContext.containsKey("curLine")) &#123; // 如果执行上下文存在 cutLine，则证明执行为 重启后执行 this.curLine = executionContext.getLong("curLine"); // 将重启值置为 true this.restart = true; &#125; else &#123; // 第一次执行，向执行上下文中打入 curLine 记录（会记录进数据库） this.curLine = 0L; executionContext.put("curLine", 0L); System.out.println("Start reading from line: " + (this.curLine + 1)); &#125; &#125; /** * 在每次读取 chunk 条数据后调用 */ @Override public void update(ExecutionContext executionContext) throws ItemStreamException &#123; // 每次 chunk 后，重新打入 curLine 为当前行（会记录进数据库） executionContext.put("curLine", this.curLine); System.out.println("Reading line: " + (this.curLine + 1)); &#125; @Override public void close() throws ItemStreamException &#123; &#125;&#125; 错误重试 在 读、处理、写 操作中任何一环出现问题都可以重新执行出现错误的 chunk 代码示例模拟在 Processor 中出现错误123456789101112131415161718192021@Componentpublic class RetryProcessor implements ItemProcessor&lt;String, String&gt; &#123; private int attemptCount = 0; @Override public String process(String item) throws Exception &#123; System.out.println("processing item :" + item); // 模拟错误：如果需要处理的数据为字符串 26，判断重试次数，如果重试次数大于等于 3 次，则数据处理成功，否则抛出异常，处理处理失败 if ("26".equalsIgnoreCase(item)) &#123; attemptCount++; if (attemptCount &gt;= 3) &#123; System.out.println("Retried " + attemptCount + "times success"); return String.valueOf(Integer.valueOf(item) * -1); &#125; System.out.println("Processed the " + attemptCount + " times fail"); throw new RuntimeException("Process failed. Attempt: " + attemptCount); &#125; return String.valueOf(Integer.valueOf(item) * -1); &#125;&#125; 在 Step 中进行错误重试操作1234567891011121314151617181920212223242526@Bean@StepScopepublic ListItemReader&lt;String&gt; reader()&#123; List&lt;String&gt; items = new ArrayList&lt;&gt;(); for (int index = 0; index&lt; 60; index++)&#123; items.add(""+index); &#125; return new ListItemReader&lt;&gt;(items);&#125;@Beanpublic Step retryDemoStep()&#123; return stepBuilderFactory.get("retryDemoStep") .&lt;String, String&gt;chunk(10) .reader(reader()) .processor(retryItemProcessor) .writer(retryItemWriter) // 容错 .faultTolerant() // 发生哪个异常时进行重试 .retry(RuntimeException.class) // 重试几次 .retryLimit(10) .build();&#125; 在此时，运行程序后，会发现控制台打印 0-20，30-60 都正常，但是在带引 20 - 30 的数据时，由于在 26 处出现了错误，会多次打印 20-25，和错误信息：”Processed the “ + attemptCount + “ times fail” 由此可证明错误重试 成功 错误跳过 在 读、处理、写 操作中任何一环出现问题都可以重新执行出现错误的 chunk 代码示例出现的错误还是以上例中的错误为本例错误 123456789101112131415@Beanpublic Step skipDemoStep()&#123; return stepBuilderFactory.get("skipDemoStep") .&lt;String, String&gt;chunk(10) .reader(reader()) .processor(retryItemProcessor) .writer(retryItemWriter) // 容错 .faultTolerant() // 跳过 .skip(RuntimeException.class) // 跳过次数 .skipLimit(10) .build();&#125; 此时运行代码，可以发现，当 26 错误错误时，processor 自动略过，在 ItemWriter 中并没有打印信息，控制台打印信息为： … 23 24 25 27 29 … 由此可看出 26 被成功跳过，则错误跳过成功 错误处理监听器错误处理监听器：可以在执行批处理时，在出现错误的地方通过监听器，监听错误信息，如：read error、write error、processor error 常见的错误处理监听器 SkipListener：错误跳过监听 RetryListener：错误重试监听，该 listener 本身不提供操作，由以下几个子 Listener 提供操作 RetryProcessListener：processor error 消息监听 RetryWriteListener：write error 消息监听 RetryReadListener：read error 消息监听 代码示例出现错误的方式还是以上例中的 字符串 26 错误为例 以 SkipListener 为例 1234567891011121314151617181920212223242526272829303132@Componentpublic class MySkipListener implements SkipListener&lt;String, String&gt; &#123; /** * 读取跳过 * @param throwable 发生的异常 */ @Override public void onSkipInRead(Throwable throwable) &#123; &#125; /** * 写入错误 * @param s 写入的数据 * @param throwable 发生的异常 */ @Override public void onSkipInWrite(String s, Throwable throwable) &#123; &#125; /** * 在处理流程中出现的异常 * @param s 出现异常的数据 * @param throwable 出现的异常 */ @Override public void onSkipInProcess(String s, Throwable throwable) &#123; System.out.println(s + " ----&gt; " + throwable.getLocalizedMessage()); &#125;&#125; Listener 使用：1234567891011121314@Beanpublic Step skipListenerStep()&#123; return stepBuilderFactory.get("skipListenerStep") .&lt;String, String&gt;chunk(10) .reader(reader()) .writer(skipItemWriter) .processor(skipItemProcessor) .faultTolerant() .skip(RuntimeException.class) // 指定错误处理 Listener .listener(skipListener) .skipLimit(10) .build();&#125;]]></content>
      <categories>
        <category>spring-batch</category>
      </categories>
      <tags>
        <tag>SpringBatch</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring Batch 学习（6） ItemWriter]]></title>
    <url>%2Fspring-batch%2Fspring-batch-study-6.html</url>
    <content type="text"><![CDATA[ItemWriterItemWriter：批处理之后的数据需要做怎样的写操作（写入文件、数据库、mongodb等） 常用的几个 ItemWriter JdbcItemWriter：使用 jdbc 写入数据库 HibernateWriter：使用 Hibernate 写入数据库 JpaItemWriter：使用 JPA 写入数据库 JsonFileItemWriter：将数据转为 JSON 写入文本文件 FlatFileItemWriter：将数据转为合适格式的字符串，写入文本文件 StaxEventItemWriter：将数据通过 oxm 框架的 XStream 写入 xml 文件 CompositeItemWriter：写入多个文件 ClassifierCompositeItemWriter：文件分类写入 …. ItemWriter 简单示例（控制台打印数据）123456789public class MyWriter implements ItemWriter&lt;String&gt; &#123; @Override public void write(List&lt;? extends String&gt; list) throws Exception &#123; // 打印数据长度 System.out.println(list.size()); // 遍历打印信息 list.stream().forEach(System.out::println); &#125;&#125; FlatFileItemWriterFlatFileItemWriter：将数据转为一定格式的字符串，将转换后的字符串写入文本文件中 代码示例使用 Jackson，将数据实体转为 Json 字符串，写入文本（数据来源：1234567891011121314151617181920212223@Beanpublic FlatFileItemWriter&lt;City&gt; cityItemWriter()&#123; FlatFileItemWriter&lt;City&gt; writer = new FlatFileItemWriter&lt;&gt;(); String path = "d:\\city.txt"; writer.setResource(new FileSystemResource(path)); writer.setLineAggregator(new LineAggregator&lt;City&gt;() &#123; @Override public String aggregate(City city) &#123; try &#123; return new ObjectMapper().writeValueAsString(city); &#125; catch (JsonProcessingException e) &#123; e.printStackTrace(); &#125; return ""; &#125; &#125;); try &#123; writer.afterPropertiesSet(); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; return writer;&#125; StaxEventItemWriterStaxEventItemWriter 结合 oxm 框架的 XStream，可以将数据转换位 xml 文件输出 代码示例12345678910111213141516171819202122232425262728@Beanpublic StaxEventItemWriter&lt;City&gt; xmlItemWriter()&#123; StaxEventItemWriter&lt;City&gt; writer = new StaxEventItemWriter&lt;&gt;(); // xml 处理器 XStreamMarshaller marshaller = new XStreamMarshaller(); // 指定根节点 Map&lt;String, Class&gt; aliases = new HashMap&lt;&gt;(1); aliases.put("city", City.class); marshaller.setAliases(aliases); // setMarshaller：写为 xml，setUnMarshaller：读 xml writer.setMarshaller(marshaller); // 文件路径 String path = "d:\\city.xml"; writer.setResource(new FileSystemResource(path)); try &#123; // 参数校验 writer.afterPropertiesSet(); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; return writer;&#125; CompositeItemWriter、ClassifierCompositeItemWriterCompositeItemWriter 可以将多个文本文件的写入方式结合在一起，实现写入多个文件的操作ClassifierCompositeItemWriter 可以自定义数据分类 代码示例1、写入多个文件1234567891011/** * 实现数据写入到多个文件 */@Beanpublic CompositeItemWriter&lt;City&gt; multiFileWriter() throws Exception &#123; CompositeItemWriter&lt;City&gt; writer = new CompositeItemWriter&lt;&gt;(); writer.setDelegates(Arrays.asList(cityItemWriter(), xmlItemWriter())); writer.afterPropertiesSet(); return writer;&#125; 2、文件分类1234567891011121314151617@Beanpublic ClassifierCompositeItemWriter&lt;City&gt; multiFileWriter() &#123; ClassifierCompositeItemWriter&lt;City&gt; writer = new ClassifierCompositeItemWriter&lt;&gt;(); writer.setClassifier(new Classifier&lt;City, ItemWriter&lt;? super City&gt;&gt;() &#123; @Override public ItemWriter&lt;? super City&gt; classify(City city) &#123; // 按照 City 的 id 进行分类 if (city.getId() % 2 == 0)&#123; return cityItemWriter(); &#125; else &#123; return xmlItemWriter(); &#125; &#125; &#125;); return writer;&#125; 多文件、分类写入注意点 在进行多文件写入时，需要将 ItemWriter 转为 ItemStreamWriter ：即 在注入时，由注入 ItemWriter 改为 ItemStreamWriter，然后将注入的 ItemWriter 放入 stream 中 示例：123456789101112131415161718@Autowiredprivate ItemStreamWriter&lt;City&gt; xmlItemWriter;@Autowiredprivate final ItemStreamWriter&lt;City&gt; cityItemWriter;@Beanpublic Step multiFileItemWriterStep()&#123; return stepBuilderFactory.get("multiFileItemWriterStep2") .&lt;City, City&gt;chunk(10) .reader(multiFileReader) .writer(multiFileWriter) // 将 ItemWriter 放入 stream .stream(xmlItemWriter) .stream(cityItemWriter) .build();&#125; JdbcBatchItemWriterJdbcBatchItemWriter 使用 jdbc 将数据批量写入数据库 代码示例123456789@Beanpublic JdbcBatchItemWriter&lt;City&gt; flatFileItemWriter()&#123; JdbcBatchItemWriter&lt;City&gt; writer = new JdbcBatchItemWriter&lt;&gt;(); writer.setDataSource(dataSource); writer.setSql("INSERT INTO t_city( id, name, countryCode, district, population) VALUES (:id, :name, :countryCode, :district, :population)"); // 使用实体属性自动映射到占位符 writer.setItemSqlParameterSourceProvider(new BeanPropertyItemSqlParameterSourceProvider&lt;&gt;()); return writer;&#125; ProcessorProcessor 是在 ItemReader 到 ItemWriter 之间的一个数据转换操作，如将需要处理的数字转换为字符串等操作 ItemProcessor&lt;T, O&gt;，其中： T 代表输入类型，即 ItemReader 的泛型，O 代表输出类型，即 ItemWriter 的类型 代码示例12345678910111213141516171819202122// 输入类型为 City，输出类型为 City，转换操作为：将城市名称转为大写。public class NameLowerProcessor implements ItemProcessor&lt;City, City&gt; &#123; @Override public City process(City city) throws Exception &#123; String name = city.getName().toUpperCase(); city.setName(name); return city; &#125;&#125;// 输入类型为 City，输出类型为 City，转换操作为：如果城市 id 可以被 2 整除，则继续执行，否则跳过public class IdFilterProcessor implements ItemProcessor&lt;City, City&gt; &#123; @Override public City process(City city) throws Exception &#123; if (city.getId() %2 == 0)&#123; return city; &#125; // 如果返回 null，相当于把对象过滤掉 return null; &#125;&#125; ItemProcessor 使用ItemProcessor 使用在 Step 域中，尽量书写在 Reader、Writer 中间 CompositeItemProcessor：关联多个 Processor 代码示例12345678910111213141516171819202122@Beanpublic CompositeItemProcessor&lt;City, City&gt; processListener() &#123; CompositeItemProcessor&lt;City, City&gt; processor = new CompositeItemProcessor&lt;&gt;(); List&lt;ItemProcessor&lt;City, City&gt;&gt; list = new ArrayList&lt;&gt;(2); list.add(nameLowerProcessor); list.add(idFiltterProcessor); // 关联多个 Processor processor.setDelegates(list); return processor;&#125;@Beanpublic Step itemProcessorStep() &#123; return stepBuilderFactory.get("itemProcessorStep2") .&lt;City, City&gt;chunk(10) .reader(multiFileReader) // 增加 Processor .processor(processListener()) .writer(cityItemWriter) .build();&#125;]]></content>
      <categories>
        <category>spring-batch</category>
      </categories>
      <tags>
        <tag>SpringBatch</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring Batch 学习（5） ItemReader]]></title>
    <url>%2Fspring-batch%2Fspring-batch-study-5.html</url>
    <content type="text"><![CDATA[ItemReaderItemReader 可以理解为：在批处理中，需要处理的数据。这些数据通常是在 文本文件， xml 文件， 数据库 中存储。在进行批处理的时候，需要从文件中获取数据。可以说，ItemReader 是整个批处理的入口。 几个常用的 ItemReader ListItemReader：从集合中获取数据 FlatFileItemReader：从文本文件中获取数据 MultiResourceItemReader：从多个文件中获取数据 StaxEventItemReader：从 xml 文件中获取数据 AbstractPagingItemReader：从数据库中获取数据： JdbcPagingItemReader：使用基础的 jdbc 获取数据 HibernatePagingItemReader：使用 Hibernate 获取数据 JpaPagingItemReader：使用 JPA 获取数据 ListItemReaderListItemReader：声明一个集合作为数据的输入，通常用于数据量较小，内存可以处理的批处理操作；数据量过大的话，放入 ListItemReader 中可能造成内存溢出。 示例：1234@Beanpublic ItemReader&lt;String&gt; itemReader()&#123; return new ListItemReader&lt;&gt;(Arrays.asList("Java", "Python", "Swift", "MyBatis"));&#125; FlatFileItemReaderFlatFileItemReader：从文本文件中获取数据，这个文本文件可以是 txt、csv 等纯文本文件。DelimitedLineTokenizer：配置数据解析方式。默认以英文逗号为数据分隔符。 示例文本数据(任意增加，但需要保持格式)：12327,2018-01-28 11:09:26,测试数据1,4500000001,1,1,1,laiyy,1,4500000001021540518164563728,2018-01-27 01:48:45,测试数据2,4500000001,1,2,1,laiyy,1,4500000001021540518164574429,2018-01-27 01:48:51,测试数据3,4500000001,1,3,1,laiyy,1,45000000010215405181645843 声明一个实体作为每一行文本数据的映射关系：1234567891011121314public class Template &#123; private int id; private String date; private String name; private String siteId; private int status; private int type; private int userId; private String username; private int share; private String markId; // 省略 get、set&#125; 使用 FlatFileItemReader 读取数据1234567891011121314151617181920212223242526272829303132333435363738394041@Bean@StepScopepublic FlatFileItemReader&lt;Template&gt; flatFileReader() &#123; FlatFileItemReader&lt;Template&gt; reader = new FlatFileItemReader&lt;&gt;(); reader.setResource(new ClassPathResource("data.txt")); // 跳过第几行 reader.setLinesToSkip(0); // 声明数据解析 DelimitedLineTokenizer tokenizer = new DelimitedLineTokenizer(); // 声明数据分隔符，默认为英文逗号，如果使用其他分隔符需要重新设置 // tokenizer.setDelimiter(","); // 声明每一行分隔符分隔的每个数据代表实体的哪个字段--需要与实体字段名一致 tokenizer.setNames("id", "date", "name", "siteId", "status", "type", "userId", "username", "share", "markId"); // 解析后的数据映射为对象 DefaultLineMapper&lt;Template&gt; mapper = new DefaultLineMapper&lt;&gt;(); mapper.setLineTokenizer(tokenizer); mapper.setFieldSetMapper(new FieldSetMapper&lt;Template&gt;() &#123; @Override public Template mapFieldSet(FieldSet fieldSet) throws BindException &#123; Template template = new Template(); // 数据映射 template.setId(fieldSet.readInt("id")); template.setDate(fieldSet.readString("date")); template.setName(fieldSet.readString("name")); template.setSiteId(fieldSet.readString("siteId")); template.setStatus(fieldSet.readInt("status")); template.setType(fieldSet.readInt("type")); template.setUserId(fieldSet.readInt("userId")); template.setUsername(fieldSet.readString("username")); template.setShare(fieldSet.readInt("share")); template.setMarkId(fieldSet.readString("markId")); return template; &#125; &#125;); // 数据校验 mapper.afterPropertiesSet(); // 绑定映射 reader.setLineMapper(mapper); return reader;&#125; StaxEventItemReaderStaxEventItemReader：用于从 xml 文件中读取数据，常常和 spring-oxm 结合使用，极大提高效率 代码示例需要读取的 xml 数据 123456789101112131415161718192021222324252627&lt;?xml version="1.0" standalone="yes"?&gt;&lt;RECORDS&gt; &lt;RECORD&gt; &lt;id&gt;20&lt;/id&gt; &lt;createDate&gt;2018/5/10 16:23:09&lt;/createDate&gt; &lt;createUserId&gt;34&lt;/createUserId&gt; &lt;label&gt;标签1&lt;/label&gt; &lt;siteId&gt;4500000001&lt;/siteId&gt; &lt;status&gt;0&lt;/status&gt; &lt;type&gt;8&lt;/type&gt; &lt;username&gt;张三&lt;/username&gt; &lt;seq&gt;20&lt;/seq&gt; &lt;userId&gt;0&lt;/userId&gt; &lt;/RECORD&gt; &lt;RECORD&gt; &lt;id&gt;21&lt;/id&gt; &lt;createDate&gt;2018/5/10 16:24:02&lt;/createDate&gt; &lt;createUserId&gt;34&lt;/createUserId&gt; &lt;label&gt;标签2&lt;/label&gt; &lt;siteId&gt;4500000001&lt;/siteId&gt; &lt;status&gt;1&lt;/status&gt; &lt;type&gt;8&lt;/type&gt; &lt;username&gt;李四&lt;/username&gt; &lt;seq&gt;22&lt;/seq&gt; &lt;userId&gt;0&lt;/userId&gt; &lt;/RECORD&gt;&lt;/RECORDS&gt; 1234567891011121314151617181920212223242526272829303132333435363738394041// 数据实体public class Label &#123; private int id; private String label = ""; private int type; private String labelType = ""; private int userId; private int createUserId; private String createDate; private String username = ""; private int status = 1; private String siteId = ""; private int seq; // 省略 get、set&#125;// 数据读取@Bean@StepScopepublic StaxEventItemReader&lt;Label&gt; xmlFileReader()&#123; StaxEventItemReader&lt;Label&gt; reader = new StaxEventItemReader&lt;&gt;(); // 要读取的文件 reader.setResource(new ClassPathResource("label.xml")); // 指定需要处理的根标签 reader.setFragmentRootElementName("RECORD"); // 把读取到的 xml 格式转为 Label XStreamMarshaller unmarshaller = new XStreamMarshaller(); // 设置要读取的 xml 根节点 --- Map&lt;String, Class&gt; map = new HashMap&lt;&gt;(1); map.put("RECORD", Label.class); unmarshaller.setAliases(map); // marshaller ：写 xml // unmarshaller： 读 xml reader.setUnmarshaller(unmarshaller); return reader;&#125; MultiResourceItemReaderMultiResourceItemReader：可以包含多个 ResourceAwareItemReaderItemStream 的子类、实现类 所构建的文件读取 ItemReader，由此可以一次性读取多个文件。 ResourceAwareItemReaderItemStream 的几个常用实现类： FlatFileItemReader：上一例中的文本文件读取 JsonItemReader：从 json 文件中获取数据 StaxEventItemReader：从 xml 文件中获取数据 代码示例FlatFileItemWriter 数据来源：1234&quot;1&quot;,&quot;Kabul&quot;,&quot;AFG&quot;,&quot;Kabol&quot;,&quot;1780000&quot;&quot;2&quot;,&quot;Qandahar&quot;,&quot;AFG&quot;,&quot;Qandahar&quot;,&quot;237500&quot;&quot;3&quot;,&quot;Herat&quot;,&quot;AFG&quot;,&quot;Herat&quot;,&quot;186800&quot;... 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647/** 声明一个 txt 文件读取*/@Bean@StepScopepublic FlatFileItemReader&lt;City&gt; flatFileReader() &#123; FlatFileItemReader&lt;City&gt; reader = new FlatFileItemReader&lt;&gt;(); // 解析数据 DelimitedLineTokenizer tokenizer = new DelimitedLineTokenizer(); tokenizer.setNames("id", "name", "countryCode", "district", "population"); // 解析后的数据映射为对象 DefaultLineMapper&lt;City&gt; mapper = new DefaultLineMapper&lt;&gt;(); mapper.setLineTokenizer(tokenizer); mapper.setFieldSetMapper(new FieldSetMapper&lt;City&gt;() &#123; @Override public City mapFieldSet(FieldSet fieldSet) throws BindException &#123; City city = new City(); city.setCountryCode(fieldSet.readString("countryCode")); city.setDistrict(fieldSet.readString("district")); city.setId(fieldSet.readInt("id")); city.setName(fieldSet.readString("name")); city.setPopulation(fieldSet.readLong("population")); return city; &#125; &#125;); // 数据校验 mapper.afterPropertiesSet(); // 绑定映射 reader.setLineMapper(mapper); return reader;&#125;// 引入 classpath下的所有以 file 开头的 txt 文件@Value("classpath:file*.txt")private Resource[] fileResources;@Bean@StepScopepublic MultiResourceItemReader&lt;City&gt; multiFileReader() &#123; MultiResourceItemReader&lt;City&gt; reader = new MultiResourceItemReader&lt;&gt;(); // 文件读取 reader.setDelegate(flatFileReader()); // 将所有文件放入 resources 中，即可实现多文件读取 reader.setResources(fileResources); return reader;&#125; AbstractPagingItemReader所有从数据库中分页读取数据的 主抽象类 ，用于定义分页结构、分页参数等 JdbcPagingItemReader以 jdbc 方式分页读取数据（最原生，但是不能自动映射字段，需要自定义） 代码示例12345678910111213141516171819202122232425262728293031323334353637/*** 注解 @StepScope 表示，该数据只在 Step 执行* JdbcPagingItemReader 从 jdbc 中，使用分页获取数据*/@Bean@StepScopepublic JdbcPagingItemReader&lt;User&gt; userItemReader()&#123; JdbcPagingItemReader&lt;User&gt; reader = new JdbcPagingItemReader&lt;&gt;(); reader.setDataSource(dataSource); reader.setFetchSize(2); // 把读取到的记录转换为 User 对象 reader.setRowMapper(new RowMapper&lt;User&gt;() &#123; @Override public User mapRow(ResultSet resultSet, int rowNum) throws SQLException &#123; User user = new User(); user.setId(resultSet.getInt("id")); user.setUsername(resultSet.getString("username")); user.setPassword(resultSet.getString("password")); user.setAge(resultSet.getInt("age")); return user; &#125; &#125;); // 指定 SQL 语句 MySqlPagingQueryProvider provider = new MySqlPagingQueryProvider(); // 查询哪些字段 provider.setSelectClause("id, username, password, age"); // 查询哪个表 provider.setFromClause("from t_user"); // 根据那个字段进行排序 Map&lt;String, Order&gt; sortMap = new HashMap&lt;&gt;(2); sortMap.put("id", Order.ASCENDING); sortMap.put("username", Order.DESCENDING); provider.setSortKeys(sortMap); reader.setQueryProvider(provider); return reader;&#125; HibernatePagingItemReader以 Hibernate 方式分页读取数据（可根据 Hibernate 注解自动映射字段） 代码示例123456789101112131415161718192021222324252627282930313233343536/*** HibernatePagingItemReader 实现*/@Bean@StepScopepublic ItemReader&lt;News&gt; hibernatePagingItemReader() &#123;HibernatePagingItemReader&lt;News&gt; reader = new HibernatePagingItemReader&lt;&gt;(); // 每页查询多少条 reader.setPageSize(500); reader.setSessionFactory(sessionFactory); HibernateNativeQueryProvider&lt;News&gt; provider = new HibernateNativeQueryProvider&lt;&gt;(); // 自动映射解析到哪个实体（该实体需要 @Entity 注解） provider.setEntityClass(News.class); String siteId = parameterMap.get("4500000001").toString(); int channelId = Integer.valueOf(parameterMap.get("2016").toString()); StringBuilder sql = new StringBuilder("SELECT * FROM zw_news where site_id ="); sql.append(siteId); if (channelId != 0) &#123; sql.append(" and channel_id = ").append(channelId); &#125; sql.append(" and status = 150 and del_status != 500"); sql.append(" order by news_weight desc, seq desc, pub_date desc, id desc "); provider.setSqlQuery(sql.toString()); try &#123; // 参数校验 provider.afterPropertiesSet(); &#125; catch (Exception e) &#123; e.printStackTrace(); throw new RuntimeException("获取 Hibernate 数据失败"); &#125; reader.setQueryProvider(provider); // 可有可无 reader.setQueryName(" News"); reader.setUseStatelessSession(true); return reader;&#125;]]></content>
      <categories>
        <category>spring-batch</category>
      </categories>
      <tags>
        <tag>SpringBatch</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring Batch 学习（4） Step 的另一种方式、Listener]]></title>
    <url>%2Fspring-batch%2Fspring-batch-study-4.html</url>
    <content type="text"><![CDATA[创建步骤的另外一种方式ItemReader 可以理解为：数据获取。在 Step 中除了可以使用 Tasklet 创建简单的步骤，也可以使用 chunk + itemReader + itemWriter 创建一个复杂的步骤。其中： chunk 表示每几条数据进行一次批量处理 itemReader 表示批量获取的数据怎么获取 itemWriter 表示 chunk 中的数据进行怎样的输出（到文件、数据库或其他） 在使用这种方式创建步骤的时候，需要注意以下几点： chunk 需要指定：输入类型，输出类型、每多少条处理一次，如： &lt;String, String&gt;chunk(10); 表示 ItemReader 的输入类型为 String，ItemWriter 的输出类型为 String，每 10 条处理一次 ItemReader 需要指定输入类型，如：ItemReader，指明获取到的数据为 String 类型 ItemWriter 需要指定输出类型，如：ItemWriter，指明输出（到文件、数据库或其他）的类型为 String 类型 创建一个 String 集合类型的 ItemReader，并进行输出1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859/*** @author laiyy* @date 2018/11/16 9:37* @description*/@Configurationpublic class ItemReaderDemo &#123; private final JobBuilderFactory jobBuilderFactory; private final StepBuilderFactory stepBuilderFactory; @Autowired public ItemReaderDemo(JobBuilderFactory jobBuilderFactory, StepBuilderFactory stepBuilderFactory) &#123; this.jobBuilderFactory = jobBuilderFactory; this.stepBuilderFactory = stepBuilderFactory; &#125; @Bean public Job itemReaderDemoJob() &#123; return jobBuilderFactory.get("itemReaderDemoJob") .start(itemReaderDemoStep()) .build(); &#125; @Bean public Step itemReaderDemoStep()&#123; return stepBuilderFactory.get("itemReaderDemoStep") // 指定数据输入为 String，数据输出为 String，每 2 条执行一次 .&lt;String, String&gt;chunk(2) // 指定数据来源 itemReader .reader(myStringItemReader()) // 指定数据数据为打印数据 .writer( list -&gt; &#123; list.forEach(System.err::println); &#125;) .build(); &#125; /** * 声明一个 String 集合，作为数据的输入 */ @Bean public MyStringItemReader myStringItemReader()&#123; List&lt;String&gt; data = Arrays.asList("Cat", "Dog", "Pig", "Duck"); return new MyStringItemReader(data); &#125;&#125;public class MyStringItemReader implements ItemReader&lt;String&gt; &#123; private Iterator&lt;String&gt; iterator; public MyStringItemReader(List&lt;String&gt; data) &#123; this.iterator = data.iterator(); &#125; @Override public String read() throws Exception, UnexpectedInputException, ParseException, NonTransientResourceException &#123; // 一个数据一个数据的读 if (iterator.hasNext()) &#123; return iterator.next(); &#125; return null; &#125;&#125; Listener几个常用的 Listener在上一篇博客中提到了 StepExecutionListener，这个 Listener 可以在 Step 执行前后获取执行上下文。除此之外还有几个比较常用的 Listener： JobExecutionListener：在 Job 执行前后获取执行上下文 ChunkListener：在 chunk 执行前后获取执行上下文 ItemReadListener：在 ItemReader 执行前后获取执行上下文 ItemWriterListener：在 ItemWriter 执行前后获取执行上下文 ItemProcessListener：在 Processor 执行前后获取执行上下文（数据处理器） 在这些 Listener 中，都有 before、after 方法，便于在执行前后获取信息，在实现这些接口，并生成为 Spring bean 后，在需要的地方引入即可。 比较特殊的几个 Listener 方法： ChunkListsner：afterChunkError，在 chunk 发生错误时调用 ItemReaderListener：onReadError，在 itemReader 发生错误时调用 ItemWriterListener：onWriteError，在 ItemWriter 发生错误时调用 ItemProcessListener：onProcessError，在处理器发生错误时调用 另外一种 Listener 实现方式除了上述实现 xxListener 接口创建 Listener 之外，还有一种更为简单的方式实现 Listener：注解 实现 StepExecutionListener 可以使用： @BeforeStep、@AfterStep 实现 JobExecutionListener 可以使用：@BeforeJob、@AfterJob … 在这些注解中也有对应 Listener 特殊方法的注解：@AfterChunkError、@OnReadError、@OnWriteError、@OnProcessError 代码示例实现接口方式创建 Listener123456789101112131415161718192021/** * @author laiyy * @date 2018/11/15 17:27 * @description * * 接口实现监听 * */public class MyJobListener implements JobExecutionListener &#123; @Override public void beforeJob(JobExecution jobExecution) &#123; // 在 job 执行之前执行 System.out.println("Job 执行之前，Job 名称：" + jobExecution.getJobInstance().getJobName()); &#125; @Override public void afterJob(JobExecution jobExecution) &#123; // 在 job 执行之后执行 System.out.println("Job 执行之后，Job 名称：" + jobExecution.getJobInstance().getJobName()); &#125;&#125; 注解方式创建 Listener12345678910111213public class MyChunkListener &#123; @BeforeChunk public void before(ChunkContext chunkContext)&#123; System.out.println("Step 执行之前，Step 名称：" + chunkContext.getStepContext().getStepName()); &#125; @AfterChunk public void after(ChunkContext chunkContext)&#123; System.out.println("Step 执行之后，Step 名称：" + chunkContext.getStepContext().getStepName()); &#125;&#125; 使用方式123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172/** * @author laiyy * @date 2018/11/15 17:30 * @description * * 执行结果 * Job 执行之前，Job 名称：listenerJob * Step 执行之前，Step 名称：listenerStep1 * （Chunk 设置为2，所以一次拿 2 个数据） * Java * Python * Step 执行之后，Step 名称：listenerStep1 * Step 执行之前，Step 名称：listenerStep1 * （两条数据取出来后，step 执行结束，开始获取下一个两条信息） * Swift * MyBatis * Step 执行之后，Step 名称：listenerStep1 * Step 执行之前，Step 名称：listenerStep1 * （数据全部取出执行结束） * Step 执行之后，Step 名称：listenerStep1 * Job 执行之后，Job 名称：listenerJob * */@Configurationpublic class ListenerDemo &#123; private final JobBuilderFactory jobBuilderFactory; private final StepBuilderFactory stepBuilderFactory; @Autowired public ListenerDemo(JobBuilderFactory jobBuilderFactory, StepBuilderFactory stepBuilderFactory) &#123; this.jobBuilderFactory = jobBuilderFactory; this.stepBuilderFactory = stepBuilderFactory; &#125; @Bean public Job listenerJob()&#123; return jobBuilderFactory.get("listenerJob") .start(listenerStep1()) // 以创建对象方式引入 JobListener，也可以注入 .listener(new MyJobListener()) .build(); &#125; @Bean public Step listenerStep1() &#123; return stepBuilderFactory.get("listenerStep1") // 以 Chunk 方式设置为每读取 2 个数据做一次相应的处理 // read、process、write；&lt;String, String&gt; 读取为 String，输出为 String .&lt;String, String&gt;chunk(2) // 容错 .faultTolerant() // 以创建对象方式引入 chunkListener，也可以注入。 // 设置 Chunk 监听 .listener(new MyChunkListener()) // 读取数据 .reader(itemReader()) // 输出数据 .writer(itemWriter()) .build(); &#125; @Bean public ItemWriter&lt;String&gt; itemWriter()&#123; return new ItemWriter&lt;String&gt;() &#123; @Override public void write(List&lt;? extends String&gt; items) throws Exception &#123; items.forEach(System.err::println); &#125; &#125;; &#125; @Bean public ItemReader&lt;String&gt; itemReader()&#123; return new ListItemReader&lt;&gt;(Arrays.asList("Java", "Python", "Swift", "MyBatis")); &#125;&#125;]]></content>
      <categories>
        <category>spring-batch</category>
      </categories>
      <tags>
        <tag>SpringBatch</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring Batch 学习（3） 决策器、JobParameters、Step 监听器]]></title>
    <url>%2Fspring-batch%2Fspring-batch-study-3.html</url>
    <content type="text"><![CDATA[决策器一些业务比较复杂的批处理操作中，可能会存在如下的需求：如在 微博抽奖 中，进行批量处理挑选中间人的时候，需要根据 活跃度，发帖量，粉丝数 的不同，进行不同筛选操作。这时就需要一个 决策器 ，决策器的作用：根据不同的条件，返回不同的状态码（自定义状态码），根据状态码的不同，选择不同的步骤进行批量处理操作。 代码示例自定义一个决策器自定义一个决策器，当输入值为 奇数 的时候，返回 “odd”，当输入值为 偶数 的时候，返回 “even” 12345678910111213141516171819202122232425/*** @author laiyy* @date 2018/11/15 16:23* @description** 自实现的决策器*/public class MyDecider implements JobExecutionDecider &#123; // 总处理条数 private int count; @Override public FlowExecutionStatus decide(JobExecution jobExecution, StepExecution stepExecution) &#123; // 每次进入决策器，则处理条数加 1 count++; if (count % 2 == 0) &#123; // 如果总条数能被 2 整除，返回 even return new FlowExecutionStatus("even"); &#125;else &#123; // 否则返回 odd return new FlowExecutionStatus("odd"); &#125; &#125;&#125; 使用自定义的决策器，进行步骤选择12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273/** * @author laiyy * @date 2018/11/15 16:10 * @description */@Configuration@EnableBatchProcessingpublic class DeciderDemo &#123; private final JobBuilderFactory jobBuilderFactory; private final StepBuilderFactory stepBuilderFactory; @Autowired public DeciderDemo(JobBuilderFactory jobBuilderFactory, StepBuilderFactory stepBuilderFactory) &#123; this.jobBuilderFactory = jobBuilderFactory; this.stepBuilderFactory = stepBuilderFactory; &#125; /** * 创建任务2 */ @Bean public Job deciderDemoJob()&#123; return jobBuilderFactory.get("deciderDemoJob") .start(deciderDemoStep1()) .next(myDecider()) // 如果决策器返回的是 even，进入 step2 .from(myDecider()).on("even").to(deciderDemoStep2()) // 如果决策器返回的是 odd，进入 step3 .from(myDecider()).on("odd").to(deciderDemoStep3()) // 由于先执行的是 step3，那么无论决策器返回值是什么都重新进入决策器，即：进入 next(myDecider())，这时会进入 step2 执行。 // 如果不加这句，则只会执行 step3，不会执行 step2 .from(deciderDemoStep3()).on("*").to(myDecider()) .end().build(); &#125; /** * 决策器 */ @Bean public JobExecutionDecider myDecider()&#123; return new MyDecider(); &#125; @Bean public Step deciderDemoStep3() &#123; return stepBuilderFactory.get("deciderDemoStep3") .tasklet(new Tasklet() &#123; @Override public RepeatStatus execute(StepContribution stepContribution, ChunkContext chunkContext) throws Exception &#123; System.out.println("odd"); return RepeatStatus.FINISHED; &#125; &#125;).build(); &#125; @Bean public Step deciderDemoStep2() &#123; return stepBuilderFactory.get("deciderDemoStep2") .tasklet(new Tasklet() &#123; @Override public RepeatStatus execute(StepContribution stepContribution, ChunkContext chunkContext) throws Exception &#123; System.out.println("even"); return RepeatStatus.FINISHED; &#125; &#125;).build(); &#125; @Bean public Step deciderDemoStep1() &#123; return stepBuilderFactory.get("deciderDemoStep1") .tasklet(new Tasklet() &#123; @Override public RepeatStatus execute(StepContribution stepContribution, ChunkContext chunkContext) throws Exception &#123; System.out.println("deciderDemoStep1"); return RepeatStatus.FINISHED; &#125; &#125;).build(); &#125;&#125; JobParamtersJobParameters，就是Job运行时的参数。它在bath中有两个作用：一是标示不同的 JobInstance 实例，二是作为 job 中用到的信息，以参数的形式传给job。 通常每个 Job 都会有不通的启动方式，或者启动参数等信息，所以一般来说，在一个 Job 中，会公用一个 JobParamters。 一般来说，不会在 Job 中使用 JobParamters，大部分情况下，是在 Job 的执行步骤中使用，即在 Step 中使用 JobParamters。在不同的 Step 中获取需要的 JobParamters，更加便于 Step 的执行（比如需要判断 JobParamerts 的内容是否是正在执行的 Step 所需要的，如果需要就获取执行，如果不需要就略过）。 StepExecutionListener在 Step 中获取 JobParameters，通常使用 StepExecutionListener 监听器。这个监听器的作用是：在某个 Step 中传入监听器，这个监听器就可以获取到这个 Step 的所有上下文信息。在监听器的是实现方法中，进行上下文信息的获取、JobParameters 的获取、Step 执行前后的上下文处理等操作。 StepExecutionListener 需要实现 2 个方法： beforeStep(StepExecution stepExecution)：在 Step 执行前获取 Step 的上下文信息 afterStep(StepExecution stepExecution)：在 Step 执行后获取 Step 的上下文信息 代码示例1234567891011121314151617181920212223242526272829/** * @author laiyy * @date 2018/11/15 17:27 * @description * * 接口实现监听 * */public class MyStepListener implements StepExecutionListener &#123; /** * 存储 Job 的参数 */ private Map&lt;String, JobParameter&gt; parameterMap; @Override public void beforeStep(SteoExecution stepExecution) &#123; // 在 Step 执行之前执行 System.out.println(" 执行之前，Step 名称：" + stepExecution.getStepName()); // 获取 JobParameters parameterMap = stepExecution.getJobParameters().getParameters(); &#125; @Override public void afterStep(StepExecution stepExecution) &#123; // 在 Step 执行之后执行 System.out.println(" 执行之后，Step 名称：" + stepExecution.getStepName()); &#125;&#125; 在 Job 运行期间获取 JobParameters在 Job 运行期间获取 JobParameters，有两种方法： Map&lt;String, JobParameter&gt; 声明为公开静态变量，在 Listener 中使用 声明 Job 的类实现 StepExecutionListener 接口，直接在本类中使用私有变量调用 代码示例（以第二种为例）123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263/** * @author laiyy * @date 2018/11/16 9:22 * @description */@Configurationpublic class ParametersDemo implements StepExecutionListener &#123; private final JobBuilderFactory jobBuilderFactory; private final StepBuilderFactory stepBuilderFactory; /** * 存储 Job 的参数 */ private Map&lt;String, JobParameter&gt; parameterMap; @Autowired public ParametersDemo(JobBuilderFactory jobBuilderFactory, StepBuilderFactory stepBuilderFactory) &#123; this.jobBuilderFactory = jobBuilderFactory; this.stepBuilderFactory = stepBuilderFactory; &#125; @Bean public Job parameterJob()&#123; return jobBuilderFactory.get("parameterJob") .start(parameterStep()) .build(); &#125; /** * Job 执行的是 Step，所以 Job 的参数是在 Step 中使用 * 所以需要给 Step 传递参数即可 * 可以使用监听的方式传递数据：即使用 Step 级别的监听在 Step 执行之前传递数据 */ @Bean public Step parameterStep()&#123; return stepBuilderFactory.get("parameterStep") // 使用 this 关键字，即使用 ParametersDemo 的实例作为 Listener .listener(this) .tasklet(new Tasklet() &#123; @Override public RepeatStatus execute(StepContribution stepContribution, ChunkContext chunkContext) throws Exception &#123; System.out.println("【parameterStep】接收到的参数：" + parameterMap.get("info")); return RepeatStatus.FINISHED; &#125; &#125;).build(); &#125; @Override public void beforeStep(StepExecution stepExecution) &#123; System.out.println("在 Step 执行之前传入参数"); // stepExecution.getJobParameters().getParameters() 是在项目执行时传入的参数，即：项目运行参数 parameterMap = stepExecution.getJobParameters().getParameters(); &#125; @Override public ExitStatus afterStep(StepExecution stepExecution) &#123; System.out.println("在 Step 执行之后处理结果"); return null; &#125;&#125;]]></content>
      <categories>
        <category>spring-batch</category>
      </categories>
      <tags>
        <tag>SpringBatch</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring Batch 学习（2） 多步骤、步骤嵌套、跳步]]></title>
    <url>%2Fspring-batch%2Fspring-batch-study-2.html</url>
    <content type="text"><![CDATA[SpringBatch 一个任务包含 N 个步骤在前一篇博客这种，学习到了 SpringBatch 的一个简单的小示例，这个小示例中只包含了一个 Job 任务，这个 Job 也只包含了一个 Step 步骤。但是有些时候我们需要在一个 Job 中分步骤的处理一些事务，比如：在第一个步骤中需要 计算所有用户的总资产，第二个步骤中需要 计算用户的平均余额，第三个步骤需要 筛选男性用户，第四个步骤…. 这时，就需要在一个 统计任务 中分步骤的获取信息。 代码示例在上一步（启动一个 Step）的基础上，增加第二个步骤12345678910111213141516171819202122232425262728293031323334353637383940414243444546/** * @author laiyy * @date 2018/11/15 16:49 * @description */@Configurationpublic class ChildJob2 &#123; private final JobBuilderFactory jobBuilderFactory; private final StepBuilderFactory stepBuilderFactory; @Autowired public ChildJob2(StepBuilderFactory stepBuilderFactory, JobBuilderFactory jobBuilderFactory) &#123; this.stepBuilderFactory = stepBuilderFactory; this.jobBuilderFactory = jobBuilderFactory; &#125; @Bean public Job childJobTwo()&#123; return jobBuilderFactory.get("childJobTwo") // 启动步骤 childJobStep2 .start(childJobStep2()) // 在 上一步执行完之后，执行 next 方法，调用下一个步骤 .next(childJobStep3()) .build(); &#125; @Bean public Step childJobStep3() &#123; return stepBuilderFactory.get("childJobStep3") .tasklet(new Tasklet() &#123; @Override public RepeatStatus execute(StepContribution stepContribution, ChunkContext chunkContext) throws Exception &#123; System.out.println("childJobStep3"); return RepeatStatus.FINISHED; &#125; &#125;).build(); &#125; @Bean public Step childJobStep2() &#123; return stepBuilderFactory.get("childJobStep2") .tasklet(new Tasklet() &#123; @Override public RepeatStatus execute(StepContribution stepContribution, ChunkContext chunkContext) throws Exception &#123; System.out.println("childJobStep2"); return RepeatStatus.FINISHED; &#125; &#125;).build(); &#125;&#125; 一个步骤里面包含多个子步骤在有些业务场景中，可能出现一个任务有多个步骤，而某些步骤又需要包含多个子步骤，如：12306 订票的时候，启动订票任务，订票任务包含：查询票，订票，付款，出票几个步骤，而在查询票的时候，又包含：总余票查询，起始站与终点站间的余票查询，锁定余票等操作。这时就需要在一个步骤里面包含多个子步骤。 在进行子步骤嵌套的时候需要额外注意 一定要严格审核步骤间的前后关系，防止出现步骤死循环嵌套、前后关系错乱等造成的系统崩溃 SpringBatch 中通过使用 Flow 来管理多个子步骤。Flow 可以算是一个步骤，也可以不算一个步骤。 说它算一个步骤，是因为它可以通过 Job 的 start、next 方法，像一个 Step 一个被调用；说它不算一个步骤，是因为 Flow 只起到包含多个子步骤，并按照 Flow 中规定的顺序执行 Step 的作用。 代码示例1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465/** * @author laiyy * @date 2018/11/15 15:21 * @description */@Configuration@EnableBatchProcessingpublic class FlowDemo &#123; @Autowired private JobBuilderFactory jobBuilderFactory; @Autowired private StepBuilderFactory stepBuilderFactory; @Bean public Job flowDemoJob()&#123; return jobBuilderFactory.get("flowDemoJob") // flow 包含了 step1、step3， 则先执行 step1，再执行 step3, .start(flowDemoFlow()) // 再执行 step2 .next(flowDemoStep2()) .end() .build(); &#125; /** * 一个 Flow 含有多个 Step * 指明 Flow 对象包含哪些 Step */ @Bean public Flow flowDemoFlow()&#123; return new FlowBuilder&lt;Flow&gt;("flowDemoFlow") .start(flowDemoStep1()) .next(flowDemoStep3()) .build(); &#125; @Bean public Step flowDemoStep1()&#123; return stepBuilderFactory.get("flowDemoStep1").tasklet(new Tasklet() &#123; @Override public RepeatStatus execute(StepContribution stepContribution, ChunkContext chunkContext) throws Exception &#123; System.out.println("flowDemoStep1"); return RepeatStatus.FINISHED; &#125; &#125;).build(); &#125; @Bean public Step flowDemoStep2()&#123; return stepBuilderFactory.get("flowDemoStep2").tasklet(new Tasklet() &#123; @Override public RepeatStatus execute(StepContribution stepContribution, ChunkContext chunkContext) throws Exception &#123; System.out.println("flowDemoStep2"); return RepeatStatus.FINISHED; &#125; &#125;).build(); &#125; @Bean public Step flowDemoStep3()&#123; return stepBuilderFactory.get("flowDemoStep1").tasklet(new Tasklet() &#123; @Override public RepeatStatus execute(StepContribution stepContribution, ChunkContext chunkContext) throws Exception &#123; System.out.println("flowDemoStep3"); return RepeatStatus.FINISHED; &#125; &#125;).build(); &#125;&#125; 执行跳步有一些业务场景会有如下需求：前期步骤执行顺序 1-&gt;2-&gt;3-&gt;4-&gt;5，但是在运行一段时间之后，需要调整执行顺序为： 1-&gt;3-&gt;2-&gt;5-&gt;4，即：当执行完第一个步骤后，执行第三个步骤；然后从第三个步骤开始执行，当第三个步骤执行结束后，执行第二个步骤；当第二个步骤执行结束后，执行第五个步骤；当第五个步骤执行结束后，执行第四个步骤；当第四个步骤执行结束后，任务结束。 这时有两种解决办法，最简单的就是重新给 start、next 赋值。另外一种就是：手动设置步骤执行顺序 代码示例123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081/** * @author laiyy * @date 2018/11/15 15:06 * @description */@Configuration@EnableBatchProcessingpublic class JobDemo &#123; // 执行成功后会返回的结果 private static final String COMPLETED = "COMPLETED"; private final JobBuilderFactory jobBuilderFactory; private final StepBuilderFactory stepBuilderFactory; @Autowired public JobDemo(JobBuilderFactory jobBuilderFactory, StepBuilderFactory stepBuilderFactory) &#123; this.jobBuilderFactory = jobBuilderFactory; this.stepBuilderFactory = stepBuilderFactory; &#125; @Bean public Job jobDemoJob() &#123; return jobBuilderFactory.get("jobDemo")// 重新给 start、next 赋值// .start(stepDemo1())// .next(stepDemo2())// .next(stepDemo3())// .next(stepDemo4())// .build();// 手动设置执行顺序 // 从 step1, 开始，当 结束 后，到 step2 .start(stepDemo1()).on(COMPLETED).to(stepDemo2()) // 从 step2 开始，当结束后，到 step3 .from(stepDemo2()).on(COMPLETED).to(stepDemo3()) .from(stepDemo3()).on(COMPLETED).to(stepDemo4()) // 从 step4 开始，到结束 .from(stepDemo4()).end().build(); &#125; @Bean public Step stepDemo4() &#123; return stepBuilderFactory.get("stepDemo4") .tasklet(new Tasklet() &#123; @Override public RepeatStatus execute(StepContribution stepContribution, ChunkContext chunkContext) throws Exception &#123; System.out.println(" stepDemo 4"); return RepeatStatus.FINISHED; &#125; &#125;).build(); &#125; @Bean public Step stepDemo3() &#123; return stepBuilderFactory.get("stepDemo3") .tasklet(new Tasklet() &#123; @Override public RepeatStatus execute(StepContribution stepContribution, ChunkContext chunkContext) throws Exception &#123; System.out.println(" stepDemo 3"); return RepeatStatus.FINISHED; &#125; &#125;).build(); &#125; @Bean public Step stepDemo2() &#123; return stepBuilderFactory.get("stepDemo2") .tasklet(new Tasklet() &#123; @Override public RepeatStatus execute(StepContribution stepContribution, ChunkContext chunkContext) throws Exception &#123; System.out.println(" stepDemo 2"); return RepeatStatus.FINISHED; &#125; &#125;).build(); &#125; @Bean public Step stepDemo1() &#123; return stepBuilderFactory.get("stepDemo1") .tasklet(new Tasklet() &#123; @Override public RepeatStatus execute(StepContribution stepContribution, ChunkContext chunkContext) throws Exception &#123; System.out.println(" stepDemo 1"); return RepeatStatus.FINISHED; &#125; &#125;).build(); &#125;&#125;]]></content>
      <categories>
        <category>spring-batch</category>
      </categories>
      <tags>
        <tag>SpringBatch</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring Batch 学习（1） 简单示例]]></title>
    <url>%2Fspring-batch%2Fspring-batch-study-1.html</url>
    <content type="text"><![CDATA[Spring Batch – 一个基于 Spring 架构的批处理框架什么是批处理在现代企业应用当中，面对复杂的业务以及海量的数据，除了通过庞杂的人机交互界面进行各种处理外，还有一类工作，不需要人工干预，只需要定期读入大批量数据，然后完成相应业务处理并进行归档。这类工作即为“批处理”。如：银行、移动、电信等公司需要每个月的月底统一处理用户的剩余金额、流量、话费等，这是一个很大的工程。如果全部使用人工操作的话，可能几个月都统计不了，这时就需要一套已经制定好规则的处理方案，按照制定好的方案，程序进行自动处理。 从上面的描述可以看出，批处理应用有如下几个特点： 数据量大，少则百万，多则上亿的数量级。 不需要人工干预，由系统根据配置自动完成。 与时间相关，如每天执行一次或每月执行一次。 同时，批处理应用又明显分为三个环节： 读数据，数据可能来自文件、数据库或消息队列等 数据处理，如电信支撑系统的计费处理 写数据，将输出结果写入文件、数据库或消息队列等 因此，从系统架构上，应重点考虑批处理应用的事务粒度、日志监控、执行、资源管理（尤其存在并发的情况下）。从系统设计上，应重点考虑数据读写与业务处理的解耦，提高复用性以及可测试性。 SpringBatch 的业务场景 周期性的提交批处理 把一个任务并行处理 消息驱动应用分级处理 大规模并行批处理 手工或调度使用任务失败之后重新启动 有依赖步骤的顺序执行（使用工作流驱动扩展） 处理时跳过部分记录（错误记录或不需要处理的记录） 成批事务：为小批量的或有的存储过程/脚本的场景使用 SpringBatch 集成操作### Spring 官方推荐使用 SpringBoot 作为 SpringBatch 的容器框架。SpringBoot 作为 Spring 官方提供的一款轻量级的 Spring 全家桶整合框架，基于 习惯优于配置 的特点，有以下几个重点特征: 基本没有或极少的配置即可启动 Spring 容器 创建独立的Spring应用程序 嵌入的Tomcat，无需部署WAR文件 简化Maven配置 自动配置Spring 提供生产就绪型功能，如指标，健康检查和外部配置 绝对没有代码生成并且对XML也没有配置要求 SpringBoot 集成 SpringBatch 简单实例（使用 IDEA）创建一个 SpringBoot 项目File –&gt; new –&gt; project –&gt; Spring Initialzer 填写 groupId、artifactId 选择需要的依赖（由于是简单实例，所以只需要 batch 的依赖即可) 完整 pom.xml 文件1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;com.laiyy&lt;/groupId&gt; &lt;artifactId&gt;batch&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;packaging&gt;jar&lt;/packaging&gt; &lt;name&gt;batch&lt;/name&gt; &lt;description&gt;Demo project for Spring Boot&lt;/description&gt; &lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.1.0.RELEASE&lt;/version&gt; &lt;relativePath/&gt; &lt;!-- lookup parent from repository --&gt; &lt;/parent&gt; &lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;project.reporting.outputEncoding&gt;UTF-8&lt;/project.reporting.outputEncoding&gt; &lt;java.version&gt;1.8&lt;/java.version&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-batch&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.batch&lt;/groupId&gt; &lt;artifactId&gt;spring-batch-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt;&lt;/project&gt; 开始第一个简单示例demo 示例编码步骤 引入 JobBuilderFactory、StepBuilderFactory，用于创建任务、任务执行的步骤 使用 JobBuilderFactory 创建一个任务 使用 StepBuilderFactory 创建这个任务要执行的步骤 启动项目，查看运行结果 需要注意的地方： 将所有操作在一个类中完成，便于理解代码 需要在这个类上加入 @Configuration、@EnableBatchProcessing 注解 直接启动主进程即可在控制台查看到运行结果 注解 @Configuration 等价于在 spring-context.xml 中声明一个 &lt;bean&gt; 节点注解 @EnableBatchProcessing 用于告诉 Spring 容易自动装配 SpringBatch 相关默认配置 具体代码：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849/** * @author laiyy * @date 2018/11/15 16:49 * @description */@EnableBatchProcessing@Configurationpublic class ChildJob1 &#123; private final JobBuilderFactory jobBuilderFactory; private final StepBuilderFactory stepBuilderFactory; @Autowired public ChildJob1(StepBuilderFactory stepBuilderFactory, JobBuilderFactory jobBuilderFactory) &#123; this.stepBuilderFactory = stepBuilderFactory; this.jobBuilderFactory = jobBuilderFactory; &#125; @Bean public Job childJobOne()&#123; // 创建一个名为 childJobOne 的任务 return jobBuilderFactory.get("childJobOne") // 启动 childJobStep1 步骤 .start(childJobStep1()) // 开始构建 Job .build(); &#125; @Bean public Step childJobStep1() &#123; // 创建一个名为 childJobStep1 的步骤 return stepBuilderFactory.get("childJobStep1") // 示例没有逻辑处理，只做一个简单的演示输出，使用 Tasklet 匿名内部类即可 .tasklet(new Tasklet() &#123; @Override public RepeatStatus execute(StepContribution stepContribution, ChunkContext chunkContext) throws Exception &#123; // 如果控制台打印了这条信息，则证明 SpringBatch 运行成功 System.out.println("childJobStep1"); // 此处有两个值：FINISHED 步骤结束，CONTINUABLE 步骤继续执行 return RepeatStatus.FINISHED; &#125; // 构建 Step &#125;).build(); &#125;&#125; 验证运行结果启用 Application 主进程，查看控制台，发现报错如下：12345678910111213141516171819Error starting ApplicationContext. To display the conditions report re-run your application with &apos;debug&apos; enabled.2018-11-28 22:48:24.326 ERROR 9226 --- [ main] o.s.b.d.LoggingFailureAnalysisReporter : ***************************APPLICATION FAILED TO START***************************Description:Failed to configure a DataSource: &apos;url&apos; attribute is not specified and no embedded datasource could be configured.Reason: Failed to determine a suitable driver classAction:Consider the following: If you want an embedded database (H2, HSQL or Derby), please put it on the classpath. If you have database settings to be loaded from a particular profile you may need to activate it (no profiles are currently active). 错误原因：SpringBatch 运行任务、Step 的时候，会进行持久化（可能是内存中、或者是数据库中，默认是数据库），所以再次我们需要引入一个数据库。作为一个 示例程序，引入内存级数据库 h2 即可 需要在 pom.xml 中加入如下配置：12345&lt;dependency&gt; &lt;groupId&gt;com.h2database&lt;/groupId&gt; &lt;artifactId&gt;h2&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt;&lt;/dependency&gt; 再次启动项目，查看控制台，可以看到控制台打印信息如下12345678910111213 . ____ _ __ _ _ /\\ / ___&apos;_ __ _ _(_)_ __ __ _ \ \ \ \( ( )\___ | &apos;_ | &apos;_| | &apos;_ \/ _` | \ \ \ \ \\/ ___)| |_)| | | | | || (_| | ) ) ) ) &apos; |____| .__|_| |_|_| |_\__, | / / / / =========|_|==============|___/=/_/_/_/ :: Spring Boot :: (v2.1.0.RELEASE)...childJobStep1... 此时可以看到，我们在 Tasklet 中输出的字符串成功打印在了控制台中，证明 SpringBatch 的简单示例启动、验证成功。]]></content>
      <categories>
        <category>spring-batch</category>
      </categories>
      <tags>
        <tag>SpringBatch</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用 Python Requests 爬取并下载小说 以 耳根 的小说 《一念永恒》 为例]]></title>
    <url>%2Fpython%2Fpython-download-novel.html</url>
    <content type="text"><![CDATA[使用 Python Requests 爬取 笔趣看 小说网站 使用工具： Python 3.6 + Requests 2.20 + 需要爬取的小说主站地址： http://www.biqukan.com/1_1094 页面分析1. 分析列表页面布局使用浏览器审查元素，查找章节列表所在位置的 dom、class、id 等属性，可以看到所有的章节列表都在一个 class 为 “listmain” 的 div 中包含着，由此可以得出结论，该 div 即是我们需要定位的章节列表所在位置。 2、分析章节名称、链接、第一章起始位置根据列表布局，可以看到，每个章节的章节名称、链接，都在 a 标签中，而小说的第一章，是在第 16 个 a 标签中。分析章节链接、名称、第一章起始位置 3、分析章节内容页进入第一章节，利用浏览器审查元素，可以看到文章的内容都在一个 id 为 content，class 为 showtxt 的 div 中，由此我们可以获取到章节内容 代码实例创建下载类，声明存放章节名称、章节链接、章节数的数组12345678910class download(object): def __init__(self): self.server = 'https://www.biqukan.com' self.target = self.server + '/1_1094' # 存放章节名称 self.names = [] # 存放章节链接 self.urls = [] # 存放章节数 self.nums = 0 在下载类中新建获取章节列表的方法12345678910111213141516171819202122# 获取下载链接def get_download_url(self): # verify 绕过 https，self.target 即为：https://www.biqukan.com/1_1094 req = requests.get(url=self.target, verify=False) # 获取请求到的文本内容 html = req.text # 将文本内容转为流 div_bf = BeautifulSoup(html) # 获取所有 class 为 listmain 的 div div = div_bf.find_all('div', class_='listmain') # 取第一个 div 转为流 a_bf = BeautifulSoup(str(div[0])) # 获取所有 a 标签 a = a_bf.find_all('a') # 由第二步得知，第一章节为第 16 个 a 标签，所以去除不必要的前 15 个章节 self.nums = len(a[15:]) # 转换 a 标签内容 for href in a[15:]: # 获取 a 标签中的文本，放入章节名称数组 self.names.append(href.string) # 获取 a 标签中的列表，放入章节链接数组（由于链接没有域名，需要拼接域名） self.urls.append(self.server + href.get('href')) 获取章节内容1234567891011121314# 获取章节内容，target 为章节内容链接def get_content(self, target): # verify 绕过 https req = requests.get(url=target, verify=False) # 获取请求到的内容 html = req.text bf = BeautifulSoup(html) # 获取 class 为 showtxt 的 div 的内容（即小说章节内容） texts = bf.find_all('div', class_='showtxt') # 将 &amp;nbsp; 转换为空字符串 texts = texts[0].text.replace('\xa0' * 8, '') # 压缩一下，把两个换行转换为一个换行 texts = texts.replace('\n\n','\n') return texts 将内容写入到 txt 文件中1234567891011""" name：文章名称 path：文章保存路径 text：文章内容"""def write(self, name, path, text): write_flag = True with open(path, 'a', encoding='utf-8') as f: f.write(name + '\n') f.writelines(text) f.write('\n') 开始下载1234567891011121314151617181920if __name__ == '__main__': """ 压制由于忽略 HTTPS，导致的运行时警告 from requests.packages.urllib3.exceptions import InsecureRequestWarning requests.packages.urllib3.disable_warnings(InsecureRequestWarning) """ from requests.packages.urllib3.exceptions import InsecureRequestWarning requests.packages.urllib3.disable_warnings(InsecureRequestWarning) dl = download() dl.get_download_url() print('开始下载') for i in range(dl.nums): dl.write(dl.names[i], '一念永恒.txt', dl.get_content(dl.urls[i])) # 计算下载百分比 sys.stdout.write('正在下载 %s，已下载：%.3f%% \r' % (dl.names[i], float(i / dl.nums))) # 刷新打印消息 sys.stdout.flush() print('下载完成')]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[常用 IDEA 插件]]></title>
    <url>%2Fjava%2Fidea-plugins.html</url>
    <content type="text"><![CDATA[RestfulToolkit在之前定位方法、Controoler 时，使用 Ctrl + Shift + F 查找只能输入方法上面的 @RequestMapping 的 value 路径，而且如果有多个相同的方法时，或者代码里面有对应的单词时，会全部匹配出来。如：查找 UserController 的 add 方法，如果在搜索框输入 add 查找的话，可能会查找出很多信息，不便于定位。使用这个插件，可以使用 ctrl + \，在弹出的搜索框输入 /user/add 直接定位到 Controoler 的 add 方法 lombok使用 lombok 注解，省略 get、set、toString、equals 等 String Manipulation转换字符串。快捷键：Alt + M material theme ui修改 idea 默认 UI Grep Console定义控制台打印日志格式、颜色 Alibaba java Coding Guidelinesalibaba 代码规约扫描器 .ignore快速生成、定义 ignore 文件 Rainbow Brackets修改括号颜色，便于定位同域内容 GsonFormat直接把 JSON 生成实体类。快捷键： Alt + S]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>IdeaPlugins</tag>
      </tags>
  </entry>
</search>
